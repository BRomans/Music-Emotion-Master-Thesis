\chapter{Conclusions and recommendations}
\label{chap:conclusions}
The goal of the experiment setup for this research was to answer the main research question: \emph{“What are the performances of classification of music-elicited emotional valence and arousal using a wearable EEG headset?”} and the two sub-research questions that extended it. This research set out to investigate the feasibility of performing \ac{ER} using a wearable interface in the form of a classification task. Data were collected using a robust protocol in two different conditions. They were then processed using a lightweight automated preprocessing pipeline and two types of features were extracted: neuromarkers and frequency-band specific spectral features calculated in the Theta, Alpha and Beta bands of the \ac{EEG} signal. Features dimensionality was reduced using \ac{PCA} and the classification task was performed with subject-dependent strategy. The problem was simplified into two separate binary classifications for valence and arousal, and two algorithms were tested: \ac{SVM} and \ac{MLP}. The hyper-parameters were tuned using GridSearch to select the configuration that yielded the highest \ac{MCC} score. All models were then trained and tested using 5-fold \ac{LOBO} cross-validation that produced two cross-validated scores: \ac{CV} accuracy and \ac{CV MCC}. Then, models were further tested on a completely unseen split of data that produced two more scores: test accuracy and \ac{MCC}. Each question is answered separately in the following section and then some recommendations for future work are proposed in the last section.
\section{Conclusions}
\label{sec:conclusions}
\emph{“What are the performances of classification of music-elicited emotional valence and arousal using a wearable EEG headset?”. }

For arousal classification, \ac{SVM} scored higher average test accuracy of 0.63 ± 0.09 and higher average \ac{MCC} score of 0.18 ± 0.2 compared to \ac{MLP} that scored average test accuracy of 0.59 ± 0.09 and average \ac{MCC} score of 0.15 ± 0.17. Cross-validated scores are consistent, with \ac{SVM} scoring higher average CV accuracy of 0.61 ± 0.06 and higher \ac{CV MCC} of 0.24 ± 0. 13, while \ac{MLP} scored average CV accuracy of 0.57 ± 0.07 and average \ac{CV MCC} of 0.15 ± 0.15. The highest consistent \ac{MCC} score for \ac{SVM} was 0.61 with a \ac{CV MCC} of 0.57, the highest consistent \ac{MCC} score for \ac{MLP} was also 0.61 with a \ac{CV} \ac{MCC} of 0.31. For valence classification, \ac{SVM} scored average test accuracy of 0.65 ± 0.12 and similarly \ac{MLP} scored average test accuracy of 0.65 ± 0.11. \ac{MLP} obtained higher average \ac{MCC} of 0.13 ± 0.15 against \ac{SVM} that scored average \ac{MCC} of 0.10 ± 0.19, however \ac{SVM} obtained higher CV accuracy of 0.61 ± 0.07 and higher \ac{CV} \ac{MCC} of 0.26 ± 0.15 against 0.57 ± 0.08 and 0.15 ± 0.16 respectively for \ac{MLP}. Overall, \ac{SVM} yielded more consistency between test and cross-validated scores. In addition, more under-fitted or over-fitted models were generated using \ac{MLP}, with a total of 6 negative \ac{CV MCC} scores in arousal classification against 0 obtained using \ac{SVM}, and a total of 5 negative \ac{CV MCC} scores in valence classification against 1 obtained using \ac{SVM}.
\\
\\
\emph{“What are the most relevant features to perform the Emotion-Recognition task using Power Spectral Density of the EEG signal?”.}

The presented results were obtained after compressing the features using PCA and the contribution of the individual features to the components was not measured. Neuromarkers and frequency band-specific spectral features showed encouraging results, but also great variability among subjects that requires more study on the causes and possible solutions. No neuromarker or subset of features could be proved to be relevant towards subject-independent classification.
\\
\\
\emph{“What is the most suitable classification strategy using a wearable EEG headset?.”}

For this research it was possible to obtain subjective appreciable results using a subject-dependent strategy. Subject-independent classification was discarded during intermediate experiments due to inability of the model to perform better than default guessing the majority class. Thus, subject-dependent classification strategy is for the moment the most suitable using the current wearable technology. Further investigation using more sophisticated signal processing techniques and approaches to deal with unbalanced datasets might lead to more consistent results and enable the development of better strategies that can be applied in an online system with minimal training and calibration time.



\section{Recommendations}
\label{sec:recommendations}
The analytical study of emotions is heavily impacted by subjective differences, and the current state of art technology and signal processing techniques still struggle to provide the desired performances to build seamless affective \ac{BCI} systems. Many critical factors starting from the data collection phase to the classification task can hinder the expected outcome. Considering the interest in a follow-up study, the factors that affected the current study are addressed in the paragraphs below. 
\\
\\
\emph{Selection of the stimuli.} The selection of the stimuli is critical for the success for affective experiments, as there is nothing worse than selecting ineffective stimuli. Music is usually a favorable stimulus, since only a few do not react at all to it. Even so, subjective preferences can highly impact the perception of the same song in a population of participants. This study conveniently “recycled” a selection of songs previously used in other experiments and proposed the same playlist to all participants for the sake of inter-subject comparison. This choice led the participants to a constrained experience, that for some resulted in listening to music genres they usually would not listen to. In addition, the annotation experience suffered of great variability, leading some subjects to never report some one or more valence-arousal classes. There are alternative solutions for the stimuli selection, as some related studies experimented \cite{thammasan_continuous_2016}. For example, the researcher can ask the subjects to pick music from a selection that covers the emotional spectrum during a pre-listening phase. A better compromise could be a hybrid selection: part of the stimuli selected by the researchers and the other part selected by the participants. Adapting the selection to account for the subjective preferences is very time consuming in the design of an experiment, but it is also what real users of an affective recommending system would expect.
\\
\\
\emph{Self-assessment of emotions.} As several participants reported, it was not always simple to assess in real-time perceived emotions, with the consequence of unreliable annotations. On one hand, knowing exactly what feelings are being experienced requires considerable self-perception. On the other hand, models for assessing emotions have limitations. As mentioned earlier (see Chapter \ref{sec:self_reported} ), the \ac{VA} space used in the experiment was simplified to make it more understandable, sacrificing the representation of some emotional states. Using a more complete representation does not automatically improve the participants ability to report emotions, on the contrary it is likely to introduce more confusion. Other studies \cite{lin_eeg-based_2010} adopted an even more simplified version that only associates one emotion to each quadrant of the ac{VA} space, that maybe partially explains the significantly better performances in classification. Continuous emotion annotations require more effort but are very valuable to capture emotion oscillations and provide classifiers with more realistic emotional distribution. Once the models for the classification of emotion will have reached maturity, continuous annotations will be discarded in favor of discrete reports, that better suit a real product. The solutions for Emotion-Recognition cannot possibly start from a complex representation of emotional states, thus building up from more simplified models might be a better strategy now to support the ongoing development of the field and then later scale up the complexity with more sophisticated tools.
\\
\\
\emph{Experimental sessions.} Two main observations were made based on the feedback received and the analysis of data. First one, a single session of 75-90 minutes (30-35 of \ac{EEG} recording) can be fatiguing for most people. Decreased attention and discomfort are not favorable conditions for recording brain activity and are likely to be reflected also on the emotional assessment. Second one, a single session does not ensure that classification performances are consistent for the same subject over time. External factors experienced prior to the session might bias the emotional perception of a subject, for example if there as a breakup with a loved one or if very good news brightened the day. In addition, the oscillatory nature of brain waves is known to generate differences in the \ac{EEG} signature of the same person over time. Multiple shorter session can prevent fatigue by reducing the overall mental load, and at the same time mitigate the effect of variations over time in the emotional assessment and in the \ac{EEG}.  
Automated lightweight preprocessing. The requirements for a preprocessing pipeline in an online system are not easy to meet. Computational time needs to be in the order of seconds or even better milliseconds; at the same time the quality of data must be ensured to prevent poor classification performances. Ocular artifacts are the greatest threat in the analysis of emotions because of the topological position near the frontal lobe, where emotions are processed. Using \ac{EOG} to subtract eye movements from the EEG signal is effective for offline studies but is clearly not suitable for a product. Methods like \ac{ICA} and \ac{PCA} are very effective for \ac{EEG} recordings using standard equipment with many electrodes, but nevertheless computationally expensive. For a final product using wearable devices with limited capabilities, inferring the presence of artifacts by classifying \ac{EEG} based on the signal qualities \cite{grosselin_quality_2019} can be achieved with low computational effort and enable surgical precision in the cleaning process. \ac{ASR} has been proven effective in artifact removal for both offline data analysis and online applications \cite{chang_evaluation_2018}, but for optimal outcome, i.e. removing artifacts and retaining the significance of the signal, it requires to be tuned using good quality \ac{EEG} samples. Investigating the best combination of approaches for lightweight processing can be a suitable research question also outside the specific scope of affective \ac{BCI}.
\\
\\
\emph{Features extraction and selection.} Selecting the right features has proved to be non-trivial and affected by subject-dependent differences. The extraction process also carries a computation cost, thus just extracting any possible feature and then apply subjective selection criteria is not feasible. The current study used \ac{PCA} to collapse the features in the minimum number of components that could account for subjective differences and retain at least 95\% of the variability of the data. The neuromarkers are a step towards the delineation of an optimal subset of features for emotional assessment but require more investigation both from neuroscience and data science perspectives to determine which combination of differential/rational measurements and EEG frequency bands are more relevant for the study of emotions. The identification of more subject-independent features, like the asymmetry indexes \cite{lin_toward_2015}, is also essential towards the development of affective \ac{BCI} systems and can be the main topic of a dedicated research. The possibility to use other physiological signals to build a multi-modal classification system has also been explored, and physiological signals were collected during this research for eventual follow up studies. A related study already assessed the increased performances that can be obtained by decision-level multi-modal fusion \cite{thammasan_multimodal_2017}, an adaptive approach to select by majority voting the optimal uni-modal sources among several physiological measurements (\ac{EEG}, \ac{ECG}, \ac{GSR}) for classification. Any system designed on other physiological data than \ac{EEG} is, however, outside the strict scope of affective \ac{BCI}.
\\
\\
\emph{Unbalanced datasets.} One of the main obstacles in training and evaluating classification models was the uneven distribution of labels. Multiple experimental sessions and subjective stimuli selection can minimize the possibility of having very unbalanced datasets, as explained in the previous paragraph. However, it would still be possible to hit the same obstacle, regardless the minimization. In the field of machine learning there are standard methods to deal with unbalanced methods. Assigning weights to the classes to penalize the prediction of the majority class is one of such methods, used in the current study with little success. Up-sampling of the minority class is another method that creates copies of labels and data in the training dataset to reduce the bias of the classifier. However, copying affective data does not seem optimal as it would simply repeat the same emotional pattern and will not likely cover the entire emotional spectrum of the minority class. Some studies investigated the possibility of simulating realistic \ac{EEG} data \cite{barzegaran_eegsourcesim_2019} from biologically plausible signals. Good affective \ac{EEG} data from multiple subjects could be collected for the realization of a plausible \ac{EEG}  simulator that can account for individual variability. The data generator could then be calibrated over a small sample of real \ac{EEG}  data from a real subject and be used to counterbalance the distribution of emotional classes, thus improving the classification performances.
\\
\\
This research on affective \ac{BCI} offers various insights and possibilities for further exploring the field of affective computing. In the time assigned to the project it was only possible to scratch the surface, but hopefully an interesting and actual overview of the state-of-art methods, devices, and strategies was provided. Researchers and designers interested in building the affective technologies of tomorrow are invited to take part in this challenging and exciting world, and share their ideas, insights and solutions with the passionate community that is growing around Brain-Computer Interfaces.
