
@article{barzegaran_eegsourcesim_2019,
	title = {{EEGSourceSim}: {A} framework for realistic simulation of {EEG} scalp data using {MRI}-based forward models and biologically plausible signals and noise},
	volume = {328},
	issn = {1872-678X},
	shorttitle = {{EEGSourceSim}},
	doi = {10.1016/j.jneumeth.2019.108377},
	abstract = {BACKGROUND: Electroencephalography (EEG) is widely used to investigate human brain function. Simulation studies are essential for assessing the validity of EEG analysis methods and the interpretability of results.
NEW METHOD: Here we present a simulation environment for generating EEG data by embedding biologically plausible signal and noise into MRI-based forward models that incorporate individual-subject variability in structure and function.
RESULTS: The package includes pipelines for the evaluation and validation of EEG analysis tools for source estimation, functional connectivity, and spatial filtering. EEG dynamics can be simulated using realistic noise and signal models with user specifiable signal-to-noise ratio (SNR). We also provide a set of quantitative metrics tailored to source estimation, connectivity and spatial filtering applications.
COMPARISON WITH EXISTING METHOD(S): We provide a larger set of forward solutions for individual MRI-based head models than has been available previously. These head models are surface-based and include two sets of regions-of-interest (ROIs) that have been brought into registration with the brain of each individual using surface-based alignment - one from a whole brain and the other from a visual cortex atlas. We derive a realistic model of noise by fitting different model components to measured resting state EEG. We also provide a set of quantitative metrics for evaluating source-localization, functional connectivity and spatial filtering methods.
CONCLUSIONS: The inclusion of a larger number of individual head-models, combined with surface-atlas based labeling of ROIs and plausible models of signal and noise, allows for simulation of EEG data with greater realism than previous packages.},
	language = {eng},
	journal = {Journal of Neuroscience Methods},
	author = {Barzegaran, Elham and Bosse, Sebastian and Kohler, Peter J. and Norcia, Anthony M.},
	month = dec,
	year = {2019},
	pmcid = {PMC6815881},
	note = {54 PMID: 31381946},
	keywords = {Adult, Atlases as Topic, Brain, Computer Simulation, Connectome, EEG simulation, Electroencephalography, Forward model, Functional connectivity, Humans, Inverse model, Magnetic Resonance Imaging, Models, Theoretical, Regions of interest, Scalp, Spatial filtering},
	pages = {108377},
}

@article{chang_evaluation_2018,
	title = {Evaluation of {Artifact} {Subspace} {Reconstruction} for {Automatic} {EEG} {Artifact} {Removal}},
	volume = {2018},
	issn = {2694-0604},
	doi = {10.1109/EMBC.2018.8512547},
	abstract = {One of the greatest challenges that hinder the decoding and application of electroencephalography (EEG) is that EEG recordings almost always contain artifacts - non-brain signals. Among existing automatic artifact-removal methods, artifact subspace reconstruction (ASR) is an online and realtime capable, component-based method that can effectively remove transient or large-amplitude artifacts. However, the effectiveness of ASR and the optimal choice of its parameter have not been evaluated and reported, especially on real EEG data. This study systematically validates ASR on ten EEG recordings in a simulated driving experiment. Independent component analysis (ICA) is applied to separate artifacts from brain signals to allow a quantitative assessment of ASR's effectiveness in removing various types of artifacts and preserving brain activities. Empirical results show that the optimal ASR parameter is between 10 and 100, which is small enough to remove activities from artifacts and eye-related components and large enough to retain signals from brain-related components. With the appropriate choice of the parameter, ASR can be a powerful and automatic artifact removal approach for offline data analysis or online real-time EEG applications such as clinical monitoring and brain-computer interfaces.},
	language = {eng},
	journal = {Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference},
	author = {Chang, Chi-Yuan and Hsu, Sheng-Hsiou and Pion-Tonachini, Luca and Jung, Tzyy-Ping},
	month = jul,
	year = {2018},
	note = {53 PMID: 30440615},
	keywords = {Algorithms, Artifacts, Brain, Brain-Computer Interfaces, Electroencephalography, Humans, Signal Processing, Computer-Assisted},
	pages = {1242--1245},
}

@article{krauledat_towards_2008,
	title = {Towards zero training for brain-computer interfacing},
	volume = {3},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0002967},
	abstract = {Electroencephalogram (EEG) signals are highly subject-specific and vary considerably even between recording sessions of the same user within the same experimental paradigm. This challenges a stable operation of Brain-Computer Interface (BCI) systems. The classical approach is to train users by neurofeedback to produce fixed stereotypical patterns of brain activity. In the machine learning approach, a widely adapted method for dealing with those variances is to record a so called calibration measurement on the beginning of each session in order to optimize spatial filters and classifiers specifically for each subject and each day. This adaptation of the system to the individual brain signature of each user relieves from the need of extensive user training. In this paper we suggest a new method that overcomes the requirement of these time-consuming calibration recordings for long-term BCI users. The method takes advantage of knowledge collected in previous sessions: By a novel technique, prototypical spatial filters are determined which have better generalization properties compared to single-session filters. In particular, they can be used in follow-up sessions without the need to recalibrate the system. This way the calibration periods can be dramatically shortened or even completely omitted for these 'experienced' BCI users. The feasibility of our novel approach is demonstrated with a series of online BCI experiments. Although performed without any calibration measurement at all, no loss of classification performance was observed.},
	language = {eng},
	number = {8},
	journal = {PloS One},
	author = {Krauledat, Matthias and Tangermann, Michael and Blankertz, Benjamin and Müller, Klaus-Robert},
	month = aug,
	year = {2008},
	pmcid = {PMC2500157},
	note = {51 PMID: 18698427},
	keywords = {Artificial Intelligence, Brain, Brain Mapping, Cortical Synchronization, Electroencephalography, Evoked Potentials, Humans, Learning, Neurophysiology, Pattern Recognition, Automated, User-Computer Interface, Wakefulness},
	pages = {e2967},
}

@inproceedings{jeong_hybrid_2021,
	title = {Hybrid {Zero}-{Training} {BCI} based on {Convolutional} {Neural} {Network} for {Lower}-limb {Motor}-{Imagery}},
	doi = {10.1109/BCI51272.2021.9385316},
	abstract = {Zero-training BCI was presented to overcome the inconvenience and impractical aspects of the training session in the Brain-Computer Interface (BCI) based on Motor Imagery (MI). Zero-training BCI can be classified into a session-to-session transfer BCI and a subject-independent BCI. The session-to-session transfer BCI is characterized by high classification accuracy, but there is a limitation that the model could not be improved as the number of subjects increased. On the other hand, the subject-independent BCI has advantage in increasing the number of subjects, but had the problem of requiring too many subjects for high accuracy. In this study, we proposed the hybrid zero-training BCI that integrates the advantages of the aforementioned two methods and Multidomain CNN that combined time-, spatial-, and phase-domain, and aimed for more practical application and higher classification accuracy. We collected three-class MI EEG data related to lower-limb movement (gait, sit-down, and rest) from three subjects with three sessions per subject. The classification accuracy of the proposed method (82.10 ±10.66\%) in the classification of three-class of MI tasks was significantly higher than that of the existing zero-training BCIs (66.42 ±9.68\%, 66.67±6.83\%) I, and also higher than the conventional BCI (70.86±9.46\%) that trains and evaluates with training sessions collected on the same day although not statistically significant.},
	booktitle = {2021 9th {International} {Winter} {Conference} on {Brain}-{Computer} {Interface} ({BCI})},
	author = {Jeong, Ji Hyeok and Kim, Dong-Joo and Kim, Hyungmin},
	month = feb,
	year = {2021},
	note = {52 ISSN: 2572-7672},
	keywords = {Biological neural networks, Brain modeling, Brain-Computer interface, Brain-computer interfaces, Convolutional neural network, Convolutional neural networks, EEG, Electroencephalography, Motor imagery, Task analysis, Training, Zero-training},
	pages = {1--4},
}

@article{avramidis_multiscale_2021,
	title = {Multiscale {Fractal} {Analysis} on {EEG} {Signals} for {Music}-{Induced} {Emotion} {Recognition}},
	url = {http://arxiv.org/abs/2010.16310},
	abstract = {Emotion Recognition from EEG signals has long been researched as it can assist numerous medical and rehabilitative applications. However, their complex and noisy structure has proven to be a serious barrier for traditional modeling methods. In this paper, we employ multifractal analysis to examine the behavior of EEG signals in terms of presence of fluctuations and the degree of fragmentation along their major frequency bands, for the task of emotion recognition. In order to extract emotion-related features we utilize two novel algorithms for EEG analysis, based on Multiscale Fractal Dimension and Multifractal Detrended Fluctuation Analysis. The proposed feature extraction methods perform efficiently, surpassing some widely used baseline features on the competitive DEAP dataset, indicating that multifractal analysis could serve as basis for the development of robust models for affective state recognition.},
	urldate = {2021-03-17},
	journal = {arXiv:2010.16310 [cs]},
	author = {Avramidis, Kleanthis and Zlatintsi, Athanasia and Garoufis, Christos and Maragos, Petros},
	month = mar,
	year = {2021},
	note = {50 arXiv: 2010.16310},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning},
}

@misc{noauthor_please_nodate,
	title = {Please {Support} {Customize} {Loss} {Function} in {SGDClassifier}/{Regressor} · {Issue} \#1701 · scikit-learn/scikit-learn},
	url = {https://github.com/scikit-learn/scikit-learn/issues/1701},
	abstract = {Hi, I want to try on some customize loss function in my data, and find the SGDClassifier and SGDRegressor in sklearn. It\&\#39;s definitely a good framework to try my own loss function. I dig into th...},
	language = {en},
	urldate = {2021-12-02},
	journal = {GitHub},
	note = {49},
}

@incollection{lin_toward_2015,
	title = {Toward {Affective} {Brain}-{Computer} {Interface}: {Fundamentals} and {Analysis} of {EEG}-{Based} {Emotion} {Classification}},
	isbn = {978-1-118-13066-7},
	shorttitle = {Toward {Affective} {Brain}-{Computer} {Interface}},
	abstract = {Emotion classification from non-invasively measured electroencephalographic (EEG) data has been a growing research topic because of its potential application to affective brain–computer interfaces (ABCI), such as brain-inspired multimedia interaction and clinical assessment. This chapter explores principles for translating neuroscientific findings into a practical ABCI. It covers not only an overview of state-of-the-art EEG-based emotion recognition techniques, but also the basic research exploring neurophysiological EEG dynamics associated with affective responses. The chapter aims at resolving EEG feature selection and electrode reduction issues by the generalization of subject-independent feature/electrode set extraction techniques that we have proposed in our series of emotion classification studies. It addresses several practical issues and potential challenges for ABCIs as well. The authors believe a user-friendly EEG cap with a small number of electrodes can efficiently detect affective states, and therefore significantly promote practical ABCI applications in daily life.},
	author = {Lin, Yuan-Pin and Jung, Tzyy-Ping and Onton, Julie},
	month = jan,
	year = {2015},
	note = {48 DOI: 10.1002/9781118910566.ch13},
	pages = {315--341},
}

@misc{martin_stacked_nodate,
	title = {Stacked {Turtles}},
	url = {https://kiwidamien.github.io},
	abstract = {View the blog.},
	language = {en},
	urldate = {2021-12-02},
	journal = {Stacked Turtles},
	author = {Martin, Damien},
	note = {47},
}

@article{chicco_advantages_2020,
	title = {The advantages of the {Matthews} correlation coefficient ({MCC}) over {F1} score and accuracy in binary classification evaluation},
	volume = {21},
	issn = {1471-2164},
	doi = {10.1186/s12864-019-6413-7},
	abstract = {BACKGROUND: To evaluate binary classifications and their confusion matrices, scientific researchers can employ several statistical rates, accordingly to the goal of the experiment they are investigating. Despite being a crucial issue in machine learning, no widespread consensus has been reached on a unified elective chosen measure yet. Accuracy and F1 score computed on confusion matrices have been (and still are) among the most popular adopted metrics in binary classification tasks. However, these statistical measures can dangerously show overoptimistic inflated results, especially on imbalanced datasets.
RESULTS: The Matthews correlation coefficient (MCC), instead, is a more reliable statistical rate which produces a high score only if the prediction obtained good results in all of the four confusion matrix categories (true positives, false negatives, true negatives, and false positives), proportionally both to the size of positive elements and the size of negative elements in the dataset.
CONCLUSIONS: In this article, we show how MCC produces a more informative and truthful score in evaluating binary classifications than accuracy and F1 score, by first explaining the mathematical properties, and then the asset of MCC in six synthetic use cases and in a real genomics scenario. We believe that the Matthews correlation coefficient should be preferred to accuracy and F1 score in evaluating binary classification tasks by all scientific communities.},
	language = {eng},
	number = {1},
	journal = {BMC genomics},
	author = {Chicco, Davide and Jurman, Giuseppe},
	month = jan,
	year = {2020},
	pmcid = {PMC6941312},
	note = {46 PMID: 31898477},
	keywords = {Accuracy, Algorithms, Binary classification, Biostatistics, Computational Biology, Confusion matrices, Correlation of Data, Data Interpretation, Statistical, Dataset imbalance, F1 score, Genomics, Machine Learning, Machine learning, Matthews correlation coefficient},
	pages = {6},
}

@article{matthews_comparison_1975,
	title = {Comparison of the predicted and observed secondary structure of {T4} phage lysozyme},
	volume = {405},
	issn = {0006-3002},
	doi = {10.1016/0005-2795(75)90109-9},
	abstract = {Predictions of the secondary structure of T4 phage lysozyme, made by a number of investigators on the basis of the amino acid sequence, are compared with the structure of the protein determined experimentally by X-ray crystallography. Within the amino terminal half of the molecule the locations of helices predicted by a number of methods agree moderately well with the observed structure, however within the carboxyl half of the molecule the overall agreement is poor. For eleven different helix predictions, the coefficients giving the correlation between prediction and observation range from 0.14 to 0.42. The accuracy of the predictions for both beta-sheet regions and for turns are generally lower than for the helices, and in a number of instances the agreement between prediction and observation is no better than would be expected for a random selection of residues. The structural predictions for T4 phage lysozyme are much less successful than was the case for adenylate kinase (Schulz et al. (1974) Nature 250, 140-142). No one method of prediction is clearly superior to all others, and although empirical predictions based on larger numbers of known protein structure tend to be more accurate than those based on a limited sample, the improvement in accuracy is not dramatic, suggesting that the accuracy of current empirical predictive methods will not be substantially increased simply by the inclusion of more data from additional protein structure determinations.},
	language = {eng},
	number = {2},
	journal = {Biochimica Et Biophysica Acta},
	author = {Matthews, B. W.},
	month = oct,
	year = {1975},
	note = {45 PMID: 1180967},
	keywords = {Adenylate Kinase, Coliphages, DNA Viruses, Mathematics, Muramidase, Protein Conformation, X-Ray Diffraction},
	pages = {442--451},
}

@book{cohen_analyzing_2014,
	address = {Cambridge, Massachusetts},
	series = {Issues in clinical and cognitive neuropsychology},
	title = {Analyzing neural time series data: theory and practice},
	isbn = {978-0-262-01987-3},
	shorttitle = {Analyzing neural time series data},
	language = {en},
	publisher = {The MIT Press},
	author = {Cohen, Mike X.},
	year = {2014},
	note = {44},
	keywords = {Artificial intelligence, Biological applications, Computational neuroscience, Neural networks (Computer science), Neural networks (Neurobiology)},
}

@article{grosselin_quality_2019,
	title = {Quality {Assessment} of {Single}-{Channel} {EEG} for {Wearable} {Devices}},
	volume = {19},
	issn = {1424-8220},
	doi = {10.3390/s19030601},
	abstract = {The recent embedding of electroencephalographic (EEG) electrodes in wearable devices raises the problem of the quality of the data recorded in such uncontrolled environments. These recordings are often obtained with dry single-channel EEG devices, and may be contaminated by many sources of noise which can compromise the detection and characterization of the brain state studied. In this paper, we propose a classification-based approach to effectively quantify artefact contamination in EEG segments, and discriminate muscular artefacts. The performance of our method were assessed on different databases containing either artificially contaminated or real artefacts recorded with different type of sensors, including wet and dry EEG electrodes. Furthermore, the quality of unlabelled databases was evaluated. For all the studied databases, the proposed method is able to rapidly assess the quality of the EEG signals with an accuracy higher than 90\%. The obtained performance suggests that our approach provide an efficient, fast and automated quality assessment of EEG signals from low-cost wearable devices typically composed of a dry single EEG channel.},
	language = {eng},
	number = {3},
	journal = {Sensors (Basel, Switzerland)},
	author = {Grosselin, Fanny and Navarro-Sune, Xavier and Vozzi, Alessia and Pandremmenou, Katerina and De Vico Fallani, Fabrizio and Attal, Yohan and Chavez, Mario},
	month = jan,
	year = {2019},
	pmcid = {PMC6387437},
	note = {43 PMID: 30709004},
	keywords = {Algorithms, Artifacts, Brain, Brain-Computer Interfaces, Electrodes, Electroencephalography, Humans, Wearable Electronic Devices, artefact detection, electroencephalography (EEG), muscular artefacts, quality assessment, single-channel EEG, wearable systems},
	pages = {E601},
}

@article{chang_experiencing_2015,
	title = {Experiencing affective music in eyes-closed and eyes-open states: an electroencephalography study},
	volume = {6},
	issn = {1664-1078},
	shorttitle = {Experiencing affective music in eyes-closed and eyes-open states},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2015.01160},
	doi = {10.3389/fpsyg.2015.01160},
	abstract = {In real life, listening to music may be associated with an eyes-closed or eyes-open state. The effect of eye state on listeners’ reaction to music has attracted some attention, but its influence on brain activity has not been fully investigated. The present study aimed to evaluate the electroencephalographic (EEG) markers for the emotional valence of music in different eye states. Thirty participants listened to musical excerpts with different emotional content in the eyes-closed and eyes-open states. The results showed that participants rated the music as more pleasant or with more positive valence under an eyes-open state. In addition, we found that the alpha asymmetry indices calculated on the parietal and temporal sites reflected emotion valence in the eyes-closed and eyes-open states, respectively. The theta power in the frontal area significantly increased while listening to emotional-positive music compared to emotional-negative music under the eyes-closed condition. These effects of eye states on EEG markers are discussed in terms of brain mechanisms underlying attention and emotion.},
	urldate = {2021-10-06},
	journal = {Frontiers in Psychology},
	author = {Chang, Yun-Hsuan and Lee, You-Yun and Liang, Keng-Chen and Chen, I-Ping and Tsai, Chen-Gia and Hsieh, Shulan},
	year = {2015},
	note = {42},
	pages = {1160},
}

@article{barry_eeg_2007,
	title = {{EEG} differences between eyes-closed and eyes-open resting conditions},
	volume = {118},
	issn = {1388-2457},
	doi = {10.1016/j.clinph.2007.07.028},
	abstract = {OBJECTIVE: Recent work has attempted to clarify the energetics of physiological responding and behaviour by refining and separating the operational definitions of "arousal" and "activation", which have different effects on physiological responding and behaviour. At the EEG level, we relate the former to widespread activity, and the latter to task-specific topographically-focussed activity reflecting regional processing. This study aimed to investigate this further in terms of differences in EEG activity between eyes-closed and eyes-open resting conditions.
METHODS: EEG activity was recorded from 28 university students during both eyes-closed and eyes-open resting conditions, Fourier transformed to provide estimates for absolute power in the delta, theta, alpha and beta bands, and analysed in 9 regions across the scalp. Skin conductance level was also measured as an indicator of arousal level.
RESULTS: Across the eyes-closed conditions, skin conductance levels were negatively correlated with mean alpha levels. Skin conductance levels increased significantly from eyes-closed to eyes-open conditions. Reductions were found in across-scalp mean absolute delta, theta, alpha and beta from the eyes-closed to eyes-open condition. Topographic changes were also evident in all bands except for alpha, with reduced lateral frontal delta and posterior theta, and decreased posterior/increased frontal beta in the eyes-open condition. In particular, the topographic beta effects indicate that the across-scalp reduction arose from focal reductions rather than global changes.
CONCLUSIONS: The obtained results confirm the use of mean alpha level as a measure of resting-state arousal under eyes-closed and eyes-open conditions. The focal nature of EEG effects in the other bands suggests that these reflect cortical processing of visual input, producing differences in activation between eyes-closed and eyes-open resting conditions, rather than just the simple increase in arousal level shown in alpha.
SIGNIFICANCE: This study demonstrates that the eyes-closed and eyes-open conditions provide EEG measures differing in topography as well as power levels. These differences should be recognised when evaluating EEG research, and considered when choosing eyes-open or eyes-closed baseline conditions for different paradigms.},
	language = {eng},
	number = {12},
	journal = {Clinical Neurophysiology: Official Journal of the International Federation of Clinical Neurophysiology},
	author = {Barry, Robert J. and Clarke, Adam R. and Johnstone, Stuart J. and Magee, Christopher A. and Rushby, Jacqueline A.},
	month = dec,
	year = {2007},
	note = {41 PMID: 17911042},
	keywords = {Adolescent, Adult, Arousal, Attention, Brain Mapping, Cerebral Cortex, Electroencephalography, Evoked Potentials, Female, Fourier Analysis, Humans, Male, Middle Aged, Nerve Net, Photic Stimulation, Visual Perception, Wakefulness},
	pages = {2765--2773},
}

@article{hagemann_effects_2001,
	title = {The effects of ocular artifacts on (lateralized) broadband power in the {EEG}},
	volume = {112},
	doi = {10.1016/S1388-2457(00)00541-1},
	abstract = {Empirical evidence suggests that blinks and eye movements do not generate substantial activity outside the delta and theta range, and that the propagation of ocular activity to the EEG is rather symmetrical. These observations suggest that an alteration of the alpha and beta asymmetry of the EEG due to ocular artifacts is not likely to occur. The aim of the present study is to examine the effects of ocular artifacts on broadband EEG parameters.
EEG and EOG were recorded from 31 participants in a resting condition with eyes open and closed, allowing for spontaneous ocular activity. General effects of ocular artifacts were examined with mean comparisons, and differential effects were examined with correlation analysis of data portions that were selected for a presence or absence of artifacts.
At single sites, blinks and eye movements exerted substantial general effects on the whole EEG spectrum, but there were no substantial differential effects of artifacts in the alpha and beta bands, except at the frontopolar sites. The distorting effects of ocular artifacts were smaller in magnitude for asymmetry than for single site measures.
The control of ocular artifacts may be dispensable for correlation analyses of alpha or beta band parameters.},
	journal = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
	author = {Hagemann, Dirk and Naumann, Ewald},
	month = mar,
	year = {2001},
	note = {40},
	pages = {215--31},
}

@article{fang_perception_2017,
	title = {Perception of {Western} {Musical} {Modes}: {A} {Chinese} {Study}},
	volume = {8},
	issn = {1664-1078},
	shorttitle = {Perception of {Western} {Musical} {Modes}},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2017.01905/full},
	doi = {10.3389/fpsyg.2017.01905},
	abstract = {The major mode conveys positive emotion, whereas the minor mode conveys negative emotion. However, previous studies have primarily focused on the emotions induced by Western music in Western participants. The influence of the musical mode (major or minor) on Chinese individuals’ perception of Western music is unclear. In the present experiments, we investigated the effects of musical mode and harmonic complexity on psychological perception among Chinese participants. In Experiment 1, the participants (N = 30) evaluated 24 musical excerpts in five dimensions (pleasure, arousal, dominance, emotional tension and liking). In Experiment 2, the participants (N = 40) evaluated 48 musical excerpts. Perceptions of the musical excerpts differed significantly according to mode, even if the stimuli were Western musical excerpts. The major-mode music induced greater pleasure and arousal and produced higher liking ratings than the minor-mode music, whereas the minor-mode music induced greater tension than the major-mode music. Mode did not influence the dominance rating. Perception of Western music was not influenced by harmonic complexity. Moreover, preference for musical mode was influenced by previous exposure to Western music. These results confirm the cross-cultural emotion induction effects of musical modes in Western music.},
	language = {English},
	urldate = {2021-03-01},
	journal = {Frontiers in Psychology},
	author = {Fang, Lele and Shang, Junchen and Chen, Nan},
	year = {2017},
	note = {39 Publisher: Frontiers},
	keywords = {Perception, culture, emotion, harmonic complexity, mode},
}

@article{salimpoor_anatomically_2011,
	title = {Anatomically distinct dopamine release during anticipation and experience of peak emotion to music},
	volume = {14},
	doi = {10.1038/nn.2726},
	abstract = {Music, an abstract stimulus, can arouse feelings of euphoria and craving, similar to tangible rewards that involve the striatal dopaminergic system. Using the neurochemical specificity of [(11)C]raclopride positron emission tomography scanning, combined with psychophysiological measures of autonomic nervous system activity, we found endogenous dopamine release in the striatum at peak emotional arousal during music listening. To examine the time course of dopamine release, we used functional magnetic resonance imaging with the same stimuli and listeners, and found a functional dissociation: the caudate was more involved during the anticipation and the nucleus accumbens was more involved during the experience of peak emotional responses to music. These results indicate that intense pleasure in response to music can lead to dopamine release in the striatal system. Notably, the anticipation of an abstract reward can result in dopamine release in an anatomical pathway distinct from that associated with the peak pleasure itself. Our results help to explain why music is of such high value across all human societies.},
	journal = {Nature neuroscience},
	author = {Salimpoor, Valorie and Benovoy, Mitchel and Larcher, Kevin and Dagher, Alain and Zatorre, Robert},
	month = feb,
	year = {2011},
	note = {38},
	pages = {257--62},
}

@article{ward_same_2013,
	title = {The same old song: {The} power of familiarity in music choice},
	volume = {25},
	shorttitle = {The same old song},
	doi = {10.1007/s11002-013-9238-1},
	abstract = {Does "familiarity breed contempt" or is "to know you is to love you"? In this research, we explore the role of familiarity in music choice. We show that although consumers say they would prefer to listen to unfamiliar music, in actuality familiarity with music positively predicts preference for songs, play lists, and radio stations. Familiarity with music is at least as good, if not a better, predictor of choice as are liking, satiation (which actually positively predicts choice), and regret. We suggest that the need for familiarity is driven by consumers' low need for stimulation in the music domain, and show that when the need for stimulation decreases, the power of familiarity significantly increases. In addition to their theoretical contribu-tion, these results are informative for music managers determining playlists, for the promotion of music events and products, and for advertisers selecting the most potentially lucrative music venues.},
	journal = {Marketing Letters},
	author = {Ward, Morgan and Goodman, Joseph and Irwin, Julie},
	month = may,
	year = {2013},
	note = {37},
}

@article{sangnark_revealing_2021,
	title = {Revealing {Preference} in {Popular} {Music} {Through} {Familiarity} and {Brain} {Response}},
	issn = {1530-437X, 1558-1748, 2379-9153},
	url = {http://arxiv.org/abs/2102.00159},
	doi = {10.1109/JSEN.2021.3073040},
	abstract = {Music preference was reported as a factor, which could elicit innermost music emotion, entailing accurate ground-truth data and music therapy efficiency. This study executes statistical analysis to investigate the distinction of music preference through familiarity scores, response times (response rates), and brain response (EEG). Twenty participants did self-assessment after listening to two types of popular music's chorus section: music without lyrics (Melody) and music with lyrics (Song). {\textbackslash}textcolor\{red\}\{We then conduct a music preference classification using a support vector machine, random forest, and k-nearest neighbors with the familiarity scores, the response rates, and EEG as the feature vectors. The statistical analysis and F1-score of EEG are congruent, which is the brain's right side outperformed its left side in classification performance.\} Finally, these behavioral and brain studies support that preference, familiarity, and response rates can contribute to the music emotion experiment's design to understand music, emotion, and listener. Not only to the music industry, the biomedical and healthcare industry can also exploit this experiment to collect data from patients to improve the efficiency of healing by music.},
	urldate = {2021-05-17},
	journal = {IEEE Sensors Journal},
	author = {Sangnark, Soravitt and Autthasan, Phairot and Ponglertnapakorn, Puntawat and Chalekarn, Phudit and Sudhawiyangkul, Thapanun and Trakulruangroj, Manatsanan and Songsermsawad, Sarita and Assabumrungrat, Rawin and Amplod, Supalak and Ounjai, Kajornvut and Wilaiprasitporn, Theerawit},
	year = {2021},
	note = {36 arXiv: 2102.00159},
	keywords = {Computer Science - Human-Computer Interaction, Electrical Engineering and Systems Science - Signal Processing},
	pages = {1--1},
}

@book{cowie_feeltrace_2000,
	title = {'{FEELTRACE}': {An} instrument for recording perceived emotion in real time},
	shorttitle = {'{FEELTRACE}'},
	abstract = {FEELTRACE is an instrument developed to let observers track the emotional content of a stimulus as they perceive it over time, allowing the emotional dynamics of speech episodes to be examined. It is based on activation-evaluation space, a representation derived from psychology. The activation dimension measures how dynamic the emotional state is; the evaluation dimension is a global measure of the positive or negative feeling associated with the state. Research suggests that the space is naturally circular, i.e. states which are at the limit of emotional intensity define a circle, with alert neutrality at the centre. To turn those ideas into a recording tool, the space was represented by a circle on a computer screen, and observers described perceived emotional state by moving a pointer (in the form of a disc) to the appropriate point in the circle, using a mouse. Prototypes were tested, and in the light of results, refinements were made to ensure that outputs were as consistent and meaningful as possible. They include colour coding the pointer in a way that users readily associate with the relevant emotional state; presenting key emotion words as 'landmarks' at the strategic points in the space; and developing an induction procedure to introduce observers to the system. An experiment assessed the reliability of the developed system. Stimuli were 16 clips from TV programs, two showing relatively strong emotions in each quadrant of activation- evaluation space, each paired with one of the same person in a relatively neural state. 24 raters took part. Differences between clips chosen to contrast were statistically robust. Results were plotted in activation-evaluation space as ellipses, each with its centre at the mean co-ordinates for the clip, and its width proportional to standard deviation across raters. The size of the ellipses meant that about 25 could be fitted into the space, i.e. FEELTRACE has resolving power comparable to an emotion vocabulary of 20 non-overlapping words, with the advantage of allowing intermediate ratings, and above all, the ability to track impressions continuously.},
	author = {Cowie, Roddy and Douglas-Cowie, E. and Savvidou, Suzie and McMahon, E. and Sawey, M. and Schr{\textbackslash}"oder, M.},
	month = jan,
	year = {2000},
	note = {35 Journal Abbreviation: Proceedings of the ISCA Workshop on Speech and Emotion
Publication Title: Proceedings of the ISCA Workshop on Speech and Emotion},
}

@article{keelawat_comparative_2021,
	title = {A {Comparative} {Study} of {Window} {Size} and {Channel} {Arrangement} on {EEG}-{Emotion} {Recognition} {Using} {Deep} {CNN}},
	volume = {21},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/21/5/1678},
	doi = {10.3390/s21051678},
	abstract = {Emotion recognition based on electroencephalograms has become an active research area. Yet, identifying emotions using only brainwaves is still very challenging, especially the subject-independent task. Numerous studies have tried to propose methods to recognize emotions, including machine learning techniques like convolutional neural network (CNN). Since CNN has shown its potential in generalization to unseen subjects, manipulating CNN hyperparameters like the window size and electrode order might be beneficial. To our knowledge, this is the first work that extensively observed the parameter selection effect on the CNN. The temporal information in distinct window sizes was found to significantly affect the recognition performance, and CNN was found to be more responsive to changing window sizes than the support vector machine. Classifying the arousal achieved the best performance with a window size of ten seconds, obtaining 56.85\% accuracy and a Matthews correlation coefficient (MCC) of 0.1369. Valence recognition had the best performance with a window length of eight seconds at 73.34\% accuracy and an MCC value of 0.4669. Spatial information from varying the electrode orders had a small effect on the classification. Overall, valence results had a much more superior performance than arousal results, which were, perhaps, influenced by features related to brain activity asymmetry between the left and right hemispheres.},
	language = {en},
	number = {5},
	urldate = {2021-03-11},
	journal = {Sensors},
	author = {Keelawat, Panayu and Thammasan, Nattapong and Numao, Masayuki and Kijsirikul, Boonserm},
	month = jan,
	year = {2021},
	note = {34 
Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {CNN, EEG, brainwave, electrode order, emotion recognition, machine learning, neuroscience, spatiotemporal data, window size},
	pages = {1678},
}

@article{bigdely-shamlo_prep_2015,
	title = {The {PREP} pipeline: standardized preprocessing for large-scale {EEG} analysis},
	volume = {9},
	issn = {1662-5196},
	shorttitle = {The {PREP} pipeline},
	url = {https://www.frontiersin.org/article/10.3389/fninf.2015.00016},
	doi = {10.3389/fninf.2015.00016},
	abstract = {The technology to collect brain imaging and physiological measures has become portable and ubiquitous, opening the possibility of large-scale analysis of real-world human imaging. By its nature, such data is large and complex, making automated processing essential. This paper shows how lack of attention to the very early stages of an EEG preprocessing pipeline can reduce the signal-to-noise ratio and introduce unwanted artifacts into the data, particularly for computations done in single precision. We demonstrate that ordinary average referencing improves the signal-to-noise ratio, but that noisy channels can contaminate the results. We also show that identification of noisy channels depends on the reference and examine the complex interaction of filtering, noisy channel identification, and referencing. We introduce a multi-stage robust referencing scheme to deal with the noisy channel-reference interaction. We propose a standardized early-stage EEG processing pipeline (PREP) and discuss the application of the pipeline to more than 600 EEG datasets. The pipeline includes an automatically generated report for each dataset processed. Users can download the PREP pipeline as a freely available MATLAB library from http://eegstudy.org/prepcode.},
	urldate = {2021-11-12},
	journal = {Frontiers in Neuroinformatics},
	author = {Bigdely-Shamlo, Nima and Mullen, Tim and Kothe, Christian and Su, Kyung-Min and Robbins, Kay A.},
	year = {2015},
	note = {33},
	pages = {16},
}

@inproceedings{thammasan_multimodal_2017,
	title = {Multimodal stability-sensitive emotion recognition based on brainwave and physiological signals},
	doi = {10.1109/ACIIW.2017.8272584},
	abstract = {This paper presents a framework for adaptive multimodal emotion recognition based on signal stability as a context. To verify the efficacy of the method, experiments were conducted using a dataset of brainwave and physiological signals (EEG, ECG, GSR) captured from nine subjects listening to music. The proposed method uses a combination of signal-based features as well as accelerometer data to quantify the approximate reliability of each modality. In contrast to existing approaches, unstable modalities are not rejected outright, instead their relative contribution is dynamically adapted based on a corresponding stability index. In the case of EEG, the stability index was calculated using an artifact rejection technique, while for the ECG and GSR modalities it was calculated based on body movement detected through accelerometers. The experimental results show that temporally varying the relative contribution of each modality can improve emotion recognition performance.},
	booktitle = {2017 {Seventh} {International} {Conference} on {Affective} {Computing} and {Intelligent} {Interaction} {Workshops} and {Demos} ({ACIIW})},
	author = {Thammasan, Nattapong and Hagad, Juan Lorenzo and Fukui, Ken-ichi and Numao, Masayuki},
	month = oct,
	year = {2017},
	note = {32},
	keywords = {Accelerometers, Electrocardiography, Electroencephalography, Emotion recognition, Feature extraction, Music},
	pages = {44--49},
}

@article{higuchi_approach_1988,
	title = {Approach to an irregular time series on the basis of the fractal theory},
	volume = {31},
	issn = {0167-2789},
	url = {https://www.sciencedirect.com/science/article/pii/0167278988900814},
	doi = {10.1016/0167-2789(88)90081-4},
	abstract = {We present a technique to measure the fractal dimension of the set of points (t, f(t)) forming the graph of a function f defined on the unit interval. First we apply it to a fractional Brownian function [1] which has a property of self-similarity for all scales, and we can get the stable and precise fractal dimension. This technique is also applied to the observational data of natural phenomena. It does not show self-similarity all over the scale but has a different self-similarity across the characteristic time scale. The present method gives us a stable characteristic time scale as well as the fractal dimension.},
	language = {en},
	number = {2},
	urldate = {2021-03-17},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Higuchi, T.},
	month = jun,
	year = {1988},
	note = {31},
	pages = {277--283},
}

@inproceedings{soleymani_bayesian_2009,
	address = {Amsterdam, Netherlands},
	title = {A {Bayesian} framework for video affective representation},
	isbn = {978-1-4244-4800-5},
	url = {http://ieeexplore.ieee.org/document/5349563/},
	doi = {10.1109/ACII.2009.5349563},
	abstract = {Emotions that are elicited in response to a video scene contain valuable information for multimedia tagging and indexing. The novelty of this paper is to introduce a Bayesian classification framework for affective video tagging that allows taking contextual information into account. A set of 21 full length movies was first segmentedFirasntdAuintfhoormr ative content-based features were extracteIdnsfrtiotmuteioacnh1shot and scene. Shots were then emotIinosntailtluytiaonnn1otaadteddr,espsroviding ground truth affect. Thefairrosutsaaluotfhsohro@tis 1w.aosrcgomputed using a linear regression on the content-based features. Bayesian classification based on the shots arousal and content-based features allowed tagging these scenes into three affective classes, namely calm, positive excited and negative excited. To improve classification accuracy, two contextual priors have been proposed: the movie genre prior, and the temporal dimension prior consisting of the probability of transition between emotions in consecutive scenes. The f1 classification measure of 54.9\% that was obtained on three emotional classes with a naïve Bayes classifier was improved to 63.4\% after utilizing all the priors.},
	language = {en},
	urldate = {2021-12-02},
	booktitle = {2009 3rd {International} {Conference} on {Affective} {Computing} and {Intelligent} {Interaction} and {Workshops}},
	publisher = {IEEE},
	author = {Soleymani, Mohammad and Kierkels, Joep J.M. and Chanel, Guillaume and Pun, Thierry},
	month = sep,
	year = {2009},
	note = {30},
	pages = {1--7},
}

@article{eerola_review_2013,
	title = {A {Review} of {Music} and {Emotion} {Studies}: {Approaches}, {Emotion} {Models}, and {Stimuli}},
	shorttitle = {A {Review} of {Music} and {Emotion} {Studies}},
	doi = {10.1525/mp.2012.30.3.307},
	abstract = {THE FIELD OF MUSIC AND EMOTION RESEARCH HAS grown rapidly and diversified during the last decade. This has led to a certain degree of confusion and inconsistency between competing notions of emotions, data, and results. The present review of 251 studies describes the focus of prevalent research approaches, methods, and models of emotion, and documents the types of musical stimuli used over the past twenty years. Although self-report approaches to emotions are the most common way of dealing with music and emotions, using multiple approaches is becoming increasingly popular. A large majority (70\%) of the studies employed variants of the discrete or the dimensional emotion models. A large proportion of stimuli rely on a relatively modest amount of familiar classical examples. The evident shortcomings of these prevalent patterns in music and emotion studies are highlighted, and concrete plans of action for future studies are suggested.},
	journal = {Music Perception},
	author = {Eerola, Tuomas and Vuoskoski, Jonna},
	month = feb,
	year = {2013},
	note = {29},
}

@article{thammasan_continuous_2016,
	title = {Continuous {Music}-{Emotion} {Recognition} {Based} on {Electroencephalogram}},
	volume = {E99.D},
	doi = {10.1587/transinf.2015EDP7251},
	abstract = {Research on emotion recognition using electroencephalogram (EEG) of subjects listening to music has become more active in the past decade. However, previous works did not consider emotional oscillations within a single musical piece. In this research, we propose a continuous music-emotion recognition approach based on brainwave signals. While considering the subject-dependent and changing-over-time characteristics of emotion, our experiment included self-reporting and continuous emotion annotation in the arousal-valence space. Fractal dimension (FD) and power spectral density (PSD) approaches were adopted to extract informative features from raw EEG signals and then we applied emotion classification algorithms to discriminate binary classes of emotion. According to our experimental results, FD slightly outperformed PSD approach both in arousal and valence classification, and FD was found to have the higher correlation with emotion reports than PSD. In addition, continuous emotion recognition during music listening based on EEG was found to be an effective method for tracking emotional reporting oscillations and provides an opportunity to better understand human emotional processes.},
	journal = {IEICE Transactions on Information and Systems},
	author = {Thammasan, Nattapong and Moriyama, Koichi and Fukui, Ken-ichi and Numao, Masayuki},
	month = apr,
	year = {2016},
	note = {27},
	pages = {1234--1241},
}

@article{koelstra_deap_2012,
	title = {{DEAP}: {A} {Database} for {Emotion} {Analysis} ;{Using} {Physiological} {Signals}},
	volume = {3},
	issn = {1949-3045},
	shorttitle = {{DEAP}},
	doi = {10.1109/T-AFFC.2011.15},
	abstract = {We present a multimodal data set for the analysis of human affective states. The electroencephalogram (EEG) and peripheral physiological signals of 32 participants were recorded as each watched 40 one-minute long excerpts of music videos. Participants rated each video in terms of the levels of arousal, valence, like/dislike, dominance, and familiarity. For 22 of the 32 participants, frontal face video was also recorded. A novel method for stimuli selection is proposed using retrieval by affective tags from the last.fm website, video highlight detection, and an online assessment tool. An extensive analysis of the participants' ratings during the experiment is presented. Correlates between the EEG signal frequencies and the participants' ratings are investigated. Methods and results are presented for single-trial classification of arousal, valence, and like/dislike ratings using the modalities of EEG, peripheral physiological signals, and multimedia content analysis. Finally, decision fusion of the classification results from different modalities is performed. The data set is made publicly available and we encourage other researchers to use it for testing their own affective state estimation methods.},
	number = {1},
	journal = {IEEE Transactions on Affective Computing},
	author = {Koelstra, Sander and Muhl, Christian and Soleymani, Mohammad and Lee, Jong-Seok and Yazdani, Ashkan and Ebrahimi, Touradj and Pun, Thierry and Nijholt, Anton and Patras, Ioannis},
	month = jan,
	year = {2012},
	note = {28 Conference Name: IEEE Transactions on Affective Computing},
	keywords = {Databases, EEG, Electroencephalography, Emotion classification, Face, Motion pictures, Multimedia communication, Videos, Visualization, affective computing., pattern classification, physiological signals, signal processing},
	pages = {18--31},
}

@inproceedings{wu_estimation_2017,
	title = {Estimation of valence of emotion using two frontal {EEG} channels},
	doi = {10.1109/BIBM.2017.8217815},
	abstract = {Emotion recognition using EEG signals has become a hot research topic in the last few years. This paper aims at providing a novel method for emotion recognition using less channels of frontal EEG signals. By employing the asymmetry theory of frontal brain, a new method fusing spatial and frequency features was presented, which only adopted two channels of frontal EEG signals at Fp1 and Fp2. In order to estimate the efficiency of the method, a GBDT classifier was evaluated and selected, and the method was implemented on the DEAP database. The maximum and mean classification accuracy were achieved as 76.34\% and 75.18\% respectively, which exhibited the best result comparing with other related studies. This method is extremely suitable for wearable EEG monitoring applications in human daily life.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Bioinformatics} and {Biomedicine} ({BIBM})},
	author = {Wu, Shiyi and Xu, Xiangmin and Shu, Lin and Hu, Bin},
	month = nov,
	year = {2017},
	note = {26},
	keywords = {Biomedical monitoring, DEAP, Electroencephalography, Emotion recognition, Entropy, Feature extraction, Frontal EEG, GBDT classifier, Indexes},
	pages = {1127--1130},
}

@article{lin_eeg-based_2010,
	title = {{EEG}-{Based} {Emotion} {Recognition} in {Music} {Listening}},
	volume = {57},
	issn = {1558-2531},
	doi = {10.1109/TBME.2010.2048568},
	abstract = {Ongoing brain activity can be recorded as electroen-cephalograph (EEG) to discover the links between emotional states and brain activity. This study applied machine-learning algorithms to categorize EEG dynamics according to subject self-reported emotional states during music listening. A framework was proposed to optimize EEG-based emotion recognition by systematically 1) seeking emotion-specific EEG features and 2) exploring the efficacy of the classifiers. Support vector machine was employed to classify four emotional states (joy, anger, sadness, and pleasure) and obtained an averaged classification accuracy of 82.29\% ± 3.06\% across 26 subjects. Further, this study identified 30 subject-independent features that were most relevant to emotional processing across subjects and explored the feasibility of using fewer electrodes to characterize the EEG dynamics during music listening. The identified features were primarily derived from electrodes placed near the frontal and the parietal lobes, consistent with many of the findings in the literature. This study might lead to a practical system for noninvasive assessment of the emotional states in practical or clinical applications.},
	number = {7},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Lin, Y. and Wang, C. and Jung, T. and Wu, T. and Jeng, S. and Duann, J. and Chen, J.},
	month = jul,
	year = {2010},
	note = {25 Conference Name: IEEE Transactions on Biomedical Engineering},
	keywords = {Brain, EEG, Electrodes, Electroencephalography, Electromyography, Emotion recognition, Hospitals, Humans, IEEE activities, Support vector machine classification, Support vector machines, emotion, machine learning, music},
	pages = {1798--1806},
}

@inproceedings{lin_eeg-based_2009,
	title = {{EEG}-based emotion recognition in music listening: {A} comparison of schemes for multiclass support vector machine},
	shorttitle = {{EEG}-based emotion recognition in music listening},
	doi = {10.1109/ICASSP.2009.4959627},
	abstract = {Currently, how to equip machines with the ability for properly recognizing users' felt-emotion during multimedia presentation is a growing issue. In this study we focused on the approach for recognizing music-induced emotional responses from brain activity. A comparative study was conducted to testify the feasibility of using hierarchical binary classifiers to improve the classification performance as compared with nonhierarchical schemes. According to our classification results, we not only found that using one-against-one scheme of hierarchical binary classifier results in an improvement to performance, but also established an alternative solution for emotion recognition by proposed model-based scheme depending on 2D emotion model.},
	booktitle = {2009 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	author = {Lin, Y. and Wang, C. and Wu, T. and Jeng, S. and Chen, J.},
	month = apr,
	year = {2009},
	note = {24 ISSN: 2379-190X},
	keywords = {Brain, Brain activity, Data acquisition, EEG-based emotion recognition, Electroencephalography, Emotion recognition, Hospitals, Humans, Multilayer perceptrons, Multiple signal classification, Neural networks, Support vector machines, brain activity, electroencephalography, emotion recognition, multiclass support vector machine, multimedia presentation, music, music listening, music-induced emotional responses, support vector machines},
	pages = {489--492},
}

@article{reuderink_valence_2013,
	title = {Valence, arousal and dominance in the {EEG} during game play},
	volume = {6},
	doi = {10.1504/IJAACS.2013.050691},
	abstract = {In this paper, we describe our investigation of traces of naturally occurring emotions in electrical brain signals, that can be used to build interfaces that respond to our emotional state. This study confirms a number of known affective correlates in a realistic, uncontrolled environment for the emotions of valence (or pleasure), arousal and dominance: (1) a significant decrease in frontal power in the theta range is found for increasingly positive valence, (2) a significant frontal increase in power in the alpha range is associated with increasing emotional arousal, (3) a significant right posterior power increase in the delta range correlates with increasing arousal and (4) asymmetry in power in the lower alpha bands correlates with self-reported valence. Furthermore, asymmetry in the higher alpha bands correlates with self-reported dominance. These last two effects provide a simple measure for subjective feelings of pleasure and feelings of control.},
	journal = {International Journal of Autonomous and Adaptive Communications Systems},
	author = {Reuderink, Boris and Mühl, Christian and Poel, Mannes},
	month = dec,
	year = {2013},
	note = {23},
	pages = {45--62},
}

@article{zhao_frontal_2018,
	title = {Frontal {EEG} {Asymmetry} and {Middle} {Line} {Power} {Difference} in {Discrete} {Emotions}},
	volume = {12},
	issn = {1662-5153},
	url = {https://www.frontiersin.org/article/10.3389/fnbeh.2018.00225},
	doi = {10.3389/fnbeh.2018.00225},
	abstract = {A traditional model of emotion cannot explain the differences in brain activities between two discrete emotions that are similar in the valence-arousal coordinate space. The current study elicited two positive emotions (amusement and tenderness) and two negative emotions (anger and fear) that are similar in both valence and arousal dimensions to examine the differences in brain activities in these emotional states. Frontal electroencephalographic (EEG) asymmetry and midline power in three bands (theta, alpha and beta) were measured when participants watched affective film excerpts. Significant differences were detected between tenderness and amusement on FP1/FP2 theta asymmetry, F3/F4 theta and alpha asymmetry. Significant differences between anger and fear on FP1/FP2 theta asymmetry and F3/F4 alpha asymmetry were also observed. For midline power, midline theta power could distinguish two negative emotions, while midline alpha and beta power could effectively differentiate two positive emotions. Liking and dominance were also related to EEG features. Stepwise multiple linear regression results revealed that frontal alpha and theta asymmetry could predict the subjective feelings of two positive and two negative emotions in different patterns. The binary classification accuracy, which used EEG frontal asymmetry and midline power as features and support vector machine (SVM) as classifiers, was as high as 64.52\% for tenderness and amusement and 78.79\% for anger and fear. The classification accuracy was improved after adding these features to other features extracted across the scalp. These findings indicate that frontal EEG asymmetry and midline power might have the potential to recognize discrete emotions that are similar in the valence-arousal coordinate space.},
	urldate = {2021-11-23},
	journal = {Frontiers in Behavioral Neuroscience},
	author = {Zhao, Guozhen and Zhang, Yulin and Ge, Yan},
	year = {2018},
	note = {22},
	pages = {225},
}

@article{sammler_music_nodate,
	title = {Music and emotion: {Electrophysiological} correlates of the processing of pleasant and unpleasant music},
	abstract = {Human emotion and its electrophysiological correlates are still poorly understood. The present study examined whether the valence of perceived emotions would differentially inﬂuence EEG power spectra and heart rate (HR). Pleasant and unpleasant emotions were induced by consonant and dissonant music. Unpleasant (compared to pleasant) music evoked a significant decrease of HR, replicating the pattern of HR responses previously described for the processing of emotional pictures, sounds, and ﬁlms. In the EEG, pleasant (contrasted to unpleasant) music was associated with an increase of frontal midline (Fm) theta power. This effect is taken to reﬂect emotional processing in close interaction with attentional functions. These ﬁndings show that Fm theta is modulated by emotion more strongly than previously believed.},
	language = {en},
	author = {Sammler, Daniela and Grigutsch, Maren and Fritz, Thomas and Koelsch, Stefan},
	note = {21},
	pages = {12},
}

@article{orgo_effect_2015,
	title = {Effect of negative and positive emotions on {EEG} spectral asymmetry},
	volume = {2015},
	issn = {2694-0604},
	doi = {10.1109/EMBC.2015.7320275},
	abstract = {The aim of the study was to evaluate the applicability of electroencephalogram (EEG) spectral asymmetry index (SASI) for discrimination of the effect of negative and positive emotions on human brain bioelectrical activity. SASI has been previously proposed as a method to detect depression based on the balance of EEG theta and beta frequency band powers. Emotions were evoked on 22 healthy subjects using emotional pictures portraying humans from International Affective Picture System (IAPS) and late response to stimuli was examined (1700-2200 ms). Electroencephalogram (EEG) was recorded in 30 channels divided into 10 brain regions: left frontal, right frontal, left temporal, right temporal, frontal, frontocentral, central, centroparietal, parietal and occipital. Negative stimuli, compared to neutral stimuli, significantly increased SASI in frontocentral, central, centroparietal, parietal and occipital areas. Positive stimuli, compared to neutral stimuli, significantly decreased SASI in left temporal, centroparietal, parietal and occipital areas. The results indicate that SASI provides a good discrimination between the effects of negative, neutral and positive emotions on human EEG.},
	language = {eng},
	journal = {Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference},
	author = {Orgo, L. and Bachmann, M. and Lass, J. and Hinrikus, H.},
	month = aug,
	year = {2015},
	note = {20 PMID: 26738175},
	keywords = {Brain, Brain Mapping, Depression, Electroencephalography, Emotions, Humans},
	pages = {8107--8110},
}

@article{heller_neuropsychological_1993,
	title = {Neuropsychological {Mechanisms} of {Individual} {Differences} in {Emotion}, {Personality}, and {Arousal}},
	volume = {7},
	issn = {0894-4105},
	url = {http://www.scopus.com/inward/record.url?scp=0001052432&partnerID=8YFLogxK},
	doi = {10.1037/0894-4105.7.4.476},
	abstract = {Evidence is reviewed to suggest that parietotemporal regions of the right hemisphere not only are specialized for the processing of emotional information but also play a critical role in the experience of emotion. In particular, it is argued that these regions of the right hemisphere constitute a system involved in modulating autonomic and behavioral arousal in emotional states. This system is characterized by a set of cognitive and attentional qualities that make it uniquely suited to respond to environmental events in an adaptive fashion. The current proposal is an elaboration of a model of emotion and brain organization (Heller, 1990) that incorporates several aspects of emotional function: (a) perception and production of emotional information, (b) mood and emotional experience, and (c) autonomic arousal. In the context of this model, it is suggested that the right-hemisphere system operates in conjunction with a system localized to the frontal lobes that is involved in modulating the emotional valence of experience. The interaction of these two systems is hypothesized to be conditioned by individual differences and developmental tendencies that contribute to the production of a unique and stable pattern of personality traits and emotional characteristics.},
	number = {4},
	urldate = {2021-09-17},
	journal = {Neuropsychology},
	author = {Heller, Wendy},
	month = oct,
	year = {1993},
	note = {19},
	pages = {476--489},
}

@article{schmidt_frontal_1999,
	title = {Frontal {Brain} {Electrical} {Activity} in {Shyness} and {Sociability}},
	volume = {10},
	issn = {0956-7976},
	url = {https://doi.org/10.1111/1467-9280.00161},
	doi = {10.1111/1467-9280.00161},
	abstract = {A number of studies have shown that shyness and sociability may be two independent personality traits that are distinguishable across a variety of measures and cultures. Utilizing recent frontal activation–emotion models as a theoretical framework, this study examined the pattern of resting frontal electroencephalographic (EEG) activity in undergraduates who self-reported high and low shyness and sociability. Analyses revealed that shyness was associated with greater relative right frontal EEG activity, whereas sociability was associated with greater relative left frontal EEG activity. Also, different combinations of shyness and sociability were distinguishable on the basis of resting frontal EEG power. Although high-shy/high-social and high-shy/low-social subjects both exhibited greater relative right frontal EEG activity, they differed significantly on EEG power in the left, but not right, frontal lead. High-shy/high-social subjects exhibited significantly less EEG power (i.e., more activity) in the left frontal lead compared with the high-shy/low-social subjects. These findings suggest that in distinguishing individual differences in personality and personality subtypes, it is important to consider not only frontal EEG asymmetry measures, but also the pattern of absolute EEG power in each frontal hemisphere.},
	language = {en},
	number = {4},
	urldate = {2021-09-17},
	journal = {Psychological Science},
	author = {Schmidt, Louis A.},
	month = jul,
	year = {1999},
	note = {18 Publisher: SAGE Publications Inc},
	pages = {316--320},
}

@article{dawson_frontal_1994,
	title = {Frontal electroencephalographic correlates of individual differences in emotion expression in infants: a brain systems perspective on emotion},
	volume = {59},
	issn = {0037-976X},
	shorttitle = {Frontal electroencephalographic correlates of individual differences in emotion expression in infants},
	abstract = {Emotion expressions can be characterized by both the type of emotion displayed and the intensity with which the emotion is expressed. Individual differences in these two aspects of emotion appear to vary independently and may perhaps account for distinct dimensions of temperament, personality, and vulnerability to psychopathology. We reviewed several sets of data gathered in our laboratory that indicate that these two dimensions of emotion expression are associated with distinct and independent patterns of frontal EEG activity in infants. Specifically, whereas the type of emotion expression was found to be associated with asymmetries in frontal EEG activity, the intensity of emotion expression was found to be associated with generalized activation of both the right and the left frontal regions. Moreover, we reviewed and provided evidence that measures of asymmetrical frontal activity are better predictors of individual differences in the tendency to express certain emotions, such as distress and sadness, whereas measures of generalized frontal activity are better predictors of individual differences in emotional reactivity and emotion intensity. The neuroanatomical bases of emotion were discussed with special reference to the role of the frontal lobe in emotion regulation. It was hypothesized that the frontal activation asymmetries that have been found to accompany emotion expressions reflect specific regulation strategies. The left frontal region is specialized for regulation strategies involving action schemes that serve to maintain continuity and stability of the organism-environment relation and of ongoing motor schemes, such as those involved in language and the expression of happiness and interest. In contrast, the right frontal region appears to be specialized for regulation strategies that involve processing novel stimuli that disrupt ongoing activity, such as might occur during the expression of fear, disgust, and distress. Furthermore, it was proposed that individual differences in patterns of frontal EEG asymmetries during emotion may be related to socialization influences rather than solely innate factors. It was speculated that the pattern of generalized frontal lobe activation that accompanies the experience of intense emotions may reflect, in part, the relatively diffuse influence of subcortical structures on the cortex and may serve to increase the infant's general readiness to receive and respond to significant external stimuli.},
	language = {eng},
	number = {2-3},
	journal = {Monographs of the Society for Research in Child Development},
	author = {Dawson, G.},
	year = {1994},
	note = {17 PMID: 7984157},
	keywords = {Affect, Anxiety, Separation, Electroencephalography, Emotions, Facial Expression, Frontal Lobe, Functional Laterality, Humans, Infant, Parietal Lobe},
	pages = {135--151},
}

@article{davidson_anterior_1992,
	title = {Anterior cerebral asymmetry and the nature of emotion},
	volume = {20},
	issn = {0278-2626},
	doi = {10.1016/0278-2626(92)90065-t},
	abstract = {This article presents an overview of the author's recent electrophysiological studies of anterior cerebral asymmetries related to emotion and affective style. A theoretical account is provided of the role of the two hemispheres in emotional processing. This account assigns a major role in approach- and withdrawal-related behavior to the left and right frontal and anterior temporal regions of two hemispheres, respectively. Individual differences in approach- and withdrawal-related emotional reactivity and temperament are associated with stable differences in baseline measures of activation asymmetry in these anterior regions. Phasic state changes in emotion result in shifts in anterior activation asymmetry which are superimposed upon these stable baseline differences. Future directions for research in this area are discussed.},
	language = {eng},
	number = {1},
	journal = {Brain and Cognition},
	author = {Davidson, R. J.},
	month = sep,
	year = {1992},
	note = {16 PMID: 1389117},
	keywords = {Adult, Brain, Cerebral Cortex, Child, Child Development, Child, Preschool, Depressive Disorder, Electroencephalography, Emotions, Female, Functional Laterality, Humans, Individuality, Infant, Infant, Newborn, Male, Models, Neurological, Research Design},
	pages = {125--151},
}

@article{schmidt_frontal_2001,
	title = {Frontal brain electrical activity ({EEG}) distinguishes valence and intensity of musical emotions},
	volume = {15},
	issn = {0269-9931},
	url = {https://doi.org/10.1080/02699930126048},
	doi = {10.1080/02699930126048},
	abstract = {Using recent regional brain activation/emotion models as a theoretical framework, we examined whether the pattern of regional EEG activity distinguished emotions induced by musical excerpts which were known to vary in affective valence (i.e., positive vs. negative) and intensity (i.e., intense vs. calm) in a group of undergraduates. We found that the pattern of asymmetrical frontal EEG activity distinguished valence of the musical excerpts. Subjects exhibited greater relative left frontal EEG activity to joy and happy musical excerpts and greater relative right frontal EEG activity to fear and sad musical excerpts. We also found that, although the pattern of frontal EEG asymmetry did not distinguish the intensity of the emotions, the pattern of overall frontal EEG activity did, with the amount of frontal activity decreasing from fear to joy to happy to sad excerpts. These data appear to be the first to distinguish valence and intensity of musical emotions on frontal electrocortical measures.},
	number = {4},
	urldate = {2021-03-07},
	journal = {Cognition and Emotion},
	author = {Schmidt, Louis A. and Trainor, Laurel J.},
	month = jul,
	year = {2001},
	note = {15 Publisher: Routledge
\_eprint: https://doi.org/10.1080/02699930126048},
	pages = {487--500},
}

@article{watson_development_nodate,
	title = {Development and {Validation} of {Brief} {Measures} of {Positive} and {Negative} {Affect}: {The} {PANAS} {Scales}},
	language = {en},
	author = {Watson, David and Anna, Lee and Tellegen, Auke},
	note = {14},
	pages = {8},
}

@article{bradley_measuring_1994,
	title = {Measuring emotion: {The} self-assessment manikin and the semantic differential},
	volume = {25},
	issn = {0005-7916},
	shorttitle = {Measuring emotion},
	url = {https://www.sciencedirect.com/science/article/pii/0005791694900639},
	doi = {10.1016/0005-7916(94)90063-9},
	abstract = {The Self-Assessment Manikin (SAM) is a non-verbal pictorial assessment technique that directly measures the pleasure, arousal, and dominance associated with a person's affective reaction to a wide variety of stimuli. In this experiment, we compare reports of affective experience obtained using SAM, which requires only three simple judgments, to the Semantic Differential scale devised by Mehrabian and Russell (An approach to environmental psychology, 1974) which requires 18 different ratings. Subjective reports were measured to a series of pictures that varied in both affective valence and intensity. Correlations across the two rating methods were high both for reports of experienced pleasure and felt arousal. Differences obtained in the dominance dimension of the two instruments suggest that SAM may better track the personal response to an affective stimulus. SAM is an inexpensive, easy method for quickly assessing reports of affective response in many contexts.},
	language = {en},
	number = {1},
	urldate = {2021-08-08},
	journal = {Journal of Behavior Therapy and Experimental Psychiatry},
	author = {Bradley, Margaret M. and Lang, Peter J.},
	month = mar,
	year = {1994},
	note = {13},
	pages = {49--59},
}

@article{russell_circumplex_1980,
	title = {A {Circumplex} {Model} of {Affect}},
	volume = {39},
	doi = {10.1037/h0077714},
	abstract = {Factor-analytic evidence has led most psychologists to describe affect as a set of dimensions, such as displeasure, distress, depression, excitement, and so on, with each dimension varying independently of the others. However, there is other evidence that rather than being independent, these affective dimensions are interrelated in a highly systematic fashion. The evidence suggests that these interrelationships can be represented by a spatial model in which affective concepts fall in a circle in the following order: pleasure (0), excitement (45), arousal (90), distress (135), displeasure (180), depression (225), sleepiness (270), and relaxation (315). This model was offered both as a way psychologists can represent the structure of affective experience, as assessed through self-report, and as a representation of the cognitive structure that laymen utilize in conceptualizing affect. Supportive evidence was obtained by scaling 28 emotion-denoting adjectives in 4 different ways: R. T. Ross's (1938) technique for a circular ordering of variables, a multidimensional scaling procedure based on perceived similarity among the terms, a unidimensional scaling on hypothesized pleasure–displeasure and degree-of-arousal dimensions, and a principal-components analysis of 343 Ss' self-reports of their current affective states. (70 ref) (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
	journal = {Journal of Personality and Social Psychology},
	author = {Russell, James},
	month = dec,
	year = {1980},
	note = {12},
	pages = {1161--1178},
}

@article{picard_affective_2003,
	title = {Affective computing: challenges},
	volume = {59},
	issn = {10715819},
	shorttitle = {Affective computing},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581903000521},
	doi = {10.1016/S1071-5819(03)00052-1},
	language = {en},
	number = {1-2},
	urldate = {2021-10-14},
	journal = {International Journal of Human-Computer Studies},
	author = {Picard, Rosalind W.},
	month = jul,
	year = {2003},
	note = {10},
	pages = {55--64},
}

@article{nicolas-alonso_brain_2012,
	title = {Brain {Computer} {Interfaces}, a {Review}},
	volume = {12},
	issn = {1424-8220},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3304110/},
	doi = {10.3390/s120201211},
	abstract = {A brain-computer interface (BCI) is a hardware and software communications system that permits cerebral activity alone to control computers or external devices. The immediate goal of BCI research is to provide communications capabilities to severely disabled people who are totally paralyzed or ‘locked in’ by neurological neuromuscular disorders, such as amyotrophic lateral sclerosis, brain stem stroke, or spinal cord injury. Here, we review the state-of-the-art of BCIs, looking at the different steps that form a standard BCI: signal acquisition, preprocessing or signal enhancement, feature extraction, classification and the control interface. We discuss their advantages, drawbacks, and latest advances, and we survey the numerous technologies reported in the scientific literature to design each step of a BCI. First, the review examines the neuroimaging modalities used in the signal acquisition step, each of which monitors a different functional brain activity such as electrical, magnetic or metabolic activity. Second, the review discusses different electrophysiological control signals that determine user intentions, which can be detected in brain activity. Third, the review includes some techniques used in the signal enhancement step to deal with the artifacts in the control signals and improve the performance. Fourth, the review studies some mathematic algorithms used in the feature extraction and classification steps which translate the information in the control signals into commands that operate a computer or other device. Finally, the review provides an overview of various BCI applications that control a range of devices.},
	number = {2},
	urldate = {2021-09-17},
	journal = {Sensors (Basel, Switzerland)},
	author = {Nicolas-Alonso, Luis Fernando and Gomez-Gil, Jaime},
	month = jan,
	year = {2012},
	note = {11},
	pages = {1211--1279},
}

@article{tromp_design_2011,
	title = {Design for {Socially} {Responsible} {Behavior}: {A} {Classification} of {Influence} {Based} on {Intended} {User} {Experience}},
	volume = {27},
	issn = {0747-9360},
	shorttitle = {Design for {Socially} {Responsible} {Behavior}},
	url = {https://doi.org/10.1162/DESI_a_00087},
	doi = {10.1162/DESI_a_00087},
	number = {3},
	urldate = {2021-07-14},
	journal = {Design Issues},
	author = {Tromp, Nynke and Hekkert, Paul and Verbeek, Peter-Paul},
	month = jul,
	year = {2011},
	note = {09},
	pages = {3--19},
}

@article{gertz_autonomy_2016,
	title = {Autonomy online: {Jacques} {Ellul} and the {Facebook} emotional manipulation study},
	volume = {12},
	issn = {1747-0161},
	shorttitle = {Autonomy online},
	url = {https://doi.org/10.1177/1747016115579534},
	doi = {10.1177/1747016115579534},
	abstract = {Though we would expect the revelation of the Facebook emotional manipulation study to have had a negative impact on Facebook, its number of active users only continues to grow. As this is precisely the result that Jacques Ellul would have predicted, this paper examines his philosophy of technology in order to investigate the relationship between Facebook and its users and what this relationship means in terms of autonomy. That Facebook can manipulate its users without losing users reveals that Facebook’s autonomy is growing while the autonomy of users is diminishing. The paper concludes by showing that the answer to this increasingly asymmetrical relationship cannot be the creation of review boards and oversight committees as the underlying issues concerning autonomy are existential more than they are ethical.},
	language = {en},
	number = {1},
	urldate = {2021-07-14},
	journal = {Research Ethics},
	author = {Gertz, Nolen},
	month = jan,
	year = {2016},
	note = {08},
	keywords = {Facebook emotional manipulation study, Jacques Ellul, autonomy, research ethics, technology},
	pages = {55--61},
}

@article{picard_mit_nodate,
	title = {{MIT} {Media} {Laboratory}; {Perceptual} {Computing}; 20 {Ames} {St}., {Cambridge}, {MA} 02139 picard@media.mit.edu, http://www.media.mit.edu/˜picard/},
	abstract = {Computers are beginning to acquire the ability to express and recognize aﬀect, and may soon be given the ability to “have emotions.” The essential role of emotion in both human cognition and perception, as demonstrated by recent neurological studies, indicates that aﬀective computers should not only provide better performance in assisting humans, but also might enhance computers’ abilities to make decisions. This paper presents and discusses key issues in “aﬀective computing,” computing that relates to, arises from, or inﬂuences emotions. Models are suggested for computer recognition of human emotion, and new applications are presented for computerassisted learning, perceptual information retrieval, arts and entertainment, and human health and interaction. Aﬀective computing, coupled with new wearable computers, will also provide the ability to gather new data necessary for advances in emotion and cognition theory.},
	language = {en},
	author = {Picard, R W},
	note = {07},
	pages = {16},
}

@article{abdul_emotion-aware_2018,
	title = {An {Emotion}-{Aware} {Personalized} {Music} {Recommendation} {System} {Using} a {Convolutional} {Neural} {Networks} {Approach}},
	volume = {8},
	doi = {10.3390/app8071103},
	abstract = {Recommending music based on a user's music preference is a way to improve user listening experience. Finding the correlation between the user data (e.g., location, time of the day, music listening history, emotion, etc.) and the music is a challenging task. In this paper, we propose an emotion-aware personalized music recommendation system (EPMRS) to extract the correlation between the user data and the music. To achieve this correlation, we combine the outputs of two approaches: the deep convolutional neural networks (DCNN) approach and the weighted feature extraction (WFE) approach. The DCNN approach is used to extract the latent features from music data (e.g., audio signals and corresponding metadata) for classification. In the WFE approach, we generate the implicit user rating for music to extract the correlation between the user data and the music data. In the WFE approach, we use the term-frequency and inverse document frequency (TF-IDF) approach to generate the implicit user ratings for the music. Later, the EPMRS recommends songs to the user based on calculated implicit user rating for the music. We use the million songs dataset (MSD) to train the EPMRS. For performance comparison, we take the content similarity music recommendation system (CSMRS) as well as the personalized music recommendation system based on electroencephalography feedback (PMRSE) as the baseline systems. Experimental results show that the EPMRS produces better accuracy of music recommendations than the CSMRS and the PMRSE. Moreover, we build the Android and iOS APPs to get realistic data of user experience on the EPMRS. The collected feedback from anonymous users also show that the EPMRS sufficiently reflect their preference on music.},
	journal = {Applied Sciences},
	author = {Abdul, Ashu and Chen, Jenhui and Liao, Hua-Yuan and Chang, Shun-Hao},
	month = jul,
	year = {2018},
	note = {06},
	pages = {1103},
}

@article{chang_personalized_2017,
	title = {A personalized music recommendation system based on electroencephalography feedback},
	volume = {76},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-015-3202-4},
	doi = {10.1007/s11042-015-3202-4},
	abstract = {Numerous domestic and foreign studies have demonstrated that music can relieve stress and that listening to music is one method of stress relief used presently. Although stress-relief music is available on the market, various music genres produce distinct effects on people. Clinical findings have indicated that approximately 30 \% of people listen to inappropriate music genres for relaxation and, consequently, their stress level increases. Therefore, to achieve the effect of stress relief, choosing the appropriate music genre is crucial. For example, a 70-year-old woman living in a military community since childhood might not consider general stress-relief music to be helpful in relieving stress, but when patriotic songs are played, her autonomic nervous system automatically relaxes because of her familiarity with the music style. Therefore, people have dissimilar needs regarding stress-relief music. In this paper, we proposed a personalized stress-relieving music recommendation system based on electroencephalography (EEG) feedback. The system structure comprises the following features: (a) automated music categorization, in which a new clustering algorithm, K-MeansH, is employed to precluster music and improve processing time; (b) the access and analysis of users’ EEG data to identify perceived stress-relieving music; and (c) personalized recommendations based on collaborative filtering and provided according to personal preferences. Experimental results indicated that the overall clustering effect of K-MeansH surpassed that of K-Means and K-Medoids by approximately 71 and 57 \%, respectively. In terms of accuracy, K-MeansH also surpassed K-Means and K-Medoids.},
	language = {en},
	number = {19},
	urldate = {2021-07-12},
	journal = {Multimedia Tools and Applications},
	author = {Chang, Hong-Yi and Huang, Shih-Chang and Wu, Jia-Hao},
	month = oct,
	year = {2017},
	note = {05},
	pages = {19523--19542},
}

@misc{statt_facebook_2019,
	title = {Facebook acquires neural interface startup {CTRL}-{Labs} for its mind-reading wristband},
	url = {https://www.theverge.com/2019/9/23/20881032/facebook-ctrl-labs-acquisition-neural-interface-armband-ar-vr-deal},
	abstract = {The deal is reportedly worth between \$500 million and \$1 billion},
	language = {en},
	urldate = {2021-11-29},
	journal = {The Verge},
	author = {Statt, Nick},
	month = sep,
	year = {2019},
	note = {04},
}

@misc{parfenov_openbci_nodate,
	title = {{OpenBCI} {Galea} with {BrainFlow}},
	url = {https://brainflow.org/2021-01-26-galea-brainflow/},
	abstract = {OpenBCI Galea device developed in collaboration with Valve corporation will use BrainFlow SDK},
	language = {en},
	urldate = {2021-11-29},
	author = {Parfenov, Andrey},
	note = {03},
}

@misc{parfenov_brainflow_nodate,
	title = {{BrainFlow} 4.6.0},
	url = {https://brainflow.org/2021-08-17-enophone/},
	abstract = {BrainFlow is the SDK for Enophone},
	language = {en},
	urldate = {2021-11-29},
	author = {Parfenov, Andrey},
	note = {02},
}

@misc{noauthor_gartners_nodate,
	title = {Gartner's 2016 {Hype} {Cycle} for {Emerging} {Technologies} {Identifies} {Three} {Key} {Trends} {That} {Organizations} {Must} {Track} to {Gain} {Competitive} {Advantage}},
	url = {https://www.gartner.com/en/newsroom/press-releases/2016-08-16-gartners-2016-hype-cycle-for-emerging-technologies-identifies-three-key-trends-that-organizations-must-track-to-gain-competitive-advantage},
	abstract = {The technologies on Gartner Inc.'s Hype Cycle for Emerging Technologies, 2016 reveal three distinct technology trends that are poised to be of the highest priority for organizations facing rapidly accelerating digital business innovation.},
	language = {en},
	urldate = {2021-11-29},
	journal = {Gartner},
	note = {01},
}

@misc{noauthor_sensors_nodate,
	title = {Sensors {\textbar} {Free} {Full}-{Text} {\textbar} {A} {Comparative} {Study} of {Window} {Size} and {Channel} {Arrangement} on {EEG}-{Emotion} {Recognition} {Using} {Deep} {CNN} {\textbar} {HTML}},
	url = {https://www.mdpi.com/1424-8220/21/5/1678/htm},
	urldate = {2021-12-02},
}

@article{koelsch_toward_2011,
	title = {Toward a {Neural} {Basis} of {Music} {Perception} – {A} {Review} and {Updated} {Model}},
	volume = {2},
	issn = {1664-1078},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3114071/},
	doi = {10.3389/fpsyg.2011.00110},
	abstract = {Music perception involves acoustic analysis, auditory memory, auditory scene analysis, processing of interval relations, of musical syntax and semantics, and activation of (pre)motor representations of actions. Moreover, music perception potentially elicits emotions, thus giving rise to the modulation of emotional effector systems such as the subjective feeling system, the autonomic nervous system, the hormonal, and the immune system. Building on a previous article (Koelsch and Siebel, ), this review presents an updated model of music perception and its neural correlates. The article describes processes involved in music perception, and reports EEG and fMRI studies that inform about the time course of these processes, as well as about where in the brain these processes might be located.},
	urldate = {2021-11-30},
	journal = {Frontiers in Psychology},
	author = {Koelsch, Stefan},
	month = jun,
	year = {2011},
	pmid = {21713060},
	pmcid = {PMC3114071},
	pages = {110},
}

@article{pieter-jan_zero-training_2015,
	title = {Zero-{Training} for {Brain}-{Computer} {Interfaces}},
	volume = {9},
	issn = {1662-5188},
	url = {http://www.frontiersin.org/Community/AbstractDetails.aspx?ABS_DOI=10.3389/conf.fncom.2015.56.00017},
	doi = {10.3389/conf.fncom.2015.56.00017},
	urldate = {2021-11-26},
	journal = {Frontiers in Computational Neuroscience},
	author = {Pieter-Jan, Kindermans},
	year = {2015},
}

@article{lin_improving_2017,
	title = {Improving {EEG}-{Based} {Emotion} {Classification} {Using} {Conditional} {Transfer} {Learning}},
	volume = {11},
	issn = {1662-5161},
	url = {https://www.frontiersin.org/article/10.3389/fnhum.2017.00334},
	doi = {10.3389/fnhum.2017.00334},
	abstract = {To overcome the individual differences, an accurate electroencephalogram (EEG)-based emotion-classification system requires a considerable amount of ecological calibration data for each individual, which is labor-intensive and time-consuming. Transfer learning (TL) has drawn increasing attention in the field of EEG signal mining in recent years. The TL leverages existing data collected from other people to build a model for a new individual with little calibration data. However, brute-force transfer to an individual (i.e., blindly leveraged the labeled data from others) may lead to a negative transfer that degrades performance rather than improving it. This study thus proposed a conditional TL (cTL) framework to facilitate a positive transfer (improving subject-specific performance without increasing the labeled data) for each individual. The cTL first assesses an individual’s transferability for positive transfer and then selectively leverages the data from others with comparable feature spaces. The empirical results showed that among 26 individuals, the proposed cTL framework identified 16 and 14 transferable individuals who could benefit from the data from others for emotion valence and arousal classification, respectively. These transferable individuals could then leverage the data from 18 and 12 individuals who had similar EEG signatures to attain maximal TL improvements in valence- and arousal-classification accuracy. The cTL improved the overall classification performance of 26 individuals by {\textasciitilde}15\% for valence categorization and {\textasciitilde}12\% for arousal counterpart, as compared to their default performance based solely on the subject-specific data. This study evidently demonstrated the feasibility of the proposed cTL framework for improving an individual’s default emotion-classification performance given a data repository. The cTL framework may shed light on the development of a robust emotion-classification model using fewer labeled subject-specific data toward a real-life affective brain-computer interface (ABCI).},
	urldate = {2021-11-25},
	journal = {Frontiers in Human Neuroscience},
	author = {Lin, Yuan-Pin and Jung, Tzyy-Ping},
	year = {2017},
	pages = {334},
}

@inproceedings{lin_support_2008,
	title = {Support vector machine for {EEG} signal classification during listening to emotional music},
	doi = {10.1109/MMSP.2008.4665061},
	abstract = {An approach to recognize the emotion responses during multimedia presentation using the electroencephalogram (EEG) signals is proposed. The association between EEG signals and music-induced emotion responses was investigated in three factors, including: 1) the types of features, 2) the temporal resolutions of features, and 3) the components of EEG. The results showed that the spectrum power asymmetry index of EEG signal was a sensitive marker to reflect the brain activation related to emotion responses, especially for the low frequency bands of delta, theta and alpha components. Besides, the maximum classification accuracy was obtained around 92.73\% by using support vector machine (SVM) based on 60 features derived from all EEG components with the feature temporal resolution of one second. As such, it will be able to provide key clues to develop EEG-inspired multimedia applications, in which multimedia contents could be offered interactively according to the userspsila immediate feedback.},
	booktitle = {2008 {IEEE} 10th {Workshop} on {Multimedia} {Signal} {Processing}},
	author = {Lin, Yuan-Pin and Wang, Chi-Hong and Wu, Tien-Lin and Jeng, Shyh-Kang and Chen, Jyh-Horng},
	month = oct,
	year = {2008},
	keywords = {Accuracy, Electrodes, Electroencephalography, Emotion recognition, Feature extraction, Multimedia communication, Support vector machines},
	pages = {127--130},
}

@article{bradley_measuring_1994-1,
	title = {Measuring emotion: the {Self}-{Assessment} {Manikin} and the {Semantic} {Differential}},
	volume = {25},
	issn = {0005-7916},
	shorttitle = {Measuring emotion},
	doi = {10.1016/0005-7916(94)90063-9},
	abstract = {The Self-Assessment Manikin (SAM) is a non-verbal pictorial assessment technique that directly measures the pleasure, arousal, and dominance associated with a person's affective reaction to a wide variety of stimuli. In this experiment, we compare reports of affective experience obtained using SAM, which requires only three simple judgments, to the Semantic Differential scale devised by Mehrabian and Russell (An approach to environmental psychology, 1974) which requires 18 different ratings. Subjective reports were measured to a series of pictures that varied in both affective valence and intensity. Correlations across the two rating methods were high both for reports of experienced pleasure and felt arousal. Differences obtained in the dominance dimension of the two instruments suggest that SAM may better track the personal response to an affective stimulus. SAM is an inexpensive, easy method for quickly assessing reports of affective response in many contexts.},
	language = {eng},
	number = {1},
	journal = {Journal of Behavior Therapy and Experimental Psychiatry},
	author = {Bradley, M. M. and Lang, P. J.},
	month = mar,
	year = {1994},
	pmid = {7962581},
	keywords = {Adult, Affect, Arousal, Emotions, Factor Analysis, Statistical, Female, Humans, Internal-External Control, Male, Personality Inventory, Psychometrics, Semantic Differential},
	pages = {49--59},
}

@inproceedings{navarro_wearable_2004,
	title = {Wearable, wireless brain computer interfaces in augmented reality environments},
	volume = {2},
	doi = {10.1109/ITCC.2004.1286726},
	abstract = {After Pierre Gloor and Hans Berger discovered the human electroencephalogram or EEG produced in the brain in 1969, brain computer interfaces (BCIs) became a reality. However, for more than a couple of decades, besides the common social fascination with such devices, they have not yet been considered as a feasible alternative interface for common daily activities. This is attributed to issues such as response time, costs and long initial user training periods. We define and outlines the current BCI technologies and reviews the current status of BCIs in the context of wearable computers. The use of augmented reality environments and the integration of wireless technologies such as Bluetooth are proposed as potential catalysts in the process of incorporating BCIs into daily life.},
	booktitle = {International {Conference} on {Information} {Technology}: {Coding} and {Computing}, 2004. {Proceedings}. {ITCC} 2004.},
	author = {Navarro, K.F.},
	month = apr,
	year = {2004},
	keywords = {Augmented reality, Bluetooth, Brain computer interfaces, Costs, Delay, Electroencephalography, Electromyography, Humans, Signal processing, Wearable computers},
	pages = {643--647 Vol.2},
}

@article{cohen_analyzing_2014-1,
	title = {Analyzing {Neural} {Time} {Series} {Data}: {Theory} and {Practice}},
	shorttitle = {Analyzing {Neural} {Time} {Series} {Data}},
	url = {https://direct.mit.edu/books/book/4013/Analyzing-Neural-Time-Series-DataTheory-and},
	doi = {10.7551/mitpress/9609.001.0001},
	abstract = {A comprehensive guide to the conceptual, mathematical, and implementational aspects of analyzing electrical brain signals, including data from MEG, EEG, and LFP},
	language = {en},
	urldate = {2021-11-12},
	author = {Cohen, Mike X.},
	month = jan,
	year = {2014},
}

@inproceedings{thammasan_multimodal_2017-1,
	title = {Multimodal stability-sensitive emotion recognition based on brainwave and physiological signals},
	doi = {10.1109/ACIIW.2017.8272584},
	abstract = {This paper presents a framework for adaptive multimodal emotion recognition based on signal stability as a context. To verify the efficacy of the method, experiments were conducted using a dataset of brainwave and physiological signals (EEG, ECG, GSR) captured from nine subjects listening to music. The proposed method uses a combination of signal-based features as well as accelerometer data to quantify the approximate reliability of each modality. In contrast to existing approaches, unstable modalities are not rejected outright, instead their relative contribution is dynamically adapted based on a corresponding stability index. In the case of EEG, the stability index was calculated using an artifact rejection technique, while for the ECG and GSR modalities it was calculated based on body movement detected through accelerometers. The experimental results show that temporally varying the relative contribution of each modality can improve emotion recognition performance.},
	booktitle = {2017 {Seventh} {International} {Conference} on {Affective} {Computing} and {Intelligent} {Interaction} {Workshops} and {Demos} ({ACIIW})},
	author = {Thammasan, Nattapong and Hagad, Juan Lorenzo and Fukui, Ken-ichi and Numao, Masayuki},
	month = oct,
	year = {2017},
	keywords = {Accelerometers, Electrocardiography, Electroencephalography, Emotion recognition, Feature extraction, Music},
	pages = {44--49},
}

@inproceedings{thammasan_multimodal_2017-2,
	title = {Multimodal stability-sensitive emotion recognition based on brainwave and physiological signals},
	doi = {10.1109/ACIIW.2017.8272584},
	abstract = {This paper presents a framework for adaptive multimodal emotion recognition based on signal stability as a context. To verify the efficacy of the method, experiments were conducted using a dataset of brainwave and physiological signals (EEG, ECG, GSR) captured from nine subjects listening to music. The proposed method uses a combination of signal-based features as well as accelerometer data to quantify the approximate reliability of each modality. In contrast to existing approaches, unstable modalities are not rejected outright, instead their relative contribution is dynamically adapted based on a corresponding stability index. In the case of EEG, the stability index was calculated using an artifact rejection technique, while for the ECG and GSR modalities it was calculated based on body movement detected through accelerometers. The experimental results show that temporally varying the relative contribution of each modality can improve emotion recognition performance.},
	booktitle = {2017 {Seventh} {International} {Conference} on {Affective} {Computing} and {Intelligent} {Interaction} {Workshops} and {Demos} ({ACIIW})},
	author = {Thammasan, Nattapong and Hagad, Juan Lorenzo and Fukui, Ken-ichi and Numao, Masayuki},
	month = oct,
	year = {2017},
	keywords = {Accelerometers, Electrocardiography, Electroencephalography, Emotion recognition, Feature extraction, Music},
	pages = {44--49},
}

@article{reuderink_valence_2013-1,
	title = {Valence, arousal and dominance in the {EEG} during game play},
	volume = {6},
	doi = {10.1504/IJAACS.2013.050691},
	abstract = {In this paper, we describe our investigation of traces of naturally occurring emotions in electrical brain signals, that can be used to build interfaces that respond to our emotional state. This study confirms a number of known affective correlates in a realistic, uncontrolled environment for the emotions of valence (or pleasure), arousal and dominance: (1) a significant decrease in frontal power in the theta range is found for increasingly positive valence, (2) a significant frontal increase in power in the alpha range is associated with increasing emotional arousal, (3) a significant right posterior power increase in the delta range correlates with increasing arousal and (4) asymmetry in power in the lower alpha bands correlates with self-reported valence. Furthermore, asymmetry in the higher alpha bands correlates with self-reported dominance. These last two effects provide a simple measure for subjective feelings of pleasure and feelings of control.},
	journal = {International Journal of Autonomous and Adaptive Communications Systems},
	author = {Reuderink, Boris and Mühl, Christian and Poel, Mannes},
	month = dec,
	year = {2013},
	pages = {45--62},
}

@article{lin_eeg-based_2010-1,
	title = {{EEG}-{Based} {Emotion} {Recognition} in {Music} {Listening}},
	volume = {57},
	issn = {1558-2531},
	doi = {10.1109/TBME.2010.2048568},
	abstract = {Ongoing brain activity can be recorded as electroen-cephalograph (EEG) to discover the links between emotional states and brain activity. This study applied machine-learning algorithms to categorize EEG dynamics according to subject self-reported emotional states during music listening. A framework was proposed to optimize EEG-based emotion recognition by systematically 1) seeking emotion-specific EEG features and 2) exploring the efficacy of the classifiers. Support vector machine was employed to classify four emotional states (joy, anger, sadness, and pleasure) and obtained an averaged classification accuracy of 82.29\% ± 3.06\% across 26 subjects. Further, this study identified 30 subject-independent features that were most relevant to emotional processing across subjects and explored the feasibility of using fewer electrodes to characterize the EEG dynamics during music listening. The identified features were primarily derived from electrodes placed near the frontal and the parietal lobes, consistent with many of the findings in the literature. This study might lead to a practical system for noninvasive assessment of the emotional states in practical or clinical applications.},
	number = {7},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Lin, Yuan-Pin and Wang, Chi-Hong and Jung, Tzyy-Ping and Wu, Tien-Lin and Jeng, Shyh-Kang and Duann, Jeng-Ren and Chen, Jyh-Horng},
	month = jul,
	year = {2010},
	note = {Conference Name: IEEE Transactions on Biomedical Engineering},
	keywords = {Brain, EEG, Electrodes, Electroencephalography, Electromyography, Emotion recognition, Hospitals, Humans, IEEE activities, Support vector machine classification, Support vector machines, emotion, machine learning, music},
	pages = {1798--1806},
}

@article{ravaja_emotional_nodate,
	title = {Emotional effects of startling background music during reading news reports: {The} moderating influence of dispositional {BIS} and {BAS} sensitivities},
	volume = {45},
	issn = {0036-5564},
	shorttitle = {Emotional effects of startling background music during reading news reports},
	url = {https://www.academia.edu/17060372/Emotional_effects_of_startling_background_music_during_reading_news_reports_The_moderating_influence_of_dispositional_BIS_and_BAS_sensitivities},
	abstract = {We examined the moderating influence of dispositional behavioral inhibition system (BIS) and behavioral activation system (BAS) sensitivities on the relationship of startling background music with emotion-related subjective and physiological},
	number = {3},
	urldate = {2021-09-10},
	journal = {Scandinavian Journal of Psychology},
	author = {Ravaja, Niklas and Kallinen, Kari},
	pages = {231--238},
}

@article{inanaga_frontal_1998,
	title = {Frontal midline theta rhythm and mental activity},
	volume = {52},
	issn = {1440-1819},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1440-1819.1998.00452.x},
	doi = {10.1046/j.1440-1819.1998.00452.x},
	abstract = {Theta rhythm at the midline of the frontal area can be observed in normal subjects, during mental task performance, rest and sleep. Frontal midline theta rhythm (Fm θ) is a train of rhythmic waves at the frequency of 6–7 Hz and can be induced by various mental tasks. Fm θ is induced not only during mental tasks but also during nocturnal sleep in which it was most frequent during rapid eye movement (REM) and second most frequent during stage 1 of non-REM (NREM) sleep, and the relationship of Fm θ to dream images during sleep was found. It is concluded, therefore, that the appearance of Fm θ is related to mental activity even during sleep. Fm θ shows individual differences and is related to certain personality traits. High Fm θ groups showed the lowest anxiety score in the Manifest Anxiety Scale (MAS), the highest score in the extrovertive scale of the Maudsley Personality Inventory (MPI) and the lowest score in the neurotic scale of MPI. Low Fm θ groups showed the opposite correlation. Significant negative correlation was found between the amount of Fm θ and platelet monoamine oxidase (MAO) activity. Summarizing the above-mentioned results, it may be concluded that the appearance of Fm θ is related to mental activity, personality traits and platelet MAO activity. Furthermore, the correlation of such markers as platelet MAO activity and Fm θ with personality traits as measured by various psychological tests may prove to be of great importance in the exploration of the biological bases of personality.},
	language = {en},
	number = {6},
	urldate = {2021-09-09},
	journal = {Psychiatry and Clinical Neurosciences},
	author = {Inanaga, Kazutoyo},
	year = {1998},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1046/j.1440-1819.1998.00452.x},
	keywords = {EEG, mental activity, monoamine oxidase, personality, theta rhythm},
	pages = {555--566},
}

@article{ishii_frontal_2014,
	title = {Frontal midline theta rhythm and gamma power changes during focused attention on mental calculation: an {MEG} beamformer analysis},
	volume = {8},
	issn = {1662-5161},
	shorttitle = {Frontal midline theta rhythm and gamma power changes during focused attention on mental calculation},
	url = {https://www.frontiersin.org/article/10.3389/fnhum.2014.00406},
	doi = {10.3389/fnhum.2014.00406},
	abstract = {Frontal midline theta rhythm (Fmθ) appears widely distributed over medial prefrontal areas in EEG recordings, indicating focused attention. Although mental calculation is often used as an attention-demanding task, little has been reported on calculation-related activation in Fmθ experiments. In this study we used spatially filtered MEG and permutation analysis to precisely localize cortical generators of the magnetic counterpart of Fmθ, as well as other sources of oscillatory activity associated with mental calculation processing (i.e., arithmetic subtraction). Our results confirmed and extended earlier EEG/MEG studies indicating that Fmθ during mental calculation is generated in the dorsal anterior cingulate and adjacent medial prefrontal cortex. Mental subtraction was also associated with gamma event-related synchronization, as an index of activation, in right parietal regions subserving basic numerical processing and number-based spatial attention. Gamma event-related desynchronization appeared in the right lateral prefrontal cortex, likely representing a mechanism to interrupt neural activity that can interfere with the ongoing cognitive task.},
	urldate = {2021-09-09},
	journal = {Frontiers in Human Neuroscience},
	author = {Ishii, Ryouhei and Canuet, Leonides and Ishihara, Tsutomu and Aoki, Yasunori and Ikeda, Shunichiro and Hata, Masahiro and Katsimichas, Themistoklis and Gunji, Atsuko and Takahashi, Hidetoshi and Nakahachi, Takayuki and Iwase, Masao and Takeda, Masatoshi},
	year = {2014},
	pages = {406},
}

@article{hernandez-olivan_music_2021,
	title = {Music {Composition} with {Deep} {Learning}: {A} {Review}},
	shorttitle = {Music {Composition} with {Deep} {Learning}},
	url = {http://arxiv.org/abs/2108.12290},
	abstract = {Generating a complex work of art such as a musical composition requires exhibiting true creativity that depends on a variety of factors that are related to the hierarchy of musical language. Music generation have been faced with Algorithmic methods and recently, with Deep Learning models that are being used in other fields such as Computer Vision. In this paper we want to put into context the existing relationships between AI-based music composition models and human musical composition and creativity processes. We give an overview of the recent Deep Learning models for music composition and we compare these models to the music composition process from a theoretical point of view. We have tried to answer some of the most relevant open questions for this task by analyzing the ability of current Deep Learning models to generate music with creativity or the similarity between AI and human composition processes, among others.},
	urldate = {2021-09-08},
	journal = {arXiv:2108.12290 [cs, eess]},
	author = {Hernandez-Olivan, Carlos and Beltran, Jose R.},
	month = sep,
	year = {2021},
	note = {arXiv: 2108.12290},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
}

@article{liu_real-time_2018,
	title = {Real-{Time} {Movie}-{Induced} {Discrete} {Emotion} {Recognition} from {EEG} {Signals}},
	volume = {9},
	issn = {1949-3045},
	doi = {10.1109/TAFFC.2017.2660485},
	abstract = {Recognition of a human's continuous emotional states in real time plays an important role in machine emotional intelligence and human-machine interaction. Existing real-time emotion recognition systems use stimuli with low ecological validity (e.g., picture, sound) to elicit emotions and to recognise only valence and arousal. To overcome these limitations, in this paper, we construct a standardised database of 16 emotional film clips that were selected from over one thousand film excerpts. Based on emotional categories that are induced by these film clips, we propose a real-time movie-induced emotion recognition system for identifying an individual's emotional states through the analysis of brain waves. Thirty participants took part in this study and watched 16 standardised film clips that characterise real-life emotional experiences and target seven discrete emotions and neutrality. Our system uses a 2-s window and a 50 percent overlap between two consecutive windows to segment the EEG signals. Emotional states, including not only the valence and arousal dimensions but also similar discrete emotions in the valence-arousal coordinate space, are predicted in each window. Our real-time system achieves an overall accuracy of 92.26 percent in recognising high-arousal and valenced emotions from neutrality and 86.63 percent in recognising positive from negative emotions. Moreover, our system classifies three positive emotions (joy, amusement, tenderness) with an average of 86.43 percent accuracy and four negative emotions (anger, disgust, fear, sadness) with an average of 65.09 percent accuracy. These results demonstrate the advantage over the existing state-of-the-art real-time emotion recognition systems from EEG signals in terms of classification accuracy and the ability to recognise similar discrete emotions that are close in the valence-arousal coordinate space.},
	number = {4},
	journal = {IEEE Transactions on Affective Computing},
	author = {Liu, Yong-Jin and Yu, Minjing and Zhao, Guozhen and Song, Jinjing and Ge, Yan and Shi, Yuanchun},
	month = oct,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Affective Computing},
	keywords = {Affective computing, Brain models, EEG, Electroencephalography, Emotion recognition, Films, Real-time systems, Support vector machines, emotion recognition, movie},
	pages = {550--562},
}

@article{etzel_cardiovascular_2006,
	series = {Psychophiosology and {Cognitive} {Neuroscience}},
	title = {Cardiovascular and respiratory responses during musical mood induction},
	volume = {61},
	issn = {0167-8760},
	url = {https://www.sciencedirect.com/science/article/pii/S0167876005002850},
	doi = {10.1016/j.ijpsycho.2005.10.025},
	abstract = {Music is used to induce moods in experimental settings as well as for therapeutic purposes. Prior studies suggest that subjects listening to certain types of music experience strong moods and show physiological responses associated with the induced emotions. We hypothesized that cardiovascular and respiratory patterns could discriminate moods induced via music. 18 healthy subjects listened to 12 music clips, four each to induce happiness, sadness, and fear, while cardiovascular and respiratory responses were recorded using an electrocardiogram and chest strain-gauge belt. After each clip subjects completed a questionnaire. Subjects consistently reported experiencing the targeted mood, suggesting successful mood induction. Cardiovascular activity was measured by calculating time domain measures and heart rate changes during each clip. Respiratory activity was measured by total, inspiration, and expiration lengths as well as changes in mean respiration rate during each clip. Evaluation of individuals' patterns and mixed-model analyses were performed. Contrary to expectations, the time domain measures of subjects' cardiovascular responses did not vary significantly between the induced moods, although a heart rate deceleration was found during the sadness inductions and acceleration during the fear inductions. The time domain respiratory measures varied with clip type: the mean breath length was longest for the sad induction, intermediate during fear, and shortest during the happiness induction. However, analysis using normalized least mean squares adaptive filters to measure time correlation indicated that much of this difference may be attributable to entrainment of respiration to characteristics of the music which varied between the stimuli. Our findings point to the difficulty in detecting psychophysiological correlates of mood induction, and further suggest that part of this difficulty may arise from failure to differentiate it from tempo-related contributions when music is used as the inducer.},
	language = {en},
	number = {1},
	urldate = {2021-08-08},
	journal = {International Journal of Psychophysiology},
	author = {Etzel, Joset A. and Johnsen, Erica L. and Dickerson, Julie and Tranel, Daniel and Adolphs, Ralph},
	month = jul,
	year = {2006},
	keywords = {Cardiovascular and respiratory responses, Mood, Music},
	pages = {57--69},
}

@misc{noauthor_implicit_nodate,
	title = {Implicit and automated emotional tagging of videos {\textbar} {Semantic} {Scholar}},
	url = {https://www.semanticscholar.org/paper/Implicit-and-automated-emotional-tagging-of-videos-Soleymani/2c92e50293b3ef711ca0de5f7f352cecc60cc2ae},
	urldate = {2021-08-08},
}

@article{smith_hemispheric_1987,
	title = {Hemispheric asymmetry and emotion: {Lateralized} parietal processing of affect and cognition},
	volume = {25},
	issn = {0301-0511},
	shorttitle = {Hemispheric asymmetry and emotion},
	url = {https://www.sciencedirect.com/science/article/pii/0301051187900500},
	doi = {10.1016/0301-0511(87)90050-0},
	abstract = {The differential cerebral processing of affect and cognition may have important implications for a more general understanding of how these two complex sets of functions differ and how they interact. Building upon recent studies of hemispheric asymmetry in emotion, the present study focused on the differential parietal processing of emotional stimuli under affective and cognitive conditions. Subjects were exposed to neutral and emotional stimuli presented under cognitive and affective instructional sets. Bilateral electroencephalographic (EEG) data showed that the principal differentiation between affective and cognitive conditions occurred in the right hemisphere, whereas the highest overall level of activation during emotional stimulation was in the left hemisphere. It was also found that affective conditions produced higher of levels of both EEG and electrodermal activity than either cognitive or neutral conditions. Finally, significant patterns of gender differentiation suggested greater focal organization for affective arousal in females than males.},
	language = {en},
	number = {3},
	urldate = {2021-08-07},
	journal = {Biological Psychology},
	author = {Smith, Barry D. and Meyers, Marilyn and Kline, Robert and Bozman, Alan},
	month = dec,
	year = {1987},
	pages = {247--260},
}

@article{smith_hemispheric_1987-1,
	title = {Hemispheric asymmetry and emotion: {Lateralized} parietal processing of affect and cognition},
	volume = {25},
	issn = {0301-0511},
	shorttitle = {Hemispheric asymmetry and emotion},
	url = {https://www.sciencedirect.com/science/article/pii/0301051187900500},
	doi = {10.1016/0301-0511(87)90050-0},
	abstract = {The differential cerebral processing of affect and cognition may have important implications for a more general understanding of how these two complex sets of functions differ and how they interact. Building upon recent studies of hemispheric asymmetry in emotion, the present study focused on the differential parietal processing of emotional stimuli under affective and cognitive conditions. Subjects were exposed to neutral and emotional stimuli presented under cognitive and affective instructional sets. Bilateral electroencephalographic (EEG) data showed that the principal differentiation between affective and cognitive conditions occurred in the right hemisphere, whereas the highest overall level of activation during emotional stimulation was in the left hemisphere. It was also found that affective conditions produced higher of levels of both EEG and electrodermal activity than either cognitive or neutral conditions. Finally, significant patterns of gender differentiation suggested greater focal organization for affective arousal in females than males.},
	language = {en},
	number = {3},
	urldate = {2021-08-07},
	journal = {Biological Psychology},
	author = {Smith, Barry D. and Meyers, Marilyn and Kline, Robert and Bozman, Alan},
	month = dec,
	year = {1987},
	pages = {247--260},
}

@article{habibi_music_2014,
	title = {Music, feelings, and the human brain.},
	volume = {24},
	issn = {2162-1535, 0275-3987},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/pmu0000033},
	doi = {10.1037/pmu0000033},
	abstract = {Music of varied kinds consistently triggers a large range of drives and emotions, which, in turn, induce a particular class of mental experiences known as feelings. The feelings are often pleasurable, though not necessarily. Neuroimaging and electrophysiological studies, in normal individuals as well as in patients with focal neurological lesions, reveal that music can change the state of large-scale neural systems of the human brain. The changes are not confined to brain sectors related to auditory and motor processing; they also occur in regions related to the regulation of life processes (homeostasis), including those related to emotions and feelings, most prominently in the insula and cingulate cortices, in the ventral striatum, in the amygdala, and in certain upper brainstem nuclei. The ease with which music leads to feelings, the predictability with which it does so, the fact that human beings of many cultures actively seek and consume music, and the evidence that early humans engaged in music practices lead us to hypothesize that music has long had a consistent relation to the neural devices of human life regulation. It is conceivable that, as a result, music-induced feelings can be informative and nourishing at the individual level and can also operate as significant promoters of sociocultural organization. We venture that the close relationship between music and feelings along with music’s effectiveness in certain personal and social contexts, that is, its roles in homeostasis, explain, at least in part, the considerable degree of selection and replication of music-related phenomena, both biologically and culturally. As the invention of music forms continued and as intellectual analysis of compositions and reflection on music expanded, the practices and uses of music became less closely aligned with its affective and homeostatic aspects and, to a certain degree, gained autonomy relative to those aspects. This may account for the varied panorama of music invention, practice, and consumption that can be found today.},
	language = {en},
	number = {1},
	urldate = {2021-08-06},
	journal = {Psychomusicology: Music, Mind, and Brain},
	author = {Habibi, Assal and Damasio, Antonio},
	year = {2014},
	pages = {92--102},
}

@article{feurer_efficient_nodate,
	title = {Efficient and {Robust} {Automated} {Machine} {Learning}},
	abstract = {The success of machine learning in a broad range of applications has led to an ever-growing demand for machine learning systems that can be used off the shelf by non-experts. To be effective in practice, such systems need to automatically choose a good algorithm and feature preprocessing steps for a new dataset at hand, and also set their respective hyperparameters. Recent work has started to tackle this automated machine learning (AutoML) problem with the help of efﬁcient Bayesian optimization methods. Building on this, we introduce a robust new AutoML system based on scikit-learn (using 15 classiﬁers, 14 feature preprocessing methods, and 4 data preprocessing methods, giving rise to a structured hypothesis space with 110 hyperparameters). This system, which we dub AUTO-SKLEARN, improves on existing AutoML methods by automatically taking into account past performance on similar datasets, and by constructing ensembles from the models evaluated during the optimization. Our system won the ﬁrst phase of the ongoing ChaLearn AutoML challenge, and our comprehensive analysis on over 100 diverse datasets shows that it substantially outperforms the previous state of the art in AutoML. We also demonstrate the performance gains due to each of our contributions and derive insights into the effectiveness of the individual components of AUTO-SKLEARN.},
	language = {en},
	author = {Feurer, Matthias and Klein, Aaron and Eggensperger, Katharina and Springenberg, Jost and Blum, Manuel and Hutter, Frank},
	pages = {9},
}

@misc{noauthor_deap_nodate,
	title = {{DEAP}: {A} {Database} for {Emotion} {Analysis} ;{Using} {Physiological} {Signals} {\textbar} {IEEE} {Journals} \& {Magazine} {\textbar} {IEEE} {Xplore}},
	url = {https://ieeexplore.ieee.org/document/5871728},
	urldate = {2021-07-30},
}

@inproceedings{khosrowabadi_affective_2009,
	title = {Affective computation on {EEG} correlates of emotion from musical and vocal stimuli},
	doi = {10.1109/IJCNN.2009.5178748},
	abstract = {Affective interface that acquires and detects the emotion of the user can potentially enhance the human-computer interface experience. In this paper, an affective brain-computer interface (ABCI) is proposed to perform affective computation on electroencephalogram (EEG) correlates of emotion. The proposed ABCI extracts EEG features from subjects while exposed to 6 emotionally-related musical and vocal stimuli using kernel smoothing density estimation (KSDE) and Gaussian mixture model probability estimation (GMM). A classification algorithm is subsequently used to learn and classify the extracted EEG features. An inter-subject validation study is performed on healthy subjects to assess the performance of ABCI using a selection of classification algorithms. The results show that ABCI that employed the Bayesian network and the one-rule classifier yielded a promising inter-subject validation accuracy of 90\%.},
	booktitle = {2009 {International} {Joint} {Conference} on {Neural} {Networks}},
	author = {Khosrowabadi, Reza and Wahab, Abdul and Ang, Kai Keng and Baniasad, Mohammad H.},
	month = jun,
	year = {2009},
	note = {ISSN: 2161-4407},
	keywords = {Brain computer interfaces, Classification algorithms, Computer interfaces, Electroencephalography, Emotion recognition, Feature extraction, Heart rate, Humans, Neural networks, Speech},
	pages = {1590--1594},
}

@article{keelawat_spatiotemporal_2019,
	title = {Spatiotemporal {Emotion} {Recognition} using {Deep} {CNN} {Based} on {EEG} during {Music} {Listening}},
	url = {http://arxiv.org/abs/1910.09719},
	abstract = {Emotion recognition based on EEG has become an active research area. As one of the machine learning models, CNN has been utilized to solve diverse problems including issues in this domain. In this work, a study of CNN and its spatiotemporal feature extraction has been conducted in order to explore capabilities of the model in varied window sizes and electrode orders. Our investigation was conducted in subject-independent fashion. Results have shown that temporal information in distinct window sizes significantly affects recognition performance in both 10-fold and leave-one-subject-out cross validation. Spatial information from varying electrode order has modicum effect on classification. SVM classifier depending on spatiotemporal knowledge on the same dataset was previously employed and compared to these empirical results. Even though CNN and SVM have a homologous trend in window size effect, CNN outperformed SVM using leave-one-subject-out cross validation. This could be caused by different extracted features in the elicitation process.},
	urldate = {2021-07-30},
	journal = {arXiv:1910.09719 [cs, eess, stat]},
	author = {Keelawat, Panayu and Thammasan, Nattapong and Numao, Masayuki and Kijsirikul, Boonserm},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.09719},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing, Statistics - Machine Learning},
}

@article{zhang_human_2019,
	title = {Human {Mind} {Control} of {Rat} {Cyborg}’s {Continuous} {Locomotion} with {Wireless} {Brain}-to-{Brain} {Interface}},
	volume = {9},
	copyright = {2019 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-018-36885-0},
	doi = {10.1038/s41598-018-36885-0},
	abstract = {Brain-machine interfaces (BMIs) provide a promising information channel between the biological brain and external devices and are applied in building brain-to-device control. Prior studies have explored the feasibility of establishing a brain-brain interface (BBI) across various brains via the combination of BMIs. However, using BBI to realize the efficient multidegree control of a living creature, such as a rat, to complete a navigation task in a complex environment has yet to be shown. In this study, we developed a BBI from the human brain to a rat implanted with microelectrodes (i.e., rat cyborg), which integrated electroencephalogram-based motor imagery and brain stimulation to realize human mind control of the rat’s continuous locomotion. Control instructions were transferred from continuous motor imagery decoding results with the proposed control models and were wirelessly sent to the rat cyborg through brain micro-electrical stimulation. The results showed that rat cyborgs could be smoothly and successfully navigated by the human mind to complete a navigation task in a complex maze. Our experiments indicated that the cooperation through transmitting multidimensional information between two brains by computer-assisted BBI is promising.},
	language = {en},
	number = {1},
	urldate = {2021-07-21},
	journal = {Scientific Reports},
	author = {Zhang, Shaomin and Yuan, Sheng and Huang, Lipeng and Zheng, Xiaoxiang and Wu, Zhaohui and Xu, Kedi and Pan, Gang},
	month = feb,
	year = {2019},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Cognitive neuroscience;Motor control
Subject\_term\_id: cognitive-neuroscience;motor-control},
	pages = {1321},
}

@misc{noauthor_mikexcohencom_nodate,
	title = {mikexcohen.com},
	url = {https://www.mikexcohen.com/},
	urldate = {2021-07-21},
}

@book{ikehara_lecture_2013,
	title = {Lecture {Notes} in {Computer} {Science}},
	isbn = {978-3-642-39453-9},
	abstract = {The strategic goal of augmented cognition is to increase task performance capacity by using physiological sensor feedback to adjust or modify the activity for the user. Gamification has been shown to increase performance by using certain combinations of game elements. Both augmented cognition and gamification address increased task performance capacity. Gamification adds to augmented cognition by directly addressing the motivation of the user to remain engaged in the activity. This has also been referred to as flow, or the optimal experience. This paper describes an example of a gamified activity in which the physiological sensors of augmented cognition are used to foster the optimal experience desired in gamification. Also, discussed is how the strategic goals of augmented cognition and gamification overlap through the use of a gamified example that describes how the components of augmented cognition and elements of gamification can be used together to better achieve the goal of increased task performance capacity.},
	author = {Ikehara, Curtis and Crosby, Martha and Silva, Paula Alexandra},
	month = jul,
	year = {2013},
	doi = {10.1007/978-3-642-39454-6_72},
	note = {Pages: 684},
}

@misc{noauthor_brain_nodate,
	title = {The {Brain} {Facts} {Book}},
	url = {http://www.brainfacts.org:80/book},
	language = {en},
	urldate = {2021-07-16},
}

@book{glasgow_minimal_2018,
	title = {Minimal {Selfhood} and the {Origins} of {Consciousness}},
	copyright = {https://creativecommons.org/licenses/by-sa/4.0/deed.de},
	isbn = {978-3-95826-078-8 978-3-95826-079-5},
	url = {https://opus.bibliothek.uni-wuerzburg.de/frontdoor/index/index/docId/15747},
	abstract = {The aim of the book is to ground the logical origins of consciousness in what I have previously called the ‘minimal self’. The idea is that elementary forms of consciousness are logically dependent not, as is commonly assumed, on ownership of an anatomical brain or nervous system, but on the intrinsic reflexivity that defines minimal selfhood. The book seeks to trace the logical pathway by which minimal selfhood gives rise to the possible appearance of consciousness. It is argued that in specific circumstances it thus makes sense to ascribe elementary consciousness to certain predatory single-celled organisms such as amoebae and dinoflagellates as well as to some of the simpler animals. Such an argument involves establishing exactly what those specific circumstances are and determining how elementary consciousness differs in nature and scope from its more complex manifestations.},
	language = {eng},
	urldate = {2021-07-16},
	publisher = {Würzburg University Press},
	author = {Glasgow, Rupert},
	year = {2018},
	doi = {10.25972/WUP-978-3-95826-079-5},
}

@phdthesis{plass-oude_bos_making_2014,
	address = {Enschede, The Netherlands},
	type = {{PhD}},
	title = {Making brain-computer interfaces better : improving usability through post-processing},
	shorttitle = {Making brain-computer interfaces better},
	url = {http://purl.org/utwente/doi/10.3990/1.9789036537797},
	language = {en},
	urldate = {2021-07-16},
	school = {University of Twente},
	author = {Plass-Oude Bos, Danny},
	month = nov,
	year = {2014},
	doi = {10.3990/1.9789036537797},
	note = {ISBN: 9789036537797},
}

@book{glasgow_minimal_2018-1,
	title = {Minimal {Selfhood} and the {Origins} of {Consciousness}},
	copyright = {https://creativecommons.org/licenses/by-sa/4.0/deed.de},
	isbn = {9783958260788 9783958260795},
	url = {https://opus.bibliothek.uni-wuerzburg.de/frontdoor/index/index/docId/15747},
	abstract = {The aim of the book is to ground the logical origins of consciousness in what I have previously called the ‘minimal self’. The idea is that elementary forms of consciousness are logically dependent not, as is commonly assumed, on ownership of an anatomical brain or nervous system, but on the intrinsic reflexivity that defines minimal selfhood. The book seeks to trace the logical pathway by which minimal selfhood gives rise to the possible appearance of consciousness. It is argued that in specific circumstances it thus makes sense to ascribe elementary consciousness to certain predatory single-celled organisms such as amoebae and dinoflagellates as well as to some of the simpler animals. Such an argument involves establishing exactly what those specific circumstances are and determining how elementary consciousness differs in nature and scope from its more complex manifestations.},
	language = {eng},
	urldate = {2021-07-16},
	publisher = {Würzburg University Press},
	author = {Glasgow, Rupert},
	year = {2018},
	doi = {10.25972/WUP-978-3-95826-079-5},
}

@inproceedings{khosrowabadi_affective_2009-1,
	title = {Affective computation on {EEG} correlates of emotion from musical and vocal stimuli},
	doi = {10.1109/IJCNN.2009.5178748},
	abstract = {Affective interface that acquires and detects the emotion of the user can potentially enhance the human-computer interface experience. In this paper, an affective brain-computer interface (ABCI) is proposed to perform affective computation on electroencephalogram (EEG) correlates of emotion. The proposed ABCI extracts EEG features from subjects while exposed to 6 emotionally-related musical and vocal stimuli using kernel smoothing density estimation (KSDE) and Gaussian mixture model probability estimation (GMM). A classification algorithm is subsequently used to learn and classify the extracted EEG features. An inter-subject validation study is performed on healthy subjects to assess the performance of ABCI using a selection of classification algorithms. The results show that ABCI that employed the Bayesian network and the one-rule classifier yielded a promising inter-subject validation accuracy of 90\%.},
	booktitle = {2009 {International} {Joint} {Conference} on {Neural} {Networks}},
	author = {Khosrowabadi, Reza and Wahab, Abdul and Ang, Kai Keng and Baniasad, Mohammad H.},
	month = jun,
	year = {2009},
	note = {ISSN: 2161-4407},
	keywords = {Brain computer interfaces, Classification algorithms, Computer interfaces, Electroencephalography, Emotion recognition, Feature extraction, Heart rate, Humans, Neural networks, Speech},
	pages = {1590--1594},
}

@article{keelawat_spatiotemporal_2019-1,
	title = {Spatiotemporal {Emotion} {Recognition} using {Deep} {CNN} {Based} on {EEG} during {Music} {Listening}},
	url = {http://arxiv.org/abs/1910.09719},
	abstract = {Emotion recognition based on EEG has become an active research area. As one of the machine learning models, CNN has been utilized to solve diverse problems including issues in this domain. In this work, a study of CNN and its spatiotemporal feature extraction has been conducted in order to explore capabilities of the model in varied window sizes and electrode orders. Our investigation was conducted in subject-independent fashion. Results have shown that temporal information in distinct window sizes significantly affects recognition performance in both 10-fold and leave-one-subject-out cross validation. Spatial information from varying electrode order has modicum effect on classification. SVM classifier depending on spatiotemporal knowledge on the same dataset was previously employed and compared to these empirical results. Even though CNN and SVM have a homologous trend in window size effect, CNN outperformed SVM using leave-one-subject-out cross validation. This could be caused by different extracted features in the elicitation process.},
	urldate = {2021-07-12},
	journal = {arXiv:1910.09719 [cs, eess, stat]},
	author = {Keelawat, Panayu and Thammasan, Nattapong and Numao, Masayuki and Kijsirikul, Boonserm},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.09719},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing, Statistics - Machine Learning},
}

@inproceedings{sourina_fractal-based_2011,
	title = {A {Fractal}-based {Algorithm} of {Emotion} {Recognition} from {EEG} using {Arousal}-{Valence} {Model}},
	doi = {10.5220/0003151802090214},
	abstract = {Emotion recognition from EEG could be used in many applications as it allows us to know the “inner” emotion regardless of the human facial expression, behaviour, or verbal communication. In this paper, we proposed and described a novel fractal dimension (FD) based emotion recognition algorithm using an Arousal-Valence emotion model. FD values calculated from the EEG signal recorded from the corresponding brain lobes are mapped to the 2D emotion model. The proposed algorithm allows us to recognize emotions that could be defined by arousal and valence levels. Only 3 electrodes are needed for the emotions recognition. Higuchi and box-counting algorithms were used for the EEG analysis and comparison. Support Vector Machine classifier was applied for arousal and valence levels recognition. The proposed method is a subject dependent one. Experiments with music and sound stimuli to induce human emotions were realized. Sound clips from the International Affective Digitized Sounds (IADS) database were used in the experiments.},
	booktitle = {{BIOSIGNALS}},
	author = {Sourina, O. and Liu, Yisi},
	year = {2011},
}

@inproceedings{noauthor_fractal-based_2011,
	address = {Rome, Italy},
	title = {A {FRACTAL}-{BASED} {ALGORITHM} {OF} {EMOTION} {RECOGNITION} {FROM} {EEG} {USING} {AROUSAL}-{VALENCE} {MODEL}:},
	isbn = {978-989-8425-35-5},
	shorttitle = {A {FRACTAL}-{BASED} {ALGORITHM} {OF} {EMOTION} {RECOGNITION} {FROM} {EEG} {USING} {AROUSAL}-{VALENCE} {MODEL}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0003151802090214},
	doi = {10.5220/0003151802090214},
	language = {en},
	urldate = {2021-06-23},
	booktitle = {Proceedings of the {International} {Conference} on {Bio}-inspired {Systems} and {Signal} {Processing}},
	publisher = {SciTePress - Science and and Technology Publications},
	year = {2011},
	pages = {209--214},
}

@article{garg_emotion_2020,
	series = {Third {International} {Conference} on {Computing} and {Network} {Communications} ({CoCoNet}'19)},
	title = {Emotion {Recognition} in {Valence}-{Arousal} {Space} from {Multi}-channel {EEG} data and {Wavelet} based {Deep} {Learning} {Framework}},
	volume = {171},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050920310644},
	doi = {10.1016/j.procs.2020.04.093},
	abstract = {The conventional emotion recognition methods are mostly based on the frequency characteristics of electroencephalograph (EEG) signals. However, spatial features are likewise valuable as it contains latent information related to emotional states. In this paper, a wavelet-based Deep Learning framework proposed by considering both frequency and spatial characteristics of multi-channel EEG signal for emotion recognition. The Continuous Wavelet Transform is utilized to produce Scalogram, a function of frequency and time to getting better time localization for short-duration, high-frequency events, and better frequency localization for low-frequency, longer-duration events. Then, the GoogleNet model is presented to recognize emotion states from Scalogram. The experiments performed with benchmark DEAP database having a three-dimensional valence, arousal, and dominance data along with multi-channel EEG data. The experimental results demonstrate that the characteristics contained in the Scalogram were complementary, and GoogleNet is more suitable for emotion recognition in two/ three-dimension space.},
	language = {en},
	urldate = {2021-06-14},
	journal = {Procedia Computer Science},
	author = {Garg, Divya and Verma, Gyanendra K.},
	month = jan,
	year = {2020},
	keywords = {Affective Computing, CNN, DEAP database, EEG, GoogleNet, Scalograms, Wavelet Transform},
	pages = {857--867},
}

@inproceedings{wu_estimation_2017-1,
	title = {Estimation of valence of emotion using two frontal {EEG} channels},
	doi = {10.1109/BIBM.2017.8217815},
	abstract = {Emotion recognition using EEG signals has become a hot research topic in the last few years. This paper aims at providing a novel method for emotion recognition using less channels of frontal EEG signals. By employing the asymmetry theory of frontal brain, a new method fusing spatial and frequency features was presented, which only adopted two channels of frontal EEG signals at Fp1 and Fp2. In order to estimate the efficiency of the method, a GBDT classifier was evaluated and selected, and the method was implemented on the DEAP database. The maximum and mean classification accuracy were achieved as 76.34\% and 75.18\% respectively, which exhibited the best result comparing with other related studies. This method is extremely suitable for wearable EEG monitoring applications in human daily life.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Bioinformatics} and {Biomedicine} ({BIBM})},
	author = {Wu, Shiyi and Xu, Xiangmin and Shu, Lin and Hu, Bin},
	month = nov,
	year = {2017},
	keywords = {Biomedical monitoring, DEAP, Electroencephalography, Emotion recognition, Entropy, Feature extraction, Frontal EEG, GBDT classifier, Indexes},
	pages = {1127--1130},
}

@misc{noauthor_view_nodate,
	title = {View of {A} {Review} on {EEG} {Signals} {Based} {Emotion} {Recognition}},
	url = {https://journals.sbmu.ac.ir/neuroscience/article/view/18477/1},
	urldate = {2021-05-31},
}

@article{zhao_frontal_2018-1,
	title = {Frontal {EEG} {Asymmetry} and {Middle} {Line} {Power} {Difference} in {Discrete} {Emotions}},
	volume = {12},
	issn = {1662-5153},
	url = {https://www.frontiersin.org/articles/10.3389/fnbeh.2018.00225/full},
	doi = {10.3389/fnbeh.2018.00225},
	abstract = {A traditional model of emotion cannot explain the differences in brain activities between two discrete emotions that are similar in the valence-arousal coordinate space. The current study elicited two positive emotions (amusement and tenderness) and two negative emotions (anger and fear) that are similar in both valence and arousal dimensions to examine the differences in brain activities in these emotional states. Frontal electroencephalographic (EEG) asymmetry and midline power in three bands (theta, alpha, and beta) were measured when participants watched affective film excerpts. Significant differences were detected between tenderness and amusement on FP1/FP2 theta asymmetry, F3/F4 theta and alpha asymmetry. Significant differences between anger and fear on FP1/FP2 theta asymmetry and F3/F4 alpha asymmetry were also observed. For midline power, midline theta power could distinguish two negative emotions, while midline alpha and beta power could effectively differentiate two positive emotions. Liking and dominance were also related to EEG features. Stepwise multiple linear regression results revealed that frontal alpha and theta asymmetry could predict the subjective feelings of two positive and two negative emotions in different patterns. The binary classification accuracy, which used EEG frontal asymmetry and midline power as features and SVM as classifiers, was as high as 64.52\% for tenderness and amusement and 78.79\% for anger and fear. The classification accuracy was improved after adding these features to other features extracted across the scalp. These findings indicate that frontal EEG asymmetry and midline power might have the potential to recognize discrete emotions that are similar in the valence-arousal coordinate space.},
	language = {English},
	urldate = {2021-05-30},
	journal = {Frontiers in Behavioral Neuroscience},
	author = {Zhao, Guozhen and Zhang, Yulin and Ge, Yan},
	year = {2018},
	note = {Publisher: Frontiers},
	keywords = {Negative Staining, Positive emotions, discrete emotion, frontal EEG asymmetry, midline power},
}

@article{wang_emotion_2020,
	title = {Emotion recognition with convolutional neural network and {EEG}-based {EFDMs}},
	volume = {146},
	issn = {0028-3932},
	url = {https://www.sciencedirect.com/science/article/pii/S0028393220301780},
	doi = {10.1016/j.neuropsychologia.2020.107506},
	abstract = {Electroencephalogram (EEG), as a direct response to brain activity, can be used to detect mental states and physical conditions. Among various EEG-based emotion recognition studies, due to the non-linear, non-stationary and the individual difference of EEG signals, traditional recognition methods still have the disadvantages of complicated feature extraction and low recognition rates. Thus, this paper first proposes a novel concept of electrode-frequency distribution maps (EFDMs) with short-time Fourier transform (STFT). Residual block based deep convolutional neural network (CNN) is proposed for automatic feature extraction and emotion classification with EFDMs. Aim at the shortcomings of the small amount of EEG samples and the challenge of differences in individual emotions, which makes it difficult to construct a universal model, this paper proposes a cross-datasets emotion recognition method of deep model transfer learning. Experiments carried out on two publicly available datasets. The proposed method achieved an average classification score of 90.59\% based on a short length of EEG data on SEED, which is 4.51\% higher than the baseline method. Then, the pre-trained model was applied to DEAP through deep model transfer learning with a few samples, resulted an average accuracy of 82.84\%. Finally, this paper adopts the gradient weighted class activation mapping (Grad-CAM) to get a glimpse of what features the CNN has learned during training from EFDMs and concludes that the high frequency bands are more favorable for emotion recognition.},
	language = {en},
	urldate = {2021-05-30},
	journal = {Neuropsychologia},
	author = {Wang, Fei and Wu, Shichao and Zhang, Weiwei and Xu, Zongfeng and Zhang, Yahui and Wu, Chengdong and Coleman, Sonya},
	month = sep,
	year = {2020},
	pages = {107506},
}

@article{asghar_eeg-based_2019,
	title = {{EEG}-{Based} {Multi}-{Modal} {Emotion} {Recognition} using {Bag} of {Deep} {Features}: {An} {Optimal} {Feature} {Selection} {Approach}},
	volume = {19},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {{EEG}-{Based} {Multi}-{Modal} {Emotion} {Recognition} using {Bag} of {Deep} {Features}},
	url = {https://www.mdpi.com/1424-8220/19/23/5218},
	doi = {10.3390/s19235218},
	abstract = {Much attention has been paid to the recognition of human emotions with the help of electroencephalogram (EEG) signals based on machine learning technology. Recognizing emotions is a challenging task due to the non-linear property of the EEG signal. This paper presents an advanced signal processing method using the deep neural network (DNN) for emotion recognition based on EEG signals. The spectral and temporal components of the raw EEG signal are first retained in the 2D Spectrogram before the extraction of features. The pre-trained AlexNet model is used to extract the raw features from the 2D Spectrogram for each channel. To reduce the feature dimensionality, spatial, and temporal based, bag of deep features (BoDF) model is proposed. A series of vocabularies consisting of 10 cluster centers of each class is calculated using the k-means cluster algorithm. Lastly, the emotion of each subject is represented using the histogram of the vocabulary set collected from the raw-feature of a single channel. Features extracted from the proposed BoDF model have considerably smaller dimensions. The proposed model achieves better classification accuracy compared to the recently reported work when validated on SJTU SEED and DEAP data sets. For optimal classification performance, we use a support vector machine (SVM) and k-nearest neighbor (k-NN) to classify the extracted features for the different emotional states of the two data sets. The BoDF model achieves 93.8\% accuracy in the SEED data set and 77.4\% accuracy in the DEAP data set, which is more accurate compared to other state-of-the-art methods of human emotion recognition.},
	language = {en},
	number = {23},
	urldate = {2021-05-30},
	journal = {Sensors},
	author = {Asghar, Muhammad Adeel and Khan, Muhammad Jamil and Fawad and Amin, Yasar and Rizwan, Muhammad and Rahman, MuhibUr and Badnava, Salman and Mirjavadi, Seyed Sajad},
	month = jan,
	year = {2019},
	note = {Number: 23
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {bag of deep features, brain computer interface, continuous wavelet transform, emotion recognition},
	pages = {5218},
}

@article{chang_experiencing_2015-1,
	title = {Experiencing affective music in eyes-closed and eyes-open states: an electroencephalography study},
	volume = {6},
	issn = {1664-1078},
	shorttitle = {Experiencing affective music in eyes-closed and eyes-open states},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01160/full},
	doi = {10.3389/fpsyg.2015.01160},
	abstract = {In real life, listening to music may be associated with an eyes-closed or eyes-open state. The effect of eye state on listeners' reaction to music has attracted some attention, but its influence on brain activity has not been fully investigated. The present study aimed to evaluate the electroencephalographic (EEG) markers for the emotional valence of music in different eye states. Thirty participants listened to musical excerpts with different emotional content in the eyes-closed and eyes-open states. The results showed that participants rated the music as more pleasant or with more positive valence under an eyes-open state. In addition, we found that the alpha asymmetry indices calculated on the parietal and temporal sites reflected emotion valence in the eyes-closed and eyes-open states, respectively. The theta power in the frontal area significantly increased while listening to emotional-positive music compared to emotional-negative music under the eyes-closed condition. These effects of eye states on EEG markers are discussed in terms of brain mechanisms underlying attention and emotion.},
	language = {English},
	urldate = {2021-05-20},
	journal = {Frontiers in Psychology},
	author = {Chang, Yun-Hsuan and Lee, You-Yun and Liang, Keng-Chen and Chen, I.-Ping and Tsai, Chen-Gia and Hsieh, Shulan},
	year = {2015},
	note = {Publisher: Frontiers},
	keywords = {Alpha asymmetry, Electroencephalography, Music, emotional valence, eye state},
}

@misc{le_how_2017,
	title = {How to build a simple song recommender system},
	url = {https://towardsdatascience.com/how-to-build-a-simple-song-recommender-296fcbc8c85},
	abstract = {This blog post is inspired by Siraj Raval’s Deep Learning Foundation Nanodegree at Udacity. Then repo of this exercise can be found here.},
	language = {en},
	urldate = {2021-05-17},
	journal = {Medium},
	author = {Le, Eric},
	month = apr,
	year = {2017},
}

@article{kostas_bendr_2021,
	title = {{BENDR}: using transformers and a contrastive self-supervised learning task to learn from massive amounts of {EEG} data},
	shorttitle = {{BENDR}},
	url = {http://arxiv.org/abs/2101.12037},
	abstract = {Deep neural networks (DNNs) used for brain-computer-interface (BCI) classification are commonly expected to learn general features when trained across a variety of contexts, such that these features could be fine-tuned to specific contexts. While some success is found in such an approach, we suggest that this interpretation is limited and an alternative would better leverage the newly (publicly) available massive EEG datasets. We consider how to adapt techniques and architectures used for language modelling (LM), that appear capable of ingesting awesome amounts of data, towards the development of encephalography modelling (EM) with DNNs in the same vein. We specifically adapt an approach effectively used for automatic speech recognition, which similarly (to LMs) uses a self-supervised training objective to learn compressed representations of raw data signals. After adaptation to EEG, we find that a single pre-trained model is capable of modelling completely novel raw EEG sequences recorded with differing hardware, and different subjects performing different tasks. Furthermore, both the internal representations of this model and the entire architecture can be fine-tuned to a variety of downstream BCI and EEG classification tasks, outperforming prior work in more task-specific (sleep stage classification) self-supervision.},
	urldate = {2021-05-14},
	journal = {arXiv:2101.12037 [cs, q-bio]},
	author = {Kostas, Demetres and Aroca-Ouellette, Stephane and Rudzicz, Frank},
	month = jan,
	year = {2021},
	note = {arXiv: 2101.12037},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Quantitative Biology - Quantitative Methods},
}

@article{jerbi_coherent_2007,
	title = {Coherent neural representation of hand speed in humans revealed by {MEG} imaging},
	volume = {104},
	copyright = {© 2007 by The National Academy of Sciences of the USA},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/104/18/7676},
	doi = {10.1073/pnas.0609632104},
	abstract = {The spiking activity of single neurons in the primate motor cortex is correlated with various limb movement parameters, including velocity. Recent findings obtained using local field potentials suggest that hand speed may also be encoded in the summed activity of neuronal populations. At this macroscopic level, the motor cortex has also been shown to display synchronized rhythmic activity modulated by motor behavior. Yet whether and how neural oscillations might be related to limb speed control is still poorly understood. Here, we applied magnetoencephalography (MEG) source imaging to the ongoing brain activity in subjects performing a continuous visuomotor (VM) task. We used coherence and phase synchronization to investigate the coupling between the estimated activity throughout the brain and the simultaneously recorded instantaneous hand speed. We found significant phase locking between slow (2- to 5-Hz) oscillatory activity in the contralateral primary motor cortex and time-varying hand speed. In addition, we report long-range task-related coupling between primary motor cortex and multiple brain regions in the same frequency band. The detected large-scale VM network spans several cortical and subcortical areas, including structures of the frontoparietal circuit and the cerebello–thalamo–cortical pathway. These findings suggest a role for slow coherent oscillations in mediating neural representations of hand kinematics in humans and provide further support for the putative role of long-range neural synchronization in large-scale VM integration. Our findings are discussed in the context of corticomotor communication, distributed motor encoding, and possible implications for brain–machine interfaces.},
	language = {en},
	number = {18},
	urldate = {2021-05-14},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Jerbi, Karim and Lachaux, Jean-Philippe and N′Diaye, Karim and Pantazis, Dimitrios and Leahy, Richard M. and Garnero, Line and Baillet, Sylvain},
	month = may,
	year = {2007},
	pmid = {17442753},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {large-scale networks, magnetoencephalography, motor cortex, oscillations, visuomotor integration},
	pages = {7676--7681},
}

@inproceedings{liu_eeg_2013,
	title = {{EEG} {Databases} for {Emotion} {Recognition}},
	doi = {10.1109/CW.2013.52},
	abstract = {Emotion recognition from Electroencephalogram (EEG) rapidly gains interest from research community. Two affective EEG databases are presented in this paper. Two experiments are conducted to set up the databases. Audio and visual stimuli are used to evoke emotions during the experiments. The stimuli are selected from IADS and IAPS databases.14 subjects participated in each experiment. Emotiv EEG device is used for the data recording. The EEG data are rated by the participants with arousal, valence, and dominance levels. The correlation between powers of different EEG bands and the affective ratings is studied. The results agree with the literature findings and analyses of benchmark DEAP database that proves the reliability of the two databases. Similar brain patterns of emotions are obtained between the established databases and the benchmark database. A SVM-based emotion recognition algorithm is proposed and applied to both databases and the benchmark database. Use of a Fractal Dimension feature in combination with statistical and Higher Order Crossings (HOC) features gives us results with the best accuracy. Up to 8 emotions can be recognized. The accuracy is consistent between the established databases and the benchmark database.},
	booktitle = {2013 {International} {Conference} on {Cyberworlds}},
	author = {Liu, Yisi and Sourina, Olga},
	month = oct,
	year = {2013},
	keywords = {Correlation, Databases, EEG, Electrodes, Electroencephalography, Emotion recognition, Fractals, Visualization, affective computing, affective database, emotion recognition, fractal dimension},
	pages = {302--309},
}

@article{slutter_exploring_2021,
	title = {Exploring the {Brain} {Activity} {Related} to {Missing} {Penalty} {Kicks}: {An} {fNIRS} {Study}},
	volume = {3},
	issn = {2624-9898},
	shorttitle = {Exploring the {Brain} {Activity} {Related} to {Missing} {Penalty} {Kicks}},
	url = {https://www.frontiersin.org/articles/10.3389/fcomp.2021.661466/full},
	doi = {10.3389/fcomp.2021.661466},
	abstract = {At vital moments in professional soccer matches, penalties were often missed. Psychological factors, such as anxiety and pressure, are among the critical causes of the mistakes, commonly known as choking under pressure. Nevertheless, the factors have not been fully explored. In this study, we used functional near-infrared spectroscopy (fNIRS) to investigate the influence of the brain on this process. An in-situ study was set-up (N=22), in which each participant took 15 penalties under three different pressure conditions: without a goalkeeper, with an amiable goalkeeper, and with a competitive goalkeeper. Both experienced and inexperienced soccer players were recruited, and the brain activation was compared across groups. Besides, fNIRS activation was compared between sessions that participants felt anxious against sessions without anxiety report, and between penalty-scoring and -missing sessions. The results show that the task-relevant brain region, the motor cortex, was more activated when players were not experiencing performance anxiety. The activation of task-irrelevant areas was shown to be related to players experiencing anxiety and missing penalties, especially the prefrontal cortex (PFC). More particularly, an overall higher activation of the PFC and an increase of PFC lateral asymmetry were related to anxious players and missed penalties, which can be caused by players' worries about the consequences of scoring or missing the penalty kicks. When experienced players were feeling anxious, their left temporal cortex activation increased, which could be an indication that experienced overthink the situation and neglect their automated skills. Besides, the left temporal cortex activation is higher when inexperienced players succeeded to score a penalty. Overall, the results of this study are in line with the neural efficiency theory and demonstrate the feasibility and ecological validity to detect neurological clues relevant to anxiety and performance from fNIRS recordings in the field.},
	language = {English},
	urldate = {2021-05-07},
	journal = {Frontiers in Computer Science},
	author = {Slutter, Max W. J. and Thammasan, Nattapong and Poel, Mannes},
	year = {2021},
	note = {Publisher: Frontiers},
	keywords = {Football, Mental pressure, Penalty kick, Soccer, Sports, choking, fNIRS, neural efficiency},
}

@article{luo_data_2020,
	title = {Data {Augmentation} for {Enhancing} {EEG}-based {Emotion} {Recognition} with {Deep} {Generative} {Models}},
	url = {http://arxiv.org/abs/2006.05331},
	abstract = {The data scarcity problem in emotion recognition from electroencephalography (EEG) leads to difficulty in building an affective model with high accuracy using machine learning algorithms or deep neural networks. Inspired by emerging deep generative models, we propose three methods for augmenting EEG training data to enhance the performance of emotion recognition models. Our proposed methods are based on two deep generative models, variational autoencoder (VAE) and generative adversarial network (GAN), and two data augmentation strategies. For the full usage strategy, all of the generated data are augmented to the training dataset without judging the quality of the generated data, while for partial usage, only high-quality data are selected and appended to the training dataset. These three methods are called conditional Wasserstein GAN (cWGAN), selective VAE (sVAE), and selective WGAN (sWGAN). To evaluate the effectiveness of these methods, we perform a systematic experimental study on two public EEG datasets for emotion recognition, namely, SEED and DEAP. We first generate realistic-like EEG training data in two forms: power spectral density and differential entropy. Then, we augment the original training datasets with a different number of generated realistic-like EEG data. Finally, we train support vector machines and deep neural networks with shortcut layers to build affective models using the original and augmented training datasets. The experimental results demonstrate that the augmented training datasets produced by our methods enhance the performance of EEG-based emotion recognition models and outperform the existing data augmentation methods such as conditional VAE, Gaussian noise, and rotational data augmentation.},
	urldate = {2021-05-03},
	journal = {arXiv:2006.05331 [cs, eess]},
	author = {Luo, Yun and Zhu, Li-Zhen and Wan, Zi-Yu and Lu, Bao-Liang},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.05331
version: 2},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing},
}

@misc{noauthor_wayback_2016,
	title = {Wayback {Machine}},
	url = {https://web.archive.org/web/20160304190605/https://www2.bc.edu/~russeljm/publications/psyc-bull1991.pdf},
	urldate = {2021-04-22},
	month = mar,
	year = {2016},
}

@book{wagner_smart_nodate,
	title = {Smart {Sensor} {Integration}: {A} {Framework} for {Multimodal} {Emotion} {Recognition} in {Real}-{Time}},
	shorttitle = {Smart {Sensor} {Integration}},
	abstract = {Affect sensing by machines has been argued as an essential part of next-generation human-computer interaction (HCI). To this end, in the recent years a large number of studies have been conducted, which report automatic recognition of emotion as a difficult, but feasible task. However, most effort has been put towards offline analysis, whereas to date only few applications exist, which are able to react to a user’s emotion in real-time. In response to this deficit we introduce a framework we call Smart Sensor Integration (SSI), which considerably jump-starts the development of multimodal online emotion recognition (OER) systems. In particular SSI supports the pattern recognition pipeline by offering tailored tools for data segmentation, feature extraction, and pattern recognition, as well as, tools to apply them offline (training phase) and online (real-time recognition). Furthermore, it has been designed to handle input from various input modalities and to suit the fusion of multimodal information. 1.},
	author = {Wagner, Johannes and André, Elisabeth and Jung, Frank},
}

@article{amelynck_toward_2012,
	title = {Toward {E}-{Motion}-{Based} {Music} {Retrieval} a {Study} of {Affective} {Gesture} {Recognition}},
	volume = {3},
	issn = {1949-3045},
	doi = {10.1109/T-AFFC.2011.39},
	abstract = {The widespread availability of digitized music collections and mobile music players have enabled us to listen to music during many of our daily activities, such as physical exercise, commuting, relaxation, and many people enjoy this. A practical problem that comes along with the wish to listen to music is that of music retrieval, the selection of desired music from a music collection. In this paper, we propose a new approach to facilitate music retrieval. Modern smart phones are commonly used as music players and are already equipped with inertial sensors that are suitable for obtaining motion information. In the proposed approach, emotion is derived automatically from arm gestures and is used to query a music collection. We derive predictive models for valence and arousal from empirical data, gathered in an experimental setup where inertial data recorded from arm movements are coupled to musical emotion. Part of the experiment is a preliminary study confirming that human subjects are generally capable of recognizing affect from arm gestures. Model validation in the main study confirmed the predictive capabilities of the models.},
	number = {2},
	journal = {IEEE Transactions on Affective Computing},
	author = {Amelynck, D. and Grachten, M. and Noorden, L. van and Leman, M.},
	month = apr,
	year = {2012},
	note = {Conference Name: IEEE Transactions on Affective Computing},
	keywords = {Acceleration, Affect detection, Feature extraction, Humans, Observers, Predictive models, Sensors, Visualization, expressive gestures, human computer interfaces., music retrieval},
	pages = {250--259},
}

@article{irrgang_motion_2016,
	title = {From {Motion} to {Emotion}: {Accelerometer} {Data} {Predict} {Subjective} {Experience} of {Music}},
	volume = {11},
	shorttitle = {From {Motion} to {Emotion}},
	doi = {10.1371/journal.pone.0154360},
	abstract = {Music is often discussed to be emotional because it reflects expressive movements in audible form. Thus, a valid approach to measure musical emotion could be to assess movement stimulated by music. In two experiments we evaluated the discriminative power of mobile-device generated acceleration data produced by free movement during music listening for the prediction of ratings on the Geneva Emotion Music Scales (GEMS-9). The quality of prediction for different dimensions of GEMS varied between experiments for tenderness (R12(first experiment) = 0.50, R22(second experiment) = 0.39), nostalgia (R12 = 0.42, R22 = 0.30), wonder (R12 = 0.25, R22 = 0.34), sadness (R12 = 0.24, R22 = 0.35), peacefulness (R12 = 0.20, R22 = 0.35) and joy (R12 = 0.19, R22 = 0.33) and transcendence (R12 = 0.14, R22 = 0.00). For others like power (R12 = 0.42, R22 = 0.49) and tension (R12 = 0.28, R22 = 0.27) results could be almost reproduced. Furthermore, we extracted two principle components from GEMS ratings, one representing arousal and the other one valence of the experienced feeling. Both qualities, arousal and valence, could be predicted by acceleration data, indicating, that they provide information on the quantity and quality of experience. On the one hand, these findings show how music-evoked movement patterns relate to music-evoked feelings. On the other hand, they contribute to integrate findings from the field of embodied music cognition into music recommender systems.},
	journal = {PLOS ONE},
	author = {Irrgang, Melanie and Egermann, Hauke},
	month = jul,
	year = {2016},
	pages = {e0154360},
}

@article{morgan_using_2015,
	title = {Using affective and behavioural sensors to explore aspects of collaborative music making},
	volume = {82},
	issn = {1071-5819},
	url = {https://www.sciencedirect.com/science/article/pii/S1071581915000853},
	doi = {10.1016/j.ijhcs.2015.05.002},
	abstract = {Our research considers the role that new technologies could play in supporting emotional and non-verbal interactions between musicians during co-present music making. To gain a better understanding of the underlying affective and communicative processes that occur during such interactions, we carried out an exploratory study where we collected self-report and continuous behavioural and physiological measures from pairs of improvising drummers. Our analyses revealed interesting relationships between creative decisions and changes in heart rate. Self-reported measures of creativity, engagement, and energy were correlated with body motion; whilst EEG beta-band activity was correlated with self-reported positivity and leadership. Regarding co-visibility, lack of visual contact between musicians had a negative influence on self reported creativity. The number of glances between musicians was positively correlated with rhythmic synchrony, and the average length of glances was correlated with self-reported boredom. Our results indicate that ECG, motion, and glance measurements could be particularly suitable for the investigation of collaborative music making.},
	language = {en},
	urldate = {2021-03-30},
	journal = {International Journal of Human-Computer Studies},
	author = {Morgan, Evan and Gunes, Hatice and Bryan-Kinns, Nick},
	month = oct,
	year = {2015},
	keywords = {Affect, Collaboration, Creativity, Improvisation, Music, Psychophysiology},
	pages = {31--47},
}

@inproceedings{shibata_emotion_2012,
	title = {Emotion recognition modeling of sitting postures by using pressure sensors and accelerometers},
	abstract = {Not only facial expressions but also body gestures and postures play an important role in non-verbal communication. Facial expressions are based on two factors: arousal and pleasant emotions, while it is not clear that body gestures and postures have the same structure as the facial expressions have. We indicate that (1) the sitting postures have the same emotion structure as facial expressions and (2) can be measured by pressure sensors on a chair and accelerometers on the body, which predict the emotion factors. We find the sitting postures have the semantic factors: "arousal", "pleasantness", and "dominance", so emotion expressions of the sitting postures are similar to those of the facial expressions. Their difference is "dominance" expressed by not the main body but the body parts such as arms and legs. We conclude that (1) "arousal" and "pleasantness" factors can be measured with the proposed sensors and (2) the body trunk and the body parts: neck, arms, and legs are important.},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Pattern} {Recognition} ({ICPR2012})},
	author = {Shibata, T. and Kijima, Y.},
	month = nov,
	year = {2012},
	note = {ISSN: 1051-4651},
	keywords = {Accelerometers, Face, Legged locomotion, Neck, Pressure measurement, Semantics, Sensors},
	pages = {1124--1127},
}

@inproceedings{quiroz_emotion-recognition_2017,
	address = {New York, NY, USA},
	series = {{UbiComp} '17},
	title = {Emotion-recognition using smart watch accelerometer data: preliminary findings},
	isbn = {978-1-4503-5190-4},
	shorttitle = {Emotion-recognition using smart watch accelerometer data},
	url = {https://doi.org/10.1145/3123024.3125614},
	doi = {10.1145/3123024.3125614},
	abstract = {This study investigates the use of accelerometer data from a smart watch to infer an individual's emotional state. We present our preliminary findings on a user study with 50 participants. Participants were primed either with audio-visual (movie clips) or audio (classical music) to elicit emotional responses. Participants then walked while wearing a smart watch on one wrist and a heart rate strap on their chest. Our hypothesis is that the accelerometer signal will exhibit different patterns for participants in response to different emotion priming. We divided the accelerometer data using sliding windows, extracted features from each window, and used the features to train supervised machine learning algorithms to infer an individual's emotion from their walking pattern. Our discussion includes a description of the methodology, data collected, and early results.},
	urldate = {2021-03-30},
	booktitle = {Proceedings of the 2017 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} and {Proceedings} of the 2017 {ACM} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {Association for Computing Machinery},
	author = {Quiroz, Juan C. and Yong, Min Hooi and Geangu, Elena},
	month = sep,
	year = {2017},
	keywords = {accelerometer, emotion-recognition, supervised learning},
	pages = {805--812},
}

@misc{noauthor_top_2014,
	title = {Top 7 {Weirdest} {EEG} {Applications} - {Neuroelectrics} {Neuroelectrics} {Blog} - {Latest} news about {EEG} \& {Brain} {Stimulation}},
	url = {https://www.neuroelectrics.com/blog/2014/12/18/top-7-weirdest-eeg-applications/},
	abstract = {As we know, the main uses of EEG include diagnosis and neurofeedback therapy (including BCI). Theses applications falls into the clinical realm, but...},
	language = {en-US},
	urldate = {2021-03-29},
	journal = {Neuroelectrics Blog - Latest news about EEG \& Brain Stimulation},
	month = dec,
	year = {2014},
}

@book{poli_towards_2013,
	title = {Towards cooperative brain-computer interfaces for space navigation},
	isbn = {978-1-4503-1965-2},
	abstract = {We explored the possibility of controlling a spacecraft simulator using an analogue Brain-Computer Interface (BCI) for 2-D pointer control. This is a difficult task, for which no previous attempt has been reported in the literature. Our system relies on an active display which produces event-related potentials (ERPs) in the user's brain. These are analysed in real-time to produce control vectors for the user interface. In tests, users of the simulator were told to pass as close as possible to the Sun. Performance was very promising, on average users managing to satisfy the simulation success criterion in 67.5\% of the runs. Furthermore, to study the potential of a collaborative approach to spacecraft navigation, we developed BCIs where the system is controlled via the integration of the ERPs of two users. Performance analysis indicates that collaborative BCIs produce trajectories that are statistically significantly superior to those obtained by single users.},
	author = {Poli, Riccardo and Cinel, Caterina and Matran-Fernandez, Ana and Sepulveda, Francisco and Stoica, Adrian},
	month = mar,
	year = {2013},
	doi = {10.1145/2449396.2449417},
	note = {Journal Abbreviation: International Conference on Intelligent User Interfaces, Proceedings IUI
Pages: 160
Publication Title: International Conference on Intelligent User Interfaces, Proceedings IUI},
}

@article{stevens_neurophysiologic_2010,
	title = {A {Neurophysiologic} {Approach} {For} {Studying} {Team} {Cognition}},
	language = {en},
	author = {Stevens, Ron and Galloway, Trysha and Berka, Chris and Behneman, Adrienne},
	year = {2010},
	pages = {7},
}

@article{bonnet_two_2013,
	title = {Two {Brains}, {One} {Game}: {Design} and {Evaluation} of a {Multiuser} {BCI} {Video} {Game} {Based} on {Motor} {Imagery}},
	volume = {5},
	issn = {1943-068X, 1943-0698},
	shorttitle = {Two {Brains}, {One} {Game}},
	url = {http://ieeexplore.ieee.org/document/6400237/},
	doi = {10.1109/TCIAIG.2012.2237173},
	abstract = {How can we connect two brains to a video game by means of a BCI, and what will happen when we do so? How will the two users behave, and how will they perceive this novel common experience? In this paper we are concerned with the design and evaluation of multi-user BCI applications. We created a multi-user videogame called “BrainArena” in which two users can play a simple football game by means of two BCIs. They can score goals on the left or right side of the screen by simply imagining left or right hand movements. To add another interesting element, the gamers can play in a collaborative manner (their two mental activities are combined to score in the same goal), or in a competitive manner (the gamers must push the ball in opposite directions). Two experiments were conducted to evaluate the performance and subjective experience of users in the different conditions. In the ﬁrst experiment we compared single-user situation with one multiuser situation: the collaborative task. Experiment 1 showed that multi-user conditions are signiﬁcantly preferred in terms of fun and motivation compared to the single-user condition. The performance of some users was even signiﬁcantly improved in the multi-user condition. A subset of well-performing subjects was involved in the second experiment, where we added the competitive task. Experiment 2 suggested that competitive and collaborative conditions may lead to similar performances and motivations. However the corresponding gaming experiences can be perceived differently among the participants. Taken together our results suggest that multi-user BCI applications can be operational, effective, and more engaging for participants.},
	language = {en},
	number = {2},
	urldate = {2021-03-28},
	journal = {IEEE Transactions on Computational Intelligence and AI in Games},
	author = {Bonnet, Laurent and Lotte, Fabien and Lecuyer, Anatole},
	month = jun,
	year = {2013},
	pages = {185--198},
}

@article{lin_eeg-based_2010,
	title = {{EEG}-{Based} {Emotion} {Recognition} in {Music} {Listening}},
	volume = {57},
	issn = {1558-2531},
	doi = {10.1109/TBME.2010.2048568},
	abstract = {Ongoing brain activity can be recorded as electroen-cephalograph (EEG) to discover the links between emotional states and brain activity. This study applied machine-learning algorithms to categorize EEG dynamics according to subject self-reported emotional states during music listening. A framework was proposed to optimize EEG-based emotion recognition by systematically 1) seeking emotion-specific EEG features and 2) exploring the efficacy of the classifiers. Support vector machine was employed to classify four emotional states (joy, anger, sadness, and pleasure) and obtained an averaged classification accuracy of 82.29\% ± 3.06\% across 26 subjects. Further, this study identified 30 subject-independent features that were most relevant to emotional processing across subjects and explored the feasibility of using fewer electrodes to characterize the EEG dynamics during music listening. The identified features were primarily derived from electrodes placed near the frontal and the parietal lobes, consistent with many of the findings in the literature. This study might lead to a practical system for noninvasive assessment of the emotional states in practical or clinical applications.},
	number = {7},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Lin, Y. and Wang, C. and Jung, T. and Wu, T. and Jeng, S. and Duann, J. and Chen, J.},
	month = jul,
	year = {2010},
	note = {Conference Name: IEEE Transactions on Biomedical Engineering},
	keywords = {Adult, Algorithms, Artificial Intelligence, Bayes Theorem, Brain, EEG, EEG based emotion recognition, Electrodes, Electroencephalography, Electromyography, Emotion recognition, Emotions, Evoked Potentials, Auditory, Female, Hospitals, Humans, IEEE activities, Male, Music, Pattern Recognition, Automated, Signal Processing, Computer-Assisted, Support vector machine classification, Support vector machines, auditory evoked potentials, brain activity, electroencephalography, emotion, emotion recognition, emotional state, frontal lobe, learning (artificial intelligence), machine learning, machine learning algorithm, medical signal processing, music, music listening, parietal lobe, support vector machine, support vector machines},
	pages = {1798--1806},
}

@article{hasanzadeh_continuous_2019,
	title = {Continuous {Emotion} {Recognition} during {Music} {Listening} {Using} {EEG} {Signals}: {A} {Fuzzy} {Parallel} {Cascades} {Model}},
	shorttitle = {Continuous {Emotion} {Recognition} during {Music} {Listening} {Using} {EEG} {Signals}},
	url = {http://arxiv.org/abs/1910.10489},
	abstract = {A controversial issue in artificial intelligence is human emotion recognition. This paper presents a fuzzy parallel cascades (FPC) model for predicting the continuous subjective appraisal of the emotional content of music by time-varying spectral content of EEG signals. The EEG, along with an emotional appraisal of 15 subjects, was recorded during listening to seven musical excerpts. The emotional appraisement was recorded along the valence and arousal emotional axes as a continuous signal. The FPC model was composed of parallel cascades with each cascade containing a fuzzy logic-based system. The FPC model performance was evaluated by comparing with linear regression (LR), support vector regression (SVR) and Long Short Term Memory recurrent neural network (LSTM RNN) models. The RMSE of the FPC was lower than other models for the estimation of both valence and arousal of all musical excerpts. The lowest RMSE was 0.089 which was obtained in estimation of the valence of MS4 by the FPC model. The analysis of MI of frontal EEG with the valence confirms the role of frontal channels in theta frequency band in emotion recognition. Considering the dynamic variations of musical features during songs, employing a modeling approach to predict dynamic variations of the emotional appraisal can be a plausible substitute for the classification of musical excerpts into predefined labels.},
	urldate = {2021-03-24},
	journal = {arXiv:1910.10489 [cs, eess, q-bio]},
	author = {Hasanzadeh, Fatemeh and Annabestani, Mohsen and Moghimi, Sahar},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.10489},
	keywords = {Computer Science - Human-Computer Interaction, Electrical Engineering and Systems Science - Signal Processing, Quantitative Biology - Neurons and Cognition},
}

@inproceedings{zhang_pmemo_2018,
	address = {New York, NY, USA},
	series = {{ICMR} '18},
	title = {The {PMEmo} {Dataset} for {Music} {Emotion} {Recognition}},
	isbn = {978-1-4503-5046-4},
	url = {https://doi.org/10.1145/3206025.3206037},
	doi = {10.1145/3206025.3206037},
	abstract = {Music Emotion Recognition (MER) has recently received considerable attention. To support the MER research which requires large music content libraries, we present the PMEmo dataset containing emotion annotations of 794 songs as well as the simultaneous electrodermal activity (EDA) signals. A Music Emotion Experiment was well-designed for collecting the affective-annotated music corpus of high quality, which recruited 457 subjects. The dataset is publically available to the research community, which is foremost intended for benchmarking in music emotion retrieval and recognition. To straightforwardly evaluate the methodologies for music affective analysis, it also involves pre-computed audio feature sets. In addition to that, manually selected chorus excerpts (compressed in MP3) of songs are provided to facilitate the development of chorus-related research. In this article, We describe in detail the resource acquisition, subject selection, experiment design and annotation collection procedures, as well as the dataset content and data reliability analysis. We also illustrate its usage in some simple music emotion recognition tasks which testified the PMEmo dataset's competence for the MER work. Compared to other homogeneous datasets, PMEmo is novel in the organization and management of the recruited annotators, and it is also characterized by its large amount of music with simultaneous physiological signals.},
	urldate = {2021-03-24},
	booktitle = {Proceedings of the 2018 {ACM} on {International} {Conference} on {Multimedia} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Kejun and Zhang, Hui and Li, Simeng and Yang, Changyuan and Sun, Lingyun},
	month = jun,
	year = {2018},
	keywords = {dataset, eda, experiment, music emotion recognition},
	pages = {135--142},
}

@article{hasson_neurocinematics_2008,
	title = {Neurocinematics: {The} {Neuroscience} of {Film}},
	volume = {2},
	shorttitle = {Neurocinematics},
	doi = {10.3167/proj.2008.020102},
	abstract = {This article describes a new method for assessing the effect of a given film on viewers' brain activity. Brain activity was measured using functional magnetic resonance imaging (fMRI) during free viewing of films, and inter-subject correlation analysis (ISC) was used to assess similarities in the spatiotemporal responses across viewers' brains during movie watching. Our results demonstrate that some films can exert considerable control over brain activity and eye movements. However, this was not the case for all types of motion picture sequences, and the level of control over viewers' brain activity differed as a function of movie content, editing, and directing style. We propose that ISC may be useful to film studies by providing a quantitative neuroscientific assessment of the impact of different styles of filmmaking on viewers' brains, and a valuable method for the film industry to better assess its products. Finally, we suggest that this method brings together two separate and largely unrelated disciplines, cognitive neuroscience and film studies, and may open the way for a new interdisciplinary field of “neurocinematic” studies.},
	journal = {Projections},
	author = {Hasson, Uri and Landesman, Ohad and Knappmeyer, Barbara and Vallines, Ignacio and Rubin, Nava and Heeger, David},
	month = jun,
	year = {2008},
	pages = {1--26},
}

@incollection{chisik_kessel_2018,
	address = {Cham},
	title = {Kessel {Run} - {A} {Cooperative} {Multiplayer} {SSVEP} {BCI} {Game}},
	volume = {215},
	isbn = {978-3-319-73061-5 978-3-319-73062-2},
	url = {http://link.springer.com/10.1007/978-3-319-73062-2_6},
	urldate = {2021-03-21},
	booktitle = {Intelligent {Technologies} for {Interactive} {Entertainment}},
	publisher = {Springer International Publishing},
	author = {Cruz, Inês and Moreira, Carlos and Poel, Mannes and Ferreira, Hugo and Nijholt, Anton},
	editor = {Chisik, Yoram and Holopainen, Jussi and Khaled, Rilla and Luis Silva, José and Alexandra Silva, Paula},
	year = {2018},
	doi = {10.1007/978-3-319-73062-2_6},
	note = {Series Title: Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
	pages = {77--95},
}

@incollection{chisik_kessel_2018-1,
	address = {Cham},
	title = {Kessel {Run} - {A} {Cooperative} {Multiplayer} {SSVEP} {BCI} {Game}},
	volume = {215},
	isbn = {978-3-319-73061-5 978-3-319-73062-2},
	url = {http://link.springer.com/10.1007/978-3-319-73062-2_6},
	urldate = {2021-03-21},
	booktitle = {Intelligent {Technologies} for {Interactive} {Entertainment}},
	publisher = {Springer International Publishing},
	author = {Cruz, Inês and Moreira, Carlos and Poel, Mannes and Ferreira, Hugo and Nijholt, Anton},
	editor = {Chisik, Yoram and Holopainen, Jussi and Khaled, Rilla and Luis Silva, José and Alexandra Silva, Paula},
	year = {2018},
	doi = {10.1007/978-3-319-73062-2_6},
	note = {Series Title: Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
	pages = {77--95},
}

@article{dikker_crowdsourcing_2021,
	title = {Crowdsourcing neuroscience: {Inter}-brain coupling during face-to-face interactions outside the laboratory},
	volume = {227},
	issn = {1053-8119},
	shorttitle = {Crowdsourcing neuroscience},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811920309216},
	doi = {10.1016/j.neuroimage.2020.117436},
	abstract = {When we feel connected or engaged during social behavior, are our brains in fact “in sync” in a formal, quantifiable sense? Most studies addressing this question use highly controlled tasks with homogenous subject pools. In an effort to take a more naturalistic approach, we collaborated with art institutions to crowdsource neuroscience data: Over the course of 5 years, we collected electroencephalogram (EEG) data from thousands of museum and festival visitors who volunteered to engage in a 10-min face-to-face interaction. Pairs of participants with various levels of familiarity sat inside the Mutual Wave Machine—an artistic neurofeedback installation that translates real-time correlations of each pair's EEG activity into light patterns. Because such inter-participant EEG correlations are prone to noise contamination, in subsequent offline analyses we computed inter-brain coupling using Imaginary Coherence and Projected Power Correlations, two synchrony metrics that are largely immune to instantaneous, noise-driven correlations. When applying these methods to two subsets of recorded data with the most consistent protocols, we found that pairs’ trait empathy, social closeness, engagement, and social behavior (joint action and eye contact) consistently predicted the extent to which their brain activity became synchronized, most prominently in low alpha ({\textasciitilde}7–10 Hz) and beta ({\textasciitilde}20–22 Hz) oscillations. These findings support an account where shared engagement and joint action drive coupled neural activity and behavior during dynamic, naturalistic social interactions. To our knowledge, this work constitutes a first demonstration that an interdisciplinary, real-world, crowdsourcing neuroscience approach may provide a promising method to collect large, rich datasets pertaining to real-life face-to-face interactions. Additionally, it is a demonstration of how the general public can participate and engage in the scientific process outside of the laboratory. Institutions such as museums, galleries, or any other organization where the public actively engages out of self-motivation, can help facilitate this type of citizen science research, and support the collection of large datasets under scientifically controlled experimental conditions. To further enhance the public interest for the out-of-the-lab experimental approach, the data and results of this study are disseminated through a website tailored to the general public (wp.nyu.edu/mutualwavemachine).},
	language = {en},
	urldate = {2021-03-21},
	journal = {NeuroImage},
	author = {Dikker, Suzanne and Michalareas, Georgios and Oostrik, Matthias and Serafimaki, Amalia and Kahraman, Hasibe Melda and Struiksma, Marijn E. and Poeppel, David},
	month = feb,
	year = {2021},
	keywords = {Brain-Computer-Interface Technology, Brain-to-brain synchrony, Hyperscanning, Inter-brain coupling, Neurofeedback, Oscillations, Real-world neuroscience},
	pages = {117436},
}

@incollection{nijholt_competing_2014,
	title = {Competing and {Collaborating} {Brains}: {Multi}-{Brain} {Computer} {Interfacing}},
	volume = {74},
	isbn = {978-3-319-10977-0},
	shorttitle = {Competing and {Collaborating} {Brains}},
	abstract = {In this chapter we survey the possibilities of brain-computer interface applications that assume two or more users, where at least one of the users’ brain activity is used as input to the application. Such ‘applications’ were already explored by artists who introduced artistic EEG applications in the early ‘seventies’ of the previous century. These early explorations were not yet supported by advanced signal process methods, simply because there was no computing support possible, and interest in artistic applications faded until it reappeared in more recent years. Research in neuroscience, signal processing, machine learning and applications in medical, assistive BCIs prevailed. It was supported by computer science that provided real-time and off-line processing to analyze and store large amounts of streaming or collected data. With the possibility to access cheap shared and distributed storage and processing power, as it became available in the last decade of the previous century and the first decade of this century, different kinds of BCI applications, following a general interest in digital games, interactive entertainment and social media, became visible. These are domains where experience, fun and emotions are more important than efficiency, robustness and control. BCI provides user and application with a new modality that can be manipulated and interpreted, in addition to other input modalities. This has been explored, but mostly from the point of view of a single user interacting with an application. In this chapter we look at BCI applications where more than one user is involved. Games are among the possible applications and there are already simple games where gamers compete or collaborate using brain signal information from one or more players. We consider extensions of current applications by looking at different types of multi-user games, including massively multi-player online role-playing games. We mention research —distinguishing between active and passive BCI—on multi-participant BCI in non-game contexts that provides us with information about the possibilities of collaborative and competitive multi-brain games and that allows us to develop a vision on such games. The results of the literature study are collected in a table where we distinguish between the various forms of interaction between players (participants) in collaborative and competitive games and team activities.},
	booktitle = {Intelligent {Systems} {Reference} {Library}},
	author = {Nijholt, Anton},
	month = nov,
	year = {2014},
	doi = {10.1007/978-3-319-10978-7_12},
	note = {Journal Abbreviation: Intelligent Systems Reference Library},
	pages = {313--335},
}

@inproceedings{nijholt_multi-brain_2016,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Multi-{Brain} {BCI}: {Characteristics} and {Social} {Interactions}},
	isbn = {978-3-319-39955-3},
	shorttitle = {Multi-{Brain} {BCI}},
	doi = {10.1007/978-3-319-39955-3_8},
	abstract = {We investigate various forms of face-to-face and multiparty interactions in the context of potential brain-computer interface interactions (BCI). BCI has been employed in clinical applications but more recently also in domestic and game and entertainment applications. This paper focusses on multi-party game applications. That is, BCI game applications that allow multiple users and different BCI paradigms to get a cooperative or competitive task done. Our observations are quite preliminary and not yet supported by experimental research. Nevertheless we think we have put forward steps to structure future BCI game research and to make connections with neuro-scientific social interaction research.},
	language = {en},
	booktitle = {Foundations of {Augmented} {Cognition}: {Neuroergonomics} and {Operational} {Neuroscience}},
	publisher = {Springer International Publishing},
	author = {Nijholt, Anton and Poel, Mannes},
	editor = {Schmorrow, Dylan D. and Fidopiastis, Cali M.},
	year = {2016},
	keywords = {Affective computing, Brain-computer interfaces, Games, Hyper scanning, Multi-brain computing, Neuroscience of social interaction},
	pages = {79--90},
}

@book{christensen_eeg_2018,
	title = {{EEG} emotion detection review},
	author = {Christensen, Lars and Abdullah, Mohamed},
	month = may,
	year = {2018},
	doi = {10.1109/CIBCB.2018.8404976},
	note = {Pages: 7},
}

@article{chang_personalized_2017,
	title = {A personalized music recommendation system based on electroencephalography feedback},
	volume = {76},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-015-3202-4},
	doi = {10.1007/s11042-015-3202-4},
	abstract = {Numerous domestic and foreign studies have demonstrated that music can relieve stress and that listening to music is one method of stress relief used presently. Although stress-relief music is available on the market, various music genres produce distinct effects on people. Clinical findings have indicated that approximately 30 \% of people listen to inappropriate music genres for relaxation and, consequently, their stress level increases. Therefore, to achieve the effect of stress relief, choosing the appropriate music genre is crucial. For example, a 70-year-old woman living in a military community since childhood might not consider general stress-relief music to be helpful in relieving stress, but when patriotic songs are played, her autonomic nervous system automatically relaxes because of her familiarity with the music style. Therefore, people have dissimilar needs regarding stress-relief music. In this paper, we proposed a personalized stress-relieving music recommendation system based on electroencephalography (EEG) feedback. The system structure comprises the following features: (a) automated music categorization, in which a new clustering algorithm, K-MeansH, is employed to precluster music and improve processing time; (b) the access and analysis of users’ EEG data to identify perceived stress-relieving music; and (c) personalized recommendations based on collaborative filtering and provided according to personal preferences. Experimental results indicated that the overall clustering effect of K-MeansH surpassed that of K-Means and K-Medoids by approximately 71 and 57 \%, respectively. In terms of accuracy, K-MeansH also surpassed K-Means and K-Medoids.},
	language = {en},
	number = {19},
	urldate = {2021-03-11},
	journal = {Multimedia Tools and Applications},
	author = {Chang, Hong-Yi and Huang, Shih-Chang and Wu, Jia-Hao},
	month = oct,
	year = {2017},
	pages = {19523--19542},
}

@article{keelawat_spatiotemporal_2019,
	title = {Spatiotemporal {Emotion} {Recognition} using {Deep} {CNN} {Based} on {EEG} during {Music} {Listening}},
	url = {http://arxiv.org/abs/1910.09719},
	abstract = {Emotion recognition based on EEG has become an active research area. As one of the machine learning models, CNN has been utilized to solve diverse problems including issues in this domain. In this work, a study of CNN and its spatiotemporal feature extraction has been conducted in order to explore capabilities of the model in varied window sizes and electrode orders. Our investigation was conducted in subject-independent fashion. Results have shown that temporal information in distinct window sizes significantly affects recognition performance in both 10-fold and leave-one-subject-out cross validation. Spatial information from varying electrode order has modicum effect on classification. SVM classifier depending on spatiotemporal knowledge on the same dataset was previously employed and compared to these empirical results. Even though CNN and SVM have a homologous trend in window size effect, CNN outperformed SVM using leave-one-subject-out cross validation. This could be caused by different extracted features in the elicitation process.},
	urldate = {2021-03-11},
	journal = {arXiv:1910.09719 [cs, eess, stat]},
	author = {Keelawat, Panayu and Thammasan, Nattapong and Numao, Masayuki and Kijsirikul, Boonserm},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.09719},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing, Statistics - Machine Learning},
}

@article{schmidt_frontal_2001,
	title = {Frontal brain electrical activity ({EEG}) distinguishes valence and intensity of musical emotions},
	volume = {15},
	issn = {0269-9931},
	url = {https://doi.org/10.1080/02699930126048},
	doi = {10.1080/02699930126048},
	abstract = {Using recent regional brain activation/emotion models as a theoretical framework, we examined whether the pattern of regional EEG activity distinguished emotions induced by musical excerpts which were known to vary in affective valence (i.e., positive vs. negative) and intensity (i.e., intense vs. calm) in a group of undergraduates. We found that the pattern of asymmetrical frontal EEG activity distinguished valence of the musical excerpts. Subjects exhibited greater relative left frontal EEG activity to joy and happy musical excerpts and greater relative right frontal EEG activity to fear and sad musical excerpts. We also found that, although the pattern of frontal EEG asymmetry did not distinguish the intensity of the emotions, the pattern of overall frontal EEG activity did, with the amount of frontal activity decreasing from fear to joy to happy to sad excerpts. These data appear to be the first to distinguish valence and intensity of musical emotions on frontal electrocortical measures.},
	number = {4},
	urldate = {2021-03-07},
	journal = {Cognition and Emotion},
	author = {Schmidt, Louis A. and Trainor, Laurel J.},
	month = jul,
	year = {2001},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/02699930126048},
	pages = {487--500},
}

@misc{november_16_what_nodate,
	title = {What is an ultrasonic cleaner and should you buy one?},
	url = {https://www.cyclingnews.com/features/what-is-an-ultrasonic-cleaner-and-should-you-buy-one/},
	abstract = {Is an ultrasonic cleaner the ultimate in drivetrain cleaning or does it come up a few chain scrubbers short?},
	language = {en},
	urldate = {2021-01-28},
	journal = {cyclingnews.com},
	author = {November 16, Colin Levitch and {2020}},
}

@misc{reports_ultrasonic_2020,
	title = {Ultrasonic {Cleaning} {Market} {Trends}, {Industry} {Analysis}, {Growth}},
	url = {https://www.openpr.com/news/2198754/ultrasonic-cleaning-market-trends-industry-analysis-growth},
	abstract = {Press release - Orion Market Reports - Ultrasonic Cleaning Market Trends, Industry Analysis, Growth and Forecast - 2025 - published on openPR.com},
	language = {en},
	urldate = {2021-01-28},
	author = {Reports, Orion Market},
	month = nov,
	year = {2020},
}

@article{maiorana_permanence_2016,
	title = {On the {Permanence} of {EEG} {Signals} for {Biometric} {Recognition}},
	volume = {11},
	issn = {1556-6021},
	doi = {10.1109/TIFS.2015.2481870},
	abstract = {Brain signals have been investigated for more than a century in the medical field. However, despite the broad interest in clinical applications, their use as a biometric identifier has been only recently considered by the scientific community. In this paper, we focus on the permanence across time of brain signals, specifically of electroencephalographic (EEG) signals, issue of paramount importance for the deployment of brain-based biometric recognition systems in real life, not yet fully addressed. In particular, we speculate about the stability of EEG features by analyzing the recognition performance that can be achieved when comparing EEG signals acquired during different sessions. We carry out an extensive set of experimental tests, performed on several EEG-based biometric systems over a large database, comprising three recordings taken from 50 healthy subjects in resting state conditions, acquired in a time span of approximately one month and a half. The results confirm that a significant level of permanence can be guaranteed.},
	number = {1},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Maiorana, E. and Rocca, D. La and Campisi, P.},
	month = jan,
	year = {2016},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Biometrics, Biometrics (access control), Brain modeling, Database, Databases, EEG signal, Electrodes, Electroencephalography, Feature extraction, Permanence, Scalp, biometric identifier, biometric recognition, biometrics (access control), brain signal, clinical application, database, electroencephalographic signal, electroencephalography, medical signal processing, permanence},
	pages = {163--175},
}

@article{bellet_metric_2015,
	title = {Metric {Learning}},
	volume = {9},
	issn = {1939-4608},
	url = {https://www.morganclaypool.com/doi/abs/10.2200/S00626ED1V01Y201501AIM030},
	doi = {10.2200/S00626ED1V01Y201501AIM030},
	number = {1},
	urldate = {2020-12-05},
	journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
	author = {Bellet, Aurélien and Habrard, Amaury and Sebban, Marc},
	month = jan,
	year = {2015},
	note = {Number: 1
Publisher: Morgan \& Claypool Publishers},
	pages = {1--151},
}

@book{plass-oude_bos_human-computer_2010,
	title = {Human-{Computer} {Interaction} for {BCI} {Games} {Usability} and {User} {Experience}},
	abstract = {Brain-computer interfaces (BCI) come with a lot of issues, such as delays, bad recognition, long training times, and cumbersome hardware. Gamers are a large potential target group for this new interaction modality, but why would healthy subjects want to use it? BCI provides a combination of information and features that no other input modality can offer. But for general acceptance of this technology, usability and user experience will need to be taken into account when designing such systems. This paper discusses the consequences of applying knowledge from Human-Computer Interaction (HCI) to the design of BCI for games. The integration of HCI with BCI is illustrated by research examples and showcases, intended to take this promising technology out of the lab. Future research needs to move beyond feasibility tests, to prove that BCI is also applicable in realistic, real-world settings.},
	author = {Plass-Oude Bos, Danny and Reuderink, Boris and Laar, Bram and Gürkök, Hayrettin and Mühl, Christian and Poel, Mannes and Heylen, Dirk and Nijholt, Anton},
	month = oct,
	year = {2010},
	doi = {10.1109/CW.2010.22},
	note = {Journal Abbreviation: Proceedings - 2010 International Conference on Cyberworlds, CW 2010
Pages: 281
Publication Title: Proceedings - 2010 International Conference on Cyberworlds, CW 2010},
}

@article{skola_embodied_2018,
	title = {Embodied {VR} environment facilitates motor imagery brain–computer interface training},
	volume = {75},
	issn = {0097-8493},
	url = {http://www.sciencedirect.com/science/article/pii/S009784931830089X},
	doi = {10.1016/j.cag.2018.05.024},
	abstract = {Motor imagery (MI) is the predominant control paradigm for brain–computer interfaces (BCIs). After sufficient effort is invested to the training, the accuracy of commands mediated by mental imagery of bodily movements grows to a satisfactory level. However, many issues with the MI-BCIs persist; e.g., low bit transfer rate, BCI illiteracy, sub-optimal training procedure. Especially the training process for the MI-BCIs requires improvements. Currently, the training has an inappropriate form, resulting in a high mental and temporal demand on the users (weeks of training are required for the control). This study aims at addressing the issues with the MI-BCI training. To support the learning process, an embodied training environment was created. Participants were placed into a virtual reality environment observed from a first-person view of a human-like avatar, and their rehearsal of MI actions was reflected by the corresponding movements performed by the avatar. Leveraging extension of the sense of ownership, agency, and self-location towards a non-body object (principles known from the rubber hand illusion and the body transfer illusions) has already been proven to help in producing stronger EEG correlates of MI. These principles were used to facilitate the MI-BCI training process for the first time. Performance of 30 healthy participants after two sessions of training was measured using an on-line BCI scenario. The group trained using our embodied VR environment gained significantly higher average accuracy for BCI actions (58.3\%) than the control group, trained with a standard MI-BCI training protocol (52.9\%).},
	language = {en},
	urldate = {2021-01-25},
	journal = {Computers \& Graphics},
	author = {Škola, Filip and Liarokapis, Fotis},
	month = oct,
	year = {2018},
	keywords = {Body transfer illusion, Brain–Computer interfaces, Embodiment, Motor imagery, Rubber hand illusion, Virtual reality},
	pages = {59--71},
}

@article{wen_deep_2018,
	title = {Deep {Convolution} {Neural} {Network} and {Autoencoders}-{Based} {Unsupervised} {Feature} {Learning} of {EEG} {Signals}},
	volume = {6},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2018.2833746},
	abstract = {Epilepsy is a health problem that seriously affects the quality of humans for many years. Therefore, it is important to accurately analyze and recognize epilepsy based on EEG signals, and for a long time, researchers have attempted to extract new features from the signals for epilepsy recognition. However, it is very difficult to select useful features from a large number of them in this diagnostic application. As the development of artificial intelligence progresses, unsupervised feature learning based on the deep learning model can obtain features that can better describe identified objects from unlabeled data. In this paper, the deep convolution network and autoencoders-based model, named as AE-CDNN, is constructed in order to perform unsupervised feature learning from EEG in epilepsy. We extract features by AE-CDNN model and classify the features based on two public EEG data sets. Experimental results showed that the classification results of features obtained by AE-CDNN are more optimal than features obtained by principal component analysis and sparse random projection. Using several common classifiers to classify features obtained by AE-CDNN model results in high accuracy and not inferior to the research results from most recent studies. The results also showed that the features of AE-CDNN model are clear, effective, and easy to learn. These features can speed up the convergence and reduce the training times of classifiers. Therefore, the AE-CDNN model can be effectively applied to feature extraction of EEG in epilepsy.},
	journal = {IEEE Access},
	author = {Wen, T. and Zhang, Z.},
	year = {2018},
	note = {Conference Name: IEEE Access},
	keywords = {AE-CDNN model, Brain modeling, CNN, Convolution, Deconvolution, EEG, EEG signals, Electroencephalography, Epilepsy, Feature extraction, Training, artificial intelligence, autoencoders-based model, convergence, deep convolution network, deep learning model, diseases, electroencephalography, epilepsy recognition, epileptic seizure, feature classification, feature extraction, feedforward neural nets, learning (artificial intelligence), medical signal processing, principal component analysis, random processes, signal classification, sparse random projection, unsupervised feature learning, unsupervised learning},
	pages = {25399--25410},
}

@misc{noauthor_deap_nodate,
	title = {{DEAP}: {A} {Dataset} for {Emotion} {Analysis} using {Physiological} and {Audiovisual} {Signals}},
	url = {http://www.eecs.qmul.ac.uk/mmv/datasets/deap/},
	urldate = {2020-12-06},
}

@article{koelstra_deap_2012,
	title = {{DEAP}: {A} {Database} for {Emotion} {Analysis} ;{Using} {Physiological} {Signals}},
	volume = {3},
	issn = {1949-3045},
	shorttitle = {{DEAP}},
	doi = {10.1109/T-AFFC.2011.15},
	abstract = {We present a multimodal data set for the analysis of human affective states. The electroencephalogram (EEG) and peripheral physiological signals of 32 participants were recorded as each watched 40 one-minute long excerpts of music videos. Participants rated each video in terms of the levels of arousal, valence, like/dislike, dominance, and familiarity. For 22 of the 32 participants, frontal face video was also recorded. A novel method for stimuli selection is proposed using retrieval by affective tags from the last.fm website, video highlight detection, and an online assessment tool. An extensive analysis of the participants' ratings during the experiment is presented. Correlates between the EEG signal frequencies and the participants' ratings are investigated. Methods and results are presented for single-trial classification of arousal, valence, and like/dislike ratings using the modalities of EEG, peripheral physiological signals, and multimedia content analysis. Finally, decision fusion of the classification results from different modalities is performed. The data set is made publicly available and we encourage other researchers to use it for testing their own affective state estimation methods.},
	number = {1},
	journal = {IEEE Transactions on Affective Computing},
	author = {Koelstra, S. and Muhl, C. and Soleymani, M. and Lee, J. and Yazdani, A. and Ebrahimi, T. and Pun, T. and Nijholt, A. and Patras, I.},
	month = jan,
	year = {2012},
	note = {Number: 1
Conference Name: IEEE Transactions on Affective Computing},
	keywords = {DEAP, Databases, EEG, EEG signal frequencies, Electroencephalography, Emotion classification, Face, Motion pictures, Multimedia communication, Videos, Visualization, Web site, Web sites, affective computing., arousal, decision fusion, dominance, electroencephalogram, electroencephalography, emotion analysis, emotion recognition, familiarity, frontal face video, human affective states, image classification, information retrieval, multimedia computing, multimedia content analysis, multimodal data set, music videos, neurophysiology, online assessment tool, pattern classification, peripheral physiological signals, physiological signals, signal processing, single-trial classification, state estimation, state estimation methods, stimuli selection, video highlight detection, video signal processing},
	pages = {18--31},
}

@article{lcuyer_brain-computer_2008,
	title = {Brain-{Computer} {Interfaces}, {Virtual} {Reality}, and {Videogames}},
	volume = {41},
	doi = {10.1109/MC.2008.410},
	abstract = {BCIs offer a new means of playing videogames or interacting with 3D virtual environments. Several impressive prototypes already exist that let users navigate in virtual scenes or manipulate virtual objects solely by means of their cerebral activity, recorded on the scalp via electroencephalography electrodes. Meanwhile, virtual reality technologies provide motivating, safe, and controlled conditions that enable improvement of BCI learning as well as the investigation of the brain responses and neural processes involved. Over the long term, these innovations could lead to newer applications, such as novel types of neurorehabilitation.},
	journal = {Computer},
	author = {L?cuyer, Anatole and Lotte, Fabien and Reilly, Richard and Leeb, Robert and Hirose, Michitaka and Slater, Mel},
	month = nov,
	year = {2008},
	pages = {66--72},
}

@article{campisi_brain_2014,
	title = {Brain waves for automatic biometric-based user recognition},
	volume = {9},
	issn = {1556-6013, 1556-6021},
	url = {http://ieeexplore.ieee.org/document/6748964/},
	doi = {10.1109/TIFS.2014.2308640},
	abstract = {Brain signals have been investigated within the medical ﬁeld for more than a century to study brain diseases like epilepsy, spinal cord injuries, Alzheimer’s, Parkinson’s, schizophrenia, and stroke among the others. They are also used in both brain computer and brain machine interface systems with assistance, rehabilitative, and entertainment applications. Despite the broad interest in clinical applications, the use of brain signals has been only recently investigated by the scientiﬁc community as a biometric characteristic to be used in automatic people recognition systems. However, brain signals present some peculiarities, not shared by the most commonly used biometrics, like face, iris, and ﬁngerprints, with reference to privacy compliance, robustness against spooﬁng attacks, possibility to perform continuous identiﬁcation, intrinsic liveness detection, and universality. These peculiarities make the use of brain signals appealing. On the other hand there are many challenges which need to be properly addressed. Among them, the understanding of the level of uniqueness and permanence of brain responses, the design of elicitation protocols, the invasiveness of the acquisition process are only few of the challenges which need to be tackled. In this paper we further speculate on those issues which represent an obstacle towards the deployment of biometric systems based on the analysis of brain activity in real life applications and intend to provide a critical and comprehensive review of state-ofthe-art methods for electroencephalogram based automatic user recognition, also reporting neurophysiological evidences related to the performed claims.},
	language = {en},
	number = {5},
	urldate = {2020-11-21},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Campisi, Patrizio and La Rocca, Daria},
	month = may,
	year = {2014},
	keywords = {Brain, EEG, Electrodes, Electroencephalography, Feature extraction, Protocols, Scalp, Visualization, acquisition process, assistance applications, authentication, automatic biometric-based user recognition, biometric characteristic, biometric system deployment, biometrics (access control), brain activity analysis, brain computer interface system, brain diseases, brain machine interface system, brain response, brain rhythms, brain signal, brain waves, brain-computer interfaces, clinical applications, continuous identification, data privacy, electroencephalogram-based automatic user recognition, electroencephalography, elicitation protocol, elicitation protocols, entertainment application, intrinsic liveness detection, invasiveness, neurophysiological evidence, neurophysiology, overview, peculiarity, privacy compliance, protocols, rehabilitative application, review, spoofing attacks},
	pages = {782--800},
}

@article{wilaiprasitporn_affective_2020,
	title = {Affective {EEG}-{Based} {Person} {Identification} {Using} the {Deep} {Learning} {Approach}},
	volume = {12},
	issn = {2379-8939},
	doi = {10.1109/TCDS.2019.2924648},
	abstract = {Electroencephalography (EEG) is another method for performing person identification (PI). Due to the nature of the EEG signals, EEG-based PI is typically done while a person is performing a mental task such as motor control. However, few studies used EEG-based PI while the person is in different mental states (affective EEG). The aim of this paper is to improve the performance of affective EEG-based PI using a deep learning (DL) approach. We proposed a cascade of DL using a combination of convolutional neural networks (CNNs) and recurrent neural networks (RNNs). CNNs are used to handle the spatial information from the EEG while RNNs extract the temporal information. We evaluated two types of RNNs, namely long short-term memory (LSTM) and gated recurrent unit (GRU). The proposed method is evaluated on the state-of-the-art affective data set DEAP. The results indicate that CNN-GRU and CNN-LSTM can perform PI from different affective states and reach up to 99.90\%-100\% mean correct recognition rate. This significantly outperformed a support vector machine baseline system that used power spectral density features. Notably, the 100\% mean CRR came from 32 subjects in DEAP data set. Even after the reduction of the number of EEG electrodes from 32 to 5 for more practical applications, the model could still maintain an optimal result obtained from the frontal region, reaching up to 99.17\%. Amongst the two DL models, we found that CNN-GRU and CNN-LSTM performed similarly while CNN-GRU expended faster training time. In conclusion, the studied DL approaches overcame the influence of affective states in EEG-Based PI reported in the previous works.},
	number = {3},
	journal = {IEEE Transactions on Cognitive and Developmental Systems},
	author = {Wilaiprasitporn, T. and Ditthapron, A. and Matchaparn, K. and Tongbuasirilai, T. and Banluesombatkul, N. and Chuangsuwanich, E.},
	month = sep,
	year = {2020},
	note = {Conference Name: IEEE Transactions on Cognitive and Developmental Systems},
	keywords = {Affective computing, Biometrics (access control), Brain modeling, CNN-GRU, CNN-LSTM, CNNs, CRR, DEAP data, Deep learning, Electroencephalography, Feature extraction, Logic gates, RNNs, Task analysis, affective EEG-based PI, affective EEG-based person identification, affective data, biometrics, convolutional neural networks, convolutional neural networks (CNNs), deep learning (DL), deep learning approach, electroencephalography, electroencephalography (EEG), feature extraction, learning (artificial intelligence), long short-term memory, long short-term memory (LSTM), medical signal processing, mental states, mental task, motor control, personal identification (PI), recurrent neural nets, recurrent neural networks, recurrent neural networks (RNNs), recurrent unit, signal classification, spatial information, support vector machine baseline system, support vector machines, temporal information},
	pages = {486--496},
}

@article{ozdenizci_adversarial_2019,
	title = {Adversarial {Deep} {Learning} in {EEG} {Biometrics}},
	volume = {26},
	issn = {1558-2361},
	doi = {10.1109/LSP.2019.2906826},
	abstract = {Deep learning methods for person identification based on electroencephalographic (EEG) brain activity encounters the problem of exploiting the temporally correlated structures or recording session specific variability within EEG. Furthermore, recent methods have mostly trained and evaluated based on single session EEG data. We address this problem from an invariant representation-learning perspective. We propose an adversarial inference approach to extend such deep learning models to learn session-invariant person-discriminative representations that can provide robustness in terms of longitudinal usability. Using adversarial learning within a deep convolutional network, we empirically assess and show improvements with our approach based on longitudinally collected EEG data for person identification from half-second EEG epochs.},
	number = {5},
	journal = {IEEE Signal Processing Letters},
	author = {Özdenizci, O. and Wang, Y. and Koike-Akino, T. and Erdoğmuş, D.},
	month = may,
	year = {2019},
	note = {Conference Name: IEEE Signal Processing Letters},
	keywords = {Biological system modeling, Biometrics (access control), Brain modeling, Convolution, EEG, EEG biometrics, Electroencephalography, Feature extraction, Person identification, Training, adversarial deep learning, adversarial inference approach, adversarial learning, biometrics, brain, convolutional networks, convolutional neural nets, deep convolutional network, deep learning models, electroencephalographic brain activity, electroencephalography, invariant representation, invariant representation-learning perspective, learning (artificial intelligence), longitudinally collected EEG data, medical signal processing, person identification, recording session specific variability, session-invariant person-discriminative representations, single session EEG data, temporally correlated structures},
	pages = {710--714},
}

@article{jalaly_bidgoly_survey_2020,
	title = {A survey on methods and challenges in {EEG} based authentication},
	volume = {93},
	issn = {0167-4048},
	url = {http://www.sciencedirect.com/science/article/pii/S0167404820300730},
	doi = {10.1016/j.cose.2020.101788},
	abstract = {EEG is the recording of electrical activities of the brain, usually along the scalp surface, which are the results of synaptic activations of the brain’s neurons. In recent years, it has been shown that EEG is an appropriate signal for the biometric authentication and has important features such as resistance to spoofing attacks and impossibility to use under pressure and coercion states. In this paper, the state-of-the-art methods in EEG based authentication are reviewed. This review includes a number of aspects such as the various tasks that the user required to perform during the authentication, devices and available datasets, the preprocessing procedures and the classification methods used in the EEG biometric authentication. Both shallow and deep classification methods are reviewed in this paper. The study shows that the deep learning approaches which are used in the past few years, although still require further research, have shown great results. Moreover, the paper summarizes the works to address the open challenges of this area. The EEG authentication challenges have been discussed from a variety of points of view, including privacy, user-friendliness, attacks, and authentication requirements such as universality, permanency, uniqueness, and collectability. This paper can be used as a preliminary plan and a roadmap for researchers interested in EEG biometric.},
	language = {en},
	urldate = {2020-11-24},
	journal = {Computers \& Security},
	author = {Jalaly Bidgoly, Amir and Jalaly Bidgoly, Hamed and Arezoumand, Zeynab},
	month = jun,
	year = {2020},
	keywords = {Authentication, Biometric factor, EEG, Pattern recognition, Survey, User identification, datasets, overview, review},
	pages = {101788},
}

@article{lun_simplified_2020,
	title = {A {Simplified} {CNN} {Classification} {Method} for {MI}-{EEG} via the {Electrode} {Pairs} {Signals}},
	volume = {14},
	issn = {1662-5161},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2020.00338/full},
	doi = {10.3389/fnhum.2020.00338},
	abstract = {The brain-computer interface (BCI), which is based on electroencephalography (EEG), provides independent information exchange and control channels for the brain and the outside world. However, EEG signals come from multiple electrodes, and the data of each electrode can extract multiple features. How to select electrodes and features to improve classification accuracy has become an urgent problem to be solved. This paper proposes a deep convolutional neural network (CNN) architecture with separated temporal and spatial filters, which selects the raw EEG signals of the electrode pairs over the motor cortex region as hybrid samples without any preprocessing or artificial feature extraction operations. It uses 5-layer CNN to learn EEG features, 4-layer max pooling to reduce dimensionality, and a fully connected (FC) layer for classification. Dropout and batch normalization are used to solve the overfitting problem of the model. In the experiment, the 4 s EEG data of 10, 20, 60, and 100 subjects in the Physionet database are used as the data source, and the motor imaginations (MI) tasks are divided into four types: left fist, right fist, both fists and both feet. The results indicate that the global averaged accuracy on group-level classification can reach 97.28\%, the area under the receiver operating characteristic (ROC) curve stands out at 0.997, and the electrode pair with the highest accuracy on 10 subjects dataset is FC3-FC4, with 98.61\%. The research results also show that this work achieves high accuracy with a CNN classification approach using minimal (2) electrodes, which is the advantage compared to other methods on the same database. This proposed approach provides a new idea for simplifying the design of BCI system, and accelerates the process of clinical application.},
	language = {English},
	urldate = {2021-01-23},
	journal = {Frontiers in Human Neuroscience},
	author = {Lun, Xiangmin and Yu, Zhenglin and Chen, Tao and Wang, Fang and Hou, Yimin},
	year = {2020},
	note = {Publisher: Frontiers},
	keywords = {Brain computer interface (BCI), Convolutional neural network (CNN), Electrode pairs, Electroencephalography (EEG), Motor Imagery (MI)},
}

@article{xu_one-dimensional_2020,
	title = {A {One}-{Dimensional} {CNN}-{LSTM} {Model} for {Epileptic} {Seizure} {Recognition} {Using} {EEG} {Signal} {Analysis}},
	volume = {14},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2020.578126/full#h4},
	doi = {10.3389/fnins.2020.578126},
	abstract = {Frequent epileptic seizure causes damage to the human’s brain, resulting in memory impairment, mental decline and so on. Therefore, it is important to detect epileptic seizure and provide medical treatment in a timely manner. Currently, medical experts recognize epileptic seizure activity through the visual inspection of electroencephalographic (EEG) signal recordings of patients based on their experience, which takes much time and effort of medical experts. In view of this, this paper proposes a one-dimensional convolutional neural network-long short-term memory (1D CNN-LSTM) model for automatic recognition of epileptic seizure through EEG signal analysis. Firstly, the raw EEG signal data is preprocessed and normalized. Then, a 1D convolutional neural network (CNN) is designed to effectively extract the features of the normalized EEG sequence data. In addition, the extracted features are then processed by the LSTM layers in order to further extract the temporal features. After that, the output features are fed into several fully connected layers for final epileptic seizure recognition. The performance of the proposed 1D CNN-LSTM model is verified on the public UCI epileptic seizure recognition data set. Experiments results show that the proposed method achieves high recognition accuracies of 99.39\% and 82.00\% on the binary and five-class epileptic seizure recognition tasks, respectively. Comparing results with traditional machine learning methods including k-nearest neighbor, support vector machine and decision tree, other deep learning methods including standard deep neural network and CNN further verify the superiority of the proposed method.},
	language = {English},
	urldate = {2021-01-22},
	journal = {Frontiers in Neuroscience},
	author = {Xu, Gaowei and Ren, Tianhe and Chen, Yu and Che, Wenliang},
	year = {2020},
	note = {Publisher: Frontiers},
	keywords = {Convolutional neural network (CNN), Epileptic Seizure Recognition, Long short-term memory (LSTM), Signal analysis, electroencephalographic (EEG)},
}

@inproceedings{elessawy_long_2020,
	title = {A {Long} {Short}-{Term} {Memory} {Autoencoder} {Approach} for {EEG} {Motor} {Imagery} {Classification}},
	doi = {10.1109/ICCAKM46823.2020.9051489},
	abstract = {Motor imagery represents one Brain-Computer Interface (BCI) paradigm that has been utilized in developing applications to assist subjects with motor disability. Such paradigm relies on analyzing brain electroencephalography (EEG) activity to identify the intended movement direction. Existing motor imagery feature extraction techniques are focused on utilizing traditional signal processing and machine learning techniques. Recent advances in the deep learning field has inspired the development of few methods for motor imagery classification that achieved further performance improvement. This paper proposes a deep neural network approach for motor imagery classification using Long Short-Term Memory (LSTM) combined with Autoencoders based on a sequence-to-sequence architecture. The proposed network extracts features from the frequency-domain representation of EEG signals. This network is trained to obtain low-dimensional representation of EEG features that are then fed into multilayer perceptron of 3 layers for classification. Systematic and extensive examinations have been carried out by applying the approach to public benchmark EEG datasets. The obtained results outperformed classical state-of-the-art methods employing standard frequency-domain features and common spatial patterns, and comparative results to methods such as filter bank common spatial pattern and its variants. Our results indicate the efficacy of the proposed LSTM autoencoder approach in EEG motor imagery classification.},
	booktitle = {2020 {International} {Conference} on {Computation}, {Automation} and {Knowledge} {Management} ({ICCAKM})},
	author = {Elessawy, R. H. and Eldawlatly, S. and Abbas, H. M.},
	month = jan,
	year = {2020},
	keywords = {EEG, EEG motor imagery classification, Motor imagery, brain computer interface, brain-computer interface paradigm, brain-computer interfaces, deep learning, deep neural network approach, electroencephalography, feature extraction, learning (artificial intelligence), long short-term memory, long short-term memory autoencoder approach, machine learning techniques, medical signal processing, motor disability, motor imagery feature extraction techniques, multilayer perceptrons, recurrent neural nets, signal classification, signal processing},
	pages = {79--84},
}

@book{wang_collaborative_2011,
	title = {A collaborative brain-computer interface},
	volume = {1},
	abstract = {Electroencephalogram (EEG) based brain-computer interfaces (BCI) have been studied for several decades since the 1970s. Current BCI research mainly aims to provide a new communication channel to patients with motor disabilities to improve their quality of life. The BCI technology can also benefit normal healthy users; however, little progress has been made in real-world practices due to low BCI performance caused by technical limits of EEG. To overcome this bottleneck, this study uses a collaborative BCI to improve overall performance through integrating information from multiple users. A dataset involving 15 subjects participating in a Go/NoGo decision-making experiment was used to evaluate the collaborative method. Using collaborative computing techniques, the classification accuracy for predicting a Go/NoGo decision was enhanced substantially from 75.8\% to 91.4\%, 97.6\%, and 99.1\% as the number of subjects increased from 1 to 5, 10, and 15, respectively. These results suggest that a collaborative BCI can effectively fuse brain activities of a group of people to improve human behavior.},
	author = {Wang, Yijun and Wang, Yu-Te and Jung, Tzyy-Ping and Gao, Xiaorong and Gao, Shangkai},
	month = oct,
	year = {2011},
	doi = {10.1109/BMEI.2011.6098286},
	note = {Journal Abbreviation: Proceedings - 2011 4th International Conference on Biomedical Engineering and Informatics, BMEI 2011
Pages: 583
Publication Title: Proceedings - 2011 4th International Conference on Biomedical Engineering and Informatics, BMEI 2011},
}

@article{salimpoor_rewarding_2009,
	title = {The {Rewarding} {Aspects} of {Music} {Listening} {Are} {Related} to {Degree} of {Emotional} {Arousal}},
	volume = {4},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0007487},
	doi = {10.1371/journal.pone.0007487},
	abstract = {Background Listening to music is amongst the most rewarding experiences for humans. Music has no functional resemblance to other rewarding stimuli, and has no demonstrated biological value, yet individuals continue listening to music for pleasure. It has been suggested that the pleasurable aspects of music listening are related to a change in emotional arousal, although this link has not been directly investigated. In this study, using methods of high temporal sensitivity we investigated whether there is a systematic relationship between dynamic increases in pleasure states and physiological indicators of emotional arousal, including changes in heart rate, respiration, electrodermal activity, body temperature, and blood volume pulse. Methodology Twenty-six participants listened to self-selected intensely pleasurable music and “neutral” music that was individually selected for them based on low pleasure ratings they provided on other participants' music. The “chills” phenomenon was used to index intensely pleasurable responses to music. During music listening, continuous real-time recordings of subjective pleasure states and simultaneous recordings of sympathetic nervous system activity, an objective measure of emotional arousal, were obtained. Principal Findings Results revealed a strong positive correlation between ratings of pleasure and emotional arousal. Importantly, a dissociation was revealed as individuals who did not experience pleasure also showed no significant increases in emotional arousal. Conclusions/Significance These results have broader implications by demonstrating that strongly felt emotions could be rewarding in themselves in the absence of a physically tangible reward or a specific functional goal.},
	language = {en},
	number = {10},
	urldate = {2021-03-01},
	journal = {PLOS ONE},
	author = {Salimpoor, Valorie N. and Benovoy, Mitchel and Longo, Gregory and Cooperstock, Jeremy R. and Zatorre, Robert J.},
	month = oct,
	year = {2009},
	note = {Publisher: Public Library of Science},
	keywords = {Autonomic nervous system, Bioacoustics, Emotions, Heart rate, Music perception, Nervous system physiology, Respiratory physiology, Sympathetic nervous system},
	pages = {e7487},
}

@article{ruiz_de_miras_fractal_2019,
	title = {Fractal dimension analysis of states of consciousness and unconsciousness using transcranial magnetic stimulation},
	volume = {175},
	issn = {0169-2607},
	url = {https://www.sciencedirect.com/science/article/pii/S0169260718314263},
	doi = {10.1016/j.cmpb.2019.04.017},
	abstract = {Background and objective
Knowing whether a subject is conscious or not is a current challenge with a deep potential clinical impact. Recent theoretical considerations suggest that consciousness is linked to the complexity of distributed interactions within the corticothalamic system. The fractal dimension (FD) is a quantitative parameter that has been extensively used to analyse the complexity of structural and functional patterns of the human brain. In this study we investigate FD to assess whether it can discriminate between consciousness and different states of unconsciousness in healthy individuals.
Methods
We study 69 high-density electroencephalogram (hd-EEG) measurements after transcranial magnetic stimulation (TMS) in 18 healthy subjects progressing from wakefulness to non-rapid eye movement (NREM) sleep and sedation induced by different anaesthetic agents (xenon and propofol). We quantify the integration of thalamocortical networks by calculating the FD of a spatiotemporal voxelization obtained from the locations of all sources that are significantly activated by the perturbation (4DFD). Moreover, we study the temporal evolution of the evoked spatial distributions and compute a measure of the differentiation of the response by means of the Higuchi FD (HFD). Finally, a Fractal Dimension Index (FDI) of perturbational complexity is computed as the product of both quantities: integration FD (4DFD) and differentiation FD (HFD).
Results
We found that FDI is significantly lower in sleep and sedation when compared to wakefulness and provides an almost perfect intra-subject discrimination between conscious and unconscious states.
Conclusions
These results support the combination of FD measures of cortical integration and cortical differentiation as a novel paradigm of tracking complex spatiotemporal dynamics in the brain that could provide further insights into the link between complexity and the brain's capacity to sustain consciousness.},
	language = {en},
	urldate = {2021-03-01},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Ruiz de Miras, J. and Soler, F. and Iglesias-Parro, S. and Ibáñez-Molina, A. J. and Casali, A. G. and Laureys, S. and Massimini, M. and Esteban, F. J. and Navas, J. and Langa, J. A.},
	month = jul,
	year = {2019},
	keywords = {Consciousness, EEG, Fractal dimension, Transcranial magnetic stimulation},
	pages = {129--137},
}

@article{smith_hemispheric_1987,
	title = {Hemispheric asymmetry and emotion: {Lateralized} parietal processing of affect and cognition},
	volume = {25},
	issn = {0301-0511},
	shorttitle = {Hemispheric asymmetry and emotion},
	url = {https://www.sciencedirect.com/science/article/pii/0301051187900500},
	doi = {10.1016/0301-0511(87)90050-0},
	abstract = {The differential cerebral processing of affect and cognition may have important implications for a more general understanding of how these two complex sets of functions differ and how they interact. Building upon recent studies of hemispheric asymmetry in emotion, the present study focused on the differential parietal processing of emotional stimuli under affective and cognitive conditions. Subjects were exposed to neutral and emotional stimuli presented under cognitive and affective instructional sets. Bilateral electroencephalographic (EEG) data showed that the principal differentiation between affective and cognitive conditions occurred in the right hemisphere, whereas the highest overall level of activation during emotional stimulation was in the left hemisphere. It was also found that affective conditions produced higher of levels of both EEG and electrodermal activity than either cognitive or neutral conditions. Finally, significant patterns of gender differentiation suggested greater focal organization for affective arousal in females than males.},
	language = {en},
	number = {3},
	urldate = {2021-03-01},
	journal = {Biological Psychology},
	author = {Smith, Barry D. and Meyers, Marilyn and Kline, Robert and Bozman, Alan},
	month = dec,
	year = {1987},
	pages = {247--260},
}

@book{scherer_approaches_2014,
	title = {Approaches {To} {Emotion}},
	isbn = {978-1-317-75764-1},
	abstract = {This sourcebook is intended as a reader in the fullest sense of that word: a work that offers researchers and students alike the opportunity to examine the many different aspects and widely divergent approaches to the study of emotion. The contributors include samples of biological, ontogenetic, ethological, psychological, sociological, and anthropological approaches.},
	language = {en},
	publisher = {Psychology Press},
	author = {Scherer, Klaus R. and Ekman, Paul},
	month = may,
	year = {2014},
	note = {Google-Books-ID: k0mhAwAAQBAJ},
	keywords = {Psychology / General, Psychology / Social Psychology},
}

@article{koelsch_towards_2005,
	title = {Towards a neural basis of music perception},
	volume = {9},
	issn = {1364-6613},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661305002901},
	doi = {10.1016/j.tics.2005.10.001},
	abstract = {Music perception involves complex brain functions underlying acoustic analysis, auditory memory, auditory scene analysis, and processing of musical syntax and semantics. Moreover, music perception potentially affects emotion, influences the autonomic nervous system, the hormonal and immune systems, and activates (pre)motor representations. During the past few years, research activities on different aspects of music processing and their neural correlates have rapidly progressed. This article provides an overview of recent developments and a framework for the perceptual side of music processing. This framework lays out a model of the cognitive modules involved in music perception, and incorporates information about the time course of activity of some of these modules, as well as research findings about where in the brain these modules might be located.},
	language = {en},
	number = {12},
	urldate = {2021-03-01},
	journal = {Trends in Cognitive Sciences},
	author = {Koelsch, Stefan and Siebel, Walter A.},
	month = dec,
	year = {2005},
	pages = {578--584},
}

@article{jentschke_neural_2014,
	title = {Neural correlates of music-syntactic processing in two-year old children},
	volume = {9},
	issn = {1878-9293},
	url = {https://www.sciencedirect.com/science/article/pii/S1878929314000322},
	doi = {10.1016/j.dcn.2014.04.005},
	abstract = {Music is a basic and ubiquitous socio-cognitive domain. However, our understanding of the time course of the development of music perception, particularly regarding implicit knowledge of music-syntactic regularities, remains contradictory and incomplete. Some authors assume that the acquisition of knowledge about these regularities lasts until late childhood, but there is also evidence for the presence of such knowledge in four- and five-year-olds. To explore whether such knowledge is already present in younger children, we tested whether 30-month-olds (N = 62) show neurophysiological responses to music-syntactically irregular harmonies. We observed an early right anterior negativity in response to both irregular in-key and out-of-key chords. The N5, a brain response usually present in older children and adults, was not observed, indicating that processes of harmonic integration (as reflected in the N5) are still in development in this age group. In conclusion, our results indicate that 30-month-olds already have acquired implicit knowledge of complex harmonic music-syntactic regularities and process musical information according to this knowledge.},
	language = {en},
	urldate = {2021-03-01},
	journal = {Developmental Cognitive Neuroscience},
	author = {Jentschke, Sebastian and Friederici, Angela D. and Koelsch, Stefan},
	month = jul,
	year = {2014},
	keywords = {EEG, ERPs, Infants (30-month-olds), Music perception, Musical syntax, Neurophysiology},
	pages = {200--208},
}

@article{keelawat_spatiotemporal_nodate,
	title = {Spatiotemporal {Emotion} {Recognition} using {Deep} {CNN} {Based} on {EEG} during {Music} {Listening}},
	abstract = {Emotion recognition based on EEG has become an active research area. As one of the machine learning models, CNN has been utilized to solve diverse problems including issues in this domain. In this work, a study of CNN and its spatiotemporal feature extraction has been conducted in order to explore the model’s capabilities in varied window sizes and electrode orders. Our investigation was conducted in subjectindependent fashion. Results have shown that temporal information in distinct window sizes significantly affects recognition performance in both 10-fold and leave-one-subject-out cross validation. Spatial information from varying electrode order has modicum effect on classification. SVM classifier depending on spatiotemporal knowledge on the same dataset was previously employed and compared to these empirical results. Even though CNN and SVM have a homologous trend in window size effect, CNN outperformed SVM using leave-one-subject-out cross validation. This could be caused by different extracted features in the elicitation process.},
	language = {en},
	author = {Keelawat, Panayu and Thammasan, Nattapong and Numao, Masayuki and Kijsirikul, Boonserm},
	pages = {11},
}

@article{vialatte_steady-state_2010,
	title = {Steady-state visually evoked potentials: {Focus} on essential paradigms and future perspectives},
	volume = {90},
	issn = {0301-0082},
	shorttitle = {Steady-state visually evoked potentials},
	url = {https://www.sciencedirect.com/science/article/pii/S0301008209001853},
	doi = {10.1016/j.pneurobio.2009.11.005},
	abstract = {After 40 years of investigation, steady-state visually evoked potentials (SSVEPs) have been shown to be useful for many paradigms in cognitive (visual attention, binocular rivalry, working memory, and brain rhythms) and clinical neuroscience (aging, neurodegenerative disorders, schizophrenia, ophthalmic pathologies, migraine, autism, depression, anxiety, stress, and epilepsy). Recently, in engineering, SSVEPs found a novel application for SSVEP-driven brain–computer interface (BCI) systems. Although some SSVEP properties are well documented, many questions are still hotly debated. We provide an overview of recent SSVEP studies in neuroscience (using implanted and scalp EEG, fMRI, or PET), with the perspective of modern theories about the visual pathway. We investigate the steady-state evoked activity, its properties, and the mechanisms behind SSVEP generation. Next, we describe the SSVEP-BCI paradigm and review recently developed SSVEP-based BCI systems. Lastly, we outline future research directions related to basic and applied aspects of SSVEPs.},
	language = {en},
	number = {4},
	urldate = {2021-02-21},
	journal = {Progress in Neurobiology},
	author = {Vialatte, François-Benoît and Maurice, Monique and Dauwels, Justin and Cichocki, Andrzej},
	month = apr,
	year = {2010},
	keywords = {BCI, Clinical, Cognitive, EEG, Evoked potentials, PET, SSVEP, fMRI},
	pages = {418--438},
}

@book{ikehara_lecture_2013,
	title = {Lecture {Notes} in {Computer} {Science}},
	isbn = {978-3-642-39453-9},
	abstract = {The strategic goal of augmented cognition is to increase task performance capacity by using physiological sensor feedback to adjust or modify the activity for the user. Gamification has been shown to increase performance by using certain combinations of game elements. Both augmented cognition and gamification address increased task performance capacity. Gamification adds to augmented cognition by directly addressing the motivation of the user to remain engaged in the activity. This has also been referred to as flow, or the optimal experience. This paper describes an example of a gamified activity in which the physiological sensors of augmented cognition are used to foster the optimal experience desired in gamification. Also, discussed is how the strategic goals of augmented cognition and gamification overlap through the use of a gamified example that describes how the components of augmented cognition and elements of gamification can be used together to better achieve the goal of increased task performance capacity.},
	author = {Ikehara, Curtis and Crosby, Martha and Silva, Paula Alexandra},
	month = jul,
	year = {2013},
	doi = {10.1007/978-3-642-39454-6_72},
	note = {Pages: 684},
}

@misc{noauthor_melomind_nodate,
	title = {Melomind - {Activez} le mode sérénité de votre cerveau.},
	url = {https://www.melomind.com/},
	abstract = {Tous les bienfaits de la neuroscience et de la méditation pour vous entraîner à la relaxation profonde. Embarquez vers l’harmonie et la sérénité.},
	language = {fr-FR},
	urldate = {2021-02-21},
	journal = {Melomind},
}

@misc{noauthor_melomind_nodate-1,
	title = {melomind at {DuckDuckGo}},
	url = {https://duckduckgo.com/?q=melomind},
	urldate = {2021-02-21},
}

@misc{noauthor_nextmind_nodate,
	title = {{NextMind} {\textbar} {Let} your mind take control {\textbar} {Order} your {Dev} {Kit}},
	url = {https://www.next-mind.com/},
	abstract = {NextMind is shipping World’s First Real-time Brain-Sensing Wearable to the Developers community, offering new human-computer interactions.},
	language = {en-US},
	urldate = {2021-02-21},
	journal = {NextMind},
}

@article{fazel-rezai_p300_2012,
	title = {P300 brain computer interface: current challenges and emerging trends},
	volume = {5},
	issn = {1662-6443},
	shorttitle = {P300 brain computer interface},
	url = {https://www.frontiersin.org/articles/10.3389/fneng.2012.00014/full},
	doi = {10.3389/fneng.2012.00014},
	abstract = {A brain-computer interface (BCI) enables communication without movement based on brain signals measured with electroencephalography (EEG). BCIs usually rely on one of three types of signals: the P300 and other components of the event-related potential (ERP), steady state visual evoked potential (SSVEP), or event related desynchronization (ERD). Although P300 BCIs were introduced over twenty years ago, the past few years have seen a strong increase in P300 BCI research. This closed-loop BCI approach relies on the P300 and other components of the event-related potential (ERP), based on an oddball paradigm presented to the subject. In this paper, we overview the current status of P300 BCI technology, and then discuss new directions: paradigms for eliciting P300s; signal processing methods; applications; and hybrid BCIs. We conclude that P300 BCIs are quite promising, as several emerging directions have not yet been fully explored and could lead to improvements in bit rate, reliability, usability, and flexibility.},
	language = {English},
	urldate = {2021-02-21},
	journal = {Frontiers in Neuroengineering},
	author = {Fazel-Rezai, Reza and Allison, Brendan Z. and Guger, Christoph and Sellers, Eric W. and Kleih, Sonja C. and Kübler, Andrea},
	year = {2012},
	note = {Publisher: Frontiers},
	keywords = {BCI, Brain Computer Interface, P300, Trends and Challenges, event-related potential (ERP)},
}

@article{tan_effect_2014,
	title = {Effect of mindfulness meditation on brain–computer interface performance},
	volume = {23},
	issn = {1053-8100},
	url = {https://www.sciencedirect.com/science/article/pii/S1053810013001499},
	doi = {10.1016/j.concog.2013.10.010},
	abstract = {Electroencephalogram based brain–computer interfaces (BCIs) enable stroke and motor neuron disease patients to communicate and control devices. Mindfulness meditation has been claimed to enhance metacognitive regulation. The current study explores whether mindfulness meditation training can thus improve the performance of BCI users. To eliminate the possibility of expectation of improvement influencing the results, we introduced a music training condition. A norming study found that both meditation and music interventions elicited clear expectations for improvement on the BCI task, with the strength of expectation being closely matched. In the main 12week intervention study, seventy-six healthy volunteers were randomly assigned to three groups: a meditation training group; a music training group; and a no treatment control group. The mindfulness meditation training group obtained a significantly higher BCI accuracy compared to both the music training and no-treatment control groups after the intervention, indicating effects of meditation above and beyond expectancy effects.},
	language = {en},
	urldate = {2021-02-16},
	journal = {Consciousness and Cognition},
	author = {Tan, Lee-Fan and Dienes, Zoltan and Jansari, Ashok and Goh, Sing-Yau},
	month = jan,
	year = {2014},
	keywords = {BCI performance, Brain–computer interface, Expectation, Meditation, Mindfulness, Music},
	pages = {12--21},
}

@misc{noauthor_2_nodate,
	title = {(2) ({PDF}) {Human}-{Computer} {Interaction} for {BCI} {Games} {Usability} and {User} {Experience}},
	url = {https://www.researchgate.net/publication/220916493_Human-Computer_Interaction_for_BCI_Games_Usability_and_User_Experience},
	urldate = {2021-02-16},
}

@article{friedman_navigating_2007,
	title = {Navigating {Virtual} {Reality} by {Thought}: {What} {Is} {It} {Like}?},
	volume = {16},
	shorttitle = {Navigating {Virtual} {Reality} by {Thought}},
	doi = {10.1162/pres.16.1.100},
	abstract = {Abstract We have set up a Brain-Computer Interface (BCI) to be used as aninput device to a highly immersive,virtual reality Cave-like system. We have carried out two navigation experiments: three subjects were required to rotate in a virtual bar room by imagining left or right hand movement, and to walk along a single axis in a virtual street by imagining foot or hand movement. In this paper we focus on the subjective experience of navigating virtual reality “by thought”, and on the interrelations between,BCI and presence.},
	journal = {Presence},
	author = {Friedman, Doron and Leeb, Robert and Guger, Christoph and Steed, Anthony and Pfurtscheller, Gert and Slater, Mel},
	month = feb,
	year = {2007},
	pages = {100--110},
}

@book{friedman_contact_nodate,
	title = {Contact:},
	shorttitle = {Contact},
	abstract = {We have set up a Brain-Computer Interface (BCI) to be used as an input device to a highly immersive virtual reality Cave-like system. We have carried out two navigation experiments: three subjects were required to rotate in a virtual bar room by imagining left or right hand movement, and to walk along a single axis in a virtual street by imagining foot or hand movement. In this paper we focus on the subjective experience of navigating virtual reality “by thought”, and on the interrelations between BCI and presence. 1.},
	author = {Friedman, Doron and Leeb, Robert and Guger, Christoph and Steed, Anthony and Pfurtscheller, Gert and Slater, Mel and Friedman, Doron},
}

@article{cherubino_consumer_2019,
	title = {Consumer {Behaviour} through the {Eyes} of {Neurophysiological} {Measures}: {State}-of-the-{Art} and {Future} {Trends}},
	volume = {2019},
	issn = {1687-5273},
	shorttitle = {Consumer {Behaviour} through the {Eyes} of {Neurophysiological} {Measures}},
	doi = {10.1155/2019/1976847},
	abstract = {The new technological advances achieved during the last decade allowed the scientific community to investigate and employ neurophysiological measures not only for research purposes but also for the study of human behaviour in real and daily life situations. The aim of this review is to understand how and whether neuroscientific technologies can be effectively employed to better understand the human behaviour in real decision-making contexts. To do so, firstly, we will describe the historical development of neuromarketing and its main applications in assessing the sensory perceptions of some marketing and advertising stimuli. Then, we will describe the main neuroscientific tools available for such kind of investigations (e.g., measuring the cerebral electrical or hemodynamic activity, the eye movements, and the psychometric responses). Also, this review will present different brain measurement techniques, along with their pros and cons, and the main cerebral indexes linked to the specific mental states of interest (used in most of the neuromarketing research). Such indexes have been supported by adequate validations from the scientific community and are largely employed in neuromarketing research. This review will also discuss a series of papers that present different neuromarketing applications, such us in-store choices and retail, services, pricing, brand perception, web usability, neuropolitics, evaluation of the food and wine taste, and aesthetic perception of artworks. Furthermore, this work will face the ethical issues arisen on the use of these tools for the evaluation of the human behaviour during decision-making tasks. In conclusion, the main challenges that neuromarketing is going to face, as well as future directions and possible scenarios that could be derived by the use of neuroscience in the marketing field, will be identified and discussed.},
	language = {eng},
	journal = {Computational Intelligence and Neuroscience},
	author = {Cherubino, Patrizia and Martinez-Levy, Ana C. and Caratù, Myriam and Cartocci, Giulia and Di Flumeri, Gianluca and Modica, Enrica and Rossi, Dario and Mancini, Marco and Trettel, Arianna},
	year = {2019},
	pmid = {31641346},
	pmcid = {PMC6766676},
	keywords = {Advertising, Brain, Consumer Behavior, Eye, Humans, Neurophysiology, Neurosciences},
	pages = {1976847},
}

@article{h_neurofeedback_2016,
	title = {Neurofeedback: {A} {Comprehensive} {Review} on {System} {Design}, {Methodology} and {Clinical} {Applications}.},
	volume = {7},
	issn = {2008-126X, 2228-7442},
	shorttitle = {Neurofeedback},
	url = {http://europepmc.org/article/PMC/4892319},
	doi = {10.15412/j.bcn.03070208},
	abstract = {Europe PMC is an archive of life sciences journal literature., Neurofeedback: A Comprehensive Review on System Design, Methodology and Clinical Applications.},
	language = {English},
	number = {2},
	urldate = {2021-02-15},
	journal = {Basic and Clinical Neuroscience},
	author = {H, Marzbani and Hr, Marateb and M, Mansourian},
	month = apr,
	year = {2016},
	pmid = {27303609},
	pages = {143--158},
}

@misc{noauthor_hackerrank_nodate,
	title = {{HackerRank}},
	url = {https://www.hackerrank.com/},
	abstract = {HackerRank is the market-leading technical assessment and remote interview solution for hiring developers. Learn how to hire technical talent from anywhere!},
	language = {en-US},
	urldate = {2021-02-15},
	journal = {HackerRank},
}

@misc{noauthor_5_nodate,
	title = {5 simple {Drawing} {Exercises} for {Beginners} and {Pros}},
	url = {https://cravepainting.com/blog/simple-drawing-exercises},
	abstract = {I have collected some easy drawing exercises for beginners and pros, that have helped me to learn drawing and sketching, so I am sharing them with you today.},
	language = {en-GB},
	urldate = {2021-02-15},
	journal = {Crave Painting},
}

@article{kato_development_2011,
	title = {Development of a {BCI} master switch based on single-trial detection of contingent negative variation related potentials},
	volume = {2011},
	doi = {10.1109/IEMBS.2011.6091146},
	abstract = {To control the startup/shutdown of a conventional brain-computer interface (BCI) that is always running for daily use, we proposed and developed a new BCI system called a BCI master switch. We designed it with on/off switching functions by detecting the contingent negative variation (CNV)--related potentials. We chose CNV to improve the single-trial discrimination of user intentions to switch because CNV had a high signal-to-noise ratio and needed high concentration for its elicitation. We also applied a support vector machine (SVM) to improve the single-trial detection of CNV-related potentials. As the best parameters of SVM were estimated and applied, the offline evaluation's best performance achieved a CNV detection rate of 99.3\% for the intention to switch and 2.1\% for the intention not to switch. Remarkably, this performance was achieved from single-trial detection, imaginary response of user's intention without physical reaction, and the data from only one recording electrode. These results suggest that our proposed BCI system might work as a master switch by single-trial detection.},
	journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
	author = {Kato, Yasuhiro and Yonemura, Tomoko and Samejima, Kazuyuki and Maeda, Taro and Ando, Hideyuki},
	month = aug,
	year = {2011},
	pages = {4629--32},
}

@article{haynes_decoding_2006,
	title = {Decoding mental states from brain activity in humans},
	volume = {7},
	issn = {1471-003X},
	doi = {10.1038/nrn1931},
	abstract = {Recent advances in human neuroimaging have shown that it is possible to accurately decode a person's conscious experience based only on non-invasive measurements of their brain activity. Such 'brain reading' has mostly been studied in the domain of visual perception, where it helps reveal the way in which individual experiences are encoded in the human brain. The same approach can also be extended to other types of mental state, such as covert attitudes and lie detection. Such applications raise important ethical issues concerning the privacy of personal thought.},
	language = {eng},
	number = {7},
	journal = {Nature Reviews. Neuroscience},
	author = {Haynes, John-Dylan and Rees, Geraint},
	month = jul,
	year = {2006},
	pmid = {16791142},
	keywords = {Brain, Brain Mapping, Consciousness, Humans, Magnetic Resonance Imaging, Mental Processes, Photic Stimulation, Visual Perception},
	pages = {523--534},
}

@article{parvizi_detecting_2018,
	title = {Detecting silent seizures by their sound},
	volume = {59},
	issn = {1528-1167},
	doi = {10.1111/epi.14043},
	abstract = {OBJECTIVE: The traditional approach to interpreting electroencephalograms (EEGs) requires physicians with formal training to visually assess the waveforms. This approach can be less practical in critical settings where a trained EEG specialist is not readily available to review the EEG and diagnose ongoing subclinical seizures, such as nonconvulsive status epilepticus.
METHODS: We have developed a novel method by which EEG data are converted to sound in real time by letting the underlying electrophysiological signal modulate a voice tone that is in the audible range. Here, we explored whether individuals without any prior EEG training could listen to 15-second sonified EEG and determine whether the EEG represents seizures or nonseizure conditions. We selected 84 EEG samples to represent seizures (n = 7), seizure-like activity (n = 25), or nonperiodic, nonrhythmic activity (normal or focal/generalized slowing, n = 52). EEGs from single channels in the left and right hemispheres were then converted to sound files. After a 4-minute training video, medical students (n = 34) and nurses (n = 30) were asked to designate each audio sample as "seizure" or "nonseizure." We then compared their performance with that of EEG-trained neurologists (n = 12) and medical students (n = 29) who also diagnosed the same EEGs on visual display.
RESULTS: Nonexperts listening to single-channel sonified EEGs detected seizures with remarkable sensitivity (students, 98\% ± 5\%; nurses, 95\% ± 14\%) compared to experts or nonexperts reviewing the same EEGs on visual display (neurologists, 88\% ± 11\%; students, 76\% ± 19\%). If the EEGs contained seizures or seizure-like activity, nonexperts listening to sonified EEGs rated them as seizures with high specificity (students, 85\% ± 9\%; nurses, 82\% ± 12\%) compared to experts or nonexperts viewing the EEGs visually (neurologists, 90\% ± 7\%; students, 65\% ± 20\%).
SIGNIFICANCE: Our study confirms that individuals without EEG training can detect ongoing seizures or seizure-like rhythmic periodic patterns by listening to sonified EEG. Although sonification of EEG cannot replace the traditional approaches to EEG interpretation, it provides a meaningful triage tool for fast assessment of patients with suspected subclinical seizures.},
	language = {eng},
	number = {4},
	journal = {Epilepsia},
	author = {Parvizi, Josef and Gururangan, Kapil and Razavi, Babak and Chafe, Chris},
	month = apr,
	year = {2018},
	pmid = {29558565},
	keywords = {Acoustic Stimulation, EEG sonification, Electroencephalography, Epilepsies, Partial, Health Personnel, Humans, Photic Stimulation, Retrospective Studies, Status Epilepticus, nonconvulsive status epilepticus, rhythmic periodic pattern, subclinical seizure},
	pages = {877--884},
}

@article{fifel_readiness_2018,
	title = {Readiness {Potential} and {Neuronal} {Determinism}: {New} {Insights} on {Libet} {Experiment}},
	volume = {38},
	issn = {1529-2401},
	shorttitle = {Readiness {Potential} and {Neuronal} {Determinism}},
	doi = {10.1523/JNEUROSCI.3136-17.2017},
	language = {eng},
	number = {4},
	journal = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
	author = {Fifel, Karim},
	month = jan,
	year = {2018},
	pmid = {29367289},
	pmcid = {PMC6596234},
	keywords = {Contingent Negative Variation, Corpus Striatum, Neostriatum},
	pages = {784--786},
}

@inproceedings{kenwright_brief_2017,
	address = {New York, NY, USA},
	series = {{SA} '17},
	title = {Brief review of video games in learning \&amp; education how far we have come},
	isbn = {978-1-4503-5409-7},
	url = {https://doi.org/10.1145/3134368.3139220},
	doi = {10.1145/3134368.3139220},
	abstract = {This paper presents a survey on video games in learning and education, including patterns and trends in technologies and correlations in popularity with regard to the entertainment industry. The fact that games have the ability to engage and captivate a person's attention for long periods of time, while offering numerous additional benefits, such as, developing high-level thinking skills, is extremely attractive and important. The capacity to unconsciously learn and master complex concepts through video games has enormous benefit in learning (beyond simple `educational' games, such as, sharpening focus, responsiveness, and collaborative working). As we show in this paper, research dating right back to the early 1980s has consistently demonstrated that playing computer games (irrespective of genre) develops faster reaction times, improved hand-eye co-ordination and raises players' self-esteem. We review video game literature in the area of education (and learning) and how technologies are changing traditional learning paradigms (e.g., mobile devices and virtual reality). What is more, we also review the disadvantages of video games in certain contexts and debate the reasons for their failures - but more importantly what measures are necessary to ensure video games facilitate as an educational `aid' and not a `hindrance'. Having said that, we deliberate on questions, such as, what makes an `educational game' and how is the design and structure different from a traditional `video game'? Above all, educational video games have changed enormously over the past few decades, with a greater emphasis on understanding the audience, learning objectives and evaluation mechanisms to `guarantee' the game is successful and accomplishes its end goal - as we discuss, this is embodied by a whole assortment of elements, from psychology, age, gender and technological factors to social and usability development. In conclusion, video games connect with a vast assortment of areas, such as, medicine and robotics, but most importantly, education and learning. With video games one of the largest growing sectors, we contemplate how past research and recent developments in technologies are changing the learning and educational sector for the better, thereby gaining insights into future strength and directions.},
	urldate = {2021-02-14},
	booktitle = {{SIGGRAPH} {Asia} 2017 {Symposium} on {Education}},
	publisher = {Association for Computing Machinery},
	author = {Kenwright, Ben},
	month = nov,
	year = {2017},
	keywords = {computing, education, gamification, learning, serious games, technologies, video games},
	pages = {1--10},
}

@misc{noauthor_iclabel_nodate,
	title = {{ICLabel} - {SCCN}},
	url = {https://sccn.ucsd.edu/wiki/ICLabel},
	urldate = {2021-02-14},
}

@misc{noauthor_sccncleanline_2020,
	title = {sccn/cleanline},
	copyright = {View license         ,                 View license},
	url = {https://github.com/sccn/cleanline},
	abstract = {Clean Line. Contribute to sccn/cleanline development by creating an account on GitHub.},
	urldate = {2021-02-14},
	publisher = {Swartz Center for Computational Neuroscience},
	month = oct,
	year = {2020},
	note = {original-date: 2019-12-03T21:30:50Z},
}

@misc{noauthor_sccnclean_rawdata_2021,
	title = {sccn/clean\_rawdata},
	copyright = {GPL-3.0 License         ,                 GPL-3.0 License},
	url = {https://github.com/sccn/clean_rawdata},
	abstract = {Cleaning Raw EEG data. Contribute to sccn/clean\_rawdata development by creating an account on GitHub.},
	urldate = {2021-02-14},
	publisher = {Swartz Center for Computational Neuroscience},
	month = jan,
	year = {2021},
	note = {original-date: 2019-01-21T00:01:49Z},
}

@misc{inc_crowdcast_nodate,
	title = {Crowdcast – {Connect} with your audience over live video},
	url = {https://www.crowdcast.io/},
	abstract = {Simple \& powerful Q\&As, webinars, live courses \& online summits with your audience.},
	urldate = {2021-02-10},
	journal = {Crowdcast},
	author = {Inc, Crowdcast},
}

@article{ijsselsteijn_game_2013,
	title = {The {Game} {Experience} {Questionnaire}},
	url = {https://research.tue.nl/en/publications/the-game-experience-questionnaire},
	language = {English},
	urldate = {2021-02-10},
	author = {IJsselsteijn, W. A. and Kort, Y. A. W. de and Poels, K.},
	year = {2013},
	note = {Publisher: Technische Universiteit Eindhoven},
}

@misc{noauthor_muse_nodate,
	title = {{MUSE} {Data} {Collection}},
	url = {https://www.krigolsonlab.com/muse-data-collection.html},
	urldate = {2021-02-10},
}

@misc{noauthor_tutorial_nodate,
	title = {Tutorial - {Muse} {Developer} {Resources}},
	url = {https://sites.google.com/a/interaxon.ca/muse-developer-site/muselab/tutorial},
	urldate = {2021-02-10},
}

@misc{noauthor_jdpigeonbci-workshop_nodate,
	title = {jdpigeon/bci-workshop},
	url = {https://github.com/jdpigeon/bci-workshop},
	abstract = {Material for the BCI Workshop held at District 3 in May 2015 by BCI Montréal. - jdpigeon/bci-workshop},
	language = {en},
	urldate = {2021-02-10},
	journal = {GitHub},
}

@misc{carroll_meditation_nodate,
	title = {Meditation for mind-control},
	url = {https://engineering.cmu.edu/news-events/news/2020/09/23-meditation.html},
	abstract = {Carnegie Mellon Biomedical Engineering Department Head Bin He and his team have discovered that mindful meditation can help subjects learn and improve the ability to mind-control brain computer interfaces (BCIs).},
	language = {en},
	urldate = {2021-02-10},
	author = {Carroll, Dan},
}

@article{sung_development_2012,
	title = {A {Development} {Architecture} for {Serious} {Games} {Using} {BCI} ({Brain} {Computer} {Interface}) {Sensors}},
	volume = {12},
	issn = {1424-8220},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3522980/},
	doi = {10.3390/s121115671},
	abstract = {Games that use brainwaves via brain–computer interface (BCI) devices, to improve brain functions are known as BCI serious games. Due to the difficulty of developing BCI serious games, various BCI engines and authoring tools are required, and these reduce the development time and cost. However, it is desirable to reduce the amount of technical knowledge of brain functions and BCI devices needed by game developers. Moreover, a systematic BCI serious game development process is required. In this paper, we present a methodology for the development of BCI serious games. We describe an architecture, authoring tools, and development process of the proposed methodology, and apply it to a game development approach for patients with mild cognitive impairment as an example. This application demonstrates that BCI serious games can be developed on the basis of expert-verified theories.},
	number = {11},
	urldate = {2021-02-10},
	journal = {Sensors (Basel, Switzerland)},
	author = {Sung, Yunsick and Cho, Kyungeun and Um, Kyhyun},
	month = nov,
	year = {2012},
	pmid = {23202227},
	pmcid = {PMC3522980},
	pages = {15671--15688},
}

@article{garcia_ensemble_2021,
	title = {An {Ensemble} of {Autonomous} {Auto}-{Encoders} for {Human} {Activity} {Recognition}},
	doi = {10.1016/j.neucom.2020.01.125},
	abstract = {Human Activity Recognition is focused on the use of sensing technology to classify human activities and to infer human behavior. While traditional machine learning approaches use hand-crafted features to train their models, recent advancements in neural networks allow for automatic feature extraction. Auto-encoders are a type of neural network that can learn complex representations of the data and are commonly used for anomaly detection. In this work we propose a novel multi-class algorithm which consists of an ensemble of auto-encoders where each auto-encoder is associated with a unique class. We compared the proposed approach with other state-of-the-art approaches in the context of human activity recognition. Experimental results show that ensembles of auto-encoders can be efficient, robust and competitive. Moreover, this modular classifier structure allows for more flexible models. For example, the extension of the number of classes, by the inclusion of new auto-encoders, without the necessity to retrain the whole model.},
	journal = {Neurocomputing},
	author = {Garcia, Kemilly and Rebelo de Sá, Cláudio and Poel, Mannes and Carvalho, Tiago and Moreira, João and Cardoso, João and de Carvalho, Andre and Kok, Joost},
	month = jan,
	year = {2021},
}

@misc{noauthor_notitle_nodate,
}

@article{delorme_independent_2012,
	title = {Independent {EEG} {Sources} {Are} {Dipolar}},
	volume = {7},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0030135},
	doi = {10.1371/journal.pone.0030135},
	language = {en},
	number = {2},
	urldate = {2021-02-01},
	journal = {PLoS ONE},
	author = {Delorme, Arnaud and Palmer, Jason and Onton, Julie and Oostenveld, Robert and Makeig, Scott},
	editor = {Ward, Lawrence M.},
	month = feb,
	year = {2012},
	pages = {e30135},
}

@misc{noauthor_consumers_nodate,
	title = {Consumers want manufacturers \& retailers to reduce plastic usage - {Retail} {Gazette}},
	url = {https://www.retailgazette.co.uk/blog/2019/09/plastic-usage-waste-sustainability-enviroment-consumers/},
	urldate = {2021-01-28},
}

@article{dilkes-hoffman_public_2019,
	title = {Public attitudes towards plastics},
	volume = {147},
	issn = {0921-3449},
	url = {http://www.sciencedirect.com/science/article/pii/S0921344919302101},
	doi = {10.1016/j.resconrec.2019.05.005},
	abstract = {Understanding and engaging the public is key for ensuring the success of government and industry initiatives aimed at addressing the problem of plastic waste. However, there has been little focus on documenting the general public’s attitudes towards plastics. This study examines public beliefs and attitudes towards plastics in Australia and provides insight on a global level. The research was conducted using an online survey of a nationally representative sample (2518 respondents). Overall, the survey results indicate that the public view plastics as a serious environmental issue. Plastic in the ocean had the highest mean rating for seriousness out of nine environmental issues, followed by two other issues relating to plastic waste production and disposal. Whilst there was an association of plastics with food packaging and convenience, there was more of a negative association with the use of plastic overall. Eighty percent of respondents indicated a desire to reduce plastic use and the majority of respondents believe that paper and glass are more environmentally friendly packaging materials than plastics. However, the results showed that many respondents do not translate their aspiration to reduce plastic use into action. Overall, while a majority of the Australian public are concerned about plastics as an environmental issue, they place the bulk of the responsibility for reducing the use of disposable plastic on industry and government.},
	language = {en},
	urldate = {2021-01-28},
	journal = {Resources, Conservation and Recycling},
	author = {Dilkes-Hoffman, Leela Sarena and Pratt, Steven and Laycock, Bronwyn and Ashworth, Peta and Lant, Paul Andrew},
	month = aug,
	year = {2019},
	keywords = {Consumer attitude, Environmental issues, Plastic in the ocean, Plastic waste, Reduce plastic use, Responsibility},
	pages = {227--235},
}

@misc{noauthor_ban_nodate,
	title = {Ban on sale of single-use plastics},
	url = {https://business.gov.nl/amendment/ban-sale-single-use-plastics/},
	abstract = {Business.gov.nl - The official source of information for doing business in the Netherlands, made available by the Dutch government.},
	language = {en},
	urldate = {2021-01-28},
	journal = {business.gov.nl},
}

@patent{noauthor_micropits_2015,
	title = {Micropits for ultrasonic treatment},
	url = {https://patents.google.com/patent/WO2015144918A1/en},
	abstract = {The invention provides a method for treating an object (100), the method comprising: (a) providing a liquid (210); (b) arranging the object (100) in the liquid (210), wherein the object (100) is at least partially enclosed in an enclosure (300), wherein the enclosure (300) comprises polymeric enclosure material (310) having a polymeric material surface (320) directed to the object (100), the polymeric material surface (320) comprising cavities (330) having equivalent circular diameters selected from the range of 10 μm - 2 mm; and (c) providing ultrasound to the liquid (210).},
	language = {en},
	urldate = {2021-01-28},
	month = mar,
	year = {2015},
}

@misc{noauthor_6_2020,
	title = {6 ways to strengthen your online presence to benefit your business},
	url = {https://www.experian.co.uk/blogs/latest-thinking/small-business/6-benefits-to-an-online-presence/},
	abstract = {Being able to adapt and make the most of the opportunities presented by the changing digital world has already seen many small businesses not only survive, but thrive. The good news is that now, more than ever, there are a multitude of low-cost, accessible ways to do that, with the potential for a great return on investment.},
	language = {en-GB},
	urldate = {2021-01-28},
	journal = {Latest Thinking Blog},
	month = sep,
	year = {2020},
}

@book{corporation_popular_1970,
	title = {Popular {Science}},
	abstract = {Popular Science gives our readers the information and tools to improve
their technology and their world.  The core belief that Popular
Science and our readers share: The future is going to be better, and
science and technology are the driving forces that will help make it
better.},
	language = {en},
	publisher = {Bonnier Corporation},
	author = {Corporation, Bonnier},
	month = mar,
	year = {1970},
	note = {Google-Books-ID: 6QAAAAAAMBAJ},
}

@misc{noauthor_sonic_nodate,
	title = {Sonic {Soak} {Ultrasonic} {Cleaner} - {Multi}-{Purpose} {Ultrasonic} {Cleaning} {Machine} for {Laundry}, {Fruits}, {Cutlery}, {Jewelry}, {Watches} \& {Accessories}},
	url = {https://sonicsoak.com/products/sonic-soak},
	urldate = {2021-01-28},
}

@misc{noauthor_google_nodate,
	title = {Google {Trends}},
	url = {https://trends.google.com/trends/explore?date=today%205-y&q=%2Fm%2F08k_gq},
	abstract = {Esplora gli interessi di ricerca per Pulizia a ultrasuoni in base alla data, all'area geografica e alla diffusione su Google Trends},
	language = {it},
	urldate = {2021-01-28},
	journal = {Google Trends},
}

@misc{noauthor_google_nodate-1,
	title = {Google {Trends}},
	url = {https://trends.google.com/trends/explore?q=ultrasonic%20cleaning%20tank},
	abstract = {Esplora gli interessi di ricerca per ultrasonic cleaning tank in base alla data, all'area geografica e alla diffusione su Google Trends},
	language = {it},
	urldate = {2021-01-28},
	journal = {Google Trends},
}

@misc{noauthor_google_nodate-2,
	title = {Google {Trends}},
	url = {https://trends.google.com/trends/explore?q=ultrasonic%20cleaning%20tank},
	abstract = {Esplora gli interessi di ricerca per ultrasonic cleaning tank in base alla data, all'area geografica e alla diffusione su Google Trends},
	language = {it},
	urldate = {2021-01-28},
	journal = {Google Trends},
}

@misc{noauthor_sudden_nodate,
	title = {The sudden urgency of online academic conferences},
	url = {https://www.universityaffairs.ca/features/feature-article/the-sudden-urgency-of-online-academic-conferences/},
	abstract = {Traditional in-person conferences have been criticized for a variety of reasons, but the current COVID-19 pandemic puts them in a whole new light.},
	language = {en-US},
	urldate = {2021-01-28},
	journal = {University Affairs},
}

@misc{noauthor_about_nodate,
	title = {About {ECIU}},
	url = {https://www.eciu.org/about-eciu#members},
	abstract = {‍We are ECIU, the European Consortium of Innovative Universities, a network of 13 universities united since 1997 by a common profile of shared beliefs, interests, and mutual trust.},
	language = {en},
	urldate = {2021-01-28},
}

@misc{noauthor_how_2020,
	title = {How the pandemic has impacted research at a global level},
	url = {https://www.medicalnewstoday.com/articles/shifting-goalposts-research-in-the-time-of-the-coronavirus},
	abstract = {Since the start of the COVID-19 pandemic, all eyes have been on coronavirus research. But how has the pandemic impacted the research community at large?},
	language = {en},
	urldate = {2021-01-28},
	month = jul,
	year = {2020},
}

@article{noauthor_europes_2020,
	title = {Europe’s {Second} {Lockdown} {Wave} {Risks} {Double}-{Dip} {Recessions}},
	url = {https://www.bloomberg.com/news/articles/2020-11-05/covid-pandemic-europe-s-second-lockdown-wave-risks-double-dip-recessions},
	abstract = {Governments are trying to limit the pain to a few industries, but the costs may still be high.},
	language = {en},
	urldate = {2021-01-28},
	journal = {Bloomberg.com},
	month = nov,
	year = {2020},
	keywords = {Beer, Coronavirus, Europe, France, Germany, Government, Italy, Milan, Paris, Rome, business, businessweek, markets, politics},
}

@misc{noauthor_world_nodate,
	title = {World {Economic} {Outlook} {Databases}},
	url = {https://www.imf.org/en/Publications/SPROLLs/world-economic-outlook-databases},
	language = {en},
	urldate = {2021-01-28},
	journal = {IMF},
}

@article{staff_ecb_2020,
	title = {{ECB} to monitor euro appreciation 'very carefully': {Lagarde}},
	shorttitle = {{ECB} to monitor euro appreciation 'very carefully'},
	url = {https://www.reuters.com/article/ecb-policy-currency-idINKBN28K1Y6},
	abstract = {The European Central Bank will keep a close eye on the strength of the euro as it tends to push down prices and thereby inflation in the single-currency bloc, ECB President Christine Lagarde said on Thursday.},
	language = {en},
	urldate = {2021-01-28},
	journal = {Reuters},
	author = {Staff, Reuters},
	month = dec,
	year = {2020},
	keywords = {Asset-Backed Securities, Banks (TRBC level 4), CURRENCY, Central Banks / Central Bank Events, Currencies / Foreign Exchange Markets, Debt / Fixed Income Markets, ECB, Economic News (3rd Party), Euro Zone as a Whole, Europe, European Central Bank, European Union, Major News, Monetary / Fiscal Policy / Policy Makers, Money Markets, National Government Debt, POLICY, Reuters Top News},
}

@misc{pettinger_low_nodate,
	title = {Low {Inflation}},
	url = {https://www.economicshelp.org/macroeconomics/low_inflation/},
	abstract = {Why economists advise targeting low inflation. Benefits of low inflation. How to achieve low inflation. Can inflation become too low? Graphs and examples of low inflation periods.},
	language = {en-GB},
	urldate = {2021-01-28},
	journal = {Economics Help},
	author = {Pettinger, Tejvan},
}

@misc{noauthor_netherlands_nodate,
	title = {Netherlands {Inflation} {Rate} {\textbar} 1971-2020 {Data} {\textbar} 2021-2023 {Forecast} {\textbar} {Calendar}},
	url = {https://tradingeconomics.com/netherlands/inflation-cpi},
	abstract = {The Netherlands' annual inflation rate increased to 1.0 percent in December 2020 from 0.8 percent in the previous month, due to a faster rise in prices of both recreation \& culture (1.9\%  vs 1.3\%) and furnishings \& household equipment (2.3\% vs 1.4\%), while housing inflation was steady (at 0.8\%) and transport prices fell less (-2.3\% vs -3.2\%). Meantime, food and non-alcoholic beverages inflation eased to a 26-month low of 0.6 percent in December from 0.8 percent in November. By contrast, clothing and footwear prices fell 2 percent, after a flat reading in the prior month. Considering 2020 full year, inflation rate averaged 1.3 percent, down from 2.6 percent in 2019. The annual core inflation, which excludes energy, food, alcohol, and tobacco increased to 1.7 percent in December from a four-month low of 1.5 percent in November. On a monthly basis, consumer prices were up 0.2 percent, after a 0.8 percent fall in the prior month. Inflation Rate in Netherlands averaged 3.17 percent from 1971 until 2020, reaching an all time high of 11.19 percent in November of 1974 and a record low of -1.30 percent in February of 1987. This page provides - Netherlands Inflation Rate - actual values, historical data, forecast, chart, statistics, economic calendar and news.},
	urldate = {2021-01-28},
}

@misc{noauthor_corporate_nodate,
	title = {Corporate income tax (vpb)},
	url = {https://business.gov.nl/regulation/corporate-income-tax/},
	abstract = {Private or public limited companies in the Netherlands (bv or nv) must complete a corporate income tax return (vpb). Read more here.},
	language = {en},
	urldate = {2021-01-28},
	journal = {business.gov.nl},
}

@misc{noauthor_how_2019,
	title = {How {Brexit} will affect shipping goods between the {EU} and the {UK}},
	url = {https://www.interloggroup.com/en/how-brexit-will-affect-shipping-goods-between-the-and-the-uk/},
	abstract = {If there’s one thing to expect from Brexit, it’s the unexpected. The UK was supposed to leave the EU on March 29, 2019. It did not happen. As of now, the new deadline is April 12. But no one knows for sure what the terms of the separation will be. Will it be the deal … Continue reading "How Brexit will affect shipping goods between the EU and the UK"},
	language = {en-US},
	urldate = {2021-01-28},
	journal = {Interlog Services},
	month = apr,
	year = {2019},
	note = {Section: Group},
}

@article{baumeister_customer_2002,
	title = {Customer {Relationship} {Management} for {SMEs}},
	abstract = {Customer Relationship Management (CRM) is getting more and more a key strategy for companies big and small. Customer care strategy and CRM software go hand in hand. In particular SME's need a CRM software that easily adapts to their customer care needs while still being low cost. In this paper I discuss the benefits of CRM for SME's and their special requirements wrt. CRM software. Further, I intro-duce the IST-project CARUSO whose objective is to provide SME's with a software framework to implement low cost, customized CRM applications. This paper presents the rational behind the CARUSO project, the architecture of the framework, and the software development process used to build the framework.},
	author = {Baumeister, Hubert},
	month = jan,
	year = {2002},
}

@misc{noauthor_review_nodate,
	title = {A review of customer relationship management system benefits and implementation in small and medium enterprises {\textbar} {Proceedings} of the 12th {WSEAS} international conference on {Mathematics} and computers in biology, business and acoustics},
	url = {https://dl.acm.org/doi/abs/10.5555/1991147.1991193},
	urldate = {2021-01-28},
}

@misc{noauthor_pdf_nodate,
	title = {({PDF}) {IMPACTS} {OF} {MARKETING} {AUTOMATION} {ON} {BUSINESS} {PERFORMANCE}},
	url = {https://www.researchgate.net/publication/342184130_IMPACTS_OF_MARKETING_AUTOMATION_ON_BUSINESS_PERFORMANCE},
	urldate = {2021-01-28},
}

@misc{noauthor_smbs_2017,
	title = {{SMBs} {Plan} to {Adopt} {Marketing} {Automation} {Despite} {Cost} \& {Familiarity} {Issues}},
	url = {https://www.marketingcharts.com/customer-centric/analytics-automated-and-martech-81650},
	abstract = {Three in 10 SMBs in the US (fewer than 1,000 employees) that have an email marketing solution in place also have marketing automation software, per results from an ActiveCampaign study [pdf]. The survey of email-using SMBs found that the bulk of those without a current automation solution plan to adopt one in the next couple… Read More »},
	language = {en-US},
	urldate = {2021-01-28},
	journal = {Marketing Charts},
	month = dec,
	year = {2017},
	note = {Section: Analytics, Automated \& MarTech},
}

@article{heimbach_marketing_2015,
	title = {Marketing {Automation}},
	volume = {57},
	issn = {2363-7005, 1867-0202},
	url = {http://link.springer.com/10.1007/s12599-015-0370-8},
	doi = {10.1007/s12599-015-0370-8},
	language = {en},
	number = {2},
	urldate = {2021-01-28},
	journal = {Business \& Information Systems Engineering},
	author = {Heimbach, Irina and Kostyra, Daniel S. and Hinz, Oliver},
	month = apr,
	year = {2015},
	pages = {129--133},
}

@article{oliveira_firms_2012,
	title = {Firms {Patterns} of e-{Business} {Adoption}: {Evidence} for the {European} {Union27}},
	volume = {13},
	shorttitle = {Firms {Patterns} of e-{Business} {Adoption}},
	abstract = {Research has shown that firms using e-business achieve considerable returns through efficiency improvements, inventory reduction, sales increase, customer relationship enhancement, new market penetration, and ultimately financial returns. However, there is little systematic research in terms of e-business adoption patterns in firms across countries and industries. This study addresses the research gap by analysing the pattern of e-business adoption by firms across European Union (EU) members. For that, we used the survey data from 6,964 businesses in EU27 members (excluding Malta and Bulgaria). The choice of variables that we will use in our study is based on the technology-organization-environment (TOE) theory. In the TOE framework, three aspects may possibly influence e-business adoption: technological context (technology readiness and technology integration); organizational context (firm size, expected benefits and barriers of e-business and improved products or services or internal processes); and environmental context (internet penetration and competitive pressure). We performed a factor analysis (FA) of multi-item indicators to evaluate the validity and to reduce the number of variables. We used the principal component technique with varimax rotation to extract four eigenvalue, which were all greater than one. The first four factors explain 72.4 \% of variance contained in the data. The four factors found are: expected benefits and obstacles of e-business, internet penetration, technology readiness and technology integration. These factors are in accordance with the literature review. Afterwards, we performed},
	author = {Oliveira, Tiago and Martins, Maria Rosario},
	month = feb,
	year = {2012},
}

@article{buyukozkan_digital_2018,
	title = {Digital {Supply} {Chain}: {Literature} review and a proposed framework for future research},
	volume = {97},
	issn = {0166-3615},
	shorttitle = {Digital {Supply} {Chain}},
	url = {http://www.sciencedirect.com/science/article/pii/S0166361517304487},
	doi = {10.1016/j.compind.2018.02.010},
	abstract = {Suppliers, partners, companies and dealers in supply chains do use, generate and share information with others. These associations lead to a multitude of challenges and opportunities within the supply chains. A Digital Supply Chain (DSC) is a smart, value-driven, efficient process to generate new forms of revenue and business value for organizations and to leverage new approaches with novel technological and analytical methods DSC is not about whether goods and services are digital or physical, it is about the way how supply chain processes are managed with a wide variety of innovative technologies, e.g. unmanned aerial vehicles, cloud computing, and internet of things, among others. Recent literature highlights the importance of DSC and many industrial researchers discuss its applications. This article reviews the state-of-the-art of existing DSC literature in detail from both academic and industrial points of view. It identifies key limitations and prospects in DSC, summarizes prior research and identifies knowledge gaps by providing advantages, weaknesses and limitations of individual methods The article also aims at providing a development framework as a roadmap for future research and practice.},
	language = {en},
	urldate = {2021-01-28},
	journal = {Computers in Industry},
	author = {Büyüközkan, Gülçin and Göçer, Fethullah},
	month = may,
	year = {2018},
	keywords = {DSC framework, Digital Supply Chain (DSC), Literature review, Technology enablers},
	pages = {157--177},
}

@book{hines_supply_2004,
	title = {Supply {Chain} {Strategies}: {Customer} {Driven} and {Customer} {Focused}},
	isbn = {978-0-08-048125-8},
	shorttitle = {Supply {Chain} {Strategies}},
	abstract = {Supply Chain Strategies: Customer Driven and Customer Focused highlights the main challenges facing organizations wanting to select, design and implement successful supply chain strategies in an increasingly global and competitive environment. The text features discussion questions at the end of each chapter to promote learning, and numerous industry examples to ilustrate key concepts within chapters. Each chapter discusses the issues in relation to previous literature, contemporary practices and the lesson to be learned from different industries where successful management of supply chains has improved organizational and industry level profitability. The text includes a number of industry examples, thereby giving a wide-ranging approach to the topic.},
	author = {Hines, Tony},
	month = jan,
	year = {2004},
	doi = {10.4324/9780080481258},
}

@article{noauthor_marketing_nodate,
	title = {Marketing {Effectiveness} in the {Digital} {Era}},
	language = {en},
	pages = {22},
}

@misc{heaton_how_2019,
	title = {How {Often} {Should} {You} {Redesign} {Your} {Website}?},
	url = {https://medium.com/swlh/how-often-should-you-redesign-your-website-15dd04ae7a2d},
	abstract = {Tips from a Former Designer and Marketing Strategist},
	language = {en},
	urldate = {2021-01-28},
	journal = {Medium},
	author = {Heaton, Tami},
	month = dec,
	year = {2019},
}

@misc{noauthor_website_nodate,
	title = {Website {Update}: {Why} {It} {Is} {Important} for {Every} {Small} {Business}},
	url = {https://www.exai.com/blog/website-update-small-business},
	urldate = {2021-01-28},
}

@misc{noauthor_single-use_nodate,
	title = {Single-use plastics ban},
	url = {http://publications.europa.eu/resource/cellar/767969e4-e663-11e9-9c4e-01aa75ed71a1.0001.02/DOC_1},
	urldate = {2021-01-28},
}

@misc{noauthor_emerson_nodate,
	title = {Emerson {\textbar} {Emerson} {NL}},
	url = {https://www.emerson.com/en-nl},
	abstract = {Helping address the world's most critical needs through our new core business platforms - Automation Solutions and Commercial \& Residential Solutions. Whatever the challenge, you can always Consider it Solved.},
	language = {en-nl},
	urldate = {2021-01-28},
}

@misc{noauthor_how_2017,
	title = {How to {Run} a {Successful} {Email} {Marketing} {Campaign} ({Step} by {Step} {Guide})},
	url = {https://optinmonster.com/how-to-run-a-successful-email-marketing-campaign/},
	abstract = {How do you run a successful email marketing campaign? Here are 10 must-do steps to follow for email marketing campaign success.},
	language = {en-US},
	urldate = {2021-01-28},
	journal = {OptinMonster},
	month = jul,
	year = {2017},
	note = {Section: Email Marketing},
}

@misc{noauthor_effects_nodate,
	title = {Effects of {Loyalty} {Programs} on {Value} {Perception}, {Program} {Loyalty}, and {Brand} {Loyalty} - {Youjae} {Yi}, {Hoseong} {Jeon}, 2003},
	url = {https://journals.sagepub.com/doi/abs/10.1177/0092070303031003002},
	urldate = {2021-01-28},
}

@article{tuskej_role_2013,
	series = {(1){Thought} leadership in brand management(2){Health} {Marketing}},
	title = {The role of consumer–brand identification in building brand relationships},
	volume = {66},
	issn = {0148-2963},
	url = {http://www.sciencedirect.com/science/article/pii/S014829631100258X},
	doi = {10.1016/j.jbusres.2011.07.022},
	abstract = {The purpose of this paper is to investigate relationships between congruity of consumer and brand values, brand identification, brand commitment, and word of mouth. The results show that congruity of consumer and brand values tends to have positive influence on consumers' identification. Consumers who identify with a brand tend to commit stronger to a brand and generate positive word of mouth. The results show that consumers' identification fully mediates the impact of value congruity on brand commitment. However, brand commitment does not mediate the impact of consumers' identification on generating positive word of mouth.},
	language = {en},
	number = {1},
	urldate = {2021-01-28},
	journal = {Journal of Business Research},
	author = {Tuškej, Urška and Golob, Urša and Podnar, Klement},
	month = jan,
	year = {2013},
	keywords = {Brand, Commitment, Consumer, Identification, Value congruity, Word of mouth},
	pages = {53--59},
}

@misc{noauthor_developing_nodate,
	title = {Developing a {Content} {Strategy}},
	url = {https://contentmarketinginstitute.com/developing-a-strategy/},
	abstract = {Here are some resources to help you get started when developing a content strategy.},
	language = {en-US},
	urldate = {2021-01-28},
	journal = {Content Marketing Institute},
}

@misc{noauthor_30_nodate,
	title = {30 branding stats and facts},
	url = {https://www.lucidpress.com/blog/25-branding-stats-facts},
	abstract = {A strong brand is the bread and butter of today's businesses. Need some data to inspire yourself or others? Check out these 25 awesome branding stats \& facts.},
	language = {en-US},
	urldate = {2021-01-28},
	journal = {Lucidpress Blog},
}

@misc{noauthor_jewelry_nodate,
	title = {Jewelry {Market} {Size}, {Share}, {Analysis} {\textbar} {Industry} {Report}, 2019-2025},
	url = {https://www.grandviewresearch.com/industry-analysis/jewelry-market},
	abstract = {The global jewelry market size is expected to reach USD 480.5 billion by 2025, due to rising disposable income, increasing shift towards elegant and stylish products with a variety of designs such as rings and bracelets, and growing acceptance of jewelry among men},
	language = {en},
	urldate = {2021-01-28},
}

@misc{cycles_topic_nodate,
	title = {Topic: {Jewelry} market worldwide},
	shorttitle = {Topic},
	url = {https://www.statista.com/topics/5163/jewelry-market-worldwide/},
	abstract = {Discover all statistics and data on Jewelry market worldwide now on statista.com!},
	language = {en},
	urldate = {2021-01-28},
	journal = {Statista},
	author = {cycles, This text provides general information Statista assumes no liability for the information given being complete or correct Due to varying update and Text, Statistics Can Display More up-to-Date Data Than Referenced in the},
}

@misc{noauthor_global_nodate,
	title = {The {Global} {Art} {Market} {Reached} \$67.4 {Billion} in 2018, up 6\% - {Artsy}},
	url = {https://www.artsy.net/article/artsy-editorial-global-art-market-reached-674-billion-2018-6},
	urldate = {2021-01-28},
}

@misc{noauthor_biotechnology_nodate,
	title = {Biotechnology {Market} {Size} {Worth} \$727.1 {Billion} {By} 2025 {\textbar} {CAGR}: 7.4\%},
	shorttitle = {Biotechnology {Market} {Size} {Worth} \$727.1 {Billion} {By} 2025 {\textbar} {CAGR}},
	url = {https://www.grandviewresearch.com/press-release/global-biotechnology-market},
	abstract = {The global biotechnology market size is expected to reach USD 727.1 billion by 2025, at a CAGR of 7.4\% according to a new report by Grand View Research, Inc. The emergence of certain key themes in the market is expected to drive growth in this industry to a lucrative extent},
	language = {en},
	urldate = {2021-01-28},
}

@misc{brandon_gaille_40_2019,
	title = {40 {Biomedical} {Industry} {Statistics}, {Trends} \& {Analysis}},
	url = {https://brandongaille.com/40-biomedical-industry-statistics-trends-analysis/},
	abstract = {The biomedical industry uses living organisms or biological systems to develop its products. Most of the items that fall under this umbrella belong to the biopharmaceutical drug segment of the industry. Europe and the United},
	language = {en-US},
	urldate = {2021-01-28},
	journal = {BrandonGaille.com},
	author = {Brandon Gaille},
	month = oct,
	year = {2019},
	note = {Section: Statistics},
}

@article{zillen_world_2000,
	title = {World dental demographics},
	volume = {50},
	issn = {0020-6539},
	doi = {10.1111/j.1875-595x.2000.tb00558.x},
	abstract = {AIMS: To collect basic data regarding dental workforce and dental education in all countries of the world and to make this data available on the FDI's Website.
METHOD: A postal questionnaire survey.
SOURCES OF INFORMATION: Member Associations of the FDI and governmental agencies.
RESULTS: Responses were received from 73 countries with a reported total number of dentists of 703,947. A comparison between the figures now reported and the figures published in 1990 shows that the total number of dentists in these countries has increased by 27.8 per cent over the ten year period. No correlation was found between the population per dentist figures and the GNP of the countries. In the reporting countries, there were 550 dental schools. A comparison between the figures now reported and the figures published in 1990 shows that the total number of dental schools in these countries has increased by 42.6 per cent over the ten year period. The total number of dental hygienists was reported to be 181,336 and the total number of dental technicians in these countries was reported to be 252,004.},
	language = {eng},
	number = {4},
	journal = {International Dental Journal},
	author = {Zillén, P. A. and Mindak, M.},
	month = aug,
	year = {2000},
	pmid = {11042819},
	keywords = {Demography, Dental Auxiliaries, Dentists, Dentists, Women, Education, Dental, Female, Humans, Internet, Male, Specialties, Dental, Surveys and Questionnaires},
	pages = {194--234},
}

@article{frow_stakeholder_2011,
	title = {A stakeholder perspective of the value proposition concept},
	volume = {45},
	issn = {0309-0566},
	url = {https://doi.org/10.1108/03090561111095676},
	doi = {10.1108/03090561111095676},
	abstract = {Purpose – The value proposition concept and the stakeholder perspective have received relatively little attention within Service‐Dominant (S‐D) logic. This paper sets out to explore value propositions in the context of S‐D logic, within the multiple stakeholder domains that form part of a marketing system. Its purpose is to identify how use of the value proposition concept, in this broader context, provides new insight into value creation within a value network. Design/methodology/approach – This paper explores the development of value propositions in key stakeholder market domains. A five‐step process is developed for identifying key stakeholders and co‐creating value propositions for them within a marketing system. Findings – Value propositions have a key role in co‐creation of value between stakeholders. The development of value propositions in multiple stakeholder domains can provide an important mechanism for aligning value within a marketing system. Practical implications – Stakeholder value propositions provide enhanced opportunities for value co‐creation and can assist managers in aligning value and stabilizing relationships within an organization's value network. Originality/value – This paper considers a broader view of value through creation of value propositions for key stakeholders. An iterative framework is proposed that couples the stakeholder concept and value co‐creation.},
	number = {1/2},
	urldate = {2021-01-28},
	journal = {European Journal of Marketing},
	author = {Frow, Pennie and Payne, Adrian},
	month = jan,
	year = {2011},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Customers, Stakeholder analysis},
	pages = {223--240},
}

@article{payne_customer_2017,
	title = {The customer value proposition: evolution, development, and application in marketing},
	volume = {45},
	issn = {1552-7824},
	shorttitle = {The customer value proposition},
	url = {https://doi.org/10.1007/s11747-017-0523-z},
	doi = {10.1007/s11747-017-0523-z},
	abstract = {The customer value proposition (CVP) has a critical role in communicating how a company aims to provide value to customers. Managers and scholars increasingly use CVP terminology, yet the concept remains poorly understood and implemented; relatively little research on this topic has been published, considering the vast breadth of investigations of the value concept. In response, this article offers a comprehensive review of fragmented CVP literature, highlighting the lack of a strong theoretical foundation; distinguishes CVPs from related concepts; proposes a conceptual model of the CVP that includes antecedents, consequences, and moderators, together with several research propositions; illustrates the application of the CVP concept to four contrasting companies; and advances a compelling agenda for research.},
	language = {en},
	number = {4},
	urldate = {2021-01-28},
	journal = {Journal of the Academy of Marketing Science},
	author = {Payne, Adrian and Frow, Pennie and Eggert, Andreas},
	month = jul,
	year = {2017},
	pages = {467--489},
}

@book{wormald_role_2013,
	title = {The role of value proposition in new product innovation - a development for design education},
	abstract = {The use of the construct 'value proposition' is becoming prominent in the world of design, as business and marketing intersect more with the processes of design. Value proposition can be a powerful way of capturing, or modelling, ideas for products, rather than the actual realisation of those products. The paper makes a case that the creation and articulation of value proposition is a necessary design ability that should concern design educators, in the same way that other modelling activities are. This is especially so within a discipline such as industrial design where the application of design relates strongly to commercial new product development. The teaching and learning of early, front end strategic innovation to design students is discussed. The building of an explicit value proposition 'model' is a key element of this work. The linkage between value proposition and front end user, global and brand research strands is presented. The paper draws on primary and secondary research activities in the areas of design education and professional design which relate to the practices of strategic innovation. Forms, models, and usage of value proposition are identified from literature relating to innovation, business models, and new product development. The paper demonstrates how value proposition can be a universal form of 'upstream' modelling for new product ideas prior to 'downstream' form-giving and technological embodiment.},
	author = {Wormald, Paul},
	month = jan,
	year = {2013},
}

@article{ang_managing_2010,
	title = {Managing {For} {Successful} {Customer} {Acquisition}: {An} {Exploration}},
	volume = {22},
	shorttitle = {Managing {For} {Successful} {Customer} {Acquisition}},
	doi = {10.1362/026725706776861217},
	abstract = {Given all the recent attention dedicated by academics, consultants and practitioners to customer retention, customer acquisition has become a secondary concern. Yet, customer acquisition is of major importance and demands attention as the first stage of the customer life-cycle. Our research shows that companies are not particularly skilled at managing the customer acquisition process. For example, less than half have a dedicated customer acquisition plan. Only one variable distinguishes companies that excel at customer acquisition – they have a budget dedicated to customer acquisition activities. Other variables examined - the presence of an executive responsible for customer acquisition, an understanding of the economics of customer acquisition, and the deployment of CRM technologies to support customer acquisition - are not associated with excellence at customer acquisition.},
	journal = {Journal of Marketing Management},
	author = {Ang, Lawrence and Buttle, Francis},
	month = feb,
	year = {2010},
	pages = {295--317},
}

@misc{noauthor_ins_nodate,
	title = {The {Ins} and {Outs} of {Customer} {Acquisition} for {Small} {Businesses}},
	url = {https://www.salesforce.com/solutions/small-business-solutions/resources/small-business-customer-acquisition/},
	abstract = {Developing a strong customer acquisition strategy requires skilled organization and depends on tracking and assessing lots of different information and data points. Invest in a robust software solution that can help you through every step in the process.},
	language = {en},
	urldate = {2021-01-28},
	journal = {Salesforce.com},
}

@misc{noauthor_importance_nodate,
	title = {The importance of competitor analysis for business growth},
	url = {https://www.lexisclick.com/blog/why-competitor-analysis-is-important-for-business-growth},
	urldate = {2021-01-28},
}

@misc{noauthor_benefits_2018,
	title = {The {Benefits} of {Benchmark} {Analysis}},
	url = {https://www.bbgbroker.com/benchmark-analysis-benefits/},
	abstract = {Benchmark analysis is comparing your business policies, programs, etc. with similar businesses. Learn some of the benefits of benchmark analysis.},
	language = {en-US},
	urldate = {2021-01-28},
	journal = {Business Benefits Group},
	month = jul,
	year = {2018},
}

@misc{noauthor_home_nodate,
	title = {Home},
	url = {http://www.bubclean.nl/home/},
	language = {en-US},
	urldate = {2021-01-28},
}

@misc{constantinides_how_2020,
	title = {How {Many} {Tech} {Startups} {Are} {Created} {Each} {Year}?},
	url = {https://netshopisp.medium.com/how-many-tech-startups-are-created-each-year-27539d0a4c48},
	abstract = {Every year, many entrepreneurs and business owners establish new businesses. Most of them have high hopes for their business future and are pretty excited about it. However, for small businesses…},
	language = {en},
	urldate = {2021-01-28},
	journal = {Medium},
	author = {Constantinides, Mike},
	month = mar,
	year = {2020},
}

@misc{noauthor_startup_nodate,
	title = {Startup {Genome}},
	url = {https://startupgenome.com/article/state-of-the-global-startup-economy},
	urldate = {2021-01-28},
}

@misc{noauthor_ultrasonic_nodate,
	title = {Ultrasonic {Cleaning} {Market} {Size}, {Share}, and {Industry} {Analysis} and {Market} {Forecast} to 2024 {\textbar} {MarketsandMarkets}™},
	url = {https://www.marketsandmarkets.com/Market-Reports/ultrasonic-cleaning-market-79998083.html?gclid=CjwKCAiA57D_BRAZEiwAZcfCxbqV6L7COjO8j5UdIfAd0kHx6RMY3TM9J-Y_H17Z3PsqBps3RxrCkhoCFVsQAvD_BwE},
	urldate = {2021-01-28},
}

@article{mason_ultrasonic_2016,
	title = {Ultrasonic cleaning: {An} historical perspective},
	volume = {29},
	issn = {1350-4177},
	shorttitle = {Ultrasonic cleaning},
	url = {http://www.sciencedirect.com/science/article/pii/S1350417715001339},
	doi = {10.1016/j.ultsonch.2015.05.004},
	abstract = {The development of ultrasonic cleaning dates from the middle of the 20th century and has become a method of choice for a range of surface cleaning operations. The reasons why this has happened and the methods of assessing the efficiency of ultrasonic cleaning baths are reviewed.},
	language = {en},
	urldate = {2021-01-28},
	journal = {Ultrasonics Sonochemistry},
	author = {Mason, Timothy J.},
	month = mar,
	year = {2016},
	keywords = {Cleaning, History, Ultrasound},
	pages = {519--523},
}

@misc{noauthor_ultrasonic_nodate-1,
	title = {Ultrasonic {Cleaning} - an overview {\textbar} {ScienceDirect} {Topics}},
	url = {https://www.sciencedirect.com/topics/chemistry/ultrasonic-cleaning},
	urldate = {2021-01-28},
}

@article{dikker_crowdsourcing_2021,
	title = {Crowdsourcing neuroscience: {Inter}-brain coupling during face-to-face interactions outside the laboratory},
	volume = {227},
	issn = {1053-8119},
	shorttitle = {Crowdsourcing neuroscience},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811920309216},
	doi = {10.1016/j.neuroimage.2020.117436},
	abstract = {When we feel connected or engaged during social behavior, are our brains in fact “in sync” in a formal, quantifiable sense? Most studies addressing this question use highly controlled tasks with homogenous subject pools. In an effort to take a more naturalistic approach, we collaborated with art institutions to crowdsource neuroscience data: Over the course of 5 years, we collected electroencephalogram (EEG) data from thousands of museum and festival visitors who volunteered to engage in a 10-min face-to-face interaction. Pairs of participants with various levels of familiarity sat inside the Mutual Wave Machine—an artistic neurofeedback installation that translates real-time correlations of each pair's EEG activity into light patterns. Because such inter-participant EEG correlations are prone to noise contamination, in subsequent offline analyses we computed inter-brain coupling using Imaginary Coherence and Projected Power Correlations, two synchrony metrics that are largely immune to instantaneous, noise-driven correlations. When applying these methods to two subsets of recorded data with the most consistent protocols, we found that pairs’ trait empathy, social closeness, engagement, and social behavior (joint action and eye contact) consistently predicted the extent to which their brain activity became synchronized, most prominently in low alpha ({\textasciitilde}7–10 Hz) and beta ({\textasciitilde}20–22 Hz) oscillations. These findings support an account where shared engagement and joint action drive coupled neural activity and behavior during dynamic, naturalistic social interactions. To our knowledge, this work constitutes a first demonstration that an interdisciplinary, real-world, crowdsourcing neuroscience approach may provide a promising method to collect large, rich datasets pertaining to real-life face-to-face interactions. Additionally, it is a demonstration of how the general public can participate and engage in the scientific process outside of the laboratory. Institutions such as museums, galleries, or any other organization where the public actively engages out of self-motivation, can help facilitate this type of citizen science research, and support the collection of large datasets under scientifically controlled experimental conditions. To further enhance the public interest for the out-of-the-lab experimental approach, the data and results of this study are disseminated through a website tailored to the general public (wp.nyu.edu/mutualwavemachine).},
	language = {en},
	urldate = {2021-01-27},
	journal = {NeuroImage},
	author = {Dikker, Suzanne and Michalareas, Georgios and Oostrik, Matthias and Serafimaki, Amalia and Kahraman, Hasibe Melda and Struiksma, Marijn E. and Poeppel, David},
	month = feb,
	year = {2021},
	keywords = {Brain-Computer-Interface Technology, Brain-to-brain synchrony, Hyperscanning, Inter-brain coupling, Neurofeedback, Oscillations, Real-world neuroscience},
	pages = {117436},
}

@article{davis_beyond_1977,
	title = {Beyond {Boredom} and {Anxiety}: {The} {Experience} of {Play} in {Work} and {Games}.},
	volume = {6},
	issn = {00943061},
	shorttitle = {Beyond {Boredom} and {Anxiety}},
	url = {http://www.jstor.org/stable/2065805?origin=crossref},
	doi = {10.2307/2065805},
	number = {2},
	urldate = {2021-01-26},
	journal = {Contemporary Sociology},
	author = {Davis, Murray S. and Csikszentmihalyi, Mihaly},
	month = mar,
	year = {1977},
	pages = {197},
}

@book{said_measuring_2005,
	title = {Measuring {The} {State} {Of} {Flow} {In} {Playing} {Online} {Games}},
	abstract = {The literature on gaming suggests that people may experience the state of flow when playing online games. The main objective of this study is to develop a measurement of a gamer's reported state of Flow using data gathered from an online survey of 218 gamers. The final Flow construct had four factors that fit the data. The factors were " Skill " , " Challenge " , " Involvement " and " Time ". This study found that all factors were best represented as first-order factors for identifying the flow construct. A test of the final model provides evidence of convergent, discriminant and predictive validities of the Flow construct. The implications of these findings are discussed.},
	author = {Said, Laila and Mizerski, Dick and Murphy, Jamie},
	month = dec,
	year = {2005},
}

@article{habe_flow_2019,
	title = {Flow and {Satisfaction} {With} {Life} in {Elite} {Musicians} and {Top} {Athletes}},
	volume = {10},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00698/full},
	doi = {10.3389/fpsyg.2019.00698},
	abstract = {Although flow has been studied extensively in music and sport, there is a lack of research comparing these two domains. With the aim of filling this gap, élite musicians and top athletes in Slovenia were contrasted in the current study. Differences for flow and satisfaction with life between élite musicians and top athletes were explored. Individual versus group performance setting and gender differences were considered. 452 participants; 114 élite Slovenian musicians (mean age 23.46 years) and 338 top Slovenian athletes (mean age 22.40 years) answered questions about flow and satisfaction with life measures. The results show differences between élite musicians and top athletes in four flow dimensions: transformation of time and autotelic experience were higher in musicians while clear goals and unambiguous feedback were higher in athletes. However differences in global flow were not confirmed. Élite musicians and top athletes experienced flow more often in group than in individual performance settings and surprisingly it was experienced more in male than in female top performers. Satisfaction with life has a positive correlation with all nine dimensions of flow, but only challenge-skill balance was a significant predictor for satisfaction with life.},
	language = {English},
	urldate = {2021-01-26},
	journal = {Frontiers in Psychology},
	author = {Habe, Katarina and Biasutti, Michele and Kajtna, Tanja},
	year = {2019},
	note = {Publisher: Frontiers},
	keywords = {Flow, Top athletes, expert performance, satisfaction with life, élite musicians},
}

@article{zeng_theoretical_2012,
	title = {A {Theoretical} {Model} of {Design} {Creativity}: {Nonlinear} {Design} {Dynamics} and {Mental} {Stress}-{Creativity} {Relation}},
	volume = {16},
	shorttitle = {A {Theoretical} {Model} of {Design} {Creativity}},
	doi = {10.3233/jid-2012-0007},
	abstract = {Creativity is an important topic in design research. Attempts have been made to develop methods and tools that can help designers become more creative. Yet how and why creativity occurs is still unknown to researchers. In this paper, we propose a theoretical model for creative design. This theoretical model builds on two postulates: 1 design reasoning follows a nonlinear dynamics, which may become chaotic; and 2 there is an inverse U shaped relationship between designer's mental stress and design creativity. In the first postulate, the nonlinear dynamics assumes the form of design governing equation and can be solved by Environment Based Design EBD. The first postulate implies that design reasoning is sensitive to initial conditions, which are defined by the combination of design problem, design solutions, design knowledge, and other design related information. Since the major components in initial conditions may evolve simultaneously and are subject to continuous change during the design process, the design process is highly unpredictable. Some of the unpredictable solutions, which could be of high quality and useful, can be deemed creative. From this first postulate, three paths to creative design are derived, which specify how the initial conditions can be changed. The second postulate states that design creativity occurs when a designer is under a medium mental stress. Mental stresses are positively related to the workload associated with a design problem and negatively related to the designer's mental capacity. The workload is related to the complexity of the design problem and the amount of work in the design process whereas the mental capacity is related to the knowledge and skills required by the design process and to the designer's affect when dealing with the stresses arising from uncertainties and unpredictability of the design dynamics. To show how this theoretical model can be used to study design phenomena, an interpretation of the roles of sketching in design is presented.},
	journal = {Journal of Integrated Design and Process Science},
	author = {Zeng, Yong},
	month = sep,
	year = {2012},
	pages = {65--88},
}

@article{liao_factors_2015,
	title = {Factors {Affecting} {Students}' {Continued} {Usage} {Intention} {Toward} {Business} {Simulation} {Games}: {An} {Empirical} {Study}},
	volume = {53},
	shorttitle = {Factors {Affecting} {Students}' {Continued} {Usage} {Intention} {Toward} {Business} {Simulation} {Games}},
	doi = {10.1177/0735633115598751},
	abstract = {While the impact and value of simulation games have been investigated in the context of business and management education, few studies have investigated why students are willing to reuse the games or not. The main purpose of this study is to explore the determinants of students’ continued usage intention for business simulation games in a higher education context based on the expectation-confirmation theory, flow theory, and motivation theory. Data collected from 381 valid respondents were used to test the research model using the partial least squares approach. The results of this study can provide several important theoretical and practical implications for educational use of business simulation games. The results indicate that continuance usage intention is influenced by learning satisfaction, which is in turn affected by perceived learning performance, learning confirmation, and learning expectation, and that learning confirmation is affected by learning expectation through the mediation of perceived learning performance. Additionally, perceived playfulness affects perceived learning performance while learning motivation influences learning expectation.},
	journal = {Journal of Educational Computing Research},
	author = {Liao, Yi-Wen and Huang, Yueh-Min and Wang, Yi-Shun},
	month = aug,
	year = {2015},
}

@article{eisenberger_flow_2005,
	title = {Flow experiences at work: for high need achievers alone?},
	volume = {26},
	copyright = {Copyright © 2005 John Wiley \& Sons, Ltd.},
	issn = {1099-1379},
	shorttitle = {Flow experiences at work},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/job.337},
	doi = {https://doi.org/10.1002/job.337},
	abstract = {Applying Csikszentmihalyi's (1990) flow theory of optimal experience to the workplace, two studies examined the relationships of employees' perceived skill and challenge at work and need for achievement with their positive mood, intrinsic task interest, and extra-role performance. Among achievement-oriented employees only, high skill and challenge was associated with greater positive mood, task interest, and performance than other skill/challenge combinations. Additionally, positive mood mediated the interactive relationship of skill/challenge and need for achievement with performance. Copyright © 2005 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {7},
	urldate = {2021-01-26},
	journal = {Journal of Organizational Behavior},
	author = {Eisenberger, Robert and Jones, Jason R. and Stinglhamber, Florence and Shanock, Linda and Randall, Amanda T.},
	year = {2005},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/job.337},
	pages = {755--775},
}

@article{riemer_flow_2000,
	title = {Flow in sports: {The} keys to optimal experiences and performances},
	volume = {17},
	shorttitle = {Flow in sports},
	journal = {Sociol. Sport J.},
	author = {Riemer, B.A.},
	year = {2000},
	pages = {206--207},
}

@incollection{moneta_measurement_2012,
	title = {On the measurement and conceptualization of flow.},
	isbn = {978-3-030-53467-7},
	abstract = {This chapter introduces in chronological order the three main measurement methods—the Flow Questionnaire, the Experience Sampling Method, and the standardized scales of the componential approach—that researchers developed and used in conducting research on the flow state. Each measurement method and underlying conceptualization is explained, and its strengths and limitations are then discussed in relation to the other measurement methods and associated conceptualizations. The analysis reveals that, although the concept of flow remained stable since its inception, the models of flow that researchers developed in conjunction with the measurement methods changed substantially over time. Moreover, the findings obtained by applying the various measurement methods led to corroborations and disconfirmations of the underlying models, and hence provided indications on how to interpret and possibly modify flow theory. The chapter then analyzes the emerging process approach, which conceptualizes and measures flow as a dynamic path rather than an object, and highlights its potential for integrating flow and creativity within the same conceptual framework. The final section outlines new directions for developing more valid and useful measurement methods that can help to advance the understanding of flow, its antecedents, and its consequences.},
	author = {Moneta, Giovanni},
	month = jan,
	year = {2012},
	doi = {10.1007/978-3-030-53468-4_2},
	pages = {23--50},
}

@article{vourvopoulos_efficacy_2019,
	title = {Efficacy and {Brain} {Imaging} {Correlates} of an {Immersive} {Motor} {Imagery} {BCI}-{Driven} {VR} {System} for {Upper} {Limb} {Motor} {Rehabilitation}: {A} {Clinical} {Case} {Report}},
	volume = {13},
	issn = {1662-5161},
	shorttitle = {Efficacy and {Brain} {Imaging} {Correlates} of an {Immersive} {Motor} {Imagery} {BCI}-{Driven} {VR} {System} for {Upper} {Limb} {Motor} {Rehabilitation}},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2019.00244/full},
	doi = {10.3389/fnhum.2019.00244},
	abstract = {To maximize brain plasticity after stroke, several rehabilitation strategies have been explored, including the use of intensive motor training, motor imagery, and action observation. Growing evidence of the positive impact of virtual reality (VR) techniques on recovery following stroke has been shown. However, most VR tools are designed to exploit active movement, and hence patients with low level of motor control cannot fully benefit from them. Consequently, the idea of directly training the central nervous system has been promoted by utilizing motor-imagery (MI) based brain-computer interfaces (BCIs). To date, detailed information on which VR strategies lead to successful functional recovery is still largely missing, and very little is known about how to optimally integrate BCI and VR paradigms for stroke rehabilitation. The purpose of this study was to examine the efficacy of a BCI-VR system using a MI paradigm for post-stroke upper limb rehabilitation on functional assessments, and related changes in MI ability and brain imaging. To achieve this, a 60 years old male chronic stroke patient was recruited. The patient underwent a 3-week intervention in a clinical environment, resulting in 10 BCI-VR training sessions. The patient was assessed before and after intervention, as well as on a one-month follow-up, in terms of clinical scales and brain imaging using functional MRI (fMRI). Consistent with prior research, we found important improvements in upper extremity scores (Fugl-Meyer) and identified increases in brain activation measured by fMRI that suggest neuroplastic changes in brain motor networks. This study expands on the current body of evidence as more data are needed on the effect of this type of interventions not only on functional improvement but also through brain imaging to study the effect of the intervention on plasticity.},
	language = {English},
	urldate = {2021-01-25},
	journal = {Frontiers in Human Neuroscience},
	author = {Vourvopoulos, Athanasios and Jorge, Carolina and Abreu, Rodolfo and Figueiredo, Patrícia and Fernandes, Jean-Claude and Bermúdez i Badia, Sergi},
	year = {2019},
	note = {Publisher: Frontiers},
	keywords = {Brain-computer interface, EEG, Neurorehabilitation, fMRI, virtual   reality},
}

@article{vourvopoulos_effects_2019,
	title = {Effects of a {Brain}-{Computer} {Interface} {With} {Virtual} {Reality} ({VR}) {Neurofeedback}: {A} {Pilot} {Study} in {Chronic} {Stroke} {Patients}},
	volume = {13},
	issn = {1662-5161},
	shorttitle = {Effects of a {Brain}-{Computer} {Interface} {With} {Virtual} {Reality} ({VR}) {Neurofeedback}},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2019.00210/full},
	doi = {10.3389/fnhum.2019.00210},
	abstract = {Rehabilitation for stroke patients with severe motor impairments is burdensome and demanding because most of the current rehabilitation options require some volitional movement to train the affected side. However, research has shown that survivors of severe stroke may receive modest benefits from action observation, virtual reality (VR), and brain-computer interfaces (BCIs). These approaches have shown some success in strengthening key motor pathways thought to support motor recovery after stroke. The purpose of this study was to combine the principles of action observation, VR, and BCI in a platform called REINVENT and assess its effects on four chronic stroke patients across different levels of motor impairment. REINVENT acquires post-stroke EEG signals that indicate an attempt to move and drives the movement of a virtual avatar arm, allowing patient-driven action observation neurofeedback in VR. In addition, synchronous electromyography (EMG) data were also captured to monitor overt muscle activity. Our results show that this EEG-based BCI can be used by stroke survivors across a wide range of motor disabilities. Finally, individual results suggest that patients with more severe motor impairments benefit the most from EEG-based neurofeedback, while patients with more mild impairments may benefit more from EMG-based feedback, harnessing existing sensorimotor pathways. Future research is needed to confirm these findings in a larger and more diverse population.},
	language = {English},
	urldate = {2021-01-25},
	journal = {Frontiers in Human Neuroscience},
	author = {Vourvopoulos, Athanasios and Pardo, Octavio Marin and Lefebvre, Stéphanie and Neureither, Meghan and Saldana, David and Jahng, Esther and Liew, Sook-Lei},
	year = {2019},
	note = {Publisher: Frontiers},
	keywords = {Neurorehabilitation, Stroke, action observation, brain-computer  interface, virtual reality},
}

@article{yang_can_2018,
	title = {Can an {Integrated} {System} of {Electroencephalography} and {Virtual} {Reality} {Further} the {Understanding} of {Relationships} {Between} {Attention}, {Meditation}, {Flow} {State}, and {Creativity}?},
	volume = {57},
	doi = {10.1177/0735633118770800},
	abstract = {The creativity of the brain is usually measured by one’s creative behavior or activity. This study explores connections between an individual’s creative behavior and his or her creative brain by asking each participant to design an open-ended virtual product in an integrated system consisting of virtual reality and brainwaves. The results show a significant correlation between the individual creativity level and the state of flow. There is a significant correlation between the state of flow and the quality of the creative product. The attention value is correlated significantly with the quality of product. The participants’ four different behaviors significantly demonstrated different attention and meditation levels. The sequential analysis shows that people with high product creativity have a higher attention value while maintaining a state of relaxation, demonstrated during the behavior of painting in the virtual reality environment. Given a limited period of time, a higher level of product creativity can be achieved through persistent implementation, concentration, and by being relaxed both physically and mentally. Implications of the study on teaching, learning, and designing a creative learning environment will be discussed.},
	journal = {Journal of Educational Computing Research},
	author = {Yang, Xiaozhe and Cheng, Pei-Yu and Lin, Lin and Huang, Yueh and Ren, Youqun},
	month = apr,
	year = {2018},
	pages = {073563311877080},
}

@article{ding_improving_2014,
	title = {Improving creativity performance by short-term meditation},
	volume = {10},
	issn = {1744-9081},
	url = {https://doi.org/10.1186/1744-9081-10-9},
	doi = {10.1186/1744-9081-10-9},
	abstract = {One form of meditation intervention, the integrative body-mind training (IBMT) has been shown to improve attention, reduce stress and change self-reports of mood. In this paper we examine whether short-term IBMT can improve performance related to creativity and determine the role that mood may play in such improvement.},
	number = {1},
	urldate = {2021-01-25},
	journal = {Behavioral and Brain Functions},
	author = {Ding, Xiaoqian and Tang, Yi-Yuan and Tang, Rongxiang and Posner, Michael I.},
	month = mar,
	year = {2014},
	keywords = {Creativity, Cross-lagged analysis, Emotion, Integrative body-mind training, Negative affect, Positive affect, Short-term meditation},
	pages = {9},
}

@inproceedings{thomas_design_2013,
	title = {Design of an online {EEG} based neurofeedback game for enhancing attention and memory},
	doi = {10.1109/EMBC.2013.6609529},
	abstract = {Brain-Computer Interface (BCI) is an alternative communication and control channel between brain and computer which finds applications in neuroprosthetics, brain wave controlled computer games etc. This paper proposes an Electroencephalogram (EEG) based neurofeedback computer game that allows the player to control the game with the help of attention based brain signals. The proposed game protocol requires the player to memorize a set of numbers in a matrix, and to correctly fill the matrix using his attention. The attention level of the player is quantified using sample entropy features of EEG. The statistically significant performance improvement of five healthy subjects after playing a number of game sessions demonstrates the effectiveness of the proposed game in enhancing their concentration and memory skills.},
	booktitle = {2013 35th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Thomas, K. P. and Vinod, A. P. and Guan, C.},
	month = jul,
	year = {2013},
	note = {ISSN: 1558-4615},
	keywords = {Attention, Attention Deficit Disorder with Hyperactivity, BCI, Brain, Brain-Computer Interfaces, Cognition, Computers, Conferences, Electroencephalography, Entropy, Games, Graphical user interfaces, Healthy Volunteers, Humans, Memory, Neurofeedback, Signal Processing, Computer-Assisted, Training, User-Computer Interface, Video Games, attention based brain signals, brain wave controlled computer games, brain-computer interface, brain-computer interfaces, communication channel, computer games, control channel, electroencephalogram based neurofeedback computer game, electroencephalography, entropy, game protocol, matrix, memory skills, neurophysiology, neuroprosthetics, online EEG based eurofeedback game, sample entropy features},
	pages = {433--436},
}

@article{thomas_design_2013-1,
	title = {Design of an online {EEG} based neurofeedback game for enhancing attention and memory},
	volume = {2013},
	issn = {2694-0604},
	doi = {10.1109/EMBC.2013.6609529},
	abstract = {Brain-Computer Interface (BCI) is an alternative communication and control channel between brain and computer which finds applications in neuroprosthetics, brain wave controlled computer games etc. This paper proposes an Electroencephalogram (EEG) based neurofeedback computer game that allows the player to control the game with the help of attention based brain signals. The proposed game protocol requires the player to memorize a set of numbers in a matrix, and to correctly fill the matrix using his attention. The attention level of the player is quantified using sample entropy features of EEG. The statistically significant performance improvement of five healthy subjects after playing a number of game sessions demonstrates the effectiveness of the proposed game in enhancing their concentration and memory skills.},
	language = {eng},
	journal = {Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference},
	author = {Thomas, Kavitha P. and Vinod, A. P. and Guan, Cuntai},
	year = {2013},
	pmid = {24109716},
	keywords = {Attention, Attention Deficit Disorder with Hyperactivity, Brain, Brain-Computer Interfaces, Cognition, Computers, Electroencephalography, Healthy Volunteers, Humans, Memory, Neurofeedback, Signal Processing, Computer-Assisted, User-Computer Interface, Video Games},
	pages = {433--436},
}

@article{katahira_eeg_2018,
	title = {{EEG} {Correlates} of the {Flow} {State}: {A} {Combination} of {Increased} {Frontal} {Theta} and {Moderate} {Frontocentral} {Alpha} {Rhythm} in the {Mental} {Arithmetic} {Task}},
	volume = {9},
	issn = {1664-1078},
	shorttitle = {{EEG} {Correlates} of the {Flow} {State}},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00300/full},
	doi = {10.3389/fpsyg.2018.00300},
	abstract = {Flow experience is a subjective state experienced during holistic involvement in a certain activity, which has been reported to function as a factor promoting motivation, skill development, and better performance in the activity. To verify the positive effects of flow and develop a method to utilize it, the establishment of a reliable measurement of the flow state is essential. The present study measured the electroencephalogram (EEG) during an experimentally evoked flow state and examined the possibility of objective measurement of immediate flow. A total of 16 participants (10 males, 6 females) participated in the experiment that employed the mental arithmetic task developed in the previous study. Post-trial self-report of the flow state and EEG during task execution were measured and compared among the three conditions (Boring, Flow, and Overload conditions) that had different levels of task difficulty. Furthermore, the correlations between subjective flow items and EEG activity were examined. As expected, the ratings on the subjective evaluation items representing the flow state were the highest in the Flow condition. Regarding the EEG data, theta activities in the frontal areas were higher in the Flow and the Overload conditions than in the Boredom condition, and alpha activity in the frontal areas and the right central area gradually increased depending on the task difficulty. These EEG activities correlated with self-reported flow experience, especially items related to the concentration on the task and task difficulty. From the results, the flow state was characterized by increased theta activities in the frontal areas and moderate alpha activities in the frontal and central areas. The former may be related to a high level of cognitive control and immersion in task, and the latter suggests that the load on the working memory was not excessive. The findings of this study suggest the possibility of distinguishing the flow state from other states using multiple EEG activities and indicate the need for other physiological indicators corresponding to the other aspects of flow experience.},
	language = {English},
	urldate = {2021-01-25},
	journal = {Frontiers in Psychology},
	author = {Katahira, Kenji and Yamazaki, Yoichi and Yamaoka, Chiaki and Ozaki, Hiroaki and Nakagawa, Sayaka and Nagata, Noriko},
	year = {2018},
	note = {Publisher: Frontiers},
	keywords = {EEG, Mental arithmetic task, Objective measurement, flow experience, fm theta},
}

@article{wang_exploratory_2014,
	title = {An exploratory study using inexpensive electroencephalography ({EEG}) to understand flow experience in computer-based instruction},
	volume = {51},
	issn = {0378-7206},
	url = {http://www.sciencedirect.com/science/article/pii/S0378720614000639},
	doi = {10.1016/j.im.2014.05.010},
	abstract = {Flow is an optimal experience that results in intense engagement in an activity. In computer-based instructional environment, flow can be used to examine learning performance. We used questionnaire survey and electroencephalography (EEG) analysis to examine the influence of challenge-skill balance on the flow experience and influence of flow experience on learning performance in a computer-based instructional environment. The results showed that the flow experience of learners depends on challenge-skill balance of learning materials. The research explored the possibility of using an inexpensive non-medical EEG device to research the association between flow experience and challenge-skill balance in educational information systems.},
	language = {en},
	number = {7},
	urldate = {2021-01-25},
	journal = {Information \& Management},
	author = {Wang, Chih-Chien and Hsu, Ming-Chang},
	month = nov,
	year = {2014},
	keywords = {Computer-based instruction, Electroencephalography (EEG), Flow, Learning performance, e-Learning},
	pages = {912--923},
}

@incollection{csikszentmihalyi_flow_1990,
	title = {Flow: {The} {Psychology} of {Optimal} {Experience}},
	shorttitle = {Flow},
	author = {Csikszentmihalyi, Mihaly},
	month = jan,
	year = {1990},
}

@article{mladenovic_impact_2017,
	title = {The {Impact} of {Flow} in an {EEG}-based {Brain} {Computer} {Interface}},
	abstract = {Major issues in Brain Computer Interfaces (BCIs) include low usability and poor user performance. This paper tackles them by ensuring the users to be in a state of immersion, control and motivation, called state of flow. Indeed, in various disciplines, being in the state of flow was shown to improve performances and learning. Hence, we intended to draw BCI users in a flow state to improve both their subjective experience and their performances. In a Motor Imagery BCI game, we manipulated flow in two ways: 1) by adapting the task difficulty and 2) by using background music. Results showed that the difficulty adaptation induced a higher flow state, however music had no effect. There was a positive correlation between subjective flow scores and offline performance, although the flow factors had no effect (adaptation) or negative effect (music) on online performance. Overall, favouring the flow state seems a promising approach for enhancing users' satisfaction, although its complexity requires more thorough investigations.},
	author = {Mladenovic, Jelena and Frey, Jérémy and Bonnet-Save, Manon and Mattout, Jérémie and Lotte, Fabien},
	month = jun,
	year = {2017},
}

@misc{subramaniyam_pitfalls_2018,
	title = {Pitfalls of {Filtering} the {EEG} {Signal}},
	url = {https://sapienlabs.org/pitfalls-of-filtering-the-eeg-signal/},
	abstract = {Filtering of the EEG signal to remove artifacts is a common pre-processing step but introduces temporal distortions in the signal. How do you chose a filter for your particular analysis goals?},
	language = {en-US},
	urldate = {2021-01-23},
	journal = {Sapien Labs {\textbar} Neuroscience {\textbar} Human Brain Diversity Project},
	author = {Subramaniyam, Narayan P.},
	month = nov,
	year = {2018},
}

@misc{noauthor_sklearnpreprocessingquantiletransformer_2021,
	title = {sklearn.preprocessing.{QuantileTransformer} — scikit-learn 0.24.1 documentation},
	url = {https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer},
	urldate = {2021-01-19},
	month = jan,
	year = {2021},
}

@article{yildirim_efficient_2018,
	title = {An efficient compression of {ECG} signals using deep convolutional autoencoders},
	volume = {52},
	issn = {1389-0417},
	url = {http://www.sciencedirect.com/science/article/pii/S1389041718302730},
	doi = {10.1016/j.cogsys.2018.07.004},
	abstract = {Background and objective
Advances in information technology have facilitated the retrieval and processing of biomedical data. Especially with wearable technologies and mobile platforms, we are able to follow our healthcare data, such as electrocardiograms (ECG), in real time. However, the hardware resources of these technologies are limited. For this reason, the optimal storage and safe transmission of the personal health data is critical. This study proposes a new deep convolutional autoencoder (CAE) model for compressing ECG signals.
Methods
In this paper, a deep network structure of 27 layers consisting of encoder and decoder parts is designed. In the encoder section of this model, the signals are reduced to low-dimensional vectors; and in the decoder section, the signals are reconstructed. The deep learning approach provides the representations of the low and high levels of signals in the hidden layers of the model. Hence, the original signal can be reconstructed with minimal loss. Very different from traditional linear transformation methods, a deep compression approach implies that it can learn to use different ECG records automatically.
Results
The performance was evaluated on an experimental data set comprising 4800 ECG fragments from 48 unique clinical patients. The compression rate (CR) of the proposed model was 32.25, and the average PRD value was 2.73\%. These favourable observation suggest that our deep model can allow secure data transfer in a low-dimensional form to remote medical centers. We present an effective compression approach that can potentially be used in wearable devices, e-health applications, telemetry and Holter systems.},
	language = {en},
	urldate = {2021-01-19},
	journal = {Cognitive Systems Research},
	author = {Yildirim, Ozal and Tan, Ru San and Acharya, U. Rajendra},
	month = dec,
	year = {2018},
	keywords = {Autoencoders, Deep learning, ECG signals, Signal compression},
	pages = {198--211},
}

@misc{noauthor_rbf_2021,
	title = {{RBF} {SVM} parameters — scikit-learn 0.24.1 documentation},
	url = {https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html},
	urldate = {2021-01-22},
	month = jan,
	year = {2021},
}

@inproceedings{al-marridi_convolutional_2018,
	title = {Convolutional {Autoencoder} {Approach} for {EEG} {Compression} and {Reconstruction} in m-{Health} {Systems}},
	doi = {10.1109/IWCMC.2018.8450511},
	abstract = {In the last few years, the number of patients with chronic diseases requiring constant monitoring increased rapidly, which motivates researchers to develop scalable remote health applications. Nevertheless, the amount of transmitted real-time data through current dynamic networks with limited and restricted bandwidth, end-to-end delay, and transmission power; limits having an efficient transmission of the data. Motivated by the high energy consumed for transmission, applying data reduction techniques to the vital signs at the transmitter side present an efficient edge-based approach that significantly reduces the transmission energy. However, a new problem arises, which is the ability of receiving the data at the server side with an acceptable distortion rate (i.e., deformation of vital signs because of inefficient data reduction). In this paper, we introduce a Deep Learning (DL) approach based on Convolutional Auto-Encoder (CAE), to compress and reconstruct the vital signs in general and Electroencephalogram Signal (EEG) specifically with minimum distortion. The results show that using CAE provides efficient distortion rate while maximizing compression ratio. However, learning makes CAE application-specific, where each CAE model is designed specifically for a certain application.},
	booktitle = {2018 14th {International} {Wireless} {Communications} {Mobile} {Computing} {Conference} ({IWCMC})},
	author = {Al-Marridi, A. Z. and Mohamed, A. and Erbad, A.},
	month = jun,
	year = {2018},
	note = {ISSN: 2376-6506},
	keywords = {Biological neural networks, Brain modeling, CAE application, Compression, Convolution, Convolutional Autoencoder, Data Reduction, Deep learning, Distortion, EEG compression, EEG signal reconstruction, Electroencephalogram Signal, Electroencephalography, Machine learning, Medical services, Signal Reconstruction, chronic diseases, compression ratio maximization, constant monitoring, convolution, convolutional autoencoder approach, data compression, data reduction, data reduction techniques, deep learning approach, diseases, distortion rate, dynamic networks, edge-based approach, electroencephalography, encoding, end-to-end delay, health care, learning (artificial intelligence), m-health systems, medical signal processing, mobile computing, patient monitoring, patients, real-time data transmission, scalable remote health applications, signal reconstruction, transmission energy, transmission power},
	pages = {370--375},
}

@inproceedings{yang_use_2015,
	title = {On the use of convolutional neural networks and augmented {CSP} features for multi-class motor imagery of {EEG} signals classification},
	doi = {10.1109/EMBC.2015.7318929},
	abstract = {Learning the deep structures and unknown correlations is important for the detection of motor imagery of EEG signals (MI-EEG). This study investigates the use of convolutional neural networks (CNNs) for the classification of multi-class MI-EEG signals. Augmented common spatial pattern (ACSP) features are generated based on pair-wise projection matrices, which covers various frequency ranges. We propose a frequency complementary feature map selection (FCMS) scheme by constraining the dependency among frequency bands. Experiments are conducted on BCI competition IV dataset IIa with 9 subjects. Averaged cross-validation accuracy of 68.45\% and 69.27\% is achieved for FCMS and all feature maps, respectively, which is significantly higher (4.53\% and 5.34\%) than random map selection and higher (1.44\% and 2.26\%) than filter-bank CSP (FBCSP). The results demonstrate that the CNNs are capable of learning discriminant, deep structure features for EEG classification without relying on the handcrafted features.},
	booktitle = {2015 37th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Yang, H. and Sakhavi, S. and Ang, K. K. and Guan, C.},
	month = aug,
	year = {2015},
	note = {ISSN: 1558-4615},
	keywords = {Accuracy, Algorithms, BCI competition IV dataset IIa, Brain models, Convolution, Electrodes, Electroencephalography, Feature extraction, Humans, Movement, Neural Networks (Computer), Neural networks, Signal Processing, Computer-Assisted, augmented CSP, augmented CSP features, augmented common spatial pattern features, averaged cross-validation accuracy, bioelectric potentials, channel bank filters, convolution, convolutional neural network, convolutional neural networks, deep learning, electroencephalography, feature selection, filter-bank CSP, frequency complementary feature map selection scheme, learning (artificial intelligence), learning discriminant, medical signal detection, medical signal processing, multi-class motor imagery of EEG, multiclass MI-EEG signal classification, multiclass motor imagery, neural nets, neurophysiology, pair-wise projection matrices, random map selection, random processes, signal classification},
	pages = {2620--2623},
}

@inproceedings{park_efficient_2007,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Efficient {Pairwise} {Classification}},
	isbn = {978-3-540-74958-5},
	doi = {10.1007/978-3-540-74958-5_65},
	abstract = {Pairwise classification is a class binarization procedure that converts a multi-class problem into a series of two-class problems, one problem for each pair of classes. While it can be shown that for training, this procedure is more efficient than the more commonly used one-against-all approach, it still has to evaluate a quadratic number of classifiers when computing the predicted class for a given example. In this paper, we propose a method that allows a faster computation of the predicted class when weighted or unweighted voting are used for combining the predictions of the individual classifiers. While its worst-case complexity is still quadratic in the number of classes, we show that even in the case of completely random base classifiers, our method still outperforms the conventional pairwise classifier. For the more practical case of well-trained base classifiers, its asymptotic computational complexity seems to be almost linear.},
	language = {en},
	booktitle = {Machine {Learning}: {ECML} 2007},
	publisher = {Springer},
	author = {Park, Sang-Hyeun and Fürnkranz, Johannes},
	editor = {Kok, Joost N. and Koronacki, Jacek and Mantaras, Raomon Lopez de and Matwin, Stan and Mladenič, Dunja and Skowron, Andrzej},
	year = {2007},
	pages = {658--665},
}

@article{shoemaker_deciphering_2007,
	title = {Deciphering {Protein}–{Protein} {Interactions}. {Part} {II}. {Computational} {Methods} to {Predict} {Protein} and {Domain} {Interaction} {Partners}},
	volume = {3},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.0030043},
	doi = {10.1371/journal.pcbi.0030043},
	language = {en},
	number = {4},
	urldate = {2021-01-03},
	journal = {PLOS Computational Biology},
	author = {Shoemaker, Benjamin A. and Panchenko, Anna R.},
	month = apr,
	year = {2007},
	note = {Number: 4
Publisher: Public Library of Science},
	keywords = {Forecasting, Genomics, Invertebrate genomics, Phylogenetic analysis, Phylogenetics, Protein domains, Protein interaction networks, Protein interactions},
	pages = {e43},
}

@inproceedings{atarashi_deep_2017,
	title = {A {Deep} {Neural} {Network} for {Pairwise} {Classification}: {Enabling} {Feature} {Conjunctions} and {Ensuring} {Symmetry}},
	isbn = {978-3-319-57453-0},
	shorttitle = {A {Deep} {Neural} {Network} for {Pairwise} {Classification}},
	doi = {10.1007/978-3-319-57454-7_7},
	abstract = {Pairwise classification is a computational problem to determine whether a given ordered pair of objects satisfies a binary relation R which is specified implicitly by a set of training data used for ‘learning’ R. It is an important component for entity resolution, network link prediction, protein-protein interaction prediction, and so on. Although deep neural networks (DNNs) outperform other methods in many tasks and have thus attracted the attention of machine learning researchers, there have been few studies of applying a DNN to pairwise classification. Important properties of pairwise classification include using feature conjunctions across examples. Also, it is known that making the classifier invariant to the data order is an important property in applications with a symmetric relation R, including those applications mentioned above. We first show that a simple DNN with fully connected layers cannot satisfy these properties and then present a pairwise DNN satisfying these properties. As an example of pairwise classification, we use the author matching problem, which is the problem of determining whether two author names in different bibliographic data sources refer to the same person. We show that the method using our model outperforms methods using a support vector machine and simple DNNs.},
	author = {Atarashi, Kyohei and Oyama, Satoshi and Kurihara, Masahito and Furudo, Kazune},
	month = apr,
	year = {2017},
	pages = {83--95},
}

@article{sun_eeg-based_2019,
	title = {{EEG}-based user identification system using {1D}-convolutional long short-term memory neural networks},
	volume = {125},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S095741741930096X},
	doi = {10.1016/j.eswa.2019.01.080},
	abstract = {Electroencephalographic (EEG) signals have been widely used in medical applications, yet the use of EEG signals as user identification systems for healthcare and Internet of Things (IoT) systems has only gained interests in the last few years. The advantages of EEG-based user identification systems lie in its dynamic property and uniqueness among different individuals. However, it is for this reason that manually designed features are not always adapted to the needs. Therefore, a novel approach based on 1D Convolutional Long Short-term Memory Neural Network (1D-Convolutional LSTM) for EEG-based user identification system is proposed in this paper. The performance of the proposed approach was validated with a public database consists of EEG data of 109 subjects. The experimental results showed that the proposed network has a very high averaged accuracy of 99.58\%, when using only 16 channels of EEG signals, which outperforms the state-of-the-art EEG-based user identification methods. The combined use of CNNs and LSTMs in the proposed 1D-Convolutional LSTM can greatly improve the accuracy of user identification systems by utilizing the spatiotemporal features of the EEG signals with LSTM, and lowering cost of the systems by reducing the number of EEG electrodes used in the systems.},
	language = {en},
	urldate = {2020-12-06},
	journal = {Expert Systems with Applications},
	author = {Sun, Yingnan and Lo, Frank P. -W. and Lo, Benny},
	month = jul,
	year = {2019},
	keywords = {1D-Convolutional LSTM, Biometrics, Electroencephalograms (EEG), User identification},
	pages = {259--267},
}

@article{bock_predicting_2001,
	title = {Predicting protein–protein interactions from primary structure},
	volume = {17},
	issn = {1367-4803},
	url = {https://doi.org/10.1093/bioinformatics/17.5.455},
	doi = {10.1093/bioinformatics/17.5.455},
	abstract = {Motivation: An ambitious goal of proteomics is to elucidate the

structure, interactions and functions of all proteins within cells

and organisms. The expectation is that this will provide a fuller

appreciation of cellular processes and networks at the protein

level, ultimately leading to a better understanding of disease

mechanisms and suggesting new means for intervention. This paper

addresses the question: can protein–protein interactions be

predicted directly from primary structure and associated data? Using

a diverse database of known protein interactions, a Support Vector

Machine (SVM) learning system was trained to recognize and predict

interactions based solely on primary structure and associated

physicochemical properties.Results: Inductive accuracy of the trained system, defined here

as the percentage of correct protein interaction predictions for

previously unseen test sets, averaged 80\% for the ensemble of

statistical experiments. Future proteomics studies may benefit from

this research by proceeding directly from the automated

identification of a cell’s gene products to prediction of

protein interaction pairs.Contact: dgough@bioeng.ucsd.edu*To whom correspondence should be

addressed.},
	number = {5},
	urldate = {2021-01-03},
	journal = {Bioinformatics},
	author = {Bock, Joel R. and Gough, David A.},
	month = may,
	year = {2001},
	note = {Number: 5},
	pages = {455--460},
}

@article{moody_physionet_2001,
	title = {{PhysioNet}: a {Web}-based resource for the study of physiologic signals},
	volume = {20},
	issn = {1937-4186},
	shorttitle = {{PhysioNet}},
	doi = {10.1109/51.932728},
	abstract = {Free access to a signals archive and a signal processing/analysis software library fosters online collaboration. This article aims to introduce PhysioNet as a resource to the biomedical research community. After a capsule summary of its history and goals, we discuss what PhysioNet offers to researchers, describe some of the technology needed to support these functions, and conclude with observations gleaned from PhysioNet's first year of service.},
	number = {3},
	journal = {IEEE Engineering in Medicine and Biology Magazine},
	author = {Moody, G. B. and Mark, R. G. and Goldberger, A. L.},
	month = may,
	year = {2001},
	note = {Number: 3
Conference Name: IEEE Engineering in Medicine and Biology Magazine},
	keywords = {Algorithm design and analysis, Biomedical signal processing, Databases, Databases, Factual, Humans, Internet, MIMIC database, Medical diagnostic imaging, Monitoring, Physiologic, Online Communities/Technical Collaboration, Open source software, PhysioNet, Signal Processing, Computer-Assisted, Signal analysis, Signal processing, Software libraries, Web sites, Web-based resource, apnoea database, database management systems, information resources, medical information systems, neurophysiology, online collaboration, physiologic signals, polysomnographic database, signal processing/analysis software library, signals archive library, sleep},
	pages = {70--75},
}

@misc{brownlee_gentle_2018,
	title = {A {Gentle} {Introduction} to {LSTM} {Autoencoders}},
	url = {https://machinelearningmastery.com/lstm-autoencoders/},
	abstract = {An LSTM Autoencoder is an implementation of an autoencoder for sequence data using an Encoder-Decoder LSTM architecture. Once fit, the encoder part of the model can be used to encode or compress sequence data that in turn may be used in data visualizations or as a feature vector input to a supervised learning model. In […]},
	language = {en-US},
	urldate = {2020-12-06},
	journal = {Machine Learning Mastery},
	author = {Brownlee, Jason},
	month = nov,
	year = {2018},
}

@article{abo-zahhad_new_2015,
	title = {A {New} {EEG} {Acquisition} {Protocol} for {Biometric} {Identification} {Using} {Eye} {Blinking} {Signals}},
	volume = {7},
	issn = {2074904X, 20749058},
	url = {http://www.mecs-press.org/ijisa/ijisa-v7-n6/v7n6-5.html},
	doi = {10.5815/ijisa.2015.06.05},
	number = {6},
	urldate = {2020-12-05},
	journal = {International Journal of Intelligent Systems and Applications},
	author = {Abo-Zahhad, M. and Ahmed, Sabah M. and Abbas, Sherif N.},
	month = may,
	year = {2015},
	note = {Number: 6},
	pages = {48--54},
}

@article{kaur_novel_2017,
	title = {A {Novel} framework of {EEG}-based user identification by analyzing music-listening behavior},
	volume = {76},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-016-4232-2},
	doi = {10.1007/s11042-016-4232-2},
	abstract = {This paper introduces a novel framework for user identification by analyzing neuro-signals. Studies regarding Electroencephalography (EEG) revealed that such bio-signals are sensitive, hard to forge, confidential, and unique which the conventional biometric systems like face, speaker, signature and voice lack. Traditionally, researchers investigated the neuro-signal patterns by asking users to perform various imaginary, visual or calculative tasks. In this work, we have analyzed this neuro-signal pattern using audio as stimuli. The EEG signals are recorded simultaneously while user is listening to music. Four different genres of music are considered as users have their own preference and accordingly they respond with different emotions and interests. The users are also asked to provide music preference which acts as a personal identification mechanism. The framework offers the benefit of uniqueness in neuro-signal pattern even with the same music preference by different users. We used two different classifiers i.e. Hidden Markov Model (HMM) based temporal classifier and Support Vector Machine (SVM) for user identification system. A dataset of 2400 EEG signals while listening to music was collected from 60 users. User identification performance of 97.50 \% and 93.83 \% have been recorded with HMM and SVM classifiers, respectively. Finally, the performance of the system is also evaluated on various emotional states after showing different emotional videos to users.},
	language = {en},
	number = {24},
	urldate = {2020-12-05},
	journal = {Multimedia Tools and Applications},
	author = {Kaur, Barjinder and Singh, Dinesh and Roy, Partha Pratim},
	month = dec,
	year = {2017},
	note = {Number: 24},
	pages = {25581--25602},
}

@book{waili_eeg_2019,
	title = {{EEG} {Based} {Biometric} {Identification} {Using} {Correlation} and {MLPNN} {Models}},
	url = {https://www.learntechlib.org/p/218031/},
	abstract = {This study investigates the capability of electroencephalogram (EEG) signals to be used for biometric identification. In the context of biometric, recently, researchers have been focusing more on biomedical signals to substitute the biometric modalities that are being used nowadays as the signals obtained from our bodies is considered more secure and privacy-compliant. The EEG signals of 6 subjects were collected where the subjects were required to undergo two baseline experiments which are, eyes open (EO) and eyes closed (EC). The signals were processed using a 2nd order Butterworth filter...},
	language = {en},
	urldate = {2020-12-05},
	publisher = {International Association of Online Engineering},
	author = {Waili, T. and Johar, Gapar and Sidek, K. and Nor, N. and Yaacob, H. and Othman, M.},
	month = jun,
	year = {2019},
	note = {Pages: 77-90},
}

@inproceedings{gui_multichannel_2015,
	title = {Multichannel {EEG}-based biometric using improved {RBF} neural networks},
	doi = {10.1109/SPMB.2015.7405418},
	abstract = {Electroencephalogram (EEG) brainwaves have recently emerged as a promising biometric that can be used for individual identification. In this study, we present a new visual stimuli-driven, non-volitional brain responses based methodological framework towards individual identification. The non-volitional mechanism provides an even more secure way in which the individuals are not aware of security credentials and thus can not manipulate their brain activities. Given the intercorrelated structure of brain functional areas, instead of making the identification decision relying on any single EEG channel, we propose a new identification approach based on the decision-level fusion of multichannel EEG signals, using the Radial Basis Function (RBF) neural network and its improved versions. Specifically, the identification decision is determined according to the identification patterns reflected from multiple EEG channels over the desired brain functional region. We evaluate the performance of our proposed methods based on four different visual stimuli and four independent EEG channels. Experimental results show that, the proposed fusion technique can significantly improve the identification accuracy, compared to the conventional single channel based solution. For RBF network, the accuracy of identifying 37 subjects could reach over 70\%, which is better than the average accuracy of about 55\% achieved through individual channels. For the improved RBF networks, the frequency-based decision making could reach the accuracy of 90\%, while the probability-based method could reach over 91\%. Our study lays a foundation for future investigation of more accurate and reliable brainwave-based biometrics.},
	booktitle = {2015 {IEEE} {Signal} {Processing} in {Medicine} and {Biology} {Symposium} ({SPMB})},
	author = {Gui, Q. and Jin, Z. and Xu, W. and Ruiz-Blondet, M. V. and Laszlo, S.},
	month = dec,
	year = {2015},
	keywords = {Biological neural networks, EEG brainwaves, Electroencephalography, Feature extraction, Neurons, RBF neural network, Radial basis function networks, Visualization, bioelectric potentials, brain, brain activity, brain functional areas, brain functional region, conventional single channel based solution, decision making, decision-level fusion, electroencephalogram brainwaves, electroencephalography, frequency-based decision making, fusion technique, identification, identification accuracy, identification decision, identification patterns, improved RBF neural networks, intercorrelated structure, medical signal processing, multichannel EEG signals, multichannel EEG-based biometrics, neurophysiology, nonvolitional mechanism, ological framework, probability, probability-based method, radial basis function networks, radial basis function neural network, single EEG channel, visual stimuli, visual stimuli-driven nonvolitional brain response based method},
	pages = {1--6},
}

@article{de_vazelhes_metric-learn_2020,
	title = {metric-learn: {Metric} {Learning} {Algorithms} in {Python}},
	volume = {21},
	number = {138},
	journal = {Journal of Machine Learning Research},
	author = {de Vazelhes, William and Carey, CJ and Tang, Yuan and Vauquier, Nathalie and Bellet, Aurélien},
	year = {2020},
	note = {Number: 138},
	pages = {1--6},
}

@article{di_robustness_2019,
	title = {Robustness {Analysis} of {Identification} {Using} {Resting}-{State} {EEG} {Signals}},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2907644},
	abstract = {The brain activity pattern can be presented by Electroencephalogram (EEG), which is considered as an alternative to traditional biometrics. Researchers have done conducted studies on EEG-based identification, while few of them discussed the effect of time robustness which is very important for the identification system. In this study, we compared and analyzed the two runs EEG signals of resting-state of eye open/closed (REO/REC). The time intervals between two runs were at least two weeks. Here are 17 participants joined in this study. Each of them took two runs experiment. Each run contains four sessions, each session includes 150 seconds of REO/REC. Spectral and statistical analyses were used to extract feature. Three classifiers, Euclidean distance, SVM, and LDA, were used to get classification accuracies and to compare the performance between features of each run and two runs. The results of two runs PSD values of both REO and REC conditions show that there is a similarity within each subject and a difference between subjects. The classification accuracies of three methods of each run are almost 99\%. The classification accuracies using two runs data as training set can also reach up to 97\% while using each of two-run data as training set is nearly 80\%. Thus, the features of most subjects have cross-time robustness and could be used as identification. This study will have an important role in EEG-based identification system.},
	journal = {IEEE Access},
	author = {Di, Y. and An, X. and He, F. and Liu, S. and Ke, Y. and Ming, D.},
	year = {2019},
	note = {Conference Name: IEEE Access},
	keywords = {Biometrics (access control), Correlation, EEG-based identification system, Electroencephalography, Electroencephalography(EEG), Euclidean distance, Feature extraction, Robustness, SVM, Support vector machines, biometrics, brain activity pattern, classification accuracies, electroencephalogram, electroencephalography, eye, eye closed, eye open, feature extraction, identification, medical signal processing, neurophysiology, resting-state, resting-state EEG signals, robustness, robustness analysis, runs PSD values, statistical analyses, statistical analysis, support vector machines, two-run data},
	pages = {42113--42122},
}

@article{hunter_australian_2005,
	title = {The {Australian} {EEG} database},
	volume = {36},
	issn = {1550-0594},
	doi = {10.1177/155005940503600206},
	abstract = {The Australian EEG Database is a web-based de-identified searchable database of 18,500 EEG records recorded at a regional public hospital over an 11-year period. Patients range in age from a premature infant born at 24 weeks gestation, through to people aged over 90 years. This paper will describe the history of the database, the range of patients represented in the database, and the nature of the text-based and digital data contained in the database. Preliminary results of the first two studies undertaken using the database are presented. Plans for sharing data from the Australian EEG database with researchers are discussed. We anticipate that such data will be useful in not only helping to answer clinical questions but also in the field of mathematical modeling of the EEG.},
	language = {eng},
	number = {2},
	journal = {Clinical EEG and neuroscience},
	author = {Hunter, M. and Smith, R. L. L. and Hyslop, W. and Rosso, O. A. and Gerlach, R. and Rostas, J. a. P. and Williams, D. B. and Henskens, F.},
	month = apr,
	year = {2005},
	pmid = {15999902},
	note = {Number: 2},
	keywords = {Adolescent, Adult, Aged, Animals, Australia, Child, Child, Preschool, Clinical Trials as Topic, Database Management Systems, Databases, Factual, Electroencephalography, Humans, Infant, Infant, Newborn, Information Dissemination, Information Storage and Retrieval, Internet, Medical Records Systems, Computerized, Middle Aged, User-Computer Interface},
	pages = {76--81},
}

@inproceedings{poulos_person_1999,
	title = {Person identification based on parametric processing of the {EEG}},
	volume = {1},
	doi = {10.1109/ICECS.1999.812278},
	abstract = {Person identification based on parametric spectral analysis of the EEG signal is addressed in this work-a problem that has not yet been seen in a signal-processing framework, to the best of our knowledge. AR parameters are estimated from a signal containing only the alpha, rhythm activity of the EEG. These parameters are used as features in the classification step, which employs a learning vector quantizer network. The proposed method was applied on a set of real EEG recordings made on healthy individuals, in an attempt to experimentally investigate the connection between a person's EEG and genetically-specific information. Correct classification scores at the range of 72\% to 84\% show the potential of our approach for person classification/identification and are in agreement with previous research showing evidence that the EEG carries genetic information.},
	booktitle = {{ICECS}'99. {Proceedings} of {ICECS} '99. 6th {IEEE} {International} {Conference} on {Electronics}, {Circuits} and {Systems} ({Cat}. {No}.{99EX357})},
	author = {Poulos, M. and Rangoussi, M. and Chrissikopoulos, V. and Evangelou, A.},
	month = sep,
	year = {1999},
	keywords = {AR parameters, Computational geometry, Data mining, EEG, Electroencephalography, Encoding, Feature extraction, Genetics, Informatics, Information security, Physiology, Rhythm, autoregressive processes, biometrics (access control), classification step, electroencephalography, genetic information, learning vector quantizer network, parametric processing, pattern classification, person classification, person identification, rhythm activity, spectral analysis, vector quantisation},
	pages = {283--286 vol.1},
}

@article{klonovs_id_2013,
	title = {{ID} {Proof} on the {Go}: {Development} of a {Mobile} {EEG}-{Based} {Biometric} {Authentication} {System}},
	volume = {8},
	issn = {1556-6080},
	shorttitle = {{ID} {Proof} on the {Go}},
	doi = {10.1109/MVT.2012.2234056},
	abstract = {In recent years, the need for greater security for storing personal and business data or accessing corporate networks on mobile devices has been growing rapidly, and one of the potential solutions is to employ innovative biometric authentication techniques. This article presents the development of a mobile biometric authentication system based on electroencephalogram (EEG) recordings in combination with already proven technologies such as facial detection and nearfield communication (NFC). The overall goal of this work is to fill the gap between mobile Web technologies and wireless EEG devices and to develop a new authentication technique and a feasible application. Therefore, we review the relevant literature, conduct several EEG measurement experiments, and discuss the procedure and results with experts in the EEG and digital signal processing (DSP) fields. On the basis of these results, we build and present a mobile prototype system capable of authenticating users based on the uniqueness of their brain waves. Furthermore, we implement a novel authentication process that will make the authentication system more secure. We also give suggestions for future improvements to the system.},
	number = {1},
	journal = {IEEE Vehicular Technology Magazine},
	author = {Klonovs, J. and Petersen, C. K. and Olesen, H. and Hammershoj, A.},
	month = mar,
	year = {2013},
	note = {Number: 1
Conference Name: IEEE Vehicular Technology Magazine},
	keywords = {Authentication, Cameras, Computer security, DSP, Data security, EEG measurement experiment, Electroencephalography, Headphones, Mobile communication, NFC, Privacy, Prototypes, biometrics (access control), brain waves, business data security, corporate network access, digital signal processing, electroencephalogram recording, electroencephalography, facial detection, innovative biometric authentication technique, medical signal processing, mobile EEG-based biometric authentication system, mobile Web technologies, mobile devices, mobile radio, near-field communication, personal data security, user authentication, wireless EEG devices},
	pages = {81--89},
}

@article{akhtar_face_2017,
	title = {A {Face} in any {Form}: {New} {Challenges} and {Opportunities} for {Face} {Recognition} {Technology}},
	volume = {50},
	issn = {1558-0814},
	shorttitle = {A {Face} in any {Form}},
	doi = {10.1109/MC.2017.119},
	abstract = {Despite new technologies that make face detection and recognition more sophisticated, long-recognized problems in security, privacy, and accuracy persist. Refining this technology and introducing it into new domains will require solving these problems through focused interdisciplinary efforts among developers, researchers, and policymakers.},
	number = {4},
	journal = {Computer},
	author = {Akhtar, Z. and Rattani, A.},
	month = apr,
	year = {2017},
	note = {Number: 4
Conference Name: Computer},
	keywords = {Algorithm design and analysis, FRS, Face recognition, Feature extraction, Image recognition, Solid modeling, Three-dimensional displays, biometrics, data analysis, face detection, face recognition, face recognition system, face recognition technology, privacy, privacy problem, security, security problem},
	pages = {80--90},
}

@article{yang_security_2019,
	title = {Security and {Accuracy} of {Fingerprint}-{Based} {Biometrics}: {A} {Review}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Security and {Accuracy} of {Fingerprint}-{Based} {Biometrics}},
	url = {https://www.mdpi.com/2073-8994/11/2/141},
	doi = {10.3390/sym11020141},
	abstract = {Biometric systems are increasingly replacing traditional password- and token-based authentication systems. Security and recognition accuracy are the two most important aspects to consider in designing a biometric system. In this paper, a comprehensive review is presented to shed light on the latest developments in the study of fingerprint-based biometrics covering these two aspects with a view to improving system security and recognition accuracy. Based on a thorough analysis and discussion, limitations of existing research work are outlined and suggestions for future work are provided. It is shown in the paper that researchers continue to face challenges in tackling the two most critical attacks to biometric systems, namely, attacks to the user interface and template databases. How to design proper countermeasures to thwart these attacks, thereby providing strong security and yet at the same time maintaining high recognition accuracy, is a hot research topic currently, as well as in the foreseeable future. Moreover, recognition accuracy under non-ideal conditions is more likely to be unsatisfactory and thus needs particular attention in biometric system design. Related challenges and current research trends are also outlined in this paper.},
	language = {en},
	number = {2},
	urldate = {2020-11-27},
	journal = {Symmetry},
	author = {Yang, Wencheng and Wang, Song and Hu, Jiankun and Zheng, Guanglou and Valli, Craig},
	month = feb,
	year = {2019},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {biometrics, latent fingerprint, recognition accuracy, security, template protection},
	pages = {141},
}

@article{galbally_image_2014,
	title = {Image {Quality} {Assessment} for {Fake} {Biometric} {Detection}: {Application} to {Iris}, {Fingerprint}, and {Face} {Recognition}},
	volume = {23},
	issn = {1941-0042},
	shorttitle = {Image {Quality} {Assessment} for {Fake} {Biometric} {Detection}},
	doi = {10.1109/TIP.2013.2292332},
	abstract = {To ensure the actual presence of a real legitimate trait in contrast to a fake self-manufactured synthetic or reconstructed sample is a significant problem in biometric authentication, which requires the development of new and efficient protection measures. In this paper, we present a novel software-based fake detection method that can be used in multiple biometric systems to detect different types of fraudulent access attempts. The objective of the proposed system is to enhance the security of biometric recognition frameworks, by adding liveness assessment in a fast, user-friendly, and non-intrusive manner, through the use of image quality assessment. The proposed approach presents a very low degree of complexity, which makes it suitable for real-time applications, using 25 general image quality features extracted from one image (i.e., the same acquired for authentication purposes) to distinguish between legitimate and impostor samples. The experimental results, obtained on publicly available data sets of fingerprint, iris, and 2D face, show that the proposed method is highly competitive compared with other state-of-the-art approaches and that the analysis of the general image quality of real biometric samples reveals highly valuable information that may be very efficiently used to discriminate them from fake traits.},
	number = {2},
	journal = {IEEE Transactions on Image Processing},
	author = {Galbally, J. and Marcel, S. and Fierrez, J.},
	month = feb,
	year = {2014},
	note = {Number: 2
Conference Name: IEEE Transactions on Image Processing},
	keywords = {Algorithms, Biomedical imaging, Biometric Identification, Dermatoglyphics, Face, Facial Recognition, Feature extraction, Fingers, Fraud, Humans, Image Interpretation, Computer-Assisted, Image quality, Image quality assessment, Iris, Iris recognition, Pattern Recognition, Automated, Reproducibility of Results, Security, Sensitivity and Specificity, attacks, biometric authentication, biometric recognition framework, biometrics, countermeasures, face recognition, fake biometric detection, feature extraction, fingerprint identification, fingerprint recognition, fraudulent access attempts, image quality assessment, iris recognition, liveness assessment, protection measures, security, software based fake detection method},
	pages = {710--724},
}

@inproceedings{schons_convolutional_2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Convolutional {Network} for {EEG}-{Based} {Biometric}},
	isbn = {978-3-319-75193-1},
	doi = {10.1007/978-3-319-75193-1_72},
	abstract = {The global expansion of biometric systems promotes the emergence of new and more robust biometric modalities. In that context, electroencephalogram (EEG) based biometric interest has been growing in recent years. In this study, a novel approach for EEG representation, based on deep learning, is proposed. The method was evaluated on a database containing 109 subjects, and all 64 EEG channels were used as input to a Deep Convolution Neural Network. Data augmentation techniques are explored to train the deep network and results showed that the method is a promising path to represent brain signals, overcoming baseline methods published in the literature.},
	language = {en},
	booktitle = {Progress in {Pattern} {Recognition}, {Image} {Analysis}, {Computer} {Vision}, and {Applications}},
	publisher = {Springer International Publishing},
	author = {Schons, Thiago and Moreira, Gladston J. P. and Silva, Pedro H. L. and Coelho, Vitor N. and Luz, Eduardo J. S.},
	editor = {Mendoza, Marcelo and Velastín, Sergio},
	year = {2018},
	keywords = {physionet},
	pages = {601--608},
}

@article{zhang_mindid_2018,
	title = {{MindID}: {Person} {Identification} from {Brain} {Waves} through {Attention}-based {Recurrent} {Neural} {Network}},
	volume = {2},
	shorttitle = {{MindID}},
	url = {https://doi.org/10.1145/3264959},
	doi = {10.1145/3264959},
	abstract = {Person identification technology recognizes individuals by exploiting their unique, measurable physiological and behavioral characteristics. However, the state-of-the-art person identification systems have been shown to be vulnerable, e.g., anti-surveillance prosthetic masks can thwart face recognition, contact lenses can trick iris recognition, vocoder can compromise voice identification and fingerprint films can deceive fingerprint sensors. EEG (Electroencephalography)-based identification, which utilizes the user's brainwave signals for identification and offers a more resilient solution, has recently drawn a lot of attention. However, the state-of-the-art systems cannot achieve similar accuracy as the aforementioned methods. We propose MindID, an EEG-based biometric identification approach, with the aim of achieving high accuracy and robust performance. At first, the EEG data patterns are analyzed and the results show that the Delta pattern contains the most distinctive information for user identification. Next, the decomposed Delta signals are fed into an attention-based Encoder-Decoder RNNs (Recurrent Neural Networks) structure which assigns varying attention weights to different EEG channels based on their importance. The discriminative representations learned from the attention-based RNN are used to identify the user through a boosting classifier. The proposed approach is evaluated over 3 datasets (two local and one public). One local dataset (EID-M) is used for performance assessment and the results illustrate that our model achieves an accuracy of 0.982 and significantly outperforms the state-of-the-art and relevant baselines. The second local dataset (EID-S) and a public dataset (EEG-S) are utilized to demonstrate the robustness and adaptability, respectively. The results indicate that the proposed approach has the potential to be widely deployed in practical settings.},
	number = {3},
	urldate = {2020-11-25},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Zhang, Xiang and Yao, Lina and Kanhere, Salil S. and Liu, Yunhao and Gu, Tao and Chen, Kaixuan},
	month = sep,
	year = {2018},
	note = {Number: 3},
	keywords = {EEG, EEG pattern decomposition, attention mechanism, biometric identification, deep learning},
	pages = {149:1--149:23},
}

@inproceedings{jayarathne_survey_2017,
	title = {Survey of {EEG}-based biometric authentication},
	doi = {10.1109/ICAwST.2017.8256471},
	abstract = {User authentication systems based on EEG (electroencephalography) is currently popular, marking an inflection point in the field. Recently, the scientific community has been making tremendous attempts towards perceiving uniqueness of brain signal patterns. Several types of methodical approaches have been proposed and prototyped to analyze EEG data with various signal-processing methods and pattern-recognition algorithms. Even though there are many stimulation methods to produce reasonable distinctiveness between subjects, optimization and lowering task complexity are still desirable from techno-economic points of view. With recent technological advancement of EEG signal capturing devices, the process is getting comparatively simpler as devices are capable of providing better portability with reduced calibration time. However, most detailed analysis suggests that a minimal number of most appropriate channels should be selected for better results, even if a system is equipped with the most advanced hardware. Researchers are now focusing on implementing computationally low cost systems with better accuracy, regardless of complexity of the tasks. This paper is a review of several approaches, providing an overview of crucial design considerations in handling EEG data for extended accuracy and practical applicability to authentication.},
	booktitle = {2017 {IEEE} 8th {International} {Conference} on {Awareness} {Science} and {Technology} ({iCAST})},
	author = {Jayarathne, I. and Cohen, M. and Amarakeerthi, S.},
	month = nov,
	year = {2017},
	note = {ISSN: 2325-5994},
	keywords = {Authentication, Conferences, EEG, EEG data, EEG signal capturing devices, EEG-based biometric authentication, Electrodes, Electroencephalography, biometrics, biometrics (access control), brain signal patterns, calibration, computationally low cost systems, electroencephalography, inflection point, optimization, pattern recognition, pattern-recognition, pattern-recognition algorithms, reduced calibration time, review, reviews, signal processing, signal-processing methods, stimulation methods, task complexity, user authentication systems},
	pages = {324--329},
}

@article{li_brain_nodate,
	title = {Brain {Signal} {Biometrics} with {Virtual} {Reality}},
	abstract = {The purpose of this research was to determine whether active portions of a person’s brain are influenced by their using Virtual Reality (VR) and whether those brain signals can be used for user authentication. Electroencephalography (EEG) signals are individually unique and non-trivial to collect. Because of these properties, brain signals are some of the strongest and most secure forms of biometric data. For this study EEG signals were collected under two conditions: while subjects were viewing video using a Veer cardboard headset and while viewing video on a traditional laptop screen. During the collection of EEG data, subjects started in a resting stage and then entered into an active stage. Brain waves collected for both the resting stage and the active stages were compared for analysis purposes. Pre-processing and feature extraction of VR and non-VR EEG data were performed. Additionally, distance computation was calculated in an attempt to authenticate the identity of the subject and Support Vector Machine (SVM) method were used for classification.},
	language = {en},
	author = {Li, Sukun and Savaliya, Sonal and Marino, Leonard and Koller, Jonathan and Leider, Avery and Tappert, Charles C},
	pages = {6},
}

@article{sooriyaarachchi_musicid_2020,
	title = {{MusicID}: {A} {Brainwave}-based {User} {Authentication} {System} for {Internet} of {Things}},
	shorttitle = {{MusicID}},
	url = {http://arxiv.org/abs/2006.01751},
	abstract = {We propose MusicID, an authentication solution for smart devices that uses music-induced brainwave patterns as a behavioral biometric modality. We experimentally evaluate MusicID using data collected from real users whilst they are listening to two forms of music; a popular English song and individual’s favorite song. We show that an accuracy over 98\% for user identiﬁcation and an accuracy over 97\% for user veriﬁcation can be achieved by using data collected from a 4electrode commodity brainwave headset. We further show that a single electrode is able to provide an accuracy of approximately 85\% and the use of two electrodes provides an accuracy of approximately 95\%. As already shown by commodity brainsensing headsets for meditation applications, we believe including dry EEG electrodes in smart-headsets is feasible and MusicID has the potential of providing an entry point and continuous authentication framework for upcoming surge of smart-devices mainly driven by Augmented Reality (AR)/Virtual Reality (VR) applications.},
	language = {en},
	urldate = {2020-11-21},
	journal = {arXiv:2006.01751 [cs, eess]},
	author = {Sooriyaarachchi, Jinani and Seneviratne, Suranga and Thilakarathna, Kanchana and Zomaya, Albert Y.},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.01751},
	keywords = {Computer Science - Cryptography and Security, Electrical Engineering and Systems Science - Signal Processing},
}

@article{iwasaki_effects_2005,
	title = {Effects of eyelid closure, blinks, and eye movements on the electroencephalogram},
	volume = {116},
	issn = {1388-2457},
	url = {http://www.sciencedirect.com/science/article/pii/S138824570400416X},
	doi = {10.1016/j.clinph.2004.11.001},
	abstract = {Objective
To characterize the effects of the eyeball and eyelid positions during eyeblinks on electroencephalographic (EEG) potentials.
Methods
Movements of the upper eyelids and eyes were measured in two healthy subjects using the magnetic search coil technique during horizontal and vertical eye rotations, eyeblinks, and lid closure. Corresponding signal changes were recorded simultaneously on the electroencephalogram (EEG).
Results
Spontaneous blinks produced small eye movements directed down and inward, whereas slow or forced blinks were associated with delayed upward eye rotations (i.e. Bell's phenomenon); both types of blinks caused positive EEG potentials with bifrontal distribution maximum at Fp1 and Fp2.
Conclusions
In prior reports, these positive EEG artifacts have been attributed to upward eyeball rotation during blinks—Bell's phenomenon. By contrast, our findings indicate that movements of the eyelid contribute to a greater extent to these EEG potentials than do upward eyeball rotations.
Significance
Care is required in attributing EEG artifacts to movements of either eyeball or eyelid, since our findings suggest that they both contribute to these potentials.},
	language = {en},
	number = {4},
	urldate = {2020-11-21},
	journal = {Clinical Neurophysiology},
	author = {Iwasaki, Masaki and Kellinghaus, Christoph and Alexopoulos, Andreas V. and Burgess, Richard C. and Kumar, Arun N. and Han, Yanning H. and Lüders, Hans O. and Leigh, R. John},
	month = apr,
	year = {2005},
	note = {Number: 4},
	keywords = {Artifacts, Blinks, Electroencephalogram, Eye movements, Eyelid, Saccades},
	pages = {878--885},
}

@inproceedings{pham_multi-factor_2014,
	title = {Multi-factor {EEG}-based user authentication},
	doi = {10.1109/IJCNN.2014.6889569},
	abstract = {Electroencephalography (EEG) signal has been used widely in health and medical fields. It is also used in brain-computer interface (BCI) systems for humans to continuously control mobile robots and wheelchairs. Recently, the research communities successfully explore the potential of using EEG as a new type of biometrics in user authentication. EEG-based user authentication systems have the combined advantages of both password-based and biometric-based authentication systems, yet without their drawbacks. In this paper, we propose to take the advantage of rich information, such as age and gender, carried by EEG signals for user authentication in multi-level security systems. Our experiments showed very promising results for the proposed multi-factor EEG-based authentication method.},
	booktitle = {2014 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Pham, T. and Ma, W. and Tran, D. and Nguyen, P. and Phung, D.},
	month = jul,
	year = {2014},
	note = {ISSN: 2161-4407},
	keywords = {Authentication, BCI systems, Brain models, EEG based user authentication systems, EEG signal, Electroencephalography, Feature extraction, Testing, biometrics, biometrics (access control), brain computer interface, brain-computer interfaces, continuously control mobile robots, electroencephalography, electroencephalography signal, health fields, medical fields, medical signal processing, multifactor EEG, multilevel security systems, user authentication, wheelchairs},
	pages = {4029--4034},
}

@inproceedings{noauthor_biometric_2010,
	address = {Valencia, Spain},
	title = {{BIOMETRIC} {AUTHENTICATION} {USING} {BRAIN} {RESPONSES} {TO} {VISUAL} {STIMULI}:},
	isbn = {978-989-674-018-4},
	shorttitle = {{BIOMETRIC} {AUTHENTICATION} {USING} {BRAIN} {RESPONSES} {TO} {VISUAL} {STIMULI}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0002750101030112},
	doi = {10.5220/0002750101030112},
	abstract = {Biometric authentication, Electroencephalograms, Visual evoked potentials.},
	language = {en},
	urldate = {2020-11-21},
	booktitle = {Proceedings of the {Third} {International} {Conference} on {Bio}-inspired {Systems} and {Signal} {Processing}},
	publisher = {SciTePress - Science and and Technology Publications},
	year = {2010},
	pages = {103--112},
}

@article{armstrong_brainprint_2015,
	title = {Brainprint: {Assessing} the uniqueness, collectability, and permanence of a novel method for {ERP} biometrics},
	volume = {166},
	issn = {0925-2312},
	shorttitle = {Brainprint},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231215004725},
	doi = {10.1016/j.neucom.2015.04.025},
	abstract = {The human brain continually generates electrical potentials representing neural communication. These potentials can be measured at the scalp, and constitute the electroencephalogram (EEG). When the EEG is time-locked to stimulation – such as the presentation of a word – and averaged over many such presentations, the Event-Related Potential (ERP) is obtained. The functional characteristics of components of the ERP are well understood, and some components represent processing that may differ uniquely from individual to individual—such as the N400 component, which represents access to the semantic network. We applied several pattern classifiers to ERPs representing the response of individuals to a stream of text designed to be idiosyncratically familiar to different individuals. Results indicate that there are robustly identifiable features of the ERP that enable labeling of ERPs as belonging to individuals with accuracy reliably above chance (in the range of 82–97\%). Further, these features are stable over time, as indicated by continued accurate identification of individuals from ERPs after a lag of up to six months. Even better, the high degree of labeling accuracy achieved in all cases was achieved with the use of only 3 electrodes on the scalp—the minimal possible number that can acquire clean data.},
	language = {en},
	urldate = {2020-11-21},
	journal = {Neurocomputing},
	author = {Armstrong, Blair C. and Ruiz-Blondet, Maria V. and Khalifian, Negin and Kurtz, Kenneth J. and Jin, Zhanpeng and Laszlo, Sarah},
	month = oct,
	year = {2015},
	keywords = {Authentication, Autoencoder, Biometrics, Cross-Correlation, DIVA, Divergent Autoencoder, EEG, Event-Related Potentials (ERPs), Identification, Linear Discriminant, N400, Naive Discriminant Learning, Neural Network, Pattern classification, SVM, Verification},
	pages = {59--67},
}

@article{rocca_human_2014,
	title = {Human {Brain} {Distinctiveness} {Based} on {EEG} {Spectral} {Coherence} {Connectivity}},
	volume = {61},
	issn = {1558-2531},
	doi = {10.1109/TBME.2014.2317881},
	abstract = {The use of EEG biometrics, for the purpose of automatic people recognition, has received increasing attention in the recent years. Most of the current analyses rely on the extraction of features characterizing the activity of single brain regions, like power spectrum estimation, thus neglecting possible temporal dependencies between the generated EEG signals. However, important physiological information can be extracted from the way different brain regions are functionally coupled. In this study, we propose a novel approach that fuses spectral coherence-based connectivity between different brain regions as a possibly viable biometric feature. The proposed approach is tested on a large dataset of subjects (N = 108) during eyes-closed (EC) and eyes-open (EO) resting state conditions. The obtained recognition performance shows that using brain connectivity leads to higher distinctiveness with respect to power-spectrum measurements, in both the experimental conditions. Notably, a 100\% recognition accuracy is obtained in EC and EO when integrating functional connectivity between regions in the frontal lobe, while a lower 97.5\% is obtained in EC (96.26\% in EO) when fusing power spectrum information from parieto-occipital (centro-parietal in EO) regions. Taken together, these results suggest that the functional connectivity patterns represent effective features for improving EEG-based biometric systems.},
	number = {9},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Rocca, D. L. and Campisi, P. and Vegso, B. and Cserti, P. and Kozmann, G. and Babiloni, F. and Fallani, F. D. V.},
	month = sep,
	year = {2014},
	note = {Number: 9
Conference Name: IEEE Transactions on Biomedical Engineering},
	keywords = {Accuracy, Biometric Identification, Biometrics, Biometrics (access control), Brain, Coherence, EEG signals, EEG spectral coherence connectivity, EEG-based biometric systems, Electrodes, Electroencephalography, Feature extraction, Humans, Signal Processing, Computer-Assisted, Vectors, authentication, automatic people recognition, bioelectric potentials, brain connectivity, brain regions, electroencephalography, electroencephalography (EEG), eyes-closed resting state conditions, eyes-open resting state conditions, feature extraction, frontal lobe, functional connectivity, functional connectivity patterns, human brain distinctiveness, match score fusion, medical signal processing, neurophysiology, parieto-occipital regions, power spectrum estimation, power spectrum information, power-spectrum measurements, resting state, spectral coherence, viable biometric feature},
	pages = {2406--2412},
}

@book{sr_classification_2017,
	title = {Classification of {Motor} {Imagery} {Based} {EEG} {Signals} {Using} {Sparsity} {Approach}},
	isbn = {978-3-319-72037-1},
	abstract = {The advancement in brain-computer interface systems (BCIs) gives a new hope to people with special needs in restoring their independence. Since, BCIs using motor imagery (MI) rhythms provides high degree of freedom, it is been used for many real-time applications, especially for locked-in people. The available BCIs using MI-based EEG signals usually makes use of spatial filtering and powerful classification methods to attain better accuracy and performance. Inter-subject variability and speed of the classifier is still a issue in MI-based BCIs. To address the aforementioned issues, in this work, we propose a new classification method, spatial filtering based sparsity (SFS) approach for MI-based BCIs. The proposed method makes use of common spatial pattern (CSP) to spatially filter the MI signals. Then frequency bandpower and wavelet features from the spatially filtered signals are used to bulid two different over-complete dictionary matrix. This dictionary matrix helps to overcome the issue of inter-subject variability. Later, sparse representation based classification is carried out to classify the two-class MI signals. We analysed the performance of the proposed approach using publicly available MI dataset IVa from BCI competition III. The proposed SFS method provides better classification accuracy and runtime than the well-known support vector machine (SVM) and logistic regression (LR) classification methods. This SFS method can be further used to develop a real-time application for people with special needs.},
	author = {Sr, Sreeja and Rabha, Joytirmoy and Samanta, Debasis and Mitra, Pabitra and Sarma, Monalisa},
	month = dec,
	year = {2017},
	doi = {10.1007/978-3-319-72038-8_5},
	note = {Pages: 59},
}

@misc{noauthor_eeg_nodate,
	title = {{EEG} {Motor} {Movement}/{Imagery} {Dataset}},
	url = {https://archive.physionet.org/pn4/eegmmidb/},
	urldate = {2020-12-06},
}

@misc{noauthor_downloads_nodate,
	title = {Downloads – {Applied} {Neuroscience}, {Inc}.},
	url = {https://appliedneuroscience.com/downloads/},
	language = {en-US},
	urldate = {2020-12-06},
}

@article{stanley_designing_2019,
	title = {Designing neural networks through neuroevolution},
	volume = {1},
	doi = {10.1038/s42256-018-0006-z},
	abstract = {Deep neural networks have become very successful at certain machine learning tasks partly due to the widely adopted method of training called backpropagation. An alternative way to optimize neural networks is by using evolutionary algorithms, which, fuelled by the increase in computing power, offers a new range of capabilities and modes of learning.},
	journal = {Nature Machine Intelligence},
	author = {Stanley, Kenneth and Clune, Jeff and Lehman, Joel and Miikkulainen, Risto},
	month = jan,
	year = {2019},
}

@article{gale_state_2019,
	title = {The {State} of {Sparsity} in {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1902.09574},
	abstract = {We rigorously evaluate three state-of-the-art techniques for inducing sparsity in deep neural networks on two large-scale learning tasks: Transformer trained on WMT 2014 English-to-German, and ResNet-50 trained on ImageNet. Across thousands of experiments, we demonstrate that complex techniques (Molchanov et al., 2017; Louizos et al., 2017b) shown to yield high compression rates on smaller datasets perform inconsistently, and that simple magnitude pruning approaches achieve comparable or better results. Additionally, we replicate the experiments performed by (Frankle \& Carbin, 2018) and (Liu et al., 2018) at scale and show that unstructured sparse architectures learned through pruning cannot be trained from scratch to the same test set performance as a model trained with joint sparsification and optimization. Together, these results highlight the need for large-scale benchmarks in the field of model compression. We open-source our code, top performing model checkpoints, and results of all hyperparameter configurations to establish rigorous baselines for future work on compression and sparsification.},
	urldate = {2020-12-02},
	journal = {arXiv:1902.09574 [cs, stat]},
	author = {Gale, Trevor and Elsen, Erich and Hooker, Sara},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.09574},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@book{camere_materializing_2016,
	title = {Materializing experiential visions into sensory properties: the use of the {Experience} {Map}},
	shorttitle = {Materializing experiential visions into sensory properties},
	abstract = {Moving from conceptual design intentions to the materialization in product sensory qualities can be challenging. For Experience-driven designers this transition can be even more difficult, as they need to move from the abstract level of user experience to the concrete level of product features. In this paper, we suggest an approach to progressively deconstruct experiential visions and decrease the level of abstraction. We propose the use of
a tool, namely the Experience Map, which describes five steps to develop a well-refined materialization and maintain a solid correlation with the initial intention. To investigate its value and challenge the approach in design practice, we set up four case studies. The analysis of designers’ attitudes towards the Experience
Map gave insights on its ability to provide a structure for creative thoughts, while suiting different and subjective attitudes of designers. Moreover, the map supports the integration of several different elements and the exploration of alternative design directions to achieve the intended, holistic experience. Some limitations were also highlighted by the case studies, which are discussed in light of future work.},
	author = {Camere, Serena and Schifferstein, Rick and Bordegoni, Monica},
	month = oct,
	year = {2016},
}

@misc{noauthor_3_nodate,
	title = {(3) ({PDF}) {Materializing} experiential visions into sensory properties: the use of the {Experience} {Map}},
	url = {https://www.researchgate.net/publication/309415318_Materializing_experiential_visions_into_sensory_properties_the_use_of_the_Experience_Map},
	urldate = {2020-11-22},
}

@misc{noauthor_camere-materializingexperientialvisionsintosensorypropertiestheuseoftheexperiencemappdf_nodate,
	title = {Camere-{MaterializingexperientialvisionsintosensorypropertiesTheuseoftheExperienceMap}.pdf: {Multisensory} {Design} (2020-{1B})},
	url = {https://canvas.utwente.nl/courses/6250/files/1816554?module_item_id=175588},
	urldate = {2020-11-22},
}

@inproceedings{soni_biometric_2016,
	address = {Coimbatore, India},
	title = {Biometric user authentication using brain waves},
	isbn = {978-1-5090-1285-5},
	url = {http://ieeexplore.ieee.org/document/7824888/},
	doi = {10.1109/INVENTIVE.2016.7824888},
	abstract = {Authentication has become an essential part of our everyday lives which is used at almost every place from banks to experimental labs, from car automation to home automation. This authentication is generally provided through systems like passwords, PIN codes, card readers. At some places biometrics like ﬁngerprint and retina scans are used. All designed with one purpose; to conﬁrm a person’s identity. Brain wave based authentication is another addition to the wide range of authentication systems, which has many advantages over other authentication systems. With a standard password someone can watch or ’shoulder-surf’ what others type, but no one can watch thoughts. Cards and keys can be lost, but the brain wave is always present. Differently abled persons can’t use systems which uses fingerprints or retina scans but they can use system using brain-waves. This clears that using brain waves as biometric to provide authentication is very beneficial. A system is designed and implemented which allows user to set a pattern of brain waves which must be provided as an unlock pattern to get the access. This pattern can be any combination of eye blink, attention and various brain rhythms like Alpha, Beta, Theta and Delta. The system described in this paper provides two-level authentication. First level of which is brain waves. Once the correct pattern of brain signal is provide the system will ask for a pass key as a second level of authentication. This paper describes the design and implementation of the system.},
	language = {en},
	urldate = {2020-11-21},
	booktitle = {2016 {International} {Conference} on {Inventive} {Computation} {Technologies} ({ICICT})},
	publisher = {IEEE},
	author = {Soni, Yashraj S. and Somani, S. B. and Shete, V. V.},
	month = aug,
	year = {2016},
	pages = {1--6},
}

@article{mohanchandra_using_2013,
	title = {Using {Brain} {Waves} as {New} {Biometric} {Feature} for {Authenticating} a {Computer} {User} in {Real}-{Time}},
	abstract = {In this paper we propose an Electroencephalogram based Brain Computer Interface as a new modality for Person Authentication and develop a screen lock application that will lock and unlock the computer screen at the users will. The brain waves of the person, recorded in real time are used as password to unlock the screen. Data fusion from 14 sensors of the Emotiv headset is done to enhance the signal features. The power spectral density of the intermingle signals is computed. The channel spectral power in the frequency band of alpha, beta and gamma is used in the classification task. A two stage checking is done to authenticate the user. A proximity value of 0.78 and above is considered a good match. The percentage of accuracy in classification is found to be good. The essence of this work is that the authentication is done in real time based on the meditation task and no external stimulus is used.},
	language = {en},
	author = {Mohanchandra, Kusuma},
	year = {2013},
	pages = {9},
}

@book{soni_biometric_2016-1,
	title = {Biometric user authentication using brain waves},
	abstract = {Authentication has become an essential part of our everyday lives which is used at almost every place from banks to experimental labs, from car automation to home automation. This authentication is generally provided through systems like passwords, PIN codes, card readers. At some places biometrics like fingerprint and retina scans are used. All designed with one purpose; to confirm a person's identity. Brain wave based authentication is another addition to the wide range of authentication systems, which has many advantages over other authentication systems. With a standard password someone can watch or ‘shoulder-surf’ what others type, but no one ca n watch thoughts. Cards and keys can be lost, but the brain wave is always present. Differently abled persons can't use systems which uses fingerprints or retina scans but they can use system using brain-waves. This clears that using brain waves as biometric to provide authentication is very beneficial. A system is designed and implemented which allows user to set a pattern of brain waves which must be provided as an unlock pattern to get the access. This pattern can be any combination of eye blink, attention and various brain rhythms like Alpha, Beta, Theta and Delta. The system described in this paper provides two-level authentication. First level of which is brain waves. Once the correct pattern of brain signal is provide the system will ask for a pass key as a second level of authentication. This paper describes the design and implementation of the system.},
	author = {Soni, Yashraj and Somani, Sunil and Shete, V.},
	month = aug,
	year = {2016},
	doi = {10.1109/INVENTIVE.2016.7824888},
	note = {Pages: 6},
}
