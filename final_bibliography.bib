
@online{noauthor_sonic_nodate,
	title = {Sonic Soak Ultrasonic Cleaner - Multi-Purpose Ultrasonic Cleaning Machine for Laundry, Fruits, Cutlery, Jewelry, Watches \& Accessories},
	url = {https://sonicsoak.com/products/sonic-soak},
	urldate = {2021-01-28},
	file = {Sonic Soak Ultrasonic Cleaner - Multi-Purpose Ultrasonic Cleaning Machine for Laundry, Fruits, Cutlery, Jewelry, Watches & Accessories:C\:\\Users\\miche\\Zotero\\storage\\UEVHLDIV\\sonic-soak.html:text/html},
}

@online{noauthor_google_nodate,
	title = {Google Trends},
	url = {https://trends.google.com/trends/explore?date=today%205-y&q=%2Fm%2F08k_gq},
	abstract = {Esplora gli interessi di ricerca per Pulizia a ultrasuoni in base alla data, all'area geografica e alla diffusione su Google Trends},
	titleaddon = {Google Trends},
	urldate = {2021-01-28},
	langid = {italian},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\IHMGRNY2\\explore.html:text/html},
}

@online{noauthor_google_nodate-1,
	title = {Google Trends},
	url = {https://trends.google.com/trends/explore?q=ultrasonic%20cleaning%20tank},
	abstract = {Esplora gli interessi di ricerca per ultrasonic cleaning tank in base alla data, all'area geografica e alla diffusione su Google Trends},
	titleaddon = {Google Trends},
	urldate = {2021-01-28},
	langid = {italian},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\5RUFYAZN\\explore.html:text/html},
}

@online{noauthor_google_nodate-2,
	title = {Google Trends},
	url = {https://trends.google.com/trends/explore?q=ultrasonic%20cleaning%20tank},
	abstract = {Esplora gli interessi di ricerca per ultrasonic cleaning tank in base alla data, all'area geografica e alla diffusione su Google Trends},
	titleaddon = {Google Trends},
	urldate = {2021-01-28},
	langid = {italian},
}

@online{noauthor_sudden_nodate,
	title = {The sudden urgency of online academic conferences},
	url = {https://www.universityaffairs.ca/features/feature-article/the-sudden-urgency-of-online-academic-conferences/},
	abstract = {Traditional in-person conferences have been criticized for a variety of reasons, but the current {COVID}-19 pandemic puts them in a whole new light.},
	titleaddon = {University Affairs},
	urldate = {2021-01-28},
	langid = {american},
}

@online{noauthor_about_nodate,
	title = {About {ECIU}},
	url = {https://www.eciu.org/about-eciu#members},
	abstract = {‍We are {ECIU}, the European Consortium of Innovative Universities, a network of 13 universities united since 1997 by a common profile of shared beliefs, interests, and mutual trust.},
	urldate = {2021-01-28},
	langid = {english},
}

@online{noauthor_how_2020,
	title = {How the pandemic has impacted research at a global level},
	url = {https://www.medicalnewstoday.com/articles/shifting-goalposts-research-in-the-time-of-the-coronavirus},
	abstract = {Since the start of the {COVID}-19 pandemic, all eyes have been on coronavirus research. But how has the pandemic impacted the research community at large?},
	urldate = {2021-01-28},
	date = {2020-07-06},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\V6GGUSI8\\shifting-goalposts-research-in-the-time-of-the-coronavirus.html:text/html},
}

@article{noauthor_europes_2020,
	title = {Europe’s Second Lockdown Wave Risks Double-Dip Recessions},
	url = {https://www.bloomberg.com/news/articles/2020-11-05/covid-pandemic-europe-s-second-lockdown-wave-risks-double-dip-recessions},
	abstract = {Governments are trying to limit the pain to a few industries, but the costs may still be high.},
	journaltitle = {Bloomberg.com},
	urldate = {2021-01-28},
	date = {2020-11-05},
	langid = {english},
	keywords = {Beer, business, businessweek, Coronavirus, Europe, France, Germany, Government, Italy, markets, Milan, Paris, politics, Rome},
}

@online{noauthor_world_nodate,
	title = {World Economic Outlook Databases},
	url = {https://www.imf.org/en/Publications/SPROLLs/world-economic-outlook-databases},
	titleaddon = {{IMF}},
	urldate = {2021-01-28},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\B7Q5YEVB\\world-economic-outlook-databases.html:text/html},
}

@article{staff_ecb_2020,
	title = {{ECB} to monitor euro appreciation 'very carefully': Lagarde},
	url = {https://www.reuters.com/article/ecb-policy-currency-idINKBN28K1Y6},
	shorttitle = {{ECB} to monitor euro appreciation 'very carefully'},
	abstract = {The European Central Bank will keep a close eye on the strength of the euro as it tends to push down prices and thereby inflation in the single-currency bloc, {ECB} President Christine Lagarde said on Thursday.},
	journaltitle = {Reuters},
	author = {Staff, Reuters},
	urldate = {2021-01-28},
	date = {2020-12-10},
	langid = {english},
	keywords = {Europe, Asset-Backed Securities, Banks ({TRBC} level 4), Central Banks / Central Bank Events, Currencies / Foreign Exchange Markets, {CURRENCY}, Debt / Fixed Income Markets, {ECB}, Economic News (3rd Party), Euro Zone as a Whole, European Central Bank, European Union, Major News, Monetary / Fiscal Policy / Policy Makers, Money Markets, National Government Debt, {POLICY}, Reuters Top News},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\NUT4XZKZ\\ecb-policy-currency-idINKBN28K1Y6.html:text/html},
}

@online{pettinger_low_nodate,
	title = {Low Inflation},
	url = {https://www.economicshelp.org/macroeconomics/low_inflation/},
	abstract = {Why economists advise targeting low inflation. Benefits of low inflation. How to achieve low inflation. Can inflation become too low? Graphs and examples of low inflation periods.},
	titleaddon = {Economics Help},
	author = {Pettinger, Tejvan},
	urldate = {2021-01-28},
	langid = {british},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\CGJLZ2PC\\low_inflation.html:text/html},
}

@online{noauthor_netherlands_nodate,
	title = {Netherlands Inflation Rate {\textbar} 1971-2020 Data {\textbar} 2021-2023 Forecast {\textbar} Calendar},
	url = {https://tradingeconomics.com/netherlands/inflation-cpi},
	abstract = {The Netherlands' annual inflation rate increased to 1.0 percent in December 2020 from 0.8 percent in the previous month, due to a faster rise in prices of both recreation \& culture (1.9\%  vs 1.3\%) and furnishings \& household equipment (2.3\% vs 1.4\%), while housing inflation was steady (at 0.8\%) and transport prices fell less (-2.3\% vs -3.2\%). Meantime, food and non-alcoholic beverages inflation eased to a 26-month low of 0.6 percent in December from 0.8 percent in November. By contrast, clothing and footwear prices fell 2 percent, after a flat reading in the prior month. Considering 2020 full year, inflation rate averaged 1.3 percent, down from 2.6 percent in 2019. The annual core inflation, which excludes energy, food, alcohol, and tobacco increased to 1.7 percent in December from a four-month low of 1.5 percent in November. On a monthly basis, consumer prices were up 0.2 percent, after a 0.8 percent fall in the prior month. Inflation Rate in Netherlands averaged 3.17 percent from 1971 until 2020, reaching an all time high of 11.19 percent in November of 1974 and a record low of -1.30 percent in February of 1987. This page provides - Netherlands Inflation Rate - actual values, historical data, forecast, chart, statistics, economic calendar and news.},
	urldate = {2021-01-28},
}

@online{noauthor_corporate_nodate,
	title = {Corporate income tax (vpb)},
	url = {https://business.gov.nl/regulation/corporate-income-tax/},
	abstract = {Private or public limited companies in the Netherlands (bv or nv) must complete a corporate income tax return (vpb). Read more here.},
	titleaddon = {business.gov.nl},
	urldate = {2021-01-28},
	langid = {english},
}

@online{noauthor_how_2019,
	title = {How Brexit will affect shipping goods between the {EU} and the {UK}},
	url = {https://www.interloggroup.com/en/how-brexit-will-affect-shipping-goods-between-the-and-the-uk/},
	abstract = {If there’s one thing to expect from Brexit, it’s the unexpected. The {UK} was supposed to leave the {EU} on March 29, 2019. It did not happen. As of now, the new deadline is April 12. But no one knows for sure what the terms of the separation will be. Will it be the deal … Continue reading "How Brexit will affect shipping goods between the {EU} and the {UK}"},
	titleaddon = {Interlog Services},
	urldate = {2021-01-28},
	date = {2019-04-09},
	langid = {american},
	note = {Section: Group},
}

@article{baumeister_customer_2002,
	title = {Customer Relationship Management for {SMEs}},
	abstract = {Customer Relationship Management ({CRM}) is getting more and more a key strategy for companies big and small. Customer care strategy and {CRM} software go hand in hand. In particular {SME}'s need a {CRM} software that easily adapts to their customer care needs while still being low cost. In this paper I discuss the benefits of {CRM} for {SME}'s and their special requirements wrt. {CRM} software. Further, I intro-duce the {IST}-project {CARUSO} whose objective is to provide {SME}'s with a software framework to implement low cost, customized {CRM} applications. This paper presents the rational behind the {CARUSO} project, the architecture of the framework, and the software development process used to build the framework.},
	author = {Baumeister, Hubert},
	date = {2002-01-01},
}

@online{noauthor_review_nodate,
	title = {A review of customer relationship management system benefits and implementation in small and medium enterprises {\textbar} Proceedings of the 12th {WSEAS} international conference on Mathematics and computers in biology, business and acoustics},
	url = {https://dl.acm.org/doi/abs/10.5555/1991147.1991193},
	urldate = {2021-01-28},
}

@online{noauthor_pdf_nodate,
	title = {({PDF}) {IMPACTS} {OF} {MARKETING} {AUTOMATION} {ON} {BUSINESS} {PERFORMANCE}},
	url = {https://www.researchgate.net/publication/342184130_IMPACTS_OF_MARKETING_AUTOMATION_ON_BUSINESS_PERFORMANCE},
	urldate = {2021-01-28},
	file = {(PDF) IMPACTS OF MARKETING AUTOMATION ON BUSINESS PERFORMANCE:C\:\\Users\\miche\\Zotero\\storage\\BBA2ZQUJ\\342184130_IMPACTS_OF_MARKETING_AUTOMATION_ON_BUSINESS_PERFORMANCE.html:text/html},
}

@online{noauthor_smbs_2017,
	title = {{SMBs} Plan to Adopt Marketing Automation Despite Cost \& Familiarity Issues},
	url = {https://www.marketingcharts.com/customer-centric/analytics-automated-and-martech-81650},
	abstract = {Three in 10 {SMBs} in the {US} (fewer than 1,000 employees) that have an email marketing solution in place also have marketing automation software, per results from an {ActiveCampaign} study [pdf]. The survey of email-using {SMBs} found that the bulk of those without a current automation solution plan to adopt one in the next couple… Read More »},
	titleaddon = {Marketing Charts},
	urldate = {2021-01-28},
	date = {2017-12-14},
	langid = {american},
	note = {Section: Analytics, Automated \& {MarTech}},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\BDP8JRRU\\analytics-automated-and-martech-81650.html:text/html},
}

@article{heimbach_marketing_2015,
	title = {Marketing Automation},
	volume = {57},
	issn = {2363-7005, 1867-0202},
	url = {http://link.springer.com/10.1007/s12599-015-0370-8},
	doi = {10.1007/s12599-015-0370-8},
	pages = {129--133},
	number = {2},
	journaltitle = {Business \& Information Systems Engineering},
	shortjournal = {Bus Inf Syst Eng},
	author = {Heimbach, Irina and Kostyra, Daniel S. and Hinz, Oliver},
	urldate = {2021-01-28},
	date = {2015-04},
	langid = {english},
	file = {Marketing Automation, Business & Information Systems Engineering | 10.1007/s12599-015-0370-8 | DeepDyve:C\:\\Users\\miche\\Zotero\\storage\\YSS24HZ5\\marketing-automation-oUz11dTPLB.html:text/html},
}

@article{oliveira_firms_2012,
	title = {Firms Patterns of e-Business Adoption: Evidence for the European Union27},
	volume = {13},
	shorttitle = {Firms Patterns of e-Business Adoption},
	abstract = {Research has shown that firms using e-business achieve considerable returns through efficiency improvements, inventory reduction, sales increase, customer relationship enhancement, new market penetration, and ultimately financial returns. However, there is little systematic research in terms of e-business adoption patterns in firms across countries and industries. This study addresses the research gap by analysing the pattern of e-business adoption by firms across European Union ({EU}) members. For that, we used the survey data from 6,964 businesses in {EU}27 members (excluding Malta and Bulgaria). The choice of variables that we will use in our study is based on the technology-organization-environment ({TOE}) theory. In the {TOE} framework, three aspects may possibly influence e-business adoption: technological context (technology readiness and technology integration); organizational context (firm size, expected benefits and barriers of e-business and improved products or services or internal processes); and environmental context (internet penetration and competitive pressure). We performed a factor analysis ({FA}) of multi-item indicators to evaluate the validity and to reduce the number of variables. We used the principal component technique with varimax rotation to extract four eigenvalue, which were all greater than one. The first four factors explain 72.4 \% of variance contained in the data. The four factors found are: expected benefits and obstacles of e-business, internet penetration, technology readiness and technology integration. These factors are in accordance with the literature review. Afterwards, we performed},
	author = {Oliveira, Tiago and Martins, Maria Rosario},
	date = {2012-02-21},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\EYA7HYFL\\Oliveira e Martins - 2012 - Firms Patterns of e-Business Adoption Evidence fo.pdf:application/pdf},
}

@article{buyukozkan_digital_2018,
	title = {Digital Supply Chain: Literature review and a proposed framework for future research},
	volume = {97},
	issn = {0166-3615},
	url = {http://www.sciencedirect.com/science/article/pii/S0166361517304487},
	doi = {10.1016/j.compind.2018.02.010},
	shorttitle = {Digital Supply Chain},
	abstract = {Suppliers, partners, companies and dealers in supply chains do use, generate and share information with others. These associations lead to a multitude of challenges and opportunities within the supply chains. A Digital Supply Chain ({DSC}) is a smart, value-driven, efficient process to generate new forms of revenue and business value for organizations and to leverage new approaches with novel technological and analytical methods {DSC} is not about whether goods and services are digital or physical, it is about the way how supply chain processes are managed with a wide variety of innovative technologies, e.g. unmanned aerial vehicles, cloud computing, and internet of things, among others. Recent literature highlights the importance of {DSC} and many industrial researchers discuss its applications. This article reviews the state-of-the-art of existing {DSC} literature in detail from both academic and industrial points of view. It identifies key limitations and prospects in {DSC}, summarizes prior research and identifies knowledge gaps by providing advantages, weaknesses and limitations of individual methods The article also aims at providing a development framework as a roadmap for future research and practice.},
	pages = {157--177},
	journaltitle = {Computers in Industry},
	shortjournal = {Computers in Industry},
	author = {Büyüközkan, Gülçin and Göçer, Fethullah},
	urldate = {2021-01-28},
	date = {2018-05-01},
	langid = {english},
	keywords = {Digital Supply Chain ({DSC}), {DSC} framework, Literature review, Technology enablers},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\537U6W2J\\S0166361517304487.html:text/html;ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\F5S5FEAM\\Büyüközkan e Göçer - 2018 - Digital Supply Chain Literature review and a prop.pdf:application/pdf},
}

@book{hines_supply_2004,
	title = {Supply Chain Strategies: Customer Driven and Customer Focused},
	isbn = {978-0-08-048125-8},
	shorttitle = {Supply Chain Strategies},
	abstract = {Supply Chain Strategies: Customer Driven and Customer Focused highlights the main challenges facing organizations wanting to select, design and implement successful supply chain strategies in an increasingly global and competitive environment. The text features discussion questions at the end of each chapter to promote learning, and numerous industry examples to ilustrate key concepts within chapters. Each chapter discusses the issues in relation to previous literature, contemporary practices and the lesson to be learned from different industries where successful management of supply chains has improved organizational and industry level profitability. The text includes a number of industry examples, thereby giving a wide-ranging approach to the topic.},
	author = {Hines, Tony},
	date = {2004-01-01},
	doi = {10.4324/9780080481258},
}

@article{noauthor_marketing_nodate,
	title = {Marketing Effectiveness in the Digital Era},
	pages = {22},
	langid = {english},
	file = {Marketing Effectiveness in the Digital Era.pdf:C\:\\Users\\miche\\Zotero\\storage\\BXNTCK78\\Marketing Effectiveness in the Digital Era.pdf:application/pdf},
}

@online{heaton_how_2019,
	title = {How Often Should You Redesign Your Website?},
	url = {https://medium.com/swlh/how-often-should-you-redesign-your-website-15dd04ae7a2d},
	abstract = {Tips from a Former Designer and Marketing Strategist},
	titleaddon = {Medium},
	author = {Heaton, Tami},
	urldate = {2021-01-28},
	date = {2019-12-13},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\ZB4RNT3U\\how-often-should-you-redesign-your-website-15dd04ae7a2d.html:text/html},
}

@online{noauthor_website_nodate,
	title = {Website Update: Why It Is Important for Every Small Business},
	url = {https://www.exai.com/blog/website-update-small-business},
	urldate = {2021-01-28},
	file = {Website Update\: Why It Is Important for Every Small Business:C\:\\Users\\miche\\Zotero\\storage\\INI9SGIU\\website-update-small-business.html:text/html},
}

@online{noauthor_single-use_nodate,
	title = {Single-use plastics ban},
	url = {http://publications.europa.eu/resource/cellar/767969e4-e663-11e9-9c4e-01aa75ed71a1.0001.02/DOC_1},
	urldate = {2021-01-28},
}

@online{noauthor_emerson_nodate,
	title = {Emerson {\textbar} Emerson {NL}},
	url = {https://www.emerson.com/en-nl},
	abstract = {Helping address the world's most critical needs through our new core business platforms - Automation Solutions and Commercial \& Residential Solutions. Whatever the challenge, you can always Consider it Solved.},
	urldate = {2021-01-28},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\9KCR9C5B\\en-nl.html:text/html},
}

@online{noauthor_how_2017,
	title = {How to Run a Successful Email Marketing Campaign (Step by Step Guide)},
	url = {https://optinmonster.com/how-to-run-a-successful-email-marketing-campaign/},
	abstract = {How do you run a successful email marketing campaign? Here are 10 must-do steps to follow for email marketing campaign success.},
	titleaddon = {{OptinMonster}},
	urldate = {2021-01-28},
	date = {2017-07-10},
	langid = {american},
	note = {Section: Email Marketing},
}

@online{noauthor_effects_nodate,
	title = {Effects of Loyalty Programs on Value Perception, Program Loyalty, and Brand Loyalty - Youjae Yi, Hoseong Jeon, 2003},
	url = {https://journals.sagepub.com/doi/abs/10.1177/0092070303031003002},
	urldate = {2021-01-28},
	file = {Effects of Loyalty Programs on Value Perception, Program Loyalty, and Brand Loyalty - Youjae Yi, Hoseong Jeon, 2003:C\:\\Users\\miche\\Zotero\\storage\\2GV3YB2V\\0092070303031003002.html:text/html},
}

@article{tuskej_role_2013,
	title = {The role of consumer–brand identification in building brand relationships},
	volume = {66},
	issn = {0148-2963},
	url = {http://www.sciencedirect.com/science/article/pii/S014829631100258X},
	doi = {10.1016/j.jbusres.2011.07.022},
	series = {(1)Thought leadership in brand management(2)Health Marketing},
	abstract = {The purpose of this paper is to investigate relationships between congruity of consumer and brand values, brand identification, brand commitment, and word of mouth. The results show that congruity of consumer and brand values tends to have positive influence on consumers' identification. Consumers who identify with a brand tend to commit stronger to a brand and generate positive word of mouth. The results show that consumers' identification fully mediates the impact of value congruity on brand commitment. However, brand commitment does not mediate the impact of consumers' identification on generating positive word of mouth.},
	pages = {53--59},
	number = {1},
	journaltitle = {Journal of Business Research},
	shortjournal = {Journal of Business Research},
	author = {Tuškej, Urška and Golob, Urša and Podnar, Klement},
	urldate = {2021-01-28},
	date = {2013-01-01},
	langid = {english},
	keywords = {Brand, Commitment, Consumer, Identification, Value congruity, Word of mouth},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\VNBJHEGD\\S014829631100258X.html:text/html;ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\9W2UFIAT\\Tuškej et al. - 2013 - The role of consumer–brand identification in build.pdf:application/pdf},
}

@online{noauthor_developing_nodate,
	title = {Developing a Content Strategy},
	url = {https://contentmarketinginstitute.com/developing-a-strategy/},
	abstract = {Here are some resources to help you get started when developing a content strategy.},
	titleaddon = {Content Marketing Institute},
	urldate = {2021-01-28},
	langid = {american},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\AVDQ2GKY\\developing-a-strategy.html:text/html},
}

@online{noauthor_30_nodate,
	title = {30 branding stats and facts},
	url = {https://www.lucidpress.com/blog/25-branding-stats-facts},
	abstract = {A strong brand is the bread and butter of today's businesses. Need some data to inspire yourself or others? Check out these 25 awesome branding stats \& facts.},
	titleaddon = {Lucidpress Blog},
	urldate = {2021-01-28},
	langid = {american},
}

@online{noauthor_jewelry_nodate,
	title = {Jewelry Market Size, Share, Analysis {\textbar} Industry Report, 2019-2025},
	url = {https://www.grandviewresearch.com/industry-analysis/jewelry-market},
	abstract = {The global jewelry market size is expected to reach {USD} 480.5 billion by 2025, due to rising disposable income, increasing shift towards elegant and stylish products with a variety of designs such as rings and bracelets, and growing acceptance of jewelry among men},
	urldate = {2021-01-28},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\92QNXL5S\\jewelry-market.html:text/html},
}

@online{cycles_topic_nodate,
	title = {Topic: Jewelry market worldwide},
	url = {https://www.statista.com/topics/5163/jewelry-market-worldwide/},
	shorttitle = {Topic},
	abstract = {Discover all statistics and data on Jewelry market worldwide now on statista.com!},
	titleaddon = {Statista},
	author = {cycles, This text provides general information Statista assumes no liability for the information given being complete or correct Due to varying update and Text, Statistics Can Display More up-to-Date Data Than Referenced in the},
	urldate = {2021-01-28},
	langid = {english},
}

@online{noauthor_global_nodate,
	title = {The Global Art Market Reached \$67.4 Billion in 2018, up 6\% - Artsy},
	url = {https://www.artsy.net/article/artsy-editorial-global-art-market-reached-674-billion-2018-6},
	urldate = {2021-01-28},
}

@online{noauthor_biotechnology_nodate,
	title = {Biotechnology Market Size Worth \$727.1 Billion By 2025 {\textbar} {CAGR}: 7.4\%},
	url = {https://www.grandviewresearch.com/press-release/global-biotechnology-market},
	shorttitle = {Biotechnology Market Size Worth \$727.1 Billion By 2025 {\textbar} {CAGR}},
	abstract = {The global biotechnology market size is expected to reach {USD} 727.1 billion by 2025, at a {CAGR} of 7.4\% according to a new report by Grand View Research, Inc. The emergence of certain key themes in the market is expected to drive growth in this industry to a lucrative extent},
	urldate = {2021-01-28},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\6D32LINQ\\global-biotechnology-market.html:text/html},
}

@online{brandon_gaille_40_2019,
	title = {40 Biomedical Industry Statistics, Trends \& Analysis},
	url = {https://brandongaille.com/40-biomedical-industry-statistics-trends-analysis/},
	abstract = {The biomedical industry uses living organisms or biological systems to develop its products. Most of the items that fall under this umbrella belong to the biopharmaceutical drug segment of the industry. Europe and the United},
	titleaddon = {{BrandonGaille}.com},
	author = {Brandon Gaille},
	urldate = {2021-01-28},
	date = {2019-10-15},
	langid = {american},
	note = {Section: Statistics},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\6XCDW8FH\\40-biomedical-industry-statistics-trends-analysis.html:text/html},
}

@article{zillen_world_2000,
	title = {World dental demographics},
	volume = {50},
	issn = {0020-6539},
	doi = {10.1111/j.1875-595x.2000.tb00558.x},
	abstract = {{AIMS}: To collect basic data regarding dental workforce and dental education in all countries of the world and to make this data available on the {FDI}'s Website.
{METHOD}: A postal questionnaire survey.
{SOURCES} {OF} {INFORMATION}: Member Associations of the {FDI} and governmental agencies.
{RESULTS}: Responses were received from 73 countries with a reported total number of dentists of 703,947. A comparison between the figures now reported and the figures published in 1990 shows that the total number of dentists in these countries has increased by 27.8 per cent over the ten year period. No correlation was found between the population per dentist figures and the {GNP} of the countries. In the reporting countries, there were 550 dental schools. A comparison between the figures now reported and the figures published in 1990 shows that the total number of dental schools in these countries has increased by 42.6 per cent over the ten year period. The total number of dental hygienists was reported to be 181,336 and the total number of dental technicians in these countries was reported to be 252,004.},
	pages = {194--234},
	number = {4},
	journaltitle = {International Dental Journal},
	shortjournal = {Int Dent J},
	author = {Zillén, P. A. and Mindak, M.},
	date = {2000-08},
	pmid = {11042819},
	keywords = {Demography, Dental Auxiliaries, Dentists, Dentists, Women, Education, Dental, Female, Humans, Internet, Male, Specialties, Dental, Surveys and Questionnaires},
	file = {Full Text:C\:\\Users\\miche\\Zotero\\storage\\ANBWA8IJ\\Zillén e Mindak - 2000 - World dental demographics.pdf:application/pdf},
}

@article{frow_stakeholder_2011,
	title = {A stakeholder perspective of the value proposition concept},
	volume = {45},
	issn = {0309-0566},
	url = {https://doi.org/10.1108/03090561111095676},
	doi = {10.1108/03090561111095676},
	abstract = {Purpose – The value proposition concept and the stakeholder perspective have received relatively little attention within Service‐Dominant (S‐D) logic. This paper sets out to explore value propositions in the context of S‐D logic, within the multiple stakeholder domains that form part of a marketing system. Its purpose is to identify how use of the value proposition concept, in this broader context, provides new insight into value creation within a value network. Design/methodology/approach – This paper explores the development of value propositions in key stakeholder market domains. A five‐step process is developed for identifying key stakeholders and co‐creating value propositions for them within a marketing system. Findings – Value propositions have a key role in co‐creation of value between stakeholders. The development of value propositions in multiple stakeholder domains can provide an important mechanism for aligning value within a marketing system. Practical implications – Stakeholder value propositions provide enhanced opportunities for value co‐creation and can assist managers in aligning value and stabilizing relationships within an organization's value network. Originality/value – This paper considers a broader view of value through creation of value propositions for key stakeholders. An iterative framework is proposed that couples the stakeholder concept and value co‐creation.},
	pages = {223--240},
	number = {1},
	journaltitle = {European Journal of Marketing},
	author = {Frow, Pennie and Payne, Adrian},
	urldate = {2021-01-28},
	date = {2011-01-01},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Customers, Stakeholder analysis},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\QL2I346I\\html.html:text/html},
}

@article{payne_customer_2017,
	title = {The customer value proposition: evolution, development, and application in marketing},
	volume = {45},
	issn = {1552-7824},
	url = {https://doi.org/10.1007/s11747-017-0523-z},
	doi = {10.1007/s11747-017-0523-z},
	shorttitle = {The customer value proposition},
	abstract = {The customer value proposition ({CVP}) has a critical role in communicating how a company aims to provide value to customers. Managers and scholars increasingly use {CVP} terminology, yet the concept remains poorly understood and implemented; relatively little research on this topic has been published, considering the vast breadth of investigations of the value concept. In response, this article offers a comprehensive review of fragmented {CVP} literature, highlighting the lack of a strong theoretical foundation; distinguishes {CVPs} from related concepts; proposes a conceptual model of the {CVP} that includes antecedents, consequences, and moderators, together with several research propositions; illustrates the application of the {CVP} concept to four contrasting companies; and advances a compelling agenda for research.},
	pages = {467--489},
	number = {4},
	journaltitle = {Journal of the Academy of Marketing Science},
	shortjournal = {J. of the Acad. Mark. Sci.},
	author = {Payne, Adrian and Frow, Pennie and Eggert, Andreas},
	urldate = {2021-01-28},
	date = {2017-07-01},
	langid = {english},
}

@book{wormald_role_2013,
	title = {The role of value proposition in new product innovation - a development for design education},
	abstract = {The use of the construct 'value proposition' is becoming prominent in the world of design, as business and marketing intersect more with the processes of design. Value proposition can be a powerful way of capturing, or modelling, ideas for products, rather than the actual realisation of those products. The paper makes a case that the creation and articulation of value proposition is a necessary design ability that should concern design educators, in the same way that other modelling activities are. This is especially so within a discipline such as industrial design where the application of design relates strongly to commercial new product development. The teaching and learning of early, front end strategic innovation to design students is discussed. The building of an explicit value proposition 'model' is a key element of this work. The linkage between value proposition and front end user, global and brand research strands is presented. The paper draws on primary and secondary research activities in the areas of design education and professional design which relate to the practices of strategic innovation. Forms, models, and usage of value proposition are identified from literature relating to innovation, business models, and new product development. The paper demonstrates how value proposition can be a universal form of 'upstream' modelling for new product ideas prior to 'downstream' form-giving and technological embodiment.},
	author = {Wormald, Paul},
	date = {2013-01-01},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\P43SHQ98\\Wormald - 2013 - The role of value proposition in new product innov.pdf:application/pdf},
}

@article{ang_managing_2010,
	title = {Managing For Successful Customer Acquisition: An Exploration},
	volume = {22},
	doi = {10.1362/026725706776861217},
	shorttitle = {Managing For Successful Customer Acquisition},
	abstract = {Given all the recent attention dedicated by academics, consultants and practitioners to customer retention, customer acquisition has become a secondary concern. Yet, customer acquisition is of major importance and demands attention as the first stage of the customer life-cycle. Our research shows that companies are not particularly skilled at managing the customer acquisition process. For example, less than half have a dedicated customer acquisition plan. Only one variable distinguishes companies that excel at customer acquisition – they have a budget dedicated to customer acquisition activities. Other variables examined - the presence of an executive responsible for customer acquisition, an understanding of the economics of customer acquisition, and the deployment of {CRM} technologies to support customer acquisition - are not associated with excellence at customer acquisition.},
	pages = {295--317},
	journaltitle = {Journal of Marketing Management},
	shortjournal = {Journal of Marketing Management},
	author = {Ang, Lawrence and Buttle, Francis},
	date = {2010-02-01},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\WZ6WWQ7G\\Ang e Buttle - 2010 - Managing For Successful Customer Acquisition An E.pdf:application/pdf},
}

@online{noauthor_ins_nodate,
	title = {The Ins and Outs of Customer Acquisition for Small Businesses},
	url = {https://www.salesforce.com/solutions/small-business-solutions/resources/small-business-customer-acquisition/},
	abstract = {Developing a strong customer acquisition strategy requires skilled organization and depends on tracking and assessing lots of different information and data points. Invest in a robust software solution that can help you through every step in the process.},
	titleaddon = {Salesforce.com},
	urldate = {2021-01-28},
	langid = {english},
}

@online{noauthor_importance_nodate,
	title = {The importance of competitor analysis for business growth},
	url = {https://www.lexisclick.com/blog/why-competitor-analysis-is-important-for-business-growth},
	urldate = {2021-01-28},
}

@online{noauthor_benefits_2018,
	title = {The Benefits of Benchmark Analysis},
	url = {https://www.bbgbroker.com/benchmark-analysis-benefits/},
	abstract = {Benchmark analysis is comparing your business policies, programs, etc. with similar businesses. Learn some of the benefits of benchmark analysis.},
	titleaddon = {Business Benefits Group},
	urldate = {2021-01-28},
	date = {2018-07-13},
	langid = {american},
}

@online{noauthor_home_nodate,
	title = {Home},
	url = {http://www.bubclean.nl/home/},
	urldate = {2021-01-28},
	langid = {american},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\P82XZHK6\\home.html:text/html},
}

@online{constantinides_how_2020,
	title = {How Many Tech Startups Are Created Each Year?},
	url = {https://netshopisp.medium.com/how-many-tech-startups-are-created-each-year-27539d0a4c48},
	abstract = {Every year, many entrepreneurs and business owners establish new businesses. Most of them have high hopes for their business future and are pretty excited about it. However, for small businesses…},
	titleaddon = {Medium},
	author = {Constantinides, Mike},
	urldate = {2021-01-28},
	date = {2020-03-25},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\2UCRYHAK\\how-many-tech-startups-are-created-each-year-27539d0a4c48.html:text/html},
}

@online{noauthor_startup_nodate,
	title = {Startup Genome},
	url = {https://startupgenome.com/article/state-of-the-global-startup-economy},
	urldate = {2021-01-28},
}

@online{noauthor_ultrasonic_nodate,
	title = {Ultrasonic Cleaning Market Size, Share, and Industry Analysis and Market Forecast to 2024 {\textbar} {MarketsandMarkets}™},
	url = {https://www.marketsandmarkets.com/Market-Reports/ultrasonic-cleaning-market-79998083.html?gclid=CjwKCAiA57D_BRAZEiwAZcfCxbqV6L7COjO8j5UdIfAd0kHx6RMY3TM9J-Y_H17Z3PsqBps3RxrCkhoCFVsQAvD_BwE},
	urldate = {2021-01-28},
}

@article{mason_ultrasonic_2016,
	title = {Ultrasonic cleaning: An historical perspective},
	volume = {29},
	issn = {1350-4177},
	url = {http://www.sciencedirect.com/science/article/pii/S1350417715001339},
	doi = {10.1016/j.ultsonch.2015.05.004},
	shorttitle = {Ultrasonic cleaning},
	abstract = {The development of ultrasonic cleaning dates from the middle of the 20th century and has become a method of choice for a range of surface cleaning operations. The reasons why this has happened and the methods of assessing the efficiency of ultrasonic cleaning baths are reviewed.},
	pages = {519--523},
	journaltitle = {Ultrasonics Sonochemistry},
	shortjournal = {Ultrasonics Sonochemistry},
	author = {Mason, Timothy J.},
	urldate = {2021-01-28},
	date = {2016-03-01},
	langid = {english},
	keywords = {Cleaning, History, Ultrasound},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\X2WX9KLK\\Mason - 2016 - Ultrasonic cleaning An historical perspective.pdf:application/pdf},
}

@online{noauthor_ultrasonic_nodate-1,
	title = {Ultrasonic Cleaning - an overview {\textbar} {ScienceDirect} Topics},
	url = {https://www.sciencedirect.com/topics/chemistry/ultrasonic-cleaning},
	urldate = {2021-01-28},
	file = {Ultrasonic Cleaning - an overview | ScienceDirect Topics:C\:\\Users\\miche\\Zotero\\storage\\AUYQRE4S\\ultrasonic-cleaning.html:text/html},
}

@article{dikker_crowdsourcing_2021,
	title = {Crowdsourcing neuroscience: Inter-brain coupling during face-to-face interactions outside the laboratory},
	volume = {227},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811920309216},
	doi = {10.1016/j.neuroimage.2020.117436},
	shorttitle = {Crowdsourcing neuroscience},
	abstract = {When we feel connected or engaged during social behavior, are our brains in fact “in sync” in a formal, quantifiable sense? Most studies addressing this question use highly controlled tasks with homogenous subject pools. In an effort to take a more naturalistic approach, we collaborated with art institutions to crowdsource neuroscience data: Over the course of 5 years, we collected electroencephalogram ({EEG}) data from thousands of museum and festival visitors who volunteered to engage in a 10-min face-to-face interaction. Pairs of participants with various levels of familiarity sat inside the Mutual Wave Machine—an artistic neurofeedback installation that translates real-time correlations of each pair's {EEG} activity into light patterns. Because such inter-participant {EEG} correlations are prone to noise contamination, in subsequent offline analyses we computed inter-brain coupling using Imaginary Coherence and Projected Power Correlations, two synchrony metrics that are largely immune to instantaneous, noise-driven correlations. When applying these methods to two subsets of recorded data with the most consistent protocols, we found that pairs’ trait empathy, social closeness, engagement, and social behavior (joint action and eye contact) consistently predicted the extent to which their brain activity became synchronized, most prominently in low alpha ({\textasciitilde}7–10 Hz) and beta ({\textasciitilde}20–22 Hz) oscillations. These findings support an account where shared engagement and joint action drive coupled neural activity and behavior during dynamic, naturalistic social interactions. To our knowledge, this work constitutes a first demonstration that an interdisciplinary, real-world, crowdsourcing neuroscience approach may provide a promising method to collect large, rich datasets pertaining to real-life face-to-face interactions. Additionally, it is a demonstration of how the general public can participate and engage in the scientific process outside of the laboratory. Institutions such as museums, galleries, or any other organization where the public actively engages out of self-motivation, can help facilitate this type of citizen science research, and support the collection of large datasets under scientifically controlled experimental conditions. To further enhance the public interest for the out-of-the-lab experimental approach, the data and results of this study are disseminated through a website tailored to the general public (wp.nyu.edu/mutualwavemachine).},
	pages = {117436},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Dikker, Suzanne and Michalareas, Georgios and Oostrik, Matthias and Serafimaki, Amalia and Kahraman, Hasibe Melda and Struiksma, Marijn E. and Poeppel, David},
	urldate = {2021-01-27},
	date = {2021-02-15},
	langid = {english},
	keywords = {Brain-Computer-Interface Technology, Brain-to-brain synchrony, Hyperscanning, Inter-brain coupling, Neurofeedback, Oscillations, Real-world neuroscience},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\UHXDLPNT\\S1053811920309216.html:text/html;ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\ECHGMWEI\\Dikker et al. - 2021 - Crowdsourcing neuroscience Inter-brain coupling d.pdf:application/pdf},
}

@article{davis_beyond_1977,
	title = {Beyond Boredom and Anxiety: The Experience of Play in Work and Games.},
	volume = {6},
	issn = {00943061},
	url = {http://www.jstor.org/stable/2065805?origin=crossref},
	doi = {10.2307/2065805},
	shorttitle = {Beyond Boredom and Anxiety},
	pages = {197},
	number = {2},
	journaltitle = {Contemporary Sociology},
	shortjournal = {Contemporary Sociology},
	author = {Davis, Murray S. and Csikszentmihalyi, Mihaly},
	urldate = {2021-01-26},
	date = {1977-03},
	file = {Davis e Csikszentmihalyi - 1977 - Beyond Boredom and Anxiety The Experience of Play.pdf:C\:\\Users\\miche\\Zotero\\storage\\SQKTNUC7\\Davis e Csikszentmihalyi - 1977 - Beyond Boredom and Anxiety The Experience of Play.pdf:application/pdf},
}

@book{said_measuring_2005,
	title = {Measuring The State Of Flow In Playing Online Games},
	abstract = {The literature on gaming suggests that people may experience the state of flow when playing online games. The main objective of this study is to develop a measurement of a gamer's reported state of Flow using data gathered from an online survey of 218 gamers. The final Flow construct had four factors that fit the data. The factors were " Skill " , " Challenge " , " Involvement " and " Time ". This study found that all factors were best represented as first-order factors for identifying the flow construct. A test of the final model provides evidence of convergent, discriminant and predictive validities of the Flow construct. The implications of these findings are discussed.},
	author = {Said, Laila and Mizerski, Dick and Murphy, Jamie},
	date = {2005-12-05},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\ZVQNT72F\\Said et al. - 2005 - Measuring The State Of Flow In Playing Online Game.pdf:application/pdf},
}

@article{habe_flow_2019,
	title = {Flow and Satisfaction With Life in Elite Musicians and Top Athletes},
	volume = {10},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00698/full},
	doi = {10.3389/fpsyg.2019.00698},
	abstract = {Although flow has been studied extensively in music and sport, there is a lack of research comparing these two domains. With the aim of filling this gap, élite musicians and top athletes in Slovenia were contrasted in the current study. Differences for flow and satisfaction with life between élite musicians and top athletes were explored. Individual versus group performance setting and gender differences were considered. 452 participants; 114 élite Slovenian musicians (mean age 23.46 years) and 338 top Slovenian athletes (mean age 22.40 years) answered questions about flow and satisfaction with life measures. The results show differences between élite musicians and top athletes in four flow dimensions: transformation of time and autotelic experience were higher in musicians while clear goals and unambiguous feedback were higher in athletes. However differences in global flow were not confirmed. Élite musicians and top athletes experienced flow more often in group than in individual performance settings and surprisingly it was experienced more in male than in female top performers. Satisfaction with life has a positive correlation with all nine dimensions of flow, but only challenge-skill balance was a significant predictor for satisfaction with life.},
	journaltitle = {Frontiers in Psychology},
	shortjournal = {Front. Psychol.},
	author = {Habe, Katarina and Biasutti, Michele and Kajtna, Tanja},
	urldate = {2021-01-26},
	date = {2019},
	note = {Publisher: Frontiers},
	keywords = {élite musicians, expert performance, Flow, satisfaction with life, Top athletes},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\XKUBGEXY\\Habe et al. - 2019 - Flow and Satisfaction With Life in Elite Musicians.pdf:application/pdf},
}

@article{zeng_theoretical_2012,
	title = {A Theoretical Model of Design Creativity: Nonlinear Design Dynamics and Mental Stress-Creativity Relation},
	volume = {16},
	doi = {10.3233/jid-2012-0007},
	shorttitle = {A Theoretical Model of Design Creativity},
	abstract = {Creativity is an important topic in design research. Attempts have been made to develop methods and tools that can help designers become more creative. Yet how and why creativity occurs is still unknown to researchers. In this paper, we propose a theoretical model for creative design. This theoretical model builds on two postulates: 1 design reasoning follows a nonlinear dynamics, which may become chaotic; and 2 there is an inverse U shaped relationship between designer's mental stress and design creativity. In the first postulate, the nonlinear dynamics assumes the form of design governing equation and can be solved by Environment Based Design {EBD}. The first postulate implies that design reasoning is sensitive to initial conditions, which are defined by the combination of design problem, design solutions, design knowledge, and other design related information. Since the major components in initial conditions may evolve simultaneously and are subject to continuous change during the design process, the design process is highly unpredictable. Some of the unpredictable solutions, which could be of high quality and useful, can be deemed creative. From this first postulate, three paths to creative design are derived, which specify how the initial conditions can be changed. The second postulate states that design creativity occurs when a designer is under a medium mental stress. Mental stresses are positively related to the workload associated with a design problem and negatively related to the designer's mental capacity. The workload is related to the complexity of the design problem and the amount of work in the design process whereas the mental capacity is related to the knowledge and skills required by the design process and to the designer's affect when dealing with the stresses arising from uncertainties and unpredictability of the design dynamics. To show how this theoretical model can be used to study design phenomena, an interpretation of the roles of sketching in design is presented.},
	pages = {65--88},
	journaltitle = {Journal of Integrated Design and Process Science},
	shortjournal = {Journal of Integrated Design and Process Science},
	author = {Zeng, Yong},
	date = {2012-09-01},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\G4J5BCH3\\Zeng - 2012 - A Theoretical Model of Design Creativity Nonlinea.pdf:application/pdf},
}

@article{liao_factors_2015,
	title = {Factors Affecting Students' Continued Usage Intention Toward Business Simulation Games: An Empirical Study},
	volume = {53},
	doi = {10.1177/0735633115598751},
	shorttitle = {Factors Affecting Students' Continued Usage Intention Toward Business Simulation Games},
	abstract = {While the impact and value of simulation games have been investigated in the context of business and management education, few studies have investigated why students are willing to reuse the games or not. The main purpose of this study is to explore the determinants of students’ continued usage intention for business simulation games in a higher education context based on the expectation-confirmation theory, flow theory, and motivation theory. Data collected from 381 valid respondents were used to test the research model using the partial least squares approach. The results of this study can provide several important theoretical and practical implications for educational use of business simulation games. The results indicate that continuance usage intention is influenced by learning satisfaction, which is in turn affected by perceived learning performance, learning confirmation, and learning expectation, and that learning confirmation is affected by learning expectation through the mediation of perceived learning performance. Additionally, perceived playfulness affects perceived learning performance while learning motivation influences learning expectation.},
	journaltitle = {Journal of Educational Computing Research},
	shortjournal = {Journal of Educational Computing Research},
	author = {Liao, Yi-Wen and Huang, Yueh-Min and Wang, Yi-Shun},
	date = {2015-08-13},
}

@article{eisenberger_flow_2005,
	title = {Flow experiences at work: for high need achievers alone?},
	volume = {26},
	rights = {Copyright © 2005 John Wiley \& Sons, Ltd.},
	issn = {1099-1379},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/job.337},
	doi = {https://doi.org/10.1002/job.337},
	shorttitle = {Flow experiences at work},
	abstract = {Applying Csikszentmihalyi's (1990) flow theory of optimal experience to the workplace, two studies examined the relationships of employees' perceived skill and challenge at work and need for achievement with their positive mood, intrinsic task interest, and extra-role performance. Among achievement-oriented employees only, high skill and challenge was associated with greater positive mood, task interest, and performance than other skill/challenge combinations. Additionally, positive mood mediated the interactive relationship of skill/challenge and need for achievement with performance. Copyright © 2005 John Wiley \& Sons, Ltd.},
	pages = {755--775},
	number = {7},
	journaltitle = {Journal of Organizational Behavior},
	author = {Eisenberger, Robert and Jones, Jason R. and Stinglhamber, Florence and Shanock, Linda and Randall, Amanda T.},
	urldate = {2021-01-26},
	date = {2005},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/job.337},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\KTKQINJC\\job.html:text/html},
}

@article{riemer_flow_2000,
	title = {Flow in sports: The keys to optimal experiences and performances},
	volume = {17},
	shorttitle = {Flow in sports},
	pages = {206--207},
	journaltitle = {Sociol. Sport J.},
	author = {Riemer, B.A.},
	date = {2000},
	file = {SCOPUS Snapshot:C\:\\Users\\miche\\Zotero\\storage\\L57I5KKF\\display.html:text/html},
}

@incollection{moneta_measurement_2012,
	title = {On the measurement and conceptualization of flow.},
	isbn = {978-3-030-53467-7},
	abstract = {This chapter introduces in chronological order the three main measurement methods—the Flow Questionnaire, the Experience Sampling Method, and the standardized scales of the componential approach—that researchers developed and used in conducting research on the flow state. Each measurement method and underlying conceptualization is explained, and its strengths and limitations are then discussed in relation to the other measurement methods and associated conceptualizations. The analysis reveals that, although the concept of flow remained stable since its inception, the models of flow that researchers developed in conjunction with the measurement methods changed substantially over time. Moreover, the findings obtained by applying the various measurement methods led to corroborations and disconfirmations of the underlying models, and hence provided indications on how to interpret and possibly modify flow theory. The chapter then analyzes the emerging process approach, which conceptualizes and measures flow as a dynamic path rather than an object, and highlights its potential for integrating flow and creativity within the same conceptual framework. The final section outlines new directions for developing more valid and useful measurement methods that can help to advance the understanding of flow, its antecedents, and its consequences.},
	pages = {23--50},
	author = {Moneta, Giovanni},
	date = {2012-01-01},
	doi = {10.1007/978-3-030-53468-4_2},
}

@article{vourvopoulos_efficacy_2019,
	title = {Efficacy and Brain Imaging Correlates of an Immersive Motor Imagery {BCI}-Driven {VR} System for Upper Limb Motor Rehabilitation: A Clinical Case Report},
	volume = {13},
	issn = {1662-5161},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2019.00244/full},
	doi = {10.3389/fnhum.2019.00244},
	shorttitle = {Efficacy and Brain Imaging Correlates of an Immersive Motor Imagery {BCI}-Driven {VR} System for Upper Limb Motor Rehabilitation},
	abstract = {To maximize brain plasticity after stroke, several rehabilitation strategies have been explored, including the use of intensive motor training, motor imagery, and action observation. Growing evidence of the positive impact of virtual reality ({VR}) techniques on recovery following stroke has been shown. However, most {VR} tools are designed to exploit active movement, and hence patients with low level of motor control cannot fully benefit from them. Consequently, the idea of directly training the central nervous system has been promoted by utilizing motor-imagery ({MI}) based brain-computer interfaces ({BCIs}). To date, detailed information on which {VR} strategies lead to successful functional recovery is still largely missing, and very little is known about how to optimally integrate {BCI} and {VR} paradigms for stroke rehabilitation. The purpose of this study was to examine the efficacy of a {BCI}-{VR} system using a {MI} paradigm for post-stroke upper limb rehabilitation on functional assessments, and related changes in {MI} ability and brain imaging. To achieve this, a 60 years old male chronic stroke patient was recruited. The patient underwent a 3-week intervention in a clinical environment, resulting in 10 {BCI}-{VR} training sessions. The patient was assessed before and after intervention, as well as on a one-month follow-up, in terms of clinical scales and brain imaging using functional {MRI} ({fMRI}). Consistent with prior research, we found important improvements in upper extremity scores (Fugl-Meyer) and identified increases in brain activation measured by {fMRI} that suggest neuroplastic changes in brain motor networks. This study expands on the current body of evidence as more data are needed on the effect of this type of interventions not only on functional improvement but also through brain imaging to study the effect of the intervention on plasticity.},
	journaltitle = {Frontiers in Human Neuroscience},
	shortjournal = {Front. Hum. Neurosci.},
	author = {Vourvopoulos, Athanasios and Jorge, Carolina and Abreu, Rodolfo and Figueiredo, Patrícia and Fernandes, Jean-Claude and Bermúdez i Badia, Sergi},
	urldate = {2021-01-25},
	date = {2019},
	note = {Publisher: Frontiers},
	keywords = {Brain-computer interface, {EEG}, {fMRI}, Neurorehabilitation, virtual   reality},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\T5UMDJJS\\Vourvopoulos et al. - 2019 - Efficacy and Brain Imaging Correlates of an Immers.pdf:application/pdf},
}

@article{vourvopoulos_effects_2019,
	title = {Effects of a Brain-Computer Interface With Virtual Reality ({VR}) Neurofeedback: A Pilot Study in Chronic Stroke Patients},
	volume = {13},
	issn = {1662-5161},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2019.00210/full},
	doi = {10.3389/fnhum.2019.00210},
	shorttitle = {Effects of a Brain-Computer Interface With Virtual Reality ({VR}) Neurofeedback},
	abstract = {Rehabilitation for stroke patients with severe motor impairments is burdensome and demanding because most of the current rehabilitation options require some volitional movement to train the affected side. However, research has shown that survivors of severe stroke may receive modest benefits from action observation, virtual reality ({VR}), and brain-computer interfaces ({BCIs}). These approaches have shown some success in strengthening key motor pathways thought to support motor recovery after stroke. The purpose of this study was to combine the principles of action observation, {VR}, and {BCI} in a platform called {REINVENT} and assess its effects on four chronic stroke patients across different levels of motor impairment. {REINVENT} acquires post-stroke {EEG} signals that indicate an attempt to move and drives the movement of a virtual avatar arm, allowing patient-driven action observation neurofeedback in {VR}. In addition, synchronous electromyography ({EMG}) data were also captured to monitor overt muscle activity. Our results show that this {EEG}-based {BCI} can be used by stroke survivors across a wide range of motor disabilities. Finally, individual results suggest that patients with more severe motor impairments benefit the most from {EEG}-based neurofeedback, while patients with more mild impairments may benefit more from {EMG}-based feedback, harnessing existing sensorimotor pathways. Future research is needed to confirm these findings in a larger and more diverse population.},
	journaltitle = {Frontiers in Human Neuroscience},
	shortjournal = {Front. Hum. Neurosci.},
	author = {Vourvopoulos, Athanasios and Pardo, Octavio Marin and Lefebvre, Stéphanie and Neureither, Meghan and Saldana, David and Jahng, Esther and Liew, Sook-Lei},
	urldate = {2021-01-25},
	date = {2019},
	note = {Publisher: Frontiers},
	keywords = {Neurorehabilitation, action observation, brain-computer  interface, Stroke, virtual reality},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\UG6N9UT5\\Vourvopoulos et al. - 2019 - Effects of a Brain-Computer Interface With Virtual.pdf:application/pdf},
}

@article{yang_can_2018,
	title = {Can an Integrated System of Electroencephalography and Virtual Reality Further the Understanding of Relationships Between Attention, Meditation, Flow State, and Creativity?},
	volume = {57},
	doi = {10.1177/0735633118770800},
	abstract = {The creativity of the brain is usually measured by one’s creative behavior or activity. This study explores connections between an individual’s creative behavior and his or her creative brain by asking each participant to design an open-ended virtual product in an integrated system consisting of virtual reality and brainwaves. The results show a significant correlation between the individual creativity level and the state of flow. There is a significant correlation between the state of flow and the quality of the creative product. The attention value is correlated significantly with the quality of product. The participants’ four different behaviors significantly demonstrated different attention and meditation levels. The sequential analysis shows that people with high product creativity have a higher attention value while maintaining a state of relaxation, demonstrated during the behavior of painting in the virtual reality environment. Given a limited period of time, a higher level of product creativity can be achieved through persistent implementation, concentration, and by being relaxed both physically and mentally. Implications of the study on teaching, learning, and designing a creative learning environment will be discussed.},
	pages = {073563311877080},
	journaltitle = {Journal of Educational Computing Research},
	shortjournal = {Journal of Educational Computing Research},
	author = {Yang, Xiaozhe and Cheng, Pei-Yu and Lin, Lin and Huang, Yueh and Ren, Youqun},
	date = {2018-04-30},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\CAEKWBXW\\Yang et al. - 2018 - Can an Integrated System of Electroencephalography.pdf:application/pdf},
}

@article{ding_improving_2014,
	title = {Improving creativity performance by short-term meditation},
	volume = {10},
	issn = {1744-9081},
	url = {https://doi.org/10.1186/1744-9081-10-9},
	doi = {10.1186/1744-9081-10-9},
	abstract = {One form of meditation intervention, the integrative body-mind training ({IBMT}) has been shown to improve attention, reduce stress and change self-reports of mood. In this paper we examine whether short-term {IBMT} can improve performance related to creativity and determine the role that mood may play in such improvement.},
	pages = {9},
	number = {1},
	journaltitle = {Behavioral and Brain Functions},
	shortjournal = {Behavioral and Brain Functions},
	author = {Ding, Xiaoqian and Tang, Yi-Yuan and Tang, Rongxiang and Posner, Michael I.},
	urldate = {2021-01-25},
	date = {2014-03-19},
	keywords = {Creativity, Cross-lagged analysis, Emotion, Integrative body-mind training, Negative affect, Positive affect, Short-term meditation},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\I2V7DREI\\1744-9081-10-9.html:text/html;Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\48AVPVTT\\Ding et al. - 2014 - Improving creativity performance by short-term med.pdf:application/pdf},
}

@inproceedings{thomas_design_2013,
	title = {Design of an online {EEG} based neurofeedback game for enhancing attention and memory},
	doi = {10.1109/EMBC.2013.6609529},
	abstract = {Brain-Computer Interface ({BCI}) is an alternative communication and control channel between brain and computer which finds applications in neuroprosthetics, brain wave controlled computer games etc. This paper proposes an Electroencephalogram ({EEG}) based neurofeedback computer game that allows the player to control the game with the help of attention based brain signals. The proposed game protocol requires the player to memorize a set of numbers in a matrix, and to correctly fill the matrix using his attention. The attention level of the player is quantified using sample entropy features of {EEG}. The statistically significant performance improvement of five healthy subjects after playing a number of game sessions demonstrates the effectiveness of the proposed game in enhancing their concentration and memory skills.},
	eventtitle = {2013 35th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
	pages = {433--436},
	booktitle = {2013 35th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
	author = {Thomas, K. P. and Vinod, A. P. and Guan, C.},
	date = {2013-07},
	note = {{ISSN}: 1558-4615},
	keywords = {Humans, Neurofeedback, Attention, attention based brain signals, Attention Deficit Disorder with Hyperactivity, {BCI}, Brain, brain wave controlled computer games, brain-computer interface, brain-computer interfaces, Brain-Computer Interfaces, Cognition, communication channel, computer games, Computers, Conferences, control channel, electroencephalogram based neurofeedback computer game, electroencephalography, Electroencephalography, entropy, Entropy, game protocol, Games, Graphical user interfaces, Healthy Volunteers, matrix, Memory, memory skills, neurophysiology, neuroprosthetics, online {EEG} based eurofeedback game, sample entropy features, Signal Processing, Computer-Assisted, Training, User-Computer Interface, Video Games},
	file = {Thomas et al. - 2013 - Design of an online EEG based neurofeedback game f.pdf:C\:\\Users\\miche\\Zotero\\storage\\BTRF7MQP\\Thomas et al. - 2013 - Design of an online EEG based neurofeedback game f.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\SRAIKSTP\\6609529.html:text/html},
}

@article{thomas_design_2013-1,
	title = {Design of an online {EEG} based neurofeedback game for enhancing attention and memory},
	volume = {2013},
	issn = {2694-0604},
	doi = {10.1109/EMBC.2013.6609529},
	abstract = {Brain-Computer Interface ({BCI}) is an alternative communication and control channel between brain and computer which finds applications in neuroprosthetics, brain wave controlled computer games etc. This paper proposes an Electroencephalogram ({EEG}) based neurofeedback computer game that allows the player to control the game with the help of attention based brain signals. The proposed game protocol requires the player to memorize a set of numbers in a matrix, and to correctly fill the matrix using his attention. The attention level of the player is quantified using sample entropy features of {EEG}. The statistically significant performance improvement of five healthy subjects after playing a number of game sessions demonstrates the effectiveness of the proposed game in enhancing their concentration and memory skills.},
	pages = {433--436},
	journaltitle = {Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society. {IEEE} Engineering in Medicine and Biology Society. Annual International Conference},
	shortjournal = {Annu Int Conf {IEEE} Eng Med Biol Soc},
	author = {Thomas, Kavitha P. and Vinod, A. P. and Guan, Cuntai},
	date = {2013},
	pmid = {24109716},
	keywords = {Humans, Neurofeedback, Attention, Attention Deficit Disorder with Hyperactivity, Brain, Brain-Computer Interfaces, Cognition, Computers, Electroencephalography, Healthy Volunteers, Memory, Signal Processing, Computer-Assisted, User-Computer Interface, Video Games},
}

@article{katahira_eeg_2018,
	title = {{EEG} Correlates of the Flow State: A Combination of Increased Frontal Theta and Moderate Frontocentral Alpha Rhythm in the Mental Arithmetic Task},
	volume = {9},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00300/full},
	doi = {10.3389/fpsyg.2018.00300},
	shorttitle = {{EEG} Correlates of the Flow State},
	abstract = {Flow experience is a subjective state experienced during holistic involvement in a certain activity, which has been reported to function as a factor promoting motivation, skill development, and better performance in the activity. To verify the positive effects of flow and develop a method to utilize it, the establishment of a reliable measurement of the flow state is essential. The present study measured the electroencephalogram ({EEG}) during an experimentally evoked flow state and examined the possibility of objective measurement of immediate flow. A total of 16 participants (10 males, 6 females) participated in the experiment that employed the mental arithmetic task developed in the previous study. Post-trial self-report of the flow state and {EEG} during task execution were measured and compared among the three conditions (Boring, Flow, and Overload conditions) that had different levels of task difficulty. Furthermore, the correlations between subjective flow items and {EEG} activity were examined. As expected, the ratings on the subjective evaluation items representing the flow state were the highest in the Flow condition. Regarding the {EEG} data, theta activities in the frontal areas were higher in the Flow and the Overload conditions than in the Boredom condition, and alpha activity in the frontal areas and the right central area gradually increased depending on the task difficulty. These {EEG} activities correlated with self-reported flow experience, especially items related to the concentration on the task and task difficulty. From the results, the flow state was characterized by increased theta activities in the frontal areas and moderate alpha activities in the frontal and central areas. The former may be related to a high level of cognitive control and immersion in task, and the latter suggests that the load on the working memory was not excessive. The findings of this study suggest the possibility of distinguishing the flow state from other states using multiple {EEG} activities and indicate the need for other physiological indicators corresponding to the other aspects of flow experience.},
	journaltitle = {Frontiers in Psychology},
	shortjournal = {Front. Psychol.},
	author = {Katahira, Kenji and Yamazaki, Yoichi and Yamaoka, Chiaki and Ozaki, Hiroaki and Nakagawa, Sayaka and Nagata, Noriko},
	urldate = {2021-01-25},
	date = {2018},
	note = {Publisher: Frontiers},
	keywords = {{EEG}, flow experience, fm theta, Mental arithmetic task, Objective measurement},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\DZ7CZSYI\\Katahira et al. - 2018 - EEG Correlates of the Flow State A Combination of.pdf:application/pdf},
}

@article{wang_exploratory_2014,
	title = {An exploratory study using inexpensive electroencephalography ({EEG}) to understand flow experience in computer-based instruction},
	volume = {51},
	issn = {0378-7206},
	url = {http://www.sciencedirect.com/science/article/pii/S0378720614000639},
	doi = {10.1016/j.im.2014.05.010},
	abstract = {Flow is an optimal experience that results in intense engagement in an activity. In computer-based instructional environment, flow can be used to examine learning performance. We used questionnaire survey and electroencephalography ({EEG}) analysis to examine the influence of challenge-skill balance on the flow experience and influence of flow experience on learning performance in a computer-based instructional environment. The results showed that the flow experience of learners depends on challenge-skill balance of learning materials. The research explored the possibility of using an inexpensive non-medical {EEG} device to research the association between flow experience and challenge-skill balance in educational information systems.},
	pages = {912--923},
	number = {7},
	journaltitle = {Information \& Management},
	shortjournal = {Information \& Management},
	author = {Wang, Chih-Chien and Hsu, Ming-Chang},
	urldate = {2021-01-25},
	date = {2014-11-01},
	langid = {english},
	keywords = {Flow, Computer-based instruction, e-Learning, Electroencephalography ({EEG}), Learning performance},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\IF33L3V3\\S0378720614000639.html:text/html;ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\8E8GUGRB\\Wang e Hsu - 2014 - An exploratory study using inexpensive electroence.pdf:application/pdf},
}

@incollection{csikszentmihalyi_flow_1990,
	title = {Flow: The Psychology of Optimal Experience},
	shorttitle = {Flow},
	author = {Csikszentmihalyi, Mihaly},
	date = {1990-01-01},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\U4UT5D8U\\Csikszentmihalyi - 1990 - Flow The Psychology of Optimal Experience.pdf:application/pdf},
}

@article{mladenovic_impact_2017,
	title = {The Impact of Flow in an {EEG}-based Brain Computer Interface},
	abstract = {Major issues in Brain Computer Interfaces ({BCIs}) include low usability and poor user performance. This paper tackles them by ensuring the users to be in a state of immersion, control and motivation, called state of flow. Indeed, in various disciplines, being in the state of flow was shown to improve performances and learning. Hence, we intended to draw {BCI} users in a flow state to improve both their subjective experience and their performances. In a Motor Imagery {BCI} game, we manipulated flow in two ways: 1) by adapting the task difficulty and 2) by using background music. Results showed that the difficulty adaptation induced a higher flow state, however music had no effect. There was a positive correlation between subjective flow scores and offline performance, although the flow factors had no effect (adaptation) or negative effect (music) on online performance. Overall, favouring the flow state seems a promising approach for enhancing users' satisfaction, although its complexity requires more thorough investigations.},
	author = {Mladenovic, Jelena and Frey, Jérémy and Bonnet-Save, Manon and Mattout, Jérémie and Lotte, Fabien},
	date = {2017-06-06},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\VXNFGM2Y\\Mladenovic et al. - 2017 - The Impact of Flow in an EEG-based Brain Computer .pdf:application/pdf},
}

@online{subramaniyam_pitfalls_2018,
	title = {Pitfalls of Filtering the {EEG} Signal},
	url = {https://sapienlabs.org/pitfalls-of-filtering-the-eeg-signal/},
	abstract = {Filtering of the {EEG} signal to remove artifacts is a common pre-processing step but introduces temporal distortions in the signal. How do you chose a filter for your particular analysis goals?},
	titleaddon = {Sapien Labs {\textbar} Neuroscience {\textbar} Human Brain Diversity Project},
	author = {Subramaniyam, Narayan P.},
	urldate = {2021-01-23},
	date = {2018-11-12},
	langid = {american},
}

@online{noauthor_sklearnpreprocessingquantiletransformer_2021,
	title = {sklearn.preprocessing.{QuantileTransformer} — scikit-learn 0.24.1 documentation},
	url = {https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer},
	urldate = {2021-01-19},
	date = {2021-01-19},
}

@article{yildirim_efficient_2018,
	title = {An efficient compression of {ECG} signals using deep convolutional autoencoders},
	volume = {52},
	issn = {1389-0417},
	url = {http://www.sciencedirect.com/science/article/pii/S1389041718302730},
	doi = {10.1016/j.cogsys.2018.07.004},
	abstract = {Background and objective
Advances in information technology have facilitated the retrieval and processing of biomedical data. Especially with wearable technologies and mobile platforms, we are able to follow our healthcare data, such as electrocardiograms ({ECG}), in real time. However, the hardware resources of these technologies are limited. For this reason, the optimal storage and safe transmission of the personal health data is critical. This study proposes a new deep convolutional autoencoder ({CAE}) model for compressing {ECG} signals.
Methods
In this paper, a deep network structure of 27 layers consisting of encoder and decoder parts is designed. In the encoder section of this model, the signals are reduced to low-dimensional vectors; and in the decoder section, the signals are reconstructed. The deep learning approach provides the representations of the low and high levels of signals in the hidden layers of the model. Hence, the original signal can be reconstructed with minimal loss. Very different from traditional linear transformation methods, a deep compression approach implies that it can learn to use different {ECG} records automatically.
Results
The performance was evaluated on an experimental data set comprising 4800 {ECG} fragments from 48 unique clinical patients. The compression rate ({CR}) of the proposed model was 32.25, and the average {PRD} value was 2.73\%. These favourable observation suggest that our deep model can allow secure data transfer in a low-dimensional form to remote medical centers. We present an effective compression approach that can potentially be used in wearable devices, e-health applications, telemetry and Holter systems.},
	pages = {198--211},
	journaltitle = {Cognitive Systems Research},
	shortjournal = {Cognitive Systems Research},
	author = {Yildirim, Ozal and Tan, Ru San and Acharya, U. Rajendra},
	urldate = {2021-01-19},
	date = {2018-12-01},
	langid = {english},
	keywords = {Autoencoders, Deep learning, {ECG} signals, Signal compression},
}

@online{noauthor_rbf_2021,
	title = {{RBF} {SVM} parameters — scikit-learn 0.24.1 documentation},
	url = {https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html},
	urldate = {2021-01-22},
	date = {2021-01-22},
}

@inproceedings{al-marridi_convolutional_2018,
	title = {Convolutional Autoencoder Approach for {EEG} Compression and Reconstruction in m-Health Systems},
	doi = {10.1109/IWCMC.2018.8450511},
	abstract = {In the last few years, the number of patients with chronic diseases requiring constant monitoring increased rapidly, which motivates researchers to develop scalable remote health applications. Nevertheless, the amount of transmitted real-time data through current dynamic networks with limited and restricted bandwidth, end-to-end delay, and transmission power; limits having an efficient transmission of the data. Motivated by the high energy consumed for transmission, applying data reduction techniques to the vital signs at the transmitter side present an efficient edge-based approach that significantly reduces the transmission energy. However, a new problem arises, which is the ability of receiving the data at the server side with an acceptable distortion rate (i.e., deformation of vital signs because of inefficient data reduction). In this paper, we introduce a Deep Learning ({DL}) approach based on Convolutional Auto-Encoder ({CAE}), to compress and reconstruct the vital signs in general and Electroencephalogram Signal ({EEG}) specifically with minimum distortion. The results show that using {CAE} provides efficient distortion rate while maximizing compression ratio. However, learning makes {CAE} application-specific, where each {CAE} model is designed specifically for a certain application.},
	eventtitle = {2018 14th International Wireless Communications Mobile Computing Conference ({IWCMC})},
	pages = {370--375},
	booktitle = {2018 14th International Wireless Communications Mobile Computing Conference ({IWCMC})},
	author = {Al-Marridi, A. Z. and Mohamed, A. and Erbad, A.},
	date = {2018-06},
	note = {{ISSN}: 2376-6506},
	keywords = {electroencephalography, Electroencephalography, Deep learning, Biological neural networks, Brain modeling, {CAE} application, chronic diseases, Compression, compression ratio maximization, constant monitoring, convolution, Convolution, Convolutional Autoencoder, convolutional autoencoder approach, data compression, data reduction, Data Reduction, data reduction techniques, deep learning approach, diseases, Distortion, distortion rate, dynamic networks, edge-based approach, {EEG} compression, {EEG} signal reconstruction, Electroencephalogram Signal, encoding, end-to-end delay, health care, learning (artificial intelligence), m-health systems, Machine learning, Medical services, medical signal processing, mobile computing, patient monitoring, patients, real-time data transmission, scalable remote health applications, signal reconstruction, Signal Reconstruction, transmission energy, transmission power},
}

@inproceedings{yang_use_2015,
	title = {On the use of convolutional neural networks and augmented {CSP} features for multi-class motor imagery of {EEG} signals classification},
	doi = {10.1109/EMBC.2015.7318929},
	abstract = {Learning the deep structures and unknown correlations is important for the detection of motor imagery of {EEG} signals ({MI}-{EEG}). This study investigates the use of convolutional neural networks ({CNNs}) for the classification of multi-class {MI}-{EEG} signals. Augmented common spatial pattern ({ACSP}) features are generated based on pair-wise projection matrices, which covers various frequency ranges. We propose a frequency complementary feature map selection ({FCMS}) scheme by constraining the dependency among frequency bands. Experiments are conducted on {BCI} competition {IV} dataset {IIa} with 9 subjects. Averaged cross-validation accuracy of 68.45\% and 69.27\% is achieved for {FCMS} and all feature maps, respectively, which is significantly higher (4.53\% and 5.34\%) than random map selection and higher (1.44\% and 2.26\%) than filter-bank {CSP} ({FBCSP}). The results demonstrate that the {CNNs} are capable of learning discriminant, deep structure features for {EEG} classification without relying on the handcrafted features.},
	eventtitle = {2015 37th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
	pages = {2620--2623},
	booktitle = {2015 37th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
	author = {Yang, H. and Sakhavi, S. and Ang, K. K. and Guan, C.},
	date = {2015-08},
	note = {{ISSN}: 1558-4615},
	keywords = {Humans, electroencephalography, Electroencephalography, neurophysiology, Signal Processing, Computer-Assisted, convolution, Convolution, learning (artificial intelligence), medical signal processing, Accuracy, Algorithms, augmented common spatial pattern features, augmented {CSP}, augmented {CSP} features, averaged cross-validation accuracy, {BCI} competition {IV} dataset {IIa}, bioelectric potentials, Brain models, channel bank filters, convolutional neural network, convolutional neural networks, deep learning, Electrodes, Feature extraction, feature selection, filter-bank {CSP}, frequency complementary feature map selection scheme, learning discriminant, medical signal detection, Movement, multi-class motor imagery of {EEG}, multiclass {MI}-{EEG} signal classification, multiclass motor imagery, neural nets, Neural networks, Neural Networks (Computer), pair-wise projection matrices, random map selection, random processes, signal classification},
}

@inproceedings{park_efficient_2007,
	location = {Berlin, Heidelberg},
	title = {Efficient Pairwise Classification},
	isbn = {978-3-540-74958-5},
	doi = {10.1007/978-3-540-74958-5_65},
	series = {Lecture Notes in Computer Science},
	abstract = {Pairwise classification is a class binarization procedure that converts a multi-class problem into a series of two-class problems, one problem for each pair of classes. While it can be shown that for training, this procedure is more efficient than the more commonly used one-against-all approach, it still has to evaluate a quadratic number of classifiers when computing the predicted class for a given example. In this paper, we propose a method that allows a faster computation of the predicted class when weighted or unweighted voting are used for combining the predictions of the individual classifiers. While its worst-case complexity is still quadratic in the number of classes, we show that even in the case of completely random base classifiers, our method still outperforms the conventional pairwise classifier. For the more practical case of well-trained base classifiers, its asymptotic computational complexity seems to be almost linear.},
	pages = {658--665},
	booktitle = {Machine Learning: {ECML} 2007},
	publisher = {Springer},
	author = {Park, Sang-Hyeun and Fürnkranz, Johannes},
	editor = {Kok, Joost N. and Koronacki, Jacek and Mantaras, Raomon Lopez de and Matwin, Stan and Mladenič, Dunja and Skowron, Andrzej},
	date = {2007},
	langid = {english},
}

@article{shoemaker_deciphering_2007,
	title = {Deciphering Protein–Protein Interactions. Part {II}. Computational Methods to Predict Protein and Domain Interaction Partners},
	volume = {3},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.0030043},
	doi = {10.1371/journal.pcbi.0030043},
	pages = {e43},
	number = {4},
	journaltitle = {{PLOS} Computational Biology},
	shortjournal = {{PLOS} Computational Biology},
	author = {Shoemaker, Benjamin A. and Panchenko, Anna R.},
	urldate = {2021-01-03},
	date = {2007-04-27},
	langid = {english},
	note = {Number: 4
Publisher: Public Library of Science},
	keywords = {Forecasting, Genomics, Invertebrate genomics, Phylogenetic analysis, Phylogenetics, Protein domains, Protein interaction networks, Protein interactions},
}

@inproceedings{atarashi_deep_2017,
	title = {A Deep Neural Network for Pairwise Classification: Enabling Feature Conjunctions and Ensuring Symmetry},
	isbn = {978-3-319-57453-0},
	doi = {10.1007/978-3-319-57454-7_7},
	shorttitle = {A Deep Neural Network for Pairwise Classification},
	abstract = {Pairwise classification is a computational problem to determine whether a given ordered pair of objects satisfies a binary relation R which is specified implicitly by a set of training data used for ‘learning’ R. It is an important component for entity resolution, network link prediction, protein-protein interaction prediction, and so on. Although deep neural networks ({DNNs}) outperform other methods in many tasks and have thus attracted the attention of machine learning researchers, there have been few studies of applying a {DNN} to pairwise classification. Important properties of pairwise classification include using feature conjunctions across examples. Also, it is known that making the classifier invariant to the data order is an important property in applications with a symmetric relation R, including those applications mentioned above. We first show that a simple {DNN} with fully connected layers cannot satisfy these properties and then present a pairwise {DNN} satisfying these properties. As an example of pairwise classification, we use the author matching problem, which is the problem of determining whether two author names in different bibliographic data sources refer to the same person. We show that the method using our model outperforms methods using a support vector machine and simple {DNNs}.},
	eventtitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	pages = {83--95},
	author = {Atarashi, Kyohei and Oyama, Satoshi and Kurihara, Masahito and Furudo, Kazune},
	date = {2017-04-01},
}

@article{sun_eeg-based_2019,
	title = {{EEG}-based user identification system using 1D-convolutional long short-term memory neural networks},
	volume = {125},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S095741741930096X},
	doi = {10.1016/j.eswa.2019.01.080},
	abstract = {Electroencephalographic ({EEG}) signals have been widely used in medical applications, yet the use of {EEG} signals as user identification systems for healthcare and Internet of Things ({IoT}) systems has only gained interests in the last few years. The advantages of {EEG}-based user identification systems lie in its dynamic property and uniqueness among different individuals. However, it is for this reason that manually designed features are not always adapted to the needs. Therefore, a novel approach based on 1D Convolutional Long Short-term Memory Neural Network (1D-Convolutional {LSTM}) for {EEG}-based user identification system is proposed in this paper. The performance of the proposed approach was validated with a public database consists of {EEG} data of 109 subjects. The experimental results showed that the proposed network has a very high averaged accuracy of 99.58\%, when using only 16 channels of {EEG} signals, which outperforms the state-of-the-art {EEG}-based user identification methods. The combined use of {CNNs} and {LSTMs} in the proposed 1D-Convolutional {LSTM} can greatly improve the accuracy of user identification systems by utilizing the spatiotemporal features of the {EEG} signals with {LSTM}, and lowering cost of the systems by reducing the number of {EEG} electrodes used in the systems.},
	pages = {259--267},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {Sun, Yingnan and Lo, Frank P. -W. and Lo, Benny},
	urldate = {2020-12-06},
	date = {2019-07-01},
	langid = {english},
	keywords = {1D-Convolutional {LSTM}, Biometrics, Electroencephalograms ({EEG}), User identification},
}

@article{bock_predicting_2001,
	title = {Predicting protein–protein interactions from primary structure},
	volume = {17},
	issn = {1367-4803},
	url = {https://doi.org/10.1093/bioinformatics/17.5.455},
	doi = {10.1093/bioinformatics/17.5.455},
	abstract = {Motivation: An ambitious goal of proteomics is to elucidate the

structure, interactions and functions of all proteins within cells

and organisms. The expectation is that this will provide a fuller

appreciation of cellular processes and networks at the protein

level, ultimately leading to a better understanding of disease

mechanisms and suggesting new means for intervention. This paper

addresses the question: can protein–protein interactions be

predicted directly from primary structure and associated data? Using

a diverse database of known protein interactions, a Support Vector

Machine ({SVM}) learning system was trained to recognize and predict

interactions based solely on primary structure and associated

physicochemical properties.Results: Inductive accuracy of the trained system, defined here

as the percentage of correct protein interaction predictions for

previously unseen test sets, averaged 80\% for the ensemble of

statistical experiments. Future proteomics studies may benefit from

this research by proceeding directly from the automated

identification of a cell’s gene products to prediction of

protein interaction pairs.Contact: dgough@bioeng.ucsd.edu*To whom correspondence should be

addressed.},
	pages = {455--460},
	number = {5},
	journaltitle = {Bioinformatics},
	shortjournal = {Bioinformatics},
	author = {Bock, Joel R. and Gough, David A.},
	urldate = {2021-01-03},
	date = {2001-05-01},
	note = {Number: 5},
}

@article{moody_physionet_2001,
	title = {{PhysioNet}: a Web-based resource for the study of physiologic signals},
	volume = {20},
	issn = {1937-4186},
	doi = {10.1109/51.932728},
	shorttitle = {{PhysioNet}},
	abstract = {Free access to a signals archive and a signal processing/analysis software library fosters online collaboration. This article aims to introduce {PhysioNet} as a resource to the biomedical research community. After a capsule summary of its history and goals, we discuss what {PhysioNet} offers to researchers, describe some of the technology needed to support these functions, and conclude with observations gleaned from {PhysioNet}'s first year of service.},
	pages = {70--75},
	number = {3},
	journaltitle = {{IEEE} Engineering in Medicine and Biology Magazine},
	author = {Moody, G. B. and Mark, R. G. and Goldberger, A. L.},
	date = {2001-05},
	note = {Number: 3
Conference Name: {IEEE} Engineering in Medicine and Biology Magazine},
	keywords = {Humans, Internet, neurophysiology, Signal Processing, Computer-Assisted, Algorithm design and analysis, apnoea database, Biomedical signal processing, database management systems, Databases, Databases, Factual, information resources, Medical diagnostic imaging, medical information systems, {MIMIC} database, Monitoring, Physiologic, online collaboration, Online Communities/Technical Collaboration, Open source software, physiologic signals, {PhysioNet}, polysomnographic database, Signal analysis, Signal processing, signal processing/analysis software library, signals archive library, sleep, Software libraries, Web sites, Web-based resource},
}

@online{brownlee_gentle_2018,
	title = {A Gentle Introduction to {LSTM} Autoencoders},
	url = {https://machinelearningmastery.com/lstm-autoencoders/},
	abstract = {An {LSTM} Autoencoder is an implementation of an autoencoder for sequence data using an Encoder-Decoder {LSTM} architecture. Once fit, the encoder part of the model can be used to encode or compress sequence data that in turn may be used in data visualizations or as a feature vector input to a supervised learning model. In […]},
	titleaddon = {Machine Learning Mastery},
	author = {Brownlee, Jason},
	urldate = {2020-12-06},
	date = {2018-11-04},
	langid = {american},
}

@article{abo-zahhad_new_2015,
	title = {A New {EEG} Acquisition Protocol for Biometric Identification Using Eye Blinking Signals},
	volume = {7},
	issn = {2074904X, 20749058},
	url = {http://www.mecs-press.org/ijisa/ijisa-v7-n6/v7n6-5.html},
	doi = {10.5815/ijisa.2015.06.05},
	pages = {48--54},
	number = {6},
	journaltitle = {International Journal of Intelligent Systems and Applications},
	shortjournal = {{IJISA}},
	author = {Abo-Zahhad, M. and Ahmed, Sabah M. and Abbas, Sherif N.},
	urldate = {2020-12-05},
	date = {2015-05-08},
	note = {Number: 6},
}

@article{kaur_novel_2017,
	title = {A Novel framework of {EEG}-based user identification by analyzing music-listening behavior},
	volume = {76},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-016-4232-2},
	doi = {10.1007/s11042-016-4232-2},
	abstract = {This paper introduces a novel framework for user identification by analyzing neuro-signals. Studies regarding Electroencephalography ({EEG}) revealed that such bio-signals are sensitive, hard to forge, confidential, and unique which the conventional biometric systems like face, speaker, signature and voice lack. Traditionally, researchers investigated the neuro-signal patterns by asking users to perform various imaginary, visual or calculative tasks. In this work, we have analyzed this neuro-signal pattern using audio as stimuli. The {EEG} signals are recorded simultaneously while user is listening to music. Four different genres of music are considered as users have their own preference and accordingly they respond with different emotions and interests. The users are also asked to provide music preference which acts as a personal identification mechanism. The framework offers the benefit of uniqueness in neuro-signal pattern even with the same music preference by different users. We used two different classifiers i.e. Hidden Markov Model ({HMM}) based temporal classifier and Support Vector Machine ({SVM}) for user identification system. A dataset of 2400 {EEG} signals while listening to music was collected from 60 users. User identification performance of 97.50 \% and 93.83 \% have been recorded with {HMM} and {SVM} classifiers, respectively. Finally, the performance of the system is also evaluated on various emotional states after showing different emotional videos to users.},
	pages = {25581--25602},
	number = {24},
	journaltitle = {Multimedia Tools and Applications},
	shortjournal = {Multimed Tools Appl},
	author = {Kaur, Barjinder and Singh, Dinesh and Roy, Partha Pratim},
	urldate = {2020-12-05},
	date = {2017-12-01},
	langid = {english},
	note = {Number: 24},
}

@book{waili_eeg_2019,
	title = {{EEG} Based Biometric Identification Using Correlation and {MLPNN} Models},
	url = {https://www.learntechlib.org/p/218031/},
	abstract = {This study investigates the capability of electroencephalogram ({EEG}) signals to be used for biometric identification. In the context of biometric, recently, researchers have been focusing more on biomedical signals to substitute the biometric modalities that are being used nowadays as the signals obtained from our bodies is considered more secure and privacy-compliant. The {EEG} signals of 6 subjects were collected where the subjects were required to undergo two baseline experiments which are, eyes open ({EO}) and eyes closed ({EC}). The signals were processed using a 2nd order Butterworth filter...},
	publisher = {International Association of Online Engineering},
	author = {Waili, T. and Johar, Gapar and Sidek, K. and Nor, N. and Yaacob, H. and Othman, M.},
	urldate = {2020-12-05},
	date = {2019-06-27},
	langid = {english},
	note = {Pages: 77-90},
}

@inproceedings{gui_multichannel_2015,
	title = {Multichannel {EEG}-based biometric using improved {RBF} neural networks},
	doi = {10.1109/SPMB.2015.7405418},
	abstract = {Electroencephalogram ({EEG}) brainwaves have recently emerged as a promising biometric that can be used for individual identification. In this study, we present a new visual stimuli-driven, non-volitional brain responses based methodological framework towards individual identification. The non-volitional mechanism provides an even more secure way in which the individuals are not aware of security credentials and thus can not manipulate their brain activities. Given the intercorrelated structure of brain functional areas, instead of making the identification decision relying on any single {EEG} channel, we propose a new identification approach based on the decision-level fusion of multichannel {EEG} signals, using the Radial Basis Function ({RBF}) neural network and its improved versions. Specifically, the identification decision is determined according to the identification patterns reflected from multiple {EEG} channels over the desired brain functional region. We evaluate the performance of our proposed methods based on four different visual stimuli and four independent {EEG} channels. Experimental results show that, the proposed fusion technique can significantly improve the identification accuracy, compared to the conventional single channel based solution. For {RBF} network, the accuracy of identifying 37 subjects could reach over 70\%, which is better than the average accuracy of about 55\% achieved through individual channels. For the improved {RBF} networks, the frequency-based decision making could reach the accuracy of 90\%, while the probability-based method could reach over 91\%. Our study lays a foundation for future investigation of more accurate and reliable brainwave-based biometrics.},
	eventtitle = {2015 {IEEE} Signal Processing in Medicine and Biology Symposium ({SPMB})},
	pages = {1--6},
	booktitle = {2015 {IEEE} Signal Processing in Medicine and Biology Symposium ({SPMB})},
	author = {Gui, Q. and Jin, Z. and Xu, W. and Ruiz-Blondet, M. V. and Laszlo, S.},
	date = {2015-12},
	keywords = {electroencephalography, Electroencephalography, neurophysiology, Biological neural networks, medical signal processing, bioelectric potentials, Feature extraction, brain, brain activity, brain functional areas, brain functional region, conventional single channel based solution, decision making, decision-level fusion, {EEG} brainwaves, electroencephalogram brainwaves, frequency-based decision making, fusion technique, identification, identification accuracy, identification decision, identification patterns, improved {RBF} neural networks, intercorrelated structure, multichannel {EEG} signals, multichannel {EEG}-based biometrics, Neurons, nonvolitional mechanism, ological framework, probability, probability-based method, radial basis function networks, Radial basis function networks, radial basis function neural network, {RBF} neural network, single {EEG} channel, visual stimuli, visual stimuli-driven nonvolitional brain response based method, Visualization},
}

@article{de_vazelhes_metric-learn_2020,
	title = {metric-learn: Metric Learning Algorithms in Python},
	volume = {21},
	pages = {1--6},
	number = {138},
	journaltitle = {Journal of Machine Learning Research},
	author = {de Vazelhes, William and Carey, {CJ} and Tang, Yuan and Vauquier, Nathalie and Bellet, Aurélien},
	date = {2020},
	note = {Number: 138},
}

@article{di_robustness_2019,
	title = {Robustness Analysis of Identification Using Resting-State {EEG} Signals},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2907644},
	abstract = {The brain activity pattern can be presented by Electroencephalogram ({EEG}), which is considered as an alternative to traditional biometrics. Researchers have done conducted studies on {EEG}-based identification, while few of them discussed the effect of time robustness which is very important for the identification system. In this study, we compared and analyzed the two runs {EEG} signals of resting-state of eye open/closed ({REO}/{REC}). The time intervals between two runs were at least two weeks. Here are 17 participants joined in this study. Each of them took two runs experiment. Each run contains four sessions, each session includes 150 seconds of {REO}/{REC}. Spectral and statistical analyses were used to extract feature. Three classifiers, Euclidean distance, {SVM}, and {LDA}, were used to get classification accuracies and to compare the performance between features of each run and two runs. The results of two runs {PSD} values of both {REO} and {REC} conditions show that there is a similarity within each subject and a difference between subjects. The classification accuracies of three methods of each run are almost 99\%. The classification accuracies using two runs data as training set can also reach up to 97\% while using each of two-run data as training set is nearly 80\%. Thus, the features of most subjects have cross-time robustness and could be used as identification. This study will have an important role in {EEG}-based identification system.},
	pages = {42113--42122},
	journaltitle = {{IEEE} Access},
	author = {Di, Y. and An, X. and He, F. and Liu, S. and Ke, Y. and Ming, D.},
	date = {2019},
	note = {Conference Name: {IEEE} Access},
	keywords = {electroencephalography, Electroencephalography, neurophysiology, medical signal processing, Feature extraction, identification, biometrics, Biometrics (access control), brain activity pattern, classification accuracies, Correlation, {EEG}-based identification system, electroencephalogram, Electroencephalography({EEG}), Euclidean distance, eye, eye closed, eye open, feature extraction, resting-state, resting-state {EEG} signals, robustness, Robustness, robustness analysis, runs {PSD} values, statistical analyses, statistical analysis, support vector machines, Support vector machines, {SVM}, two-run data},
}

@article{hunter_australian_2005,
	title = {The Australian {EEG} database},
	volume = {36},
	issn = {1550-0594},
	doi = {10.1177/155005940503600206},
	abstract = {The Australian {EEG} Database is a web-based de-identified searchable database of 18,500 {EEG} records recorded at a regional public hospital over an 11-year period. Patients range in age from a premature infant born at 24 weeks gestation, through to people aged over 90 years. This paper will describe the history of the database, the range of patients represented in the database, and the nature of the text-based and digital data contained in the database. Preliminary results of the first two studies undertaken using the database are presented. Plans for sharing data from the Australian {EEG} database with researchers are discussed. We anticipate that such data will be useful in not only helping to answer clinical questions but also in the field of mathematical modeling of the {EEG}.},
	pages = {76--81},
	number = {2},
	journaltitle = {Clinical {EEG} and neuroscience},
	shortjournal = {Clin {EEG} Neurosci},
	author = {Hunter, M. and Smith, R. L. L. and Hyslop, W. and Rosso, O. A. and Gerlach, R. and Rostas, J. a. P. and Williams, D. B. and Henskens, F.},
	date = {2005-04},
	pmid = {15999902},
	note = {Number: 2},
	keywords = {Humans, Internet, Electroencephalography, User-Computer Interface, Databases, Factual, Adolescent, Adult, Aged, Animals, Australia, Child, Child, Preschool, Clinical Trials as Topic, Database Management Systems, Infant, Infant, Newborn, Information Dissemination, Information Storage and Retrieval, Medical Records Systems, Computerized, Middle Aged},
}

@inproceedings{poulos_person_1999,
	title = {Person identification based on parametric processing of the {EEG}},
	volume = {1},
	doi = {10.1109/ICECS.1999.812278},
	abstract = {Person identification based on parametric spectral analysis of the {EEG} signal is addressed in this work-a problem that has not yet been seen in a signal-processing framework, to the best of our knowledge. {AR} parameters are estimated from a signal containing only the alpha, rhythm activity of the {EEG}. These parameters are used as features in the classification step, which employs a learning vector quantizer network. The proposed method was applied on a set of real {EEG} recordings made on healthy individuals, in an attempt to experimentally investigate the connection between a person's {EEG} and genetically-specific information. Correct classification scores at the range of 72\% to 84\% show the potential of our approach for person classification/identification and are in agreement with previous research showing evidence that the {EEG} carries genetic information.},
	eventtitle = {{ICECS}'99. Proceedings of {ICECS} '99. 6th {IEEE} International Conference on Electronics, Circuits and Systems (Cat. No.99EX357)},
	pages = {283--286 vol.1},
	booktitle = {{ICECS}'99. Proceedings of {ICECS} '99. 6th {IEEE} International Conference on Electronics, Circuits and Systems (Cat. No.99EX357)},
	author = {Poulos, M. and Rangoussi, M. and Chrissikopoulos, V. and Evangelou, A.},
	date = {1999-09},
	keywords = {{EEG}, electroencephalography, Electroencephalography, Feature extraction, {AR} parameters, autoregressive processes, biometrics (access control), classification step, Computational geometry, Data mining, Encoding, genetic information, Genetics, Informatics, Information security, learning vector quantizer network, parametric processing, pattern classification, person classification, person identification, Physiology, Rhythm, rhythm activity, spectral analysis, vector quantisation},
}

@article{klonovs_id_2013,
	title = {{ID} Proof on the Go: Development of a Mobile {EEG}-Based Biometric Authentication System},
	volume = {8},
	issn = {1556-6080},
	doi = {10.1109/MVT.2012.2234056},
	shorttitle = {{ID} Proof on the Go},
	abstract = {In recent years, the need for greater security for storing personal and business data or accessing corporate networks on mobile devices has been growing rapidly, and one of the potential solutions is to employ innovative biometric authentication techniques. This article presents the development of a mobile biometric authentication system based on electroencephalogram ({EEG}) recordings in combination with already proven technologies such as facial detection and nearfield communication ({NFC}). The overall goal of this work is to fill the gap between mobile Web technologies and wireless {EEG} devices and to develop a new authentication technique and a feasible application. Therefore, we review the relevant literature, conduct several {EEG} measurement experiments, and discuss the procedure and results with experts in the {EEG} and digital signal processing ({DSP}) fields. On the basis of these results, we build and present a mobile prototype system capable of authenticating users based on the uniqueness of their brain waves. Furthermore, we implement a novel authentication process that will make the authentication system more secure. We also give suggestions for future improvements to the system.},
	pages = {81--89},
	number = {1},
	journaltitle = {{IEEE} Vehicular Technology Magazine},
	author = {Klonovs, J. and Petersen, C. K. and Olesen, H. and Hammershoj, A.},
	date = {2013-03},
	note = {Number: 1
Conference Name: {IEEE} Vehicular Technology Magazine},
	keywords = {electroencephalography, Electroencephalography, medical signal processing, biometrics (access control), Authentication, brain waves, business data security, Cameras, Computer security, corporate network access, Data security, digital signal processing, {DSP}, {EEG} measurement experiment, electroencephalogram recording, facial detection, Headphones, innovative biometric authentication technique, Mobile communication, mobile devices, mobile {EEG}-based biometric authentication system, mobile radio, mobile Web technologies, near-field communication, {NFC}, personal data security, Privacy, Prototypes, user authentication, wireless {EEG} devices},
}

@article{akhtar_face_2017,
	title = {A Face in any Form: New Challenges and Opportunities for Face Recognition Technology},
	volume = {50},
	issn = {1558-0814},
	doi = {10.1109/MC.2017.119},
	shorttitle = {A Face in any Form},
	abstract = {Despite new technologies that make face detection and recognition more sophisticated, long-recognized problems in security, privacy, and accuracy persist. Refining this technology and introducing it into new domains will require solving these problems through focused interdisciplinary efforts among developers, researchers, and policymakers.},
	pages = {80--90},
	number = {4},
	journaltitle = {Computer},
	author = {Akhtar, Z. and Rattani, A.},
	date = {2017-04},
	note = {Number: 4
Conference Name: Computer},
	keywords = {Feature extraction, Algorithm design and analysis, biometrics, data analysis, face detection, face recognition, Face recognition, face recognition system, face recognition technology, {FRS}, Image recognition, privacy, privacy problem, security, security problem, Solid modeling, Three-dimensional displays},
}

@article{yang_security_2019,
	title = {Security and Accuracy of Fingerprint-Based Biometrics: A Review},
	volume = {11},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2073-8994/11/2/141},
	doi = {10.3390/sym11020141},
	shorttitle = {Security and Accuracy of Fingerprint-Based Biometrics},
	abstract = {Biometric systems are increasingly replacing traditional password- and token-based authentication systems. Security and recognition accuracy are the two most important aspects to consider in designing a biometric system. In this paper, a comprehensive review is presented to shed light on the latest developments in the study of fingerprint-based biometrics covering these two aspects with a view to improving system security and recognition accuracy. Based on a thorough analysis and discussion, limitations of existing research work are outlined and suggestions for future work are provided. It is shown in the paper that researchers continue to face challenges in tackling the two most critical attacks to biometric systems, namely, attacks to the user interface and template databases. How to design proper countermeasures to thwart these attacks, thereby providing strong security and yet at the same time maintaining high recognition accuracy, is a hot research topic currently, as well as in the foreseeable future. Moreover, recognition accuracy under non-ideal conditions is more likely to be unsatisfactory and thus needs particular attention in biometric system design. Related challenges and current research trends are also outlined in this paper.},
	pages = {141},
	number = {2},
	journaltitle = {Symmetry},
	author = {Yang, Wencheng and Wang, Song and Hu, Jiankun and Zheng, Guanglou and Valli, Craig},
	urldate = {2020-11-27},
	date = {2019-02},
	langid = {english},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {biometrics, security, latent fingerprint, recognition accuracy, template protection},
}

@article{galbally_image_2014,
	title = {Image Quality Assessment for Fake Biometric Detection: Application to Iris, Fingerprint, and Face Recognition},
	volume = {23},
	issn = {1941-0042},
	doi = {10.1109/TIP.2013.2292332},
	shorttitle = {Image Quality Assessment for Fake Biometric Detection},
	abstract = {To ensure the actual presence of a real legitimate trait in contrast to a fake self-manufactured synthetic or reconstructed sample is a significant problem in biometric authentication, which requires the development of new and efficient protection measures. In this paper, we present a novel software-based fake detection method that can be used in multiple biometric systems to detect different types of fraudulent access attempts. The objective of the proposed system is to enhance the security of biometric recognition frameworks, by adding liveness assessment in a fast, user-friendly, and non-intrusive manner, through the use of image quality assessment. The proposed approach presents a very low degree of complexity, which makes it suitable for real-time applications, using 25 general image quality features extracted from one image (i.e., the same acquired for authentication purposes) to distinguish between legitimate and impostor samples. The experimental results, obtained on publicly available data sets of fingerprint, iris, and 2D face, show that the proposed method is highly competitive compared with other state-of-the-art approaches and that the analysis of the general image quality of real biometric samples reveals highly valuable information that may be very efficiently used to discriminate them from fake traits.},
	pages = {710--724},
	number = {2},
	journaltitle = {{IEEE} Transactions on Image Processing},
	author = {Galbally, J. and Marcel, S. and Fierrez, J.},
	date = {2014-02},
	note = {Number: 2
Conference Name: {IEEE} Transactions on Image Processing},
	keywords = {Humans, Algorithms, Feature extraction, biometrics, feature extraction, face recognition, security, attacks, Biomedical imaging, biometric authentication, Biometric Identification, biometric recognition framework, countermeasures, Dermatoglyphics, Face, Facial Recognition, fake biometric detection, fingerprint identification, fingerprint recognition, Fingers, Fraud, fraudulent access attempts, Image Interpretation, Computer-Assisted, Image quality, image quality assessment, Image quality assessment, Iris, iris recognition, Iris recognition, liveness assessment, Pattern Recognition, Automated, protection measures, Reproducibility of Results, Security, Sensitivity and Specificity, software based fake detection method},
}

@inproceedings{schons_convolutional_2018,
	location = {Cham},
	title = {Convolutional Network for {EEG}-Based Biometric},
	isbn = {978-3-319-75193-1},
	doi = {10.1007/978-3-319-75193-1_72},
	series = {Lecture Notes in Computer Science},
	abstract = {The global expansion of biometric systems promotes the emergence of new and more robust biometric modalities. In that context, electroencephalogram ({EEG}) based biometric interest has been growing in recent years. In this study, a novel approach for {EEG} representation, based on deep learning, is proposed. The method was evaluated on a database containing 109 subjects, and all 64 {EEG} channels were used as input to a Deep Convolution Neural Network. Data augmentation techniques are explored to train the deep network and results showed that the method is a promising path to represent brain signals, overcoming baseline methods published in the literature.},
	pages = {601--608},
	booktitle = {Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications},
	publisher = {Springer International Publishing},
	author = {Schons, Thiago and Moreira, Gladston J. P. and Silva, Pedro H. L. and Coelho, Vitor N. and Luz, Eduardo J. S.},
	editor = {Mendoza, Marcelo and Velastín, Sergio},
	date = {2018},
	langid = {english},
	keywords = {physionet},
}

@inproceedings{jayarathne_survey_2017,
	title = {Survey of {EEG}-based biometric authentication},
	doi = {10.1109/ICAwST.2017.8256471},
	abstract = {User authentication systems based on {EEG} (electroencephalography) is currently popular, marking an inflection point in the field. Recently, the scientific community has been making tremendous attempts towards perceiving uniqueness of brain signal patterns. Several types of methodical approaches have been proposed and prototyped to analyze {EEG} data with various signal-processing methods and pattern-recognition algorithms. Even though there are many stimulation methods to produce reasonable distinctiveness between subjects, optimization and lowering task complexity are still desirable from techno-economic points of view. With recent technological advancement of {EEG} signal capturing devices, the process is getting comparatively simpler as devices are capable of providing better portability with reduced calibration time. However, most detailed analysis suggests that a minimal number of most appropriate channels should be selected for better results, even if a system is equipped with the most advanced hardware. Researchers are now focusing on implementing computationally low cost systems with better accuracy, regardless of complexity of the tasks. This paper is a review of several approaches, providing an overview of crucial design considerations in handling {EEG} data for extended accuracy and practical applicability to authentication.},
	eventtitle = {2017 {IEEE} 8th International Conference on Awareness Science and Technology ({iCAST})},
	pages = {324--329},
	booktitle = {2017 {IEEE} 8th International Conference on Awareness Science and Technology ({iCAST})},
	author = {Jayarathne, I. and Cohen, M. and Amarakeerthi, S.},
	date = {2017-11},
	note = {{ISSN}: 2325-5994},
	keywords = {{EEG}, Conferences, electroencephalography, Electroencephalography, Electrodes, biometrics, biometrics (access control), Authentication, brain signal patterns, calibration, computationally low cost systems, {EEG} data, {EEG} signal capturing devices, {EEG}-based biometric authentication, inflection point, optimization, pattern recognition, pattern-recognition, pattern-recognition algorithms, reduced calibration time, review, reviews, signal processing, signal-processing methods, stimulation methods, task complexity, user authentication systems},
}

@article{zhang_mindid_2018,
	title = {{MindID}: Person Identification from Brain Waves through Attention-based Recurrent Neural Network},
	volume = {2},
	url = {https://doi.org/10.1145/3264959},
	doi = {10.1145/3264959},
	shorttitle = {{MindID}},
	abstract = {Person identification technology recognizes individuals by exploiting their unique, measurable physiological and behavioral characteristics. However, the state-of-the-art person identification systems have been shown to be vulnerable, e.g., anti-surveillance prosthetic masks can thwart face recognition, contact lenses can trick iris recognition, vocoder can compromise voice identification and fingerprint films can deceive fingerprint sensors. {EEG} (Electroencephalography)-based identification, which utilizes the user's brainwave signals for identification and offers a more resilient solution, has recently drawn a lot of attention. However, the state-of-the-art systems cannot achieve similar accuracy as the aforementioned methods. We propose {MindID}, an {EEG}-based biometric identification approach, with the aim of achieving high accuracy and robust performance. At first, the {EEG} data patterns are analyzed and the results show that the Delta pattern contains the most distinctive information for user identification. Next, the decomposed Delta signals are fed into an attention-based Encoder-Decoder {RNNs} (Recurrent Neural Networks) structure which assigns varying attention weights to different {EEG} channels based on their importance. The discriminative representations learned from the attention-based {RNN} are used to identify the user through a boosting classifier. The proposed approach is evaluated over 3 datasets (two local and one public). One local dataset ({EID}-M) is used for performance assessment and the results illustrate that our model achieves an accuracy of 0.982 and significantly outperforms the state-of-the-art and relevant baselines. The second local dataset ({EID}-S) and a public dataset ({EEG}-S) are utilized to demonstrate the robustness and adaptability, respectively. The results indicate that the proposed approach has the potential to be widely deployed in practical settings.},
	pages = {149:1--149:23},
	number = {3},
	journaltitle = {Proceedings of the {ACM} on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	shortjournal = {Proc. {ACM} Interact. Mob. Wearable Ubiquitous Technol.},
	author = {Zhang, Xiang and Yao, Lina and Kanhere, Salil S. and Liu, Yunhao and Gu, Tao and Chen, Kaixuan},
	urldate = {2020-11-25},
	date = {2018-09-18},
	note = {Number: 3},
	keywords = {{EEG}, deep learning, attention mechanism, biometric identification, {EEG} pattern decomposition},
}

@article{li_brain_nodate,
	title = {Brain Signal Biometrics with Virtual Reality},
	abstract = {The purpose of this research was to determine whether active portions of a person’s brain are influenced by their using Virtual Reality ({VR}) and whether those brain signals can be used for user authentication. Electroencephalography ({EEG}) signals are individually unique and non-trivial to collect. Because of these properties, brain signals are some of the strongest and most secure forms of biometric data. For this study {EEG} signals were collected under two conditions: while subjects were viewing video using a Veer cardboard headset and while viewing video on a traditional laptop screen. During the collection of {EEG} data, subjects started in a resting stage and then entered into an active stage. Brain waves collected for both the resting stage and the active stages were compared for analysis purposes. Pre-processing and feature extraction of {VR} and non-{VR} {EEG} data were performed. Additionally, distance computation was calculated in an attempt to authenticate the identity of the subject and Support Vector Machine ({SVM}) method were used for classification.},
	pages = {6},
	author = {Li, Sukun and Savaliya, Sonal and Marino, Leonard and Koller, Jonathan and Leider, Avery and Tappert, Charles C},
	langid = {english},
}

@article{sooriyaarachchi_musicid_2020,
	title = {{MusicID}: A Brainwave-based User Authentication System for Internet of Things},
	url = {http://arxiv.org/abs/2006.01751},
	shorttitle = {{MusicID}},
	abstract = {We propose {MusicID}, an authentication solution for smart devices that uses music-induced brainwave patterns as a behavioral biometric modality. We experimentally evaluate {MusicID} using data collected from real users whilst they are listening to two forms of music; a popular English song and individual’s favorite song. We show that an accuracy over 98\% for user identiﬁcation and an accuracy over 97\% for user veriﬁcation can be achieved by using data collected from a 4electrode commodity brainwave headset. We further show that a single electrode is able to provide an accuracy of approximately 85\% and the use of two electrodes provides an accuracy of approximately 95\%. As already shown by commodity brainsensing headsets for meditation applications, we believe including dry {EEG} electrodes in smart-headsets is feasible and {MusicID} has the potential of providing an entry point and continuous authentication framework for upcoming surge of smart-devices mainly driven by Augmented Reality ({AR})/Virtual Reality ({VR}) applications.},
	journaltitle = {{arXiv}:2006.01751 [cs, eess]},
	author = {Sooriyaarachchi, Jinani and Seneviratne, Suranga and Thilakarathna, Kanchana and Zomaya, Albert Y.},
	urldate = {2020-11-21},
	date = {2020-06-02},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2006.01751},
	keywords = {Computer Science - Cryptography and Security, Electrical Engineering and Systems Science - Signal Processing},
}

@article{iwasaki_effects_2005,
	title = {Effects of eyelid closure, blinks, and eye movements on the electroencephalogram},
	volume = {116},
	issn = {1388-2457},
	url = {http://www.sciencedirect.com/science/article/pii/S138824570400416X},
	doi = {10.1016/j.clinph.2004.11.001},
	abstract = {Objective
To characterize the effects of the eyeball and eyelid positions during eyeblinks on electroencephalographic ({EEG}) potentials.
Methods
Movements of the upper eyelids and eyes were measured in two healthy subjects using the magnetic search coil technique during horizontal and vertical eye rotations, eyeblinks, and lid closure. Corresponding signal changes were recorded simultaneously on the electroencephalogram ({EEG}).
Results
Spontaneous blinks produced small eye movements directed down and inward, whereas slow or forced blinks were associated with delayed upward eye rotations (i.e. Bell's phenomenon); both types of blinks caused positive {EEG} potentials with bifrontal distribution maximum at Fp1 and Fp2.
Conclusions
In prior reports, these positive {EEG} artifacts have been attributed to upward eyeball rotation during blinks—Bell's phenomenon. By contrast, our findings indicate that movements of the eyelid contribute to a greater extent to these {EEG} potentials than do upward eyeball rotations.
Significance
Care is required in attributing {EEG} artifacts to movements of either eyeball or eyelid, since our findings suggest that they both contribute to these potentials.},
	pages = {878--885},
	number = {4},
	journaltitle = {Clinical Neurophysiology},
	shortjournal = {Clinical Neurophysiology},
	author = {Iwasaki, Masaki and Kellinghaus, Christoph and Alexopoulos, Andreas V. and Burgess, Richard C. and Kumar, Arun N. and Han, Yanning H. and Lüders, Hans O. and Leigh, R. John},
	urldate = {2020-11-21},
	date = {2005-04-01},
	langid = {english},
	note = {Number: 4},
	keywords = {Artifacts, Blinks, Electroencephalogram, Eye movements, Eyelid, Saccades},
}

@inproceedings{pham_multi-factor_2014,
	title = {Multi-factor {EEG}-based user authentication},
	doi = {10.1109/IJCNN.2014.6889569},
	abstract = {Electroencephalography ({EEG}) signal has been used widely in health and medical fields. It is also used in brain-computer interface ({BCI}) systems for humans to continuously control mobile robots and wheelchairs. Recently, the research communities successfully explore the potential of using {EEG} as a new type of biometrics in user authentication. {EEG}-based user authentication systems have the combined advantages of both password-based and biometric-based authentication systems, yet without their drawbacks. In this paper, we propose to take the advantage of rich information, such as age and gender, carried by {EEG} signals for user authentication in multi-level security systems. Our experiments showed very promising results for the proposed multi-factor {EEG}-based authentication method.},
	eventtitle = {2014 International Joint Conference on Neural Networks ({IJCNN})},
	pages = {4029--4034},
	booktitle = {2014 International Joint Conference on Neural Networks ({IJCNN})},
	author = {Pham, T. and Ma, W. and Tran, D. and Nguyen, P. and Phung, D.},
	date = {2014-07},
	note = {{ISSN}: 2161-4407},
	keywords = {brain-computer interfaces, electroencephalography, Electroencephalography, medical signal processing, Brain models, Feature extraction, biometrics, biometrics (access control), Authentication, user authentication, {BCI} systems, brain computer interface, continuously control mobile robots, {EEG} based user authentication systems, {EEG} signal, electroencephalography signal, health fields, medical fields, multifactor {EEG}, multilevel security systems, Testing, wheelchairs},
}

@inproceedings{noauthor_biometric_2010,
	location = {Valencia, Spain},
	title = {{BIOMETRIC} {AUTHENTICATION} {USING} {BRAIN} {RESPONSES} {TO} {VISUAL} {STIMULI}:},
	isbn = {978-989-674-018-4},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0002750101030112},
	doi = {10.5220/0002750101030112},
	shorttitle = {{BIOMETRIC} {AUTHENTICATION} {USING} {BRAIN} {RESPONSES} {TO} {VISUAL} {STIMULI}},
	abstract = {Biometric authentication, Electroencephalograms, Visual evoked potentials.},
	eventtitle = {International Conference on Bio-inspired Systems and Signal Processing},
	pages = {103--112},
	booktitle = {Proceedings of the Third International Conference on Bio-inspired Systems and Signal Processing},
	publisher = {{SciTePress} - Science and and Technology Publications},
	urldate = {2020-11-21},
	date = {2010},
	langid = {english},
}

@article{armstrong_brainprint_2015,
	title = {Brainprint: Assessing the uniqueness, collectability, and permanence of a novel method for {ERP} biometrics},
	volume = {166},
	issn = {0925-2312},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231215004725},
	doi = {10.1016/j.neucom.2015.04.025},
	shorttitle = {Brainprint},
	abstract = {The human brain continually generates electrical potentials representing neural communication. These potentials can be measured at the scalp, and constitute the electroencephalogram ({EEG}). When the {EEG} is time-locked to stimulation – such as the presentation of a word – and averaged over many such presentations, the Event-Related Potential ({ERP}) is obtained. The functional characteristics of components of the {ERP} are well understood, and some components represent processing that may differ uniquely from individual to individual—such as the N400 component, which represents access to the semantic network. We applied several pattern classifiers to {ERPs} representing the response of individuals to a stream of text designed to be idiosyncratically familiar to different individuals. Results indicate that there are robustly identifiable features of the {ERP} that enable labeling of {ERPs} as belonging to individuals with accuracy reliably above chance (in the range of 82–97\%). Further, these features are stable over time, as indicated by continued accurate identification of individuals from {ERPs} after a lag of up to six months. Even better, the high degree of labeling accuracy achieved in all cases was achieved with the use of only 3 electrodes on the scalp—the minimal possible number that can acquire clean data.},
	pages = {59--67},
	journaltitle = {Neurocomputing},
	shortjournal = {Neurocomputing},
	author = {Armstrong, Blair C. and Ruiz-Blondet, Maria V. and Khalifian, Negin and Kurtz, Kenneth J. and Jin, Zhanpeng and Laszlo, Sarah},
	urldate = {2020-11-21},
	date = {2015-10-20},
	langid = {english},
	keywords = {Identification, {EEG}, Biometrics, {SVM}, Authentication, Autoencoder, Cross-Correlation, {DIVA}, Divergent Autoencoder, Event-Related Potentials ({ERPs}), Linear Discriminant, N400, Naive Discriminant Learning, Neural Network, Pattern classification, Verification},
}

@article{rocca_human_2014,
	title = {Human Brain Distinctiveness Based on {EEG} Spectral Coherence Connectivity},
	volume = {61},
	issn = {1558-2531},
	doi = {10.1109/TBME.2014.2317881},
	abstract = {The use of {EEG} biometrics, for the purpose of automatic people recognition, has received increasing attention in the recent years. Most of the current analyses rely on the extraction of features characterizing the activity of single brain regions, like power spectrum estimation, thus neglecting possible temporal dependencies between the generated {EEG} signals. However, important physiological information can be extracted from the way different brain regions are functionally coupled. In this study, we propose a novel approach that fuses spectral coherence-based connectivity between different brain regions as a possibly viable biometric feature. The proposed approach is tested on a large dataset of subjects (N = 108) during eyes-closed ({EC}) and eyes-open ({EO}) resting state conditions. The obtained recognition performance shows that using brain connectivity leads to higher distinctiveness with respect to power-spectrum measurements, in both the experimental conditions. Notably, a 100\% recognition accuracy is obtained in {EC} and {EO} when integrating functional connectivity between regions in the frontal lobe, while a lower 97.5\% is obtained in {EC} (96.26\% in {EO}) when fusing power spectrum information from parieto-occipital (centro-parietal in {EO}) regions. Taken together, these results suggest that the functional connectivity patterns represent effective features for improving {EEG}-based biometric systems.},
	pages = {2406--2412},
	number = {9},
	journaltitle = {{IEEE} Transactions on Biomedical Engineering},
	author = {Rocca, D. L. and Campisi, P. and Vegso, B. and Cserti, P. and Kozmann, G. and Babiloni, F. and Fallani, F. D. V.},
	date = {2014-09},
	note = {Number: 9
Conference Name: {IEEE} Transactions on Biomedical Engineering},
	keywords = {Humans, Brain, electroencephalography, Electroencephalography, neurophysiology, Signal Processing, Computer-Assisted, medical signal processing, Accuracy, bioelectric potentials, Electrodes, Feature extraction, Biometrics, Biometrics (access control), feature extraction, Biometric Identification, authentication, automatic people recognition, brain connectivity, brain regions, Coherence, {EEG} signals, {EEG} spectral coherence connectivity, {EEG}-based biometric systems, electroencephalography ({EEG}), eyes-closed resting state conditions, eyes-open resting state conditions, frontal lobe, functional connectivity, functional connectivity patterns, human brain distinctiveness, match score fusion, parieto-occipital regions, power spectrum estimation, power spectrum information, power-spectrum measurements, resting state, spectral coherence, Vectors, viable biometric feature},
}

@book{sr_classification_2017,
	title = {Classification of Motor Imagery Based {EEG} Signals Using Sparsity Approach},
	isbn = {978-3-319-72037-1},
	abstract = {The advancement in brain-computer interface systems ({BCIs}) gives a new hope to people with special needs in restoring their independence. Since, {BCIs} using motor imagery ({MI}) rhythms provides high degree of freedom, it is been used for many real-time applications, especially for locked-in people. The available {BCIs} using {MI}-based {EEG} signals usually makes use of spatial filtering and powerful classification methods to attain better accuracy and performance. Inter-subject variability and speed of the classifier is still a issue in {MI}-based {BCIs}. To address the aforementioned issues, in this work, we propose a new classification method, spatial filtering based sparsity ({SFS}) approach for {MI}-based {BCIs}. The proposed method makes use of common spatial pattern ({CSP}) to spatially filter the {MI} signals. Then frequency bandpower and wavelet features from the spatially filtered signals are used to bulid two different over-complete dictionary matrix. This dictionary matrix helps to overcome the issue of inter-subject variability. Later, sparse representation based classification is carried out to classify the two-class {MI} signals. We analysed the performance of the proposed approach using publicly available {MI} dataset {IVa} from {BCI} competition {III}. The proposed {SFS} method provides better classification accuracy and runtime than the well-known support vector machine ({SVM}) and logistic regression ({LR}) classification methods. This {SFS} method can be further used to develop a real-time application for people with special needs.},
	pagetotal = {47},
	author = {Sr, Sreeja and Rabha, Joytirmoy and Samanta, Debasis and Mitra, Pabitra and Sarma, Monalisa},
	date = {2017-12-01},
	doi = {10.1007/978-3-319-72038-8_5},
	note = {Pages: 59},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\S7Q5SP24\\Sr et al. - 2017 - Classification of Motor Imagery Based EEG Signals .pdf:application/pdf},
}

@online{noauthor_eeg_nodate,
	title = {{EEG} Motor Movement/Imagery Dataset},
	url = {https://archive.physionet.org/pn4/eegmmidb/},
	urldate = {2020-12-06},
	file = {EEG Motor Movement/Imagery Dataset:C\:\\Users\\miche\\Zotero\\storage\\W9HRP3P5\\eegmmidb.html:text/html},
}

@online{noauthor_downloads_nodate,
	title = {Downloads – Applied Neuroscience, Inc.},
	url = {https://appliedneuroscience.com/downloads/},
	urldate = {2020-12-06},
	langid = {american},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\2RRXW6NW\\downloads.html:text/html},
}

@article{stanley_designing_2019,
	title = {Designing neural networks through neuroevolution},
	volume = {1},
	doi = {10.1038/s42256-018-0006-z},
	abstract = {Deep neural networks have become very successful at certain machine learning tasks partly due to the widely adopted method of training called backpropagation. An alternative way to optimize neural networks is by using evolutionary algorithms, which, fuelled by the increase in computing power, offers a new range of capabilities and modes of learning.},
	journaltitle = {Nature Machine Intelligence},
	shortjournal = {Nature Machine Intelligence},
	author = {Stanley, Kenneth and Clune, Jeff and Lehman, Joel and Miikkulainen, Risto},
	date = {2019-01-07},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\78PLPEZW\\Stanley et al. - 2019 - Designing neural networks through neuroevolution.pdf:application/pdf},
}

@article{gale_state_2019,
	title = {The State of Sparsity in Deep Neural Networks},
	url = {http://arxiv.org/abs/1902.09574},
	abstract = {We rigorously evaluate three state-of-the-art techniques for inducing sparsity in deep neural networks on two large-scale learning tasks: Transformer trained on {WMT} 2014 English-to-German, and {ResNet}-50 trained on {ImageNet}. Across thousands of experiments, we demonstrate that complex techniques (Molchanov et al., 2017; Louizos et al., 2017b) shown to yield high compression rates on smaller datasets perform inconsistently, and that simple magnitude pruning approaches achieve comparable or better results. Additionally, we replicate the experiments performed by (Frankle \& Carbin, 2018) and (Liu et al., 2018) at scale and show that unstructured sparse architectures learned through pruning cannot be trained from scratch to the same test set performance as a model trained with joint sparsification and optimization. Together, these results highlight the need for large-scale benchmarks in the field of model compression. We open-source our code, top performing model checkpoints, and results of all hyperparameter configurations to establish rigorous baselines for future work on compression and sparsification.},
	journaltitle = {{arXiv}:1902.09574 [cs, stat]},
	author = {Gale, Trevor and Elsen, Erich and Hooker, Sara},
	urldate = {2020-12-02},
	date = {2019-02-25},
	eprinttype = {arxiv},
	eprint = {1902.09574},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\miche\\Zotero\\storage\\JJNEWTW9\\1902.html:text/html;arXiv Fulltext PDF:C\:\\Users\\miche\\Zotero\\storage\\44P799VC\\Gale et al. - 2019 - The State of Sparsity in Deep Neural Networks.pdf:application/pdf},
}

@book{camere_materializing_2016,
	title = {Materializing experiential visions into sensory properties: the use of the Experience Map},
	shorttitle = {Materializing experiential visions into sensory properties},
	abstract = {Moving from conceptual design intentions to the materialization in product sensory qualities can be challenging. For Experience-driven designers this transition can be even more difficult, as they need to move from the abstract level of user experience to the concrete level of product features. In this paper, we suggest an approach to progressively deconstruct experiential visions and decrease the level of abstraction. We propose the use of
a tool, namely the Experience Map, which describes five steps to develop a well-refined materialization and maintain a solid correlation with the initial intention. To investigate its value and challenge the approach in design practice, we set up four case studies. The analysis of designers’ attitudes towards the Experience
Map gave insights on its ability to provide a structure for creative thoughts, while suiting different and subjective attitudes of designers. Moreover, the map supports the integration of several different elements and the exploration of alternative design directions to achieve the intended, holistic experience. Some limitations were also highlighted by the case studies, which are discussed in light of future work.},
	author = {Camere, Serena and Schifferstein, Rick and Bordegoni, Monica},
	date = {2016-10-01},
	file = {Camere-MaterializingexperientialvisionsintosensorypropertiesTheuseoftheExperienceMap.pdf:C\:\\Users\\miche\\Zotero\\storage\\V8CXSM7H\\Camere-MaterializingexperientialvisionsintosensorypropertiesTheuseoftheExperienceMap.pdf:application/pdf},
}

@online{noauthor_3_nodate,
	title = {(3) ({PDF}) Materializing experiential visions into sensory properties: the use of the Experience Map},
	url = {https://www.researchgate.net/publication/309415318_Materializing_experiential_visions_into_sensory_properties_the_use_of_the_Experience_Map},
	urldate = {2020-11-22},
	file = {(3) (PDF) Materializing experiential visions into sensory properties\: the use of the Experience Map:C\:\\Users\\miche\\Zotero\\storage\\VLCYF7HZ\\309415318_Materializing_experiential_visions_into_sensory_properties_the_use_of_the_Experience_.html:text/html},
}

@online{noauthor_camere-materializingexperientialvisionsintosensorypropertiestheuseoftheexperiencemappdf_nodate,
	title = {Camere-{MaterializingexperientialvisionsintosensorypropertiesTheuseoftheExperienceMap}.pdf: Multisensory Design (2020-1B)},
	url = {https://canvas.utwente.nl/courses/6250/files/1816554?module_item_id=175588},
	urldate = {2020-11-22},
	file = {Camere-MaterializingexperientialvisionsintosensorypropertiesTheuseoftheExperienceMap.pdf\: Multisensory Design (2020-1B):C\:\\Users\\miche\\Zotero\\storage\\NP75QQDJ\\1816554.html:text/html},
}

@inproceedings{soni_biometric_2016,
	location = {Coimbatore, India},
	title = {Biometric user authentication using brain waves},
	isbn = {978-1-5090-1285-5},
	url = {http://ieeexplore.ieee.org/document/7824888/},
	doi = {10.1109/INVENTIVE.2016.7824888},
	abstract = {Authentication has become an essential part of our everyday lives which is used at almost every place from banks to experimental labs, from car automation to home automation. This authentication is generally provided through systems like passwords, {PIN} codes, card readers. At some places biometrics like ﬁngerprint and retina scans are used. All designed with one purpose; to conﬁrm a person’s identity. Brain wave based authentication is another addition to the wide range of authentication systems, which has many advantages over other authentication systems. With a standard password someone can watch or ’shoulder-surf’ what others type, but no one can watch thoughts. Cards and keys can be lost, but the brain wave is always present. Differently abled persons can’t use systems which uses fingerprints or retina scans but they can use system using brain-waves. This clears that using brain waves as biometric to provide authentication is very beneficial. A system is designed and implemented which allows user to set a pattern of brain waves which must be provided as an unlock pattern to get the access. This pattern can be any combination of eye blink, attention and various brain rhythms like Alpha, Beta, Theta and Delta. The system described in this paper provides two-level authentication. First level of which is brain waves. Once the correct pattern of brain signal is provide the system will ask for a pass key as a second level of authentication. This paper describes the design and implementation of the system.},
	eventtitle = {2016 International Conference on Inventive Computation Technologies ({ICICT})},
	pages = {1--6},
	booktitle = {2016 International Conference on Inventive Computation Technologies ({ICICT})},
	publisher = {{IEEE}},
	author = {Soni, Yashraj S. and Somani, S. B. and Shete, V. V.},
	urldate = {2020-11-21},
	date = {2016-08},
	langid = {english},
	file = {Soni et al. - 2016 - Biometric user authentication using brain waves.pdf:C\:\\Users\\miche\\Zotero\\storage\\G44KJ9GQ\\Soni et al. - 2016 - Biometric user authentication using brain waves.pdf:application/pdf},
}

@article{mohanchandra_using_2013,
	title = {Using Brain Waves as New Biometric Feature for Authenticating a Computer User in Real-Time},
	abstract = {In this paper we propose an Electroencephalogram based Brain Computer Interface as a new modality for Person Authentication and develop a screen lock application that will lock and unlock the computer screen at the users will. The brain waves of the person, recorded in real time are used as password to unlock the screen. Data fusion from 14 sensors of the Emotiv headset is done to enhance the signal features. The power spectral density of the intermingle signals is computed. The channel spectral power in the frequency band of alpha, beta and gamma is used in the classification task. A two stage checking is done to authenticate the user. A proximity value of 0.78 and above is considered a good match. The percentage of accuracy in classification is found to be good. The essence of this work is that the authentication is done in real time based on the meditation task and no external stimulus is used.},
	pages = {9},
	author = {Mohanchandra, Kusuma},
	date = {2013},
	langid = {english},
	file = {Mohanchandra - 2013 - Using Brain Waves as New Biometric Feature for Aut.pdf:C\:\\Users\\miche\\Zotero\\storage\\GSM4PLIK\\Mohanchandra - 2013 - Using Brain Waves as New Biometric Feature for Aut.pdf:application/pdf},
}

@book{soni_biometric_2016-1,
	title = {Biometric user authentication using brain waves},
	abstract = {Authentication has become an essential part of our everyday lives which is used at almost every place from banks to experimental labs, from car automation to home automation. This authentication is generally provided through systems like passwords, {PIN} codes, card readers. At some places biometrics like fingerprint and retina scans are used. All designed with one purpose; to confirm a person's identity. Brain wave based authentication is another addition to the wide range of authentication systems, which has many advantages over other authentication systems. With a standard password someone can watch or ‘shoulder-surf’ what others type, but no one ca n watch thoughts. Cards and keys can be lost, but the brain wave is always present. Differently abled persons can't use systems which uses fingerprints or retina scans but they can use system using brain-waves. This clears that using brain waves as biometric to provide authentication is very beneficial. A system is designed and implemented which allows user to set a pattern of brain waves which must be provided as an unlock pattern to get the access. This pattern can be any combination of eye blink, attention and various brain rhythms like Alpha, Beta, Theta and Delta. The system described in this paper provides two-level authentication. First level of which is brain waves. Once the correct pattern of brain signal is provide the system will ask for a pass key as a second level of authentication. This paper describes the design and implementation of the system.},
	pagetotal = {1},
	author = {Soni, Yashraj and Somani, Sunil and Shete, V.},
	date = {2016-08-01},
	doi = {10.1109/INVENTIVE.2016.7824888},
	note = {Pages: 6},
}

@online{noauthor_wayback_2016,
	title = {Wayback Machine},
	url = {https://web.archive.org/web/20160304190605/https://www2.bc.edu/~russeljm/publications/psyc-bull1991.pdf},
	urldate = {2021-04-22},
	date = {2016-03-04},
	file = {PDF Snapshot:C\:\\Users\\miche\\Zotero\\storage\\RLTY85FP\\2016 - Wayback Machine.pdf:application/pdf},
}

@book{wagner_smart_nodate,
	title = {Smart Sensor Integration: A Framework for Multimodal Emotion Recognition in Real-Time},
	shorttitle = {Smart Sensor Integration},
	abstract = {Affect sensing by machines has been argued as an essential part of next-generation human-computer interaction ({HCI}). To this end, in the recent years a large number of studies have been conducted, which report automatic recognition of emotion as a difficult, but feasible task. However, most effort has been put towards offline analysis, whereas to date only few applications exist, which are able to react to a user’s emotion in real-time. In response to this deficit we introduce a framework we call Smart Sensor Integration ({SSI}), which considerably jump-starts the development of multimodal online emotion recognition ({OER}) systems. In particular {SSI} supports the pattern recognition pipeline by offering tailored tools for data segmentation, feature extraction, and pattern recognition, as well as, tools to apply them offline (training phase) and online (real-time recognition). Furthermore, it has been designed to handle input from various input modalities and to suit the fusion of multimodal information. 1.},
	author = {Wagner, Johannes and André, Elisabeth and Jung, Frank},
	file = {Citeseer - Snapshot:C\:\\Users\\miche\\Zotero\\storage\\HPF6DC56\\summary.html:text/html;Citeseer - Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\6NZMKUYI\\Wagner et al. - Smart Sensor Integration A Framework for Multimod.pdf:application/pdf},
}

@article{amelynck_toward_2012,
	title = {Toward E-Motion-Based Music Retrieval a Study of Affective Gesture Recognition},
	volume = {3},
	issn = {1949-3045},
	doi = {10.1109/T-AFFC.2011.39},
	abstract = {The widespread availability of digitized music collections and mobile music players have enabled us to listen to music during many of our daily activities, such as physical exercise, commuting, relaxation, and many people enjoy this. A practical problem that comes along with the wish to listen to music is that of music retrieval, the selection of desired music from a music collection. In this paper, we propose a new approach to facilitate music retrieval. Modern smart phones are commonly used as music players and are already equipped with inertial sensors that are suitable for obtaining motion information. In the proposed approach, emotion is derived automatically from arm gestures and is used to query a music collection. We derive predictive models for valence and arousal from empirical data, gathered in an experimental setup where inertial data recorded from arm movements are coupled to musical emotion. Part of the experiment is a preliminary study confirming that human subjects are generally capable of recognizing affect from arm gestures. Model validation in the main study confirmed the predictive capabilities of the models.},
	pages = {250--259},
	number = {2},
	journaltitle = {{IEEE} Transactions on Affective Computing},
	author = {Amelynck, D. and Grachten, M. and Noorden, L. van and Leman, M.},
	date = {2012-04},
	note = {Conference Name: {IEEE} Transactions on Affective Computing},
	keywords = {Humans, Feature extraction, Visualization, Acceleration, Affect detection, expressive gestures, human computer interfaces., music retrieval, Observers, Predictive models, Sensors},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\7D7PM3SM\\6112745.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\72GL24CZ\\Amelynck et al. - 2012 - Toward E-Motion-Based Music Retrieval a Study of A.pdf:application/pdf},
}

@article{irrgang_motion_2016,
	title = {From Motion to Emotion: Accelerometer Data Predict Subjective Experience of Music},
	volume = {11},
	doi = {10.1371/journal.pone.0154360},
	shorttitle = {From Motion to Emotion},
	abstract = {Music is often discussed to be emotional because it reflects expressive movements in audible form. Thus, a valid approach to measure musical emotion could be to assess movement stimulated by music. In two experiments we evaluated the discriminative power of mobile-device generated acceleration data produced by free movement during music listening for the prediction of ratings on the Geneva Emotion Music Scales ({GEMS}-9). The quality of prediction for different dimensions of {GEMS} varied between experiments for tenderness (R12(first experiment) = 0.50, R22(second experiment) = 0.39), nostalgia (R12 = 0.42, R22 = 0.30), wonder (R12 = 0.25, R22 = 0.34), sadness (R12 = 0.24, R22 = 0.35), peacefulness (R12 = 0.20, R22 = 0.35) and joy (R12 = 0.19, R22 = 0.33) and transcendence (R12 = 0.14, R22 = 0.00). For others like power (R12 = 0.42, R22 = 0.49) and tension (R12 = 0.28, R22 = 0.27) results could be almost reproduced. Furthermore, we extracted two principle components from {GEMS} ratings, one representing arousal and the other one valence of the experienced feeling. Both qualities, arousal and valence, could be predicted by acceleration data, indicating, that they provide information on the quantity and quality of experience. On the one hand, these findings show how music-evoked movement patterns relate to music-evoked feelings. On the other hand, they contribute to integrate findings from the field of embodied music cognition into music recommender systems.},
	pages = {e0154360},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Irrgang, Melanie and Egermann, Hauke},
	date = {2016-07-14},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\EGY9WG5B\\Irrgang e Egermann - 2016 - From Motion to Emotion Accelerometer Data Predict.pdf:application/pdf},
}

@article{morgan_using_2015,
	title = {Using affective and behavioural sensors to explore aspects of collaborative music making},
	volume = {82},
	issn = {1071-5819},
	url = {https://www.sciencedirect.com/science/article/pii/S1071581915000853},
	doi = {10.1016/j.ijhcs.2015.05.002},
	abstract = {Our research considers the role that new technologies could play in supporting emotional and non-verbal interactions between musicians during co-present music making. To gain a better understanding of the underlying affective and communicative processes that occur during such interactions, we carried out an exploratory study where we collected self-report and continuous behavioural and physiological measures from pairs of improvising drummers. Our analyses revealed interesting relationships between creative decisions and changes in heart rate. Self-reported measures of creativity, engagement, and energy were correlated with body motion; whilst {EEG} beta-band activity was correlated with self-reported positivity and leadership. Regarding co-visibility, lack of visual contact between musicians had a negative influence on self reported creativity. The number of glances between musicians was positively correlated with rhythmic synchrony, and the average length of glances was correlated with self-reported boredom. Our results indicate that {ECG}, motion, and glance measurements could be particularly suitable for the investigation of collaborative music making.},
	pages = {31--47},
	journaltitle = {International Journal of Human-Computer Studies},
	shortjournal = {International Journal of Human-Computer Studies},
	author = {Morgan, Evan and Gunes, Hatice and Bryan-Kinns, Nick},
	urldate = {2021-03-30},
	date = {2015-10-01},
	langid = {english},
	keywords = {Creativity, Affect, Collaboration, Improvisation, Music, Psychophysiology},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\3TTXZXBF\\S1071581915000853.html:text/html;Submitted Version:C\:\\Users\\miche\\Zotero\\storage\\TELZLUM3\\Morgan et al. - 2015 - Using affective and behavioural sensors to explore.pdf:application/pdf},
}

@inproceedings{shibata_emotion_2012,
	title = {Emotion recognition modeling of sitting postures by using pressure sensors and accelerometers},
	abstract = {Not only facial expressions but also body gestures and postures play an important role in non-verbal communication. Facial expressions are based on two factors: arousal and pleasant emotions, while it is not clear that body gestures and postures have the same structure as the facial expressions have. We indicate that (1) the sitting postures have the same emotion structure as facial expressions and (2) can be measured by pressure sensors on a chair and accelerometers on the body, which predict the emotion factors. We find the sitting postures have the semantic factors: "arousal", "pleasantness", and "dominance", so emotion expressions of the sitting postures are similar to those of the facial expressions. Their difference is "dominance" expressed by not the main body but the body parts such as arms and legs. We conclude that (1) "arousal" and "pleasantness" factors can be measured with the proposed sensors and (2) the body trunk and the body parts: neck, arms, and legs are important.},
	eventtitle = {Proceedings of the 21st International Conference on Pattern Recognition ({ICPR}2012)},
	pages = {1124--1127},
	booktitle = {Proceedings of the 21st International Conference on Pattern Recognition ({ICPR}2012)},
	author = {Shibata, T. and Kijima, Y.},
	date = {2012-11},
	note = {{ISSN}: 1051-4651},
	keywords = {Face, Sensors, Accelerometers, Legged locomotion, Neck, Pressure measurement, Semantics},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\WXXDPKNG\\Shibata e Kijima - 2012 - Emotion recognition modeling of sitting postures b.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\V9Q2XRDA\\6460334.html:text/html},
}

@inproceedings{quiroz_emotion-recognition_2017,
	location = {New York, {NY}, {USA}},
	title = {Emotion-recognition using smart watch accelerometer data: preliminary findings},
	isbn = {978-1-4503-5190-4},
	url = {https://doi.org/10.1145/3123024.3125614},
	doi = {10.1145/3123024.3125614},
	series = {{UbiComp} '17},
	shorttitle = {Emotion-recognition using smart watch accelerometer data},
	abstract = {This study investigates the use of accelerometer data from a smart watch to infer an individual's emotional state. We present our preliminary findings on a user study with 50 participants. Participants were primed either with audio-visual (movie clips) or audio (classical music) to elicit emotional responses. Participants then walked while wearing a smart watch on one wrist and a heart rate strap on their chest. Our hypothesis is that the accelerometer signal will exhibit different patterns for participants in response to different emotion priming. We divided the accelerometer data using sliding windows, extracted features from each window, and used the features to train supervised machine learning algorithms to infer an individual's emotion from their walking pattern. Our discussion includes a description of the methodology, data collected, and early results.},
	pages = {805--812},
	booktitle = {Proceedings of the 2017 {ACM} International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 {ACM} International Symposium on Wearable Computers},
	publisher = {Association for Computing Machinery},
	author = {Quiroz, Juan C. and Yong, Min Hooi and Geangu, Elena},
	urldate = {2021-03-30},
	date = {2017-09-11},
	keywords = {accelerometer, emotion-recognition, supervised learning},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\VBM6UTJM\\Quiroz et al. - 2017 - Emotion-recognition using smart watch acceleromete.pdf:application/pdf},
}

@online{noauthor_top_2014,
	title = {Top 7 Weirdest {EEG} Applications - Neuroelectrics Neuroelectrics Blog - Latest news about {EEG} \& Brain Stimulation},
	url = {https://www.neuroelectrics.com/blog/2014/12/18/top-7-weirdest-eeg-applications/},
	abstract = {As we know, the main uses of {EEG} include diagnosis and neurofeedback therapy (including {BCI}). Theses applications falls into the clinical realm, but...},
	titleaddon = {Neuroelectrics Blog - Latest news about {EEG} \& Brain Stimulation},
	urldate = {2021-03-29},
	date = {2014-12-18},
	langid = {american},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\3PET9YFU\\top-7-weirdest-eeg-applications.html:text/html},
}

@book{poli_towards_2013,
	title = {Towards cooperative brain-computer interfaces for space navigation},
	isbn = {978-1-4503-1965-2},
	abstract = {We explored the possibility of controlling a spacecraft simulator using an analogue Brain-Computer Interface ({BCI}) for 2-D pointer control. This is a difficult task, for which no previous attempt has been reported in the literature. Our system relies on an active display which produces event-related potentials ({ERPs}) in the user's brain. These are analysed in real-time to produce control vectors for the user interface. In tests, users of the simulator were told to pass as close as possible to the Sun. Performance was very promising, on average users managing to satisfy the simulation success criterion in 67.5\% of the runs. Furthermore, to study the potential of a collaborative approach to spacecraft navigation, we developed {BCIs} where the system is controlled via the integration of the {ERPs} of two users. Performance analysis indicates that collaborative {BCIs} produce trajectories that are statistically significantly superior to those obtained by single users.},
	pagetotal = {149},
	author = {Poli, Riccardo and Cinel, Caterina and Matran-Fernandez, Ana and Sepulveda, Francisco and Stoica, Adrian},
	date = {2013-03-19},
	doi = {10.1145/2449396.2449417},
	note = {Journal Abbreviation: International Conference on Intelligent User Interfaces, Proceedings {IUI}
Pages: 160
Publication Title: International Conference on Intelligent User Interfaces, Proceedings {IUI}},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\5KA3MKMV\\Poli et al. - 2013 - Towards cooperative brain-computer interfaces for .pdf:application/pdf},
}

@article{stevens_neurophysiologic_2010,
	title = {A Neurophysiologic Approach For Studying Team Cognition},
	pages = {7},
	author = {Stevens, Ron and Galloway, Trysha and Berka, Chris and Behneman, Adrienne},
	date = {2010},
	langid = {english},
	file = {Stevens et al. - 2010 - A Neurophysiologic Approach For Studying Team Cogn.pdf:C\:\\Users\\miche\\Zotero\\storage\\P7QX7TYI\\Stevens et al. - 2010 - A Neurophysiologic Approach For Studying Team Cogn.pdf:application/pdf},
}

@article{bonnet_two_2013,
	title = {Two Brains, One Game: Design and Evaluation of a Multiuser {BCI} Video Game Based on Motor Imagery},
	volume = {5},
	issn = {1943-068X, 1943-0698},
	url = {http://ieeexplore.ieee.org/document/6400237/},
	doi = {10.1109/TCIAIG.2012.2237173},
	shorttitle = {Two Brains, One Game},
	abstract = {How can we connect two brains to a video game by means of a {BCI}, and what will happen when we do so? How will the two users behave, and how will they perceive this novel common experience? In this paper we are concerned with the design and evaluation of multi-user {BCI} applications. We created a multi-user videogame called “{BrainArena}” in which two users can play a simple football game by means of two {BCIs}. They can score goals on the left or right side of the screen by simply imagining left or right hand movements. To add another interesting element, the gamers can play in a collaborative manner (their two mental activities are combined to score in the same goal), or in a competitive manner (the gamers must push the ball in opposite directions). Two experiments were conducted to evaluate the performance and subjective experience of users in the different conditions. In the ﬁrst experiment we compared single-user situation with one multiuser situation: the collaborative task. Experiment 1 showed that multi-user conditions are signiﬁcantly preferred in terms of fun and motivation compared to the single-user condition. The performance of some users was even signiﬁcantly improved in the multi-user condition. A subset of well-performing subjects was involved in the second experiment, where we added the competitive task. Experiment 2 suggested that competitive and collaborative conditions may lead to similar performances and motivations. However the corresponding gaming experiences can be perceived differently among the participants. Taken together our results suggest that multi-user {BCI} applications can be operational, effective, and more engaging for participants.},
	pages = {185--198},
	number = {2},
	journaltitle = {{IEEE} Transactions on Computational Intelligence and {AI} in Games},
	shortjournal = {{IEEE} Trans. Comput. Intell. {AI} Games},
	author = {Bonnet, Laurent and Lotte, Fabien and Lecuyer, Anatole},
	urldate = {2021-03-28},
	date = {2013-06},
	langid = {english},
	file = {Bonnet et al. - 2013 - Two Brains, One Game Design and Evaluation of a M.pdf:C\:\\Users\\miche\\Zotero\\storage\\75HAZYTJ\\Bonnet et al. - 2013 - Two Brains, One Game Design and Evaluation of a M.pdf:application/pdf},
}

@article{lin_eeg-based_2010,
	title = {{EEG}-Based Emotion Recognition in Music Listening},
	volume = {57},
	issn = {1558-2531},
	doi = {10.1109/TBME.2010.2048568},
	abstract = {Ongoing brain activity can be recorded as electroen-cephalograph ({EEG}) to discover the links between emotional states and brain activity. This study applied machine-learning algorithms to categorize {EEG} dynamics according to subject self-reported emotional states during music listening. A framework was proposed to optimize {EEG}-based emotion recognition by systematically 1) seeking emotion-specific {EEG} features and 2) exploring the efficacy of the classifiers. Support vector machine was employed to classify four emotional states (joy, anger, sadness, and pleasure) and obtained an averaged classification accuracy of 82.29\% ± 3.06\% across 26 subjects. Further, this study identified 30 subject-independent features that were most relevant to emotional processing across subjects and explored the feasibility of using fewer electrodes to characterize the {EEG} dynamics during music listening. The identified features were primarily derived from electrodes placed near the frontal and the parietal lobes, consistent with many of the findings in the literature. This study might lead to a practical system for noninvasive assessment of the emotional states in practical or clinical applications.},
	pages = {1798--1806},
	number = {7},
	journaltitle = {{IEEE} Transactions on Biomedical Engineering},
	author = {Lin, Y. and Wang, C. and Jung, T. and Wu, T. and Jeng, S. and Duann, J. and Chen, J.},
	date = {2010-07},
	note = {Conference Name: {IEEE} Transactions on Biomedical Engineering},
	keywords = {Humans, {EEG}, Brain, Electroencephalography, Electrodes, Support vector machines, Electromyography, emotion, Emotion recognition, Hospitals, {IEEE} activities, machine learning, music, Support vector machine classification},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\QXVMPPQN\\Lin et al. - 2010 - EEG-Based Emotion Recognition in Music Listening.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\7WAAPQNY\\5458075.html:text/html},
}

@inproceedings{lin_eeg-based_2009,
	title = {{EEG}-based emotion recognition in music listening: A comparison of schemes for multiclass support vector machine},
	doi = {10.1109/ICASSP.2009.4959627},
	shorttitle = {{EEG}-based emotion recognition in music listening},
	abstract = {Currently, how to equip machines with the ability for properly recognizing users' felt-emotion during multimedia presentation is a growing issue. In this study we focused on the approach for recognizing music-induced emotional responses from brain activity. A comparative study was conducted to testify the feasibility of using hierarchical binary classifiers to improve the classification performance as compared with nonhierarchical schemes. According to our classification results, we not only found that using one-against-one scheme of hierarchical binary classifier results in an improvement to performance, but also established an alternative solution for emotion recognition by proposed model-based scheme depending on 2D emotion model.},
	eventtitle = {2009 {IEEE} International Conference on Acoustics, Speech and Signal Processing},
	pages = {489--492},
	booktitle = {2009 {IEEE} International Conference on Acoustics, Speech and Signal Processing},
	author = {Lin, Y. and Wang, C. and Wu, T. and Jeng, S. and Chen, J.},
	date = {2009-04},
	note = {{ISSN}: 2379-190X},
	keywords = {Humans, Brain, electroencephalography, Electroencephalography, Neural networks, brain activity, support vector machines, Support vector machines, Emotion recognition, Hospitals, music, Brain activity, Data acquisition, {EEG}-based emotion recognition, emotion recognition, multiclass support vector machine, Multilayer perceptrons, multimedia presentation, Multiple signal classification, music listening, music-induced emotional responses},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\PMGNNMZ8\\4959627.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\B35SUXUE\\Lin et al. - 2009 - EEG-based emotion recognition in music listening .pdf:application/pdf;EEG-based_emotion_recognition_in_music_listening_A_comparison_of_schemes_for_multiclass_support_vector_machine.pdf:C\:\\Users\\miche\\Zotero\\storage\\IJD79NZK\\EEG-based_emotion_recognition_in_music_listening_A_comparison_of_schemes_for_multiclass_support_vector_machine.pdf:application/pdf},
}

@article{lin_eeg-based_2010-1,
	title = {{EEG}-Based Emotion Recognition in Music Listening},
	volume = {57},
	issn = {1558-2531},
	doi = {10.1109/TBME.2010.2048568},
	abstract = {Ongoing brain activity can be recorded as electroen-cephalograph ({EEG}) to discover the links between emotional states and brain activity. This study applied machine-learning algorithms to categorize {EEG} dynamics according to subject self-reported emotional states during music listening. A framework was proposed to optimize {EEG}-based emotion recognition by systematically 1) seeking emotion-specific {EEG} features and 2) exploring the efficacy of the classifiers. Support vector machine was employed to classify four emotional states (joy, anger, sadness, and pleasure) and obtained an averaged classification accuracy of 82.29\% ± 3.06\% across 26 subjects. Further, this study identified 30 subject-independent features that were most relevant to emotional processing across subjects and explored the feasibility of using fewer electrodes to characterize the {EEG} dynamics during music listening. The identified features were primarily derived from electrodes placed near the frontal and the parietal lobes, consistent with many of the findings in the literature. This study might lead to a practical system for noninvasive assessment of the emotional states in practical or clinical applications.},
	pages = {1798--1806},
	number = {7},
	journaltitle = {{IEEE} Transactions on Biomedical Engineering},
	author = {Lin, Y. and Wang, C. and Jung, T. and Wu, T. and Jeng, S. and Duann, J. and Chen, J.},
	date = {2010-07},
	note = {Conference Name: {IEEE} Transactions on Biomedical Engineering},
	keywords = {Female, Humans, Male, {EEG}, Brain, electroencephalography, Electroencephalography, Signal Processing, Computer-Assisted, learning (artificial intelligence), medical signal processing, Algorithms, Electrodes, brain activity, support vector machines, Support vector machines, Adult, Pattern Recognition, Automated, frontal lobe, Music, Electromyography, emotion, Emotion recognition, Hospitals, {IEEE} activities, machine learning, music, Support vector machine classification, emotion recognition, music listening, Artificial Intelligence, auditory evoked potentials, Bayes Theorem, {EEG} based emotion recognition, emotional state, Emotions, Evoked Potentials, Auditory, machine learning algorithm, parietal lobe, support vector machine},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\TUTH6T9G\\5458075.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\6LGIFXRJ\\Lin et al. - 2010 - EEG-Based Emotion Recognition in Music Listening.pdf:application/pdf},
}

@article{hasanzadeh_continuous_2019,
	title = {Continuous Emotion Recognition during Music Listening Using {EEG} Signals: A Fuzzy Parallel Cascades Model},
	url = {http://arxiv.org/abs/1910.10489},
	shorttitle = {Continuous Emotion Recognition during Music Listening Using {EEG} Signals},
	abstract = {A controversial issue in artificial intelligence is human emotion recognition. This paper presents a fuzzy parallel cascades ({FPC}) model for predicting the continuous subjective appraisal of the emotional content of music by time-varying spectral content of {EEG} signals. The {EEG}, along with an emotional appraisal of 15 subjects, was recorded during listening to seven musical excerpts. The emotional appraisement was recorded along the valence and arousal emotional axes as a continuous signal. The {FPC} model was composed of parallel cascades with each cascade containing a fuzzy logic-based system. The {FPC} model performance was evaluated by comparing with linear regression ({LR}), support vector regression ({SVR}) and Long Short Term Memory recurrent neural network ({LSTM} {RNN}) models. The {RMSE} of the {FPC} was lower than other models for the estimation of both valence and arousal of all musical excerpts. The lowest {RMSE} was 0.089 which was obtained in estimation of the valence of {MS}4 by the {FPC} model. The analysis of {MI} of frontal {EEG} with the valence confirms the role of frontal channels in theta frequency band in emotion recognition. Considering the dynamic variations of musical features during songs, employing a modeling approach to predict dynamic variations of the emotional appraisal can be a plausible substitute for the classification of musical excerpts into predefined labels.},
	journaltitle = {{arXiv}:1910.10489 [cs, eess, q-bio]},
	author = {Hasanzadeh, Fatemeh and Annabestani, Mohsen and Moghimi, Sahar},
	urldate = {2021-03-24},
	date = {2019-10-19},
	eprinttype = {arxiv},
	eprint = {1910.10489},
	keywords = {Electrical Engineering and Systems Science - Signal Processing, Computer Science - Human-Computer Interaction, Quantitative Biology - Neurons and Cognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\miche\\Zotero\\storage\\3M249A7M\\Hasanzadeh et al. - 2019 - Continuous Emotion Recognition during Music Listen.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\miche\\Zotero\\storage\\UVEXN2BZ\\1910.html:text/html},
}

@inproceedings{zhang_pmemo_2018,
	location = {New York, {NY}, {USA}},
	title = {The {PMEmo} Dataset for Music Emotion Recognition},
	isbn = {978-1-4503-5046-4},
	url = {https://doi.org/10.1145/3206025.3206037},
	doi = {10.1145/3206025.3206037},
	series = {{ICMR} '18},
	abstract = {Music Emotion Recognition ({MER}) has recently received considerable attention. To support the {MER} research which requires large music content libraries, we present the {PMEmo} dataset containing emotion annotations of 794 songs as well as the simultaneous electrodermal activity ({EDA}) signals. A Music Emotion Experiment was well-designed for collecting the affective-annotated music corpus of high quality, which recruited 457 subjects. The dataset is publically available to the research community, which is foremost intended for benchmarking in music emotion retrieval and recognition. To straightforwardly evaluate the methodologies for music affective analysis, it also involves pre-computed audio feature sets. In addition to that, manually selected chorus excerpts (compressed in {MP}3) of songs are provided to facilitate the development of chorus-related research. In this article, We describe in detail the resource acquisition, subject selection, experiment design and annotation collection procedures, as well as the dataset content and data reliability analysis. We also illustrate its usage in some simple music emotion recognition tasks which testified the {PMEmo} dataset's competence for the {MER} work. Compared to other homogeneous datasets, {PMEmo} is novel in the organization and management of the recruited annotators, and it is also characterized by its large amount of music with simultaneous physiological signals.},
	pages = {135--142},
	booktitle = {Proceedings of the 2018 {ACM} on International Conference on Multimedia Retrieval},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Kejun and Zhang, Hui and Li, Simeng and Yang, Changyuan and Sun, Lingyun},
	urldate = {2021-03-24},
	date = {2018-06-05},
	keywords = {dataset, eda, experiment, music emotion recognition},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\3WQCH7B2\\Zhang et al. - 2018 - The PMEmo Dataset for Music Emotion Recognition.pdf:application/pdf},
}

@article{hasson_neurocinematics_2008,
	title = {Neurocinematics: The Neuroscience of Film},
	volume = {2},
	doi = {10.3167/proj.2008.020102},
	shorttitle = {Neurocinematics},
	abstract = {This article describes a new method for assessing the effect of a given film on viewers' brain activity. Brain activity was measured using functional magnetic resonance imaging ({fMRI}) during free viewing of films, and inter-subject correlation analysis ({ISC}) was used to assess similarities in the spatiotemporal responses across viewers' brains during movie watching. Our results demonstrate that some films can exert considerable control over brain activity and eye movements. However, this was not the case for all types of motion picture sequences, and the level of control over viewers' brain activity differed as a function of movie content, editing, and directing style. We propose that {ISC} may be useful to film studies by providing a quantitative neuroscientific assessment of the impact of different styles of filmmaking on viewers' brains, and a valuable method for the film industry to better assess its products. Finally, we suggest that this method brings together two separate and largely unrelated disciplines, cognitive neuroscience and film studies, and may open the way for a new interdisciplinary field of “neurocinematic” studies.},
	pages = {1--26},
	journaltitle = {Projections},
	shortjournal = {Projections},
	author = {Hasson, Uri and Landesman, Ohad and Knappmeyer, Barbara and Vallines, Ignacio and Rubin, Nava and Heeger, David},
	date = {2008-06-01},
	file = {Submitted Version:C\:\\Users\\miche\\Zotero\\storage\\DNEYE46X\\Hasson et al. - 2008 - Neurocinematics The Neuroscience of Film.pdf:application/pdf},
}

@incollection{chisik_kessel_2018,
	location = {Cham},
	title = {Kessel Run - A Cooperative Multiplayer {SSVEP} {BCI} Game},
	volume = {215},
	isbn = {978-3-319-73061-5 978-3-319-73062-2},
	url = {http://link.springer.com/10.1007/978-3-319-73062-2_6},
	pages = {77--95},
	booktitle = {Intelligent Technologies for Interactive Entertainment},
	publisher = {Springer International Publishing},
	author = {Cruz, Inês and Moreira, Carlos and Poel, Mannes and Ferreira, Hugo and Nijholt, Anton},
	editor = {Chisik, Yoram and Holopainen, Jussi and Khaled, Rilla and Luis Silva, José and Alexandra Silva, Paula},
	urldate = {2021-03-21},
	date = {2018},
	doi = {10.1007/978-3-319-73062-2_6},
	note = {Series Title: Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
}

@incollection{chisik_kessel_2018-1,
	location = {Cham},
	title = {Kessel Run - A Cooperative Multiplayer {SSVEP} {BCI} Game},
	volume = {215},
	isbn = {978-3-319-73061-5 978-3-319-73062-2},
	url = {http://link.springer.com/10.1007/978-3-319-73062-2_6},
	pages = {77--95},
	booktitle = {Intelligent Technologies for Interactive Entertainment},
	publisher = {Springer International Publishing},
	author = {Cruz, Inês and Moreira, Carlos and Poel, Mannes and Ferreira, Hugo and Nijholt, Anton},
	editor = {Chisik, Yoram and Holopainen, Jussi and Khaled, Rilla and Luis Silva, José and Alexandra Silva, Paula},
	urldate = {2021-03-21},
	date = {2018},
	doi = {10.1007/978-3-319-73062-2_6},
	note = {Series Title: Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
	file = {Cruz et al. - 2018 - Kessel Run - A Cooperative Multiplayer SSVEP BCI G.pdf:C\:\\Users\\miche\\Zotero\\storage\\TFQBUQFW\\Cruz et al. - 2018 - Kessel Run - A Cooperative Multiplayer SSVEP BCI G.pdf:application/pdf},
}

@article{dikker_crowdsourcing_2021-1,
	title = {Crowdsourcing neuroscience: Inter-brain coupling during face-to-face interactions outside the laboratory},
	volume = {227},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811920309216},
	doi = {10.1016/j.neuroimage.2020.117436},
	shorttitle = {Crowdsourcing neuroscience},
	abstract = {When we feel connected or engaged during social behavior, are our brains in fact “in sync” in a formal, quantifiable sense? Most studies addressing this question use highly controlled tasks with homogenous subject pools. In an effort to take a more naturalistic approach, we collaborated with art institutions to crowdsource neuroscience data: Over the course of 5 years, we collected electroencephalogram ({EEG}) data from thousands of museum and festival visitors who volunteered to engage in a 10-min face-to-face interaction. Pairs of participants with various levels of familiarity sat inside the Mutual Wave Machine—an artistic neurofeedback installation that translates real-time correlations of each pair's {EEG} activity into light patterns. Because such inter-participant {EEG} correlations are prone to noise contamination, in subsequent offline analyses we computed inter-brain coupling using Imaginary Coherence and Projected Power Correlations, two synchrony metrics that are largely immune to instantaneous, noise-driven correlations. When applying these methods to two subsets of recorded data with the most consistent protocols, we found that pairs’ trait empathy, social closeness, engagement, and social behavior (joint action and eye contact) consistently predicted the extent to which their brain activity became synchronized, most prominently in low alpha ({\textasciitilde}7–10 Hz) and beta ({\textasciitilde}20–22 Hz) oscillations. These findings support an account where shared engagement and joint action drive coupled neural activity and behavior during dynamic, naturalistic social interactions. To our knowledge, this work constitutes a first demonstration that an interdisciplinary, real-world, crowdsourcing neuroscience approach may provide a promising method to collect large, rich datasets pertaining to real-life face-to-face interactions. Additionally, it is a demonstration of how the general public can participate and engage in the scientific process outside of the laboratory. Institutions such as museums, galleries, or any other organization where the public actively engages out of self-motivation, can help facilitate this type of citizen science research, and support the collection of large datasets under scientifically controlled experimental conditions. To further enhance the public interest for the out-of-the-lab experimental approach, the data and results of this study are disseminated through a website tailored to the general public (wp.nyu.edu/mutualwavemachine).},
	pages = {117436},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Dikker, Suzanne and Michalareas, Georgios and Oostrik, Matthias and Serafimaki, Amalia and Kahraman, Hasibe Melda and Struiksma, Marijn E. and Poeppel, David},
	urldate = {2021-03-21},
	date = {2021-02-15},
	langid = {english},
	keywords = {Brain-Computer-Interface Technology, Brain-to-brain synchrony, Hyperscanning, Inter-brain coupling, Neurofeedback, Oscillations, Real-world neuroscience},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\GI3AKKT2\\S1053811920309216.html:text/html;ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\G5N59JBD\\Dikker et al. - 2021 - Crowdsourcing neuroscience Inter-brain coupling d.pdf:application/pdf},
}

@incollection{nijholt_competing_2014,
	title = {Competing and Collaborating Brains: Multi-Brain Computer Interfacing},
	volume = {74},
	isbn = {978-3-319-10977-0},
	shorttitle = {Competing and Collaborating Brains},
	abstract = {In this chapter we survey the possibilities of brain-computer interface applications that assume two or more users, where at least one of the users’ brain activity is used as input to the application. Such ‘applications’ were already explored by artists who introduced artistic {EEG} applications in the early ‘seventies’ of the previous century. These early explorations were not yet supported by advanced signal process methods, simply because there was no computing support possible, and interest in artistic applications faded until it reappeared in more recent years. Research in neuroscience, signal processing, machine learning and applications in medical, assistive {BCIs} prevailed. It was supported by computer science that provided real-time and off-line processing to analyze and store large amounts of streaming or collected data. With the possibility to access cheap shared and distributed storage and processing power, as it became available in the last decade of the previous century and the first decade of this century, different kinds of {BCI} applications, following a general interest in digital games, interactive entertainment and social media, became visible. These are domains where experience, fun and emotions are more important than efficiency, robustness and control. {BCI} provides user and application with a new modality that can be manipulated and interpreted, in addition to other input modalities. This has been explored, but mostly from the point of view of a single user interacting with an application. In this chapter we look at {BCI} applications where more than one user is involved. Games are among the possible applications and there are already simple games where gamers compete or collaborate using brain signal information from one or more players. We consider extensions of current applications by looking at different types of multi-user games, including massively multi-player online role-playing games. We mention research —distinguishing between active and passive {BCI}—on multi-participant {BCI} in non-game contexts that provides us with information about the possibilities of collaborative and competitive multi-brain games and that allows us to develop a vision on such games. The results of the literature study are collected in a table where we distinguish between the various forms of interaction between players (participants) in collaborative and competitive games and team activities.},
	pages = {313--335},
	booktitle = {Intelligent Systems Reference Library},
	author = {Nijholt, Anton},
	date = {2014-11-02},
	doi = {10.1007/978-3-319-10978-7_12},
	note = {Journal Abbreviation: Intelligent Systems Reference Library},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\Y424UXLM\\Nijholt - 2014 - Competing and Collaborating Brains Multi-Brain Co.pdf:application/pdf},
}

@inproceedings{nijholt_multi-brain_2016,
	location = {Cham},
	title = {Multi-Brain {BCI}: Characteristics and Social Interactions},
	isbn = {978-3-319-39955-3},
	doi = {10.1007/978-3-319-39955-3_8},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Multi-Brain {BCI}},
	abstract = {We investigate various forms of face-to-face and multiparty interactions in the context of potential brain-computer interface interactions ({BCI}). {BCI} has been employed in clinical applications but more recently also in domestic and game and entertainment applications. This paper focusses on multi-party game applications. That is, {BCI} game applications that allow multiple users and different {BCI} paradigms to get a cooperative or competitive task done. Our observations are quite preliminary and not yet supported by experimental research. Nevertheless we think we have put forward steps to structure future {BCI} game research and to make connections with neuro-scientific social interaction research.},
	pages = {79--90},
	booktitle = {Foundations of Augmented Cognition: Neuroergonomics and Operational Neuroscience},
	publisher = {Springer International Publishing},
	author = {Nijholt, Anton and Poel, Mannes},
	editor = {Schmorrow, Dylan D. and Fidopiastis, Cali M.},
	date = {2016},
	langid = {english},
	keywords = {Games, Affective computing, Brain-computer interfaces, Hyper scanning, Multi-brain computing, Neuroscience of social interaction},
	file = {Springer Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\PW8PAIF7\\Nijholt e Poel - 2016 - Multi-Brain BCI Characteristics and Social Intera.pdf:application/pdf},
}

@article{salimpoor_anatomically_2011,
	title = {Anatomically distinct dopamine release during anticipation and experience of peak emotion to music},
	volume = {14},
	doi = {10.1038/nn.2726},
	abstract = {Music, an abstract stimulus, can arouse feelings of euphoria and craving, similar to tangible rewards that involve the striatal dopaminergic system. Using the neurochemical specificity of [(11)C]raclopride positron emission tomography scanning, combined with psychophysiological measures of autonomic nervous system activity, we found endogenous dopamine release in the striatum at peak emotional arousal during music listening. To examine the time course of dopamine release, we used functional magnetic resonance imaging with the same stimuli and listeners, and found a functional dissociation: the caudate was more involved during the anticipation and the nucleus accumbens was more involved during the experience of peak emotional responses to music. These results indicate that intense pleasure in response to music can lead to dopamine release in the striatal system. Notably, the anticipation of an abstract reward can result in dopamine release in an anatomical pathway distinct from that associated with the peak pleasure itself. Our results help to explain why music is of such high value across all human societies.},
	pages = {257--62},
	journaltitle = {Nature neuroscience},
	shortjournal = {Nature neuroscience},
	author = {Salimpoor, Valorie and Benovoy, Mitchel and Larcher, Kevin and Dagher, Alain and Zatorre, Robert},
	date = {2011-02-01},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\ETQLM87Z\\Salimpoor et al. - 2011 - Anatomically distinct dopamine release during anti.pdf:application/pdf},
}

@article{higuchi_approach_1988,
	title = {Approach to an irregular time series on the basis of the fractal theory},
	volume = {31},
	issn = {0167-2789},
	url = {https://www.sciencedirect.com/science/article/pii/0167278988900814},
	doi = {10.1016/0167-2789(88)90081-4},
	abstract = {We present a technique to measure the fractal dimension of the set of points (t, f(t)) forming the graph of a function f defined on the unit interval. First we apply it to a fractional Brownian function [1] which has a property of self-similarity for all scales, and we can get the stable and precise fractal dimension. This technique is also applied to the observational data of natural phenomena. It does not show self-similarity all over the scale but has a different self-similarity across the characteristic time scale. The present method gives us a stable characteristic time scale as well as the fractal dimension.},
	pages = {277--283},
	number = {2},
	journaltitle = {Physica D: Nonlinear Phenomena},
	shortjournal = {Physica D: Nonlinear Phenomena},
	author = {Higuchi, T.},
	urldate = {2021-03-17},
	date = {1988-06-01},
	langid = {english},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\SNZPKBP2\\0167278988900814.html:text/html;ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\RYUL8FKJ\\Higuchi - 1988 - Approach to an irregular time series on the basis .pdf:application/pdf},
}

@article{avramidis_multiscale_2021,
	title = {Multiscale Fractal Analysis on {EEG} Signals for Music-Induced Emotion Recognition},
	url = {http://arxiv.org/abs/2010.16310},
	abstract = {Emotion Recognition from {EEG} signals has long been researched as it can assist numerous medical and rehabilitative applications. However, their complex and noisy structure has proven to be a serious barrier for traditional modeling methods. In this paper, we employ multifractal analysis to examine the behavior of {EEG} signals in terms of presence of fluctuations and the degree of fragmentation along their major frequency bands, for the task of emotion recognition. In order to extract emotion-related features we utilize two novel algorithms for {EEG} analysis, based on Multiscale Fractal Dimension and Multifractal Detrended Fluctuation Analysis. The proposed feature extraction methods perform efficiently, surpassing some widely used baseline features on the competitive {DEAP} dataset, indicating that multifractal analysis could serve as basis for the development of robust models for affective state recognition.},
	journaltitle = {{arXiv}:2010.16310 [cs]},
	author = {Avramidis, Kleanthis and Zlatintsi, Athanasia and Garoufis, Christos and Maragos, Petros},
	urldate = {2021-03-17},
	date = {2021-03-02},
	eprinttype = {arxiv},
	eprint = {2010.16310},
	keywords = {Computer Science - Machine Learning, Computer Science - Information Retrieval},
	file = {arXiv.org Snapshot:C\:\\Users\\miche\\Zotero\\storage\\FZYHCG45\\2010.html:text/html;arXiv Fulltext PDF:C\:\\Users\\miche\\Zotero\\storage\\ID9V422X\\Avramidis et al. - 2021 - Multiscale Fractal Analysis on EEG Signals for Mus.pdf:application/pdf},
}

@book{christensen_eeg_2018,
	title = {{EEG} emotion detection review},
	pagetotal = {1},
	author = {Christensen, Lars and Abdullah, Mohamed},
	date = {2018-05-01},
	doi = {10.1109/CIBCB.2018.8404976},
	note = {Pages: 7},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\DXAAE54H\\Christensen e Abdullah - 2018 - EEG emotion detection review.pdf:application/pdf},
}

@article{chang_personalized_2017,
	title = {A personalized music recommendation system based on electroencephalography feedback},
	volume = {76},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-015-3202-4},
	doi = {10.1007/s11042-015-3202-4},
	abstract = {Numerous domestic and foreign studies have demonstrated that music can relieve stress and that listening to music is one method of stress relief used presently. Although stress-relief music is available on the market, various music genres produce distinct effects on people. Clinical findings have indicated that approximately 30 \% of people listen to inappropriate music genres for relaxation and, consequently, their stress level increases. Therefore, to achieve the effect of stress relief, choosing the appropriate music genre is crucial. For example, a 70-year-old woman living in a military community since childhood might not consider general stress-relief music to be helpful in relieving stress, but when patriotic songs are played, her autonomic nervous system automatically relaxes because of her familiarity with the music style. Therefore, people have dissimilar needs regarding stress-relief music. In this paper, we proposed a personalized stress-relieving music recommendation system based on electroencephalography ({EEG}) feedback. The system structure comprises the following features: (a) automated music categorization, in which a new clustering algorithm, K-{MeansH}, is employed to precluster music and improve processing time; (b) the access and analysis of users’ {EEG} data to identify perceived stress-relieving music; and (c) personalized recommendations based on collaborative filtering and provided according to personal preferences. Experimental results indicated that the overall clustering effect of K-{MeansH} surpassed that of K-Means and K-Medoids by approximately 71 and 57 \%, respectively. In terms of accuracy, K-{MeansH} also surpassed K-Means and K-Medoids.},
	pages = {19523--19542},
	number = {19},
	journaltitle = {Multimedia Tools and Applications},
	shortjournal = {Multimed Tools Appl},
	author = {Chang, Hong-Yi and Huang, Shih-Chang and Wu, Jia-Hao},
	urldate = {2021-03-11},
	date = {2017-10-01},
	langid = {english},
	file = {Springer Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\BGL9MES2\\Chang et al. - 2017 - A personalized music recommendation system based o.pdf:application/pdf},
}

@article{abdul_emotion-aware_2018,
	title = {An Emotion-Aware Personalized Music Recommendation System Using a Convolutional Neural Networks Approach},
	volume = {8},
	doi = {10.3390/app8071103},
	abstract = {Recommending music based on a user's music preference is a way to improve user listening experience. Finding the correlation between the user data (e.g., location, time of the day, music listening history, emotion, etc.) and the music is a challenging task. In this paper, we propose an emotion-aware personalized music recommendation system ({EPMRS}) to extract the correlation between the user data and the music. To achieve this correlation, we combine the outputs of two approaches: the deep convolutional neural networks ({DCNN}) approach and the weighted feature extraction ({WFE}) approach. The {DCNN} approach is used to extract the latent features from music data (e.g., audio signals and corresponding metadata) for classification. In the {WFE} approach, we generate the implicit user rating for music to extract the correlation between the user data and the music data. In the {WFE} approach, we use the term-frequency and inverse document frequency ({TF}-{IDF}) approach to generate the implicit user ratings for the music. Later, the {EPMRS} recommends songs to the user based on calculated implicit user rating for the music. We use the million songs dataset ({MSD}) to train the {EPMRS}. For performance comparison, we take the content similarity music recommendation system ({CSMRS}) as well as the personalized music recommendation system based on electroencephalography feedback ({PMRSE}) as the baseline systems. Experimental results show that the {EPMRS} produces better accuracy of music recommendations than the {CSMRS} and the {PMRSE}. Moreover, we build the Android and {iOS} {APPs} to get realistic data of user experience on the {EPMRS}. The collected feedback from anonymous users also show that the {EPMRS} sufficiently reflect their preference on music.},
	pages = {1103},
	journaltitle = {Applied Sciences},
	shortjournal = {Applied Sciences},
	author = {Abdul, Ashu and Chen, Jenhui and Liao, Hua-Yuan and Chang, Shun-Hao},
	date = {2018-07-08},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\A4T3B3SZ\\Abdul et al. - 2018 - An Emotion-Aware Personalized Music Recommendation.pdf:application/pdf},
}

@article{keelawat_comparative_2021,
	title = {A Comparative Study of Window Size and Channel Arrangement on {EEG}-Emotion Recognition Using Deep {CNN}},
	volume = {21},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/21/5/1678},
	doi = {10.3390/s21051678},
	abstract = {Emotion recognition based on electroencephalograms has become an active research area. Yet, identifying emotions using only brainwaves is still very challenging, especially the subject-independent task. Numerous studies have tried to propose methods to recognize emotions, including machine learning techniques like convolutional neural network ({CNN}). Since {CNN} has shown its potential in generalization to unseen subjects, manipulating {CNN} hyperparameters like the window size and electrode order might be beneficial. To our knowledge, this is the first work that extensively observed the parameter selection effect on the {CNN}. The temporal information in distinct window sizes was found to significantly affect the recognition performance, and {CNN} was found to be more responsive to changing window sizes than the support vector machine. Classifying the arousal achieved the best performance with a window size of ten seconds, obtaining 56.85\% accuracy and a Matthews correlation coefficient ({MCC}) of 0.1369. Valence recognition had the best performance with a window length of eight seconds at 73.34\% accuracy and an {MCC} value of 0.4669. Spatial information from varying the electrode orders had a small effect on the classification. Overall, valence results had a much more superior performance than arousal results, which were, perhaps, influenced by features related to brain activity asymmetry between the left and right hemispheres.},
	pages = {1678},
	number = {5},
	journaltitle = {Sensors},
	author = {Keelawat, Panayu and Thammasan, Nattapong and Numao, Masayuki and Kijsirikul, Boonserm},
	urldate = {2021-03-11},
	date = {2021-01},
	langid = {english},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {{EEG}, machine learning, emotion recognition, brainwave, {CNN}, electrode order, neuroscience, spatiotemporal data, window size},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\F68EEJEX\\1678.html:text/html;Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\JF4QZCF8\\sensors-21-01678-v2.pdf:application/pdf},
}

@article{keelawat_spatiotemporal_2019,
	title = {Spatiotemporal Emotion Recognition using Deep {CNN} Based on {EEG} during Music Listening},
	url = {http://arxiv.org/abs/1910.09719},
	abstract = {Emotion recognition based on {EEG} has become an active research area. As one of the machine learning models, {CNN} has been utilized to solve diverse problems including issues in this domain. In this work, a study of {CNN} and its spatiotemporal feature extraction has been conducted in order to explore capabilities of the model in varied window sizes and electrode orders. Our investigation was conducted in subject-independent fashion. Results have shown that temporal information in distinct window sizes significantly affects recognition performance in both 10-fold and leave-one-subject-out cross validation. Spatial information from varying electrode order has modicum effect on classification. {SVM} classifier depending on spatiotemporal knowledge on the same dataset was previously employed and compared to these empirical results. Even though {CNN} and {SVM} have a homologous trend in window size effect, {CNN} outperformed {SVM} using leave-one-subject-out cross validation. This could be caused by different extracted features in the elicitation process.},
	journaltitle = {{arXiv}:1910.09719 [cs, eess, stat]},
	author = {Keelawat, Panayu and Thammasan, Nattapong and Numao, Masayuki and Kijsirikul, Boonserm},
	urldate = {2021-03-11},
	date = {2019-10-21},
	eprinttype = {arxiv},
	eprint = {1910.09719},
	keywords = {Electrical Engineering and Systems Science - Signal Processing, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Human-Computer Interaction},
	file = {arXiv Fulltext PDF:C\:\\Users\\miche\\Zotero\\storage\\8E9DSVGG\\Keelawat et al. - 2019 - Spatiotemporal Emotion Recognition using Deep CNN .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\miche\\Zotero\\storage\\ZTRFQF29\\1910.html:text/html},
}

@article{schmidt_frontal_2001,
	title = {Frontal brain electrical activity ({EEG}) distinguishes valence and intensity of musical emotions},
	volume = {15},
	issn = {0269-9931},
	url = {https://doi.org/10.1080/02699930126048},
	doi = {10.1080/02699930126048},
	abstract = {Using recent regional brain activation/emotion models as a theoretical framework, we examined whether the pattern of regional {EEG} activity distinguished emotions induced by musical excerpts which were known to vary in affective valence (i.e., positive vs. negative) and intensity (i.e., intense vs. calm) in a group of undergraduates. We found that the pattern of asymmetrical frontal {EEG} activity distinguished valence of the musical excerpts. Subjects exhibited greater relative left frontal {EEG} activity to joy and happy musical excerpts and greater relative right frontal {EEG} activity to fear and sad musical excerpts. We also found that, although the pattern of frontal {EEG} asymmetry did not distinguish the intensity of the emotions, the pattern of overall frontal {EEG} activity did, with the amount of frontal activity decreasing from fear to joy to happy to sad excerpts. These data appear to be the first to distinguish valence and intensity of musical emotions on frontal electrocortical measures.},
	pages = {487--500},
	number = {4},
	journaltitle = {Cognition and Emotion},
	author = {Schmidt, Louis A. and Trainor, Laurel J.},
	urldate = {2021-03-07},
	date = {2001-07-01},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/02699930126048},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\6SW9N35B\\02699930126048.html:text/html;Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\9UPX9UWP\\Schmidt and Trainor - 2001 - Frontal brain electrical activity (EEG) distinguis.pdf:application/pdf},
}

@article{schmidt_frontal_2001-1,
	title = {Frontal brain electrical activity ({EEG}) distinguishes valence and intensity of musical emotions},
	volume = {15},
	issn = {0269-9931},
	url = {https://doi.org/10.1080/02699930126048},
	doi = {10.1080/02699930126048},
	abstract = {Using recent regional brain activation/emotion models as a theoretical framework, we examined whether the pattern of regional {EEG} activity distinguished emotions induced by musical excerpts which were known to vary in affective valence (i.e., positive vs. negative) and intensity (i.e., intense vs. calm) in a group of undergraduates. We found that the pattern of asymmetrical frontal {EEG} activity distinguished valence of the musical excerpts. Subjects exhibited greater relative left frontal {EEG} activity to joy and happy musical excerpts and greater relative right frontal {EEG} activity to fear and sad musical excerpts. We also found that, although the pattern of frontal {EEG} asymmetry did not distinguish the intensity of the emotions, the pattern of overall frontal {EEG} activity did, with the amount of frontal activity decreasing from fear to joy to happy to sad excerpts. These data appear to be the first to distinguish valence and intensity of musical emotions on frontal electrocortical measures.},
	pages = {487--500},
	number = {4},
	journaltitle = {Cognition and Emotion},
	author = {Schmidt, Louis A. and Trainor, Laurel J.},
	urldate = {2021-03-07},
	date = {2001-07-01},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/02699930126048},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\WYBV3F8J\\02699930126048.html:text/html},
}

@online{november_16_what_nodate,
	title = {What is an ultrasonic cleaner and should you buy one?},
	url = {https://www.cyclingnews.com/features/what-is-an-ultrasonic-cleaner-and-should-you-buy-one/},
	abstract = {Is an ultrasonic cleaner the ultimate in drivetrain cleaning or does it come up a few chain scrubbers short?},
	titleaddon = {cyclingnews.com},
	author = {November 16, Colin Levitch and {2020}},
	urldate = {2021-01-28},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\WQ6CUH4Z\\what-is-an-ultrasonic-cleaner-and-should-you-buy-one.html:text/html},
}

@online{reports_ultrasonic_2020,
	title = {Ultrasonic Cleaning Market Trends, Industry Analysis, Growth},
	url = {https://www.openpr.com/news/2198754/ultrasonic-cleaning-market-trends-industry-analysis-growth},
	abstract = {Press release - Orion Market Reports - Ultrasonic Cleaning Market Trends, Industry Analysis, Growth and Forecast - 2025 - published on {openPR}.com},
	author = {Reports, Orion Market},
	urldate = {2021-01-28},
	date = {2020-11-30},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\LYKF2CUJ\\ultrasonic-cleaning-market-trends-industry-analysis-growth.html:text/html},
}

@article{maiorana_permanence_2016,
	title = {On the Permanence of {EEG} Signals for Biometric Recognition},
	volume = {11},
	issn = {1556-6021},
	doi = {10.1109/TIFS.2015.2481870},
	abstract = {Brain signals have been investigated for more than a century in the medical field. However, despite the broad interest in clinical applications, their use as a biometric identifier has been only recently considered by the scientific community. In this paper, we focus on the permanence across time of brain signals, specifically of electroencephalographic ({EEG}) signals, issue of paramount importance for the deployment of brain-based biometric recognition systems in real life, not yet fully addressed. In particular, we speculate about the stability of {EEG} features by analyzing the recognition performance that can be achieved when comparing {EEG} signals acquired during different sessions. We carry out an extensive set of experimental tests, performed on several {EEG}-based biometric systems over a large database, comprising three recordings taken from 50 healthy subjects in resting state conditions, acquired in a time span of approximately one month and a half. The results confirm that a significant level of permanence can be guaranteed.},
	pages = {163--175},
	number = {1},
	journaltitle = {{IEEE} Transactions on Information Forensics and Security},
	author = {Maiorana, E. and Rocca, D. La and Campisi, P.},
	date = {2016-01},
	note = {Conference Name: {IEEE} Transactions on Information Forensics and Security},
	keywords = {electroencephalography, Electroencephalography, Brain modeling, medical signal processing, Electrodes, Feature extraction, Biometrics, Databases, Biometrics (access control), biometrics (access control), {EEG} signal, biometric identifier, biometric recognition, brain signal, clinical application, database, Database, electroencephalographic signal, permanence, Permanence, Scalp},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\KTXCMT6H\\7275167.html:text/html;Maiorana et al. - 2016 - On the Permanence of EEG Signals for Biometric Rec.html:C\:\\Users\\miche\\Zotero\\storage\\KS24Z3IT\\Maiorana et al. - 2016 - On the Permanence of EEG Signals for Biometric Rec.html:text/html;Maiorana et al. - 2016 - On the Permanence of EEG Signals for Biometric Rec.pdf:C\:\\Users\\miche\\Zotero\\storage\\8H8J7MXI\\Maiorana et al. - 2016 - On the Permanence of EEG Signals for Biometric Rec.pdf:application/pdf},
}

@article{bellet_metric_2015,
	title = {Metric Learning},
	volume = {9},
	issn = {1939-4608},
	url = {https://www.morganclaypool.com/doi/abs/10.2200/S00626ED1V01Y201501AIM030},
	doi = {10.2200/S00626ED1V01Y201501AIM030},
	pages = {1--151},
	number = {1},
	journaltitle = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
	author = {Bellet, Aurélien and Habrard, Amaury and Sebban, Marc},
	urldate = {2020-12-05},
	date = {2015-01-15},
	note = {Number: 1
Publisher: Morgan \& Claypool Publishers},
}

@book{plass-oude_bos_human-computer_2010,
	title = {Human-Computer Interaction for {BCI} Games Usability and User Experience},
	abstract = {Brain-computer interfaces ({BCI}) come with a lot of issues, such as delays, bad recognition, long training times, and cumbersome hardware. Gamers are a large potential target group for this new interaction modality, but why would healthy subjects want to use it? {BCI} provides a combination of information and features that no other input modality can offer. But for general acceptance of this technology, usability and user experience will need to be taken into account when designing such systems. This paper discusses the consequences of applying knowledge from Human-Computer Interaction ({HCI}) to the design of {BCI} for games. The integration of {HCI} with {BCI} is illustrated by research examples and showcases, intended to take this promising technology out of the lab. Future research needs to move beyond feasibility tests, to prove that {BCI} is also applicable in realistic, real-world settings.},
	pagetotal = {277},
	author = {Plass-Oude Bos, Danny and Reuderink, Boris and Laar, Bram and Gürkök, Hayrettin and Mühl, Christian and Poel, Mannes and Heylen, Dirk and Nijholt, Anton},
	date = {2010-10-01},
	doi = {10.1109/CW.2010.22},
	note = {Journal Abbreviation: Proceedings - 2010 International Conference on Cyberworlds, {CW} 2010
Pages: 281
Publication Title: Proceedings - 2010 International Conference on Cyberworlds, {CW} 2010},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\KMVW2EWW\\Plass-Oude Bos et al. - 2010 - Human-Computer Interaction for BCI Games Usability.pdf:application/pdf;Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\RCG4GXS3\\Plass-Oude Bos et al. - 2010 - Human-Computer Interaction for BCI Games Usability.pdf:application/pdf},
}

@article{skola_embodied_2018,
	title = {Embodied {VR} environment facilitates motor imagery brain–computer interface training},
	volume = {75},
	issn = {0097-8493},
	url = {http://www.sciencedirect.com/science/article/pii/S009784931830089X},
	doi = {10.1016/j.cag.2018.05.024},
	abstract = {Motor imagery ({MI}) is the predominant control paradigm for brain–computer interfaces ({BCIs}). After sufficient effort is invested to the training, the accuracy of commands mediated by mental imagery of bodily movements grows to a satisfactory level. However, many issues with the {MI}-{BCIs} persist; e.g., low bit transfer rate, {BCI} illiteracy, sub-optimal training procedure. Especially the training process for the {MI}-{BCIs} requires improvements. Currently, the training has an inappropriate form, resulting in a high mental and temporal demand on the users (weeks of training are required for the control). This study aims at addressing the issues with the {MI}-{BCI} training. To support the learning process, an embodied training environment was created. Participants were placed into a virtual reality environment observed from a first-person view of a human-like avatar, and their rehearsal of {MI} actions was reflected by the corresponding movements performed by the avatar. Leveraging extension of the sense of ownership, agency, and self-location towards a non-body object (principles known from the rubber hand illusion and the body transfer illusions) has already been proven to help in producing stronger {EEG} correlates of {MI}. These principles were used to facilitate the {MI}-{BCI} training process for the first time. Performance of 30 healthy participants after two sessions of training was measured using an on-line {BCI} scenario. The group trained using our embodied {VR} environment gained significantly higher average accuracy for {BCI} actions (58.3\%) than the control group, trained with a standard {MI}-{BCI} training protocol (52.9\%).},
	pages = {59--71},
	journaltitle = {Computers \& Graphics},
	shortjournal = {Computers \& Graphics},
	author = {Škola, Filip and Liarokapis, Fotis},
	urldate = {2021-01-25},
	date = {2018-10-01},
	langid = {english},
	keywords = {Body transfer illusion, Brain–Computer interfaces, Embodiment, Motor imagery, Rubber hand illusion, Virtual reality},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\HTHJVKLE\\S009784931830089X.html:text/html;ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\5K9UD382\\Škola e Liarokapis - 2018 - Embodied VR environment facilitates motor imagery .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\4PZ9KNH9\\S009784931830089X.html:text/html;ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\D9PWUU2E\\Škola e Liarokapis - 2018 - Embodied VR environment facilitates motor imagery .pdf:application/pdf},
}

@article{wen_deep_2018,
	title = {Deep Convolution Neural Network and Autoencoders-Based Unsupervised Feature Learning of {EEG} Signals},
	volume = {6},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2018.2833746},
	abstract = {Epilepsy is a health problem that seriously affects the quality of humans for many years. Therefore, it is important to accurately analyze and recognize epilepsy based on {EEG} signals, and for a long time, researchers have attempted to extract new features from the signals for epilepsy recognition. However, it is very difficult to select useful features from a large number of them in this diagnostic application. As the development of artificial intelligence progresses, unsupervised feature learning based on the deep learning model can obtain features that can better describe identified objects from unlabeled data. In this paper, the deep convolution network and autoencoders-based model, named as {AE}-{CDNN}, is constructed in order to perform unsupervised feature learning from {EEG} in epilepsy. We extract features by {AE}-{CDNN} model and classify the features based on two public {EEG} data sets. Experimental results showed that the classification results of features obtained by {AE}-{CDNN} are more optimal than features obtained by principal component analysis and sparse random projection. Using several common classifiers to classify features obtained by {AE}-{CDNN} model results in high accuracy and not inferior to the research results from most recent studies. The results also showed that the features of {AE}-{CDNN} model are clear, effective, and easy to learn. These features can speed up the convergence and reduce the training times of classifiers. Therefore, the {AE}-{CDNN} model can be effectively applied to feature extraction of {EEG} in epilepsy.},
	pages = {25399--25410},
	journaltitle = {{IEEE} Access},
	author = {Wen, T. and Zhang, Z.},
	date = {2018},
	note = {Conference Name: {IEEE} Access},
	keywords = {{EEG}, electroencephalography, Electroencephalography, Training, Brain modeling, Convolution, diseases, learning (artificial intelligence), medical signal processing, Feature extraction, random processes, signal classification, feature extraction, {EEG} signals, {CNN}, {AE}-{CDNN} model, artificial intelligence, autoencoders-based model, convergence, Deconvolution, deep convolution network, deep learning model, Epilepsy, epilepsy recognition, epileptic seizure, feature classification, feedforward neural nets, principal component analysis, sparse random projection, unsupervised feature learning, unsupervised learning},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\SM2834V9\\8355473.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\TSBU4XKV\\Wen and Zhang - 2018 - Deep Convolution Neural Network and Autoencoders-B.pdf:application/pdf},
}

@online{noauthor_deap_nodate,
	title = {{DEAP}: A Dataset for Emotion Analysis using Physiological and Audiovisual Signals},
	url = {http://www.eecs.qmul.ac.uk/mmv/datasets/deap/},
	urldate = {2020-12-06},
	file = {DEAP\: A Dataset for Emotion Analysis using Physiological and Audiovisual Signals:C\:\\Users\\miche\\Zotero\\storage\\KDNUPMCC\\deap.html:text/html;DEAP\: A Dataset for Emotion Analysis using Physiological and Audiovisual Signals:C\:\\Users\\miche\\Zotero\\storage\\AE349ND2\\deap.html:text/html},
}

@article{koelstra_deap_2012,
	title = {{DEAP}: A Database for Emotion Analysis ;Using Physiological Signals},
	volume = {3},
	issn = {1949-3045},
	doi = {10.1109/T-AFFC.2011.15},
	shorttitle = {{DEAP}},
	abstract = {We present a multimodal data set for the analysis of human affective states. The electroencephalogram ({EEG}) and peripheral physiological signals of 32 participants were recorded as each watched 40 one-minute long excerpts of music videos. Participants rated each video in terms of the levels of arousal, valence, like/dislike, dominance, and familiarity. For 22 of the 32 participants, frontal face video was also recorded. A novel method for stimuli selection is proposed using retrieval by affective tags from the last.fm website, video highlight detection, and an online assessment tool. An extensive analysis of the participants' ratings during the experiment is presented. Correlates between the {EEG} signal frequencies and the participants' ratings are investigated. Methods and results are presented for single-trial classification of arousal, valence, and like/dislike ratings using the modalities of {EEG}, peripheral physiological signals, and multimedia content analysis. Finally, decision fusion of the classification results from different modalities is performed. The data set is made publicly available and we encourage other researchers to use it for testing their own affective state estimation methods.},
	pages = {18--31},
	number = {1},
	journaltitle = {{IEEE} Transactions on Affective Computing},
	author = {Koelstra, S. and Muhl, C. and Soleymani, M. and Lee, J. and Yazdani, A. and Ebrahimi, T. and Pun, T. and Nijholt, A. and Patras, I.},
	date = {2012-01},
	note = {Number: 1
Conference Name: {IEEE} Transactions on Affective Computing},
	keywords = {{EEG}, electroencephalography, Electroencephalography, neurophysiology, Databases, Web sites, Visualization, electroencephalogram, pattern classification, Face, signal processing, emotion recognition, affective computing., arousal, {DEAP}, decision fusion, dominance, {EEG} signal frequencies, emotion analysis, Emotion classification, familiarity, frontal face video, human affective states, image classification, information retrieval, Motion pictures, Multimedia communication, multimedia computing, multimedia content analysis, multimodal data set, music videos, online assessment tool, peripheral physiological signals, physiological signals, single-trial classification, state estimation, state estimation methods, stimuli selection, video highlight detection, video signal processing, Videos, Web site},
	file = {Koelstra et al. - 2012 - DEAP A Database for Emotion Analysis \;Using Physi.pdf:C\:\\Users\\miche\\Zotero\\storage\\JJ2YUZLL\\Koelstra et al. - 2012 - DEAP A Database for Emotion Analysis \;Using Physi.pdf:application/pdf},
}

@article{lcuyer_brain-computer_2008,
	title = {Brain-Computer Interfaces, Virtual Reality, and Videogames},
	volume = {41},
	doi = {10.1109/MC.2008.410},
	abstract = {{BCIs} offer a new means of playing videogames or interacting with 3D virtual environments. Several impressive prototypes already exist that let users navigate in virtual scenes or manipulate virtual objects solely by means of their cerebral activity, recorded on the scalp via electroencephalography electrodes. Meanwhile, virtual reality technologies provide motivating, safe, and controlled conditions that enable improvement of {BCI} learning as well as the investigation of the brain responses and neural processes involved. Over the long term, these innovations could lead to newer applications, such as novel types of neurorehabilitation.},
	pages = {66--72},
	journaltitle = {Computer},
	shortjournal = {Computer},
	author = {L?cuyer, Anatole and Lotte, Fabien and Reilly, Richard and Leeb, Robert and Hirose, Michitaka and Slater, Mel},
	date = {2008-11-01},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\ZGLXPZ52\\Lcuyer et al. - 2008 - Brain-Computer Interfaces, Virtual Reality, and Vi.pdf:application/pdf;Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\T5KPTALI\\Lcuyer et al. - 2008 - Brain-Computer Interfaces, Virtual Reality, and Vi.pdf:application/pdf},
}

@article{campisi_brain_2014,
	title = {Brain waves for automatic biometric-based user recognition},
	volume = {9},
	issn = {1556-6013, 1556-6021},
	url = {http://ieeexplore.ieee.org/document/6748964/},
	doi = {10.1109/TIFS.2014.2308640},
	abstract = {Brain signals have been investigated within the medical ﬁeld for more than a century to study brain diseases like epilepsy, spinal cord injuries, Alzheimer’s, Parkinson’s, schizophrenia, and stroke among the others. They are also used in both brain computer and brain machine interface systems with assistance, rehabilitative, and entertainment applications. Despite the broad interest in clinical applications, the use of brain signals has been only recently investigated by the scientiﬁc community as a biometric characteristic to be used in automatic people recognition systems. However, brain signals present some peculiarities, not shared by the most commonly used biometrics, like face, iris, and ﬁngerprints, with reference to privacy compliance, robustness against spooﬁng attacks, possibility to perform continuous identiﬁcation, intrinsic liveness detection, and universality. These peculiarities make the use of brain signals appealing. On the other hand there are many challenges which need to be properly addressed. Among them, the understanding of the level of uniqueness and permanence of brain responses, the design of elicitation protocols, the invasiveness of the acquisition process are only few of the challenges which need to be tackled. In this paper we further speculate on those issues which represent an obstacle towards the deployment of biometric systems based on the analysis of brain activity in real life applications and intend to provide a critical and comprehensive review of state-ofthe-art methods for electroencephalogram based automatic user recognition, also reporting neurophysiological evidences related to the performed claims.},
	pages = {782--800},
	number = {5},
	journaltitle = {{IEEE} Transactions on Information Forensics and Security},
	shortjournal = {{IEEE} Trans.Inform.Forensic Secur.},
	author = {Campisi, Patrizio and La Rocca, Daria},
	urldate = {2020-11-21},
	date = {2014-05},
	langid = {english},
	keywords = {{EEG}, Brain, brain-computer interfaces, electroencephalography, Electroencephalography, neurophysiology, Electrodes, Feature extraction, Visualization, biometrics (access control), brain waves, review, authentication, brain signal, Scalp, acquisition process, assistance applications, automatic biometric-based user recognition, biometric characteristic, biometric system deployment, brain activity analysis, brain computer interface system, brain diseases, brain machine interface system, brain response, brain rhythms, clinical applications, continuous identification, data privacy, electroencephalogram-based automatic user recognition, elicitation protocol, elicitation protocols, entertainment application, intrinsic liveness detection, invasiveness, neurophysiological evidence, overview, peculiarity, privacy compliance, protocols, Protocols, rehabilitative application, spoofing attacks},
	file = {Campisi e La Rocca - 2014 - Brain waves for automatic biometric-based user rec.pdf:C\:\\Users\\miche\\Zotero\\storage\\HESR4UAB\\Campisi e La Rocca - 2014 - Brain waves for automatic biometric-based user rec.pdf:application/pdf},
}

@article{wilaiprasitporn_affective_2020,
	title = {Affective {EEG}-Based Person Identification Using the Deep Learning Approach},
	volume = {12},
	issn = {2379-8939},
	doi = {10.1109/TCDS.2019.2924648},
	abstract = {Electroencephalography ({EEG}) is another method for performing person identification ({PI}). Due to the nature of the {EEG} signals, {EEG}-based {PI} is typically done while a person is performing a mental task such as motor control. However, few studies used {EEG}-based {PI} while the person is in different mental states (affective {EEG}). The aim of this paper is to improve the performance of affective {EEG}-based {PI} using a deep learning ({DL}) approach. We proposed a cascade of {DL} using a combination of convolutional neural networks ({CNNs}) and recurrent neural networks ({RNNs}). {CNNs} are used to handle the spatial information from the {EEG} while {RNNs} extract the temporal information. We evaluated two types of {RNNs}, namely long short-term memory ({LSTM}) and gated recurrent unit ({GRU}). The proposed method is evaluated on the state-of-the-art affective data set {DEAP}. The results indicate that {CNN}-{GRU} and {CNN}-{LSTM} can perform {PI} from different affective states and reach up to 99.90\%-100\% mean correct recognition rate. This significantly outperformed a support vector machine baseline system that used power spectral density features. Notably, the 100\% mean {CRR} came from 32 subjects in {DEAP} data set. Even after the reduction of the number of {EEG} electrodes from 32 to 5 for more practical applications, the model could still maintain an optimal result obtained from the frontal region, reaching up to 99.17\%. Amongst the two {DL} models, we found that {CNN}-{GRU} and {CNN}-{LSTM} performed similarly while {CNN}-{GRU} expended faster training time. In conclusion, the studied {DL} approaches overcame the influence of affective states in {EEG}-Based {PI} reported in the previous works.},
	pages = {486--496},
	number = {3},
	journaltitle = {{IEEE} Transactions on Cognitive and Developmental Systems},
	author = {Wilaiprasitporn, T. and Ditthapron, A. and Matchaparn, K. and Tongbuasirilai, T. and Banluesombatkul, N. and Chuangsuwanich, E.},
	date = {2020-09},
	note = {Conference Name: {IEEE} Transactions on Cognitive and Developmental Systems},
	keywords = {electroencephalography, Electroencephalography, Deep learning, Brain modeling, deep learning approach, learning (artificial intelligence), medical signal processing, convolutional neural networks, Feature extraction, signal classification, biometrics, Biometrics (access control), feature extraction, support vector machines, electroencephalography ({EEG}), Affective computing, affective data, affective {EEG}-based person identification, affective {EEG}-based {PI}, {CNN}-{GRU}, {CNN}-{LSTM}, {CNNs}, convolutional neural networks ({CNNs}), {CRR}, {DEAP} data, deep learning ({DL}), Logic gates, long short-term memory, long short-term memory ({LSTM}), mental states, mental task, motor control, personal identification ({PI}), recurrent neural nets, recurrent neural networks, recurrent neural networks ({RNNs}), recurrent unit, {RNNs}, spatial information, support vector machine baseline system, Task analysis, temporal information},
	file = {Wilaiprasitporn et al. - 2020 - Affective EEG-Based Person Identification Using th.html:C\:\\Users\\miche\\Zotero\\storage\\HITFJYDD\\Wilaiprasitporn et al. - 2020 - Affective EEG-Based Person Identification Using th.html:text/html;Wilaiprasitporn et al. - 2020 - Affective EEG-Based Person Identification Using th.pdf:C\:\\Users\\miche\\Zotero\\storage\\FS6FUQ4L\\Wilaiprasitporn et al. - 2020 - Affective EEG-Based Person Identification Using th.pdf:application/pdf},
}

@article{ozdenizci_adversarial_2019,
	title = {Adversarial Deep Learning in {EEG} Biometrics},
	volume = {26},
	issn = {1558-2361},
	doi = {10.1109/LSP.2019.2906826},
	abstract = {Deep learning methods for person identification based on electroencephalographic ({EEG}) brain activity encounters the problem of exploiting the temporally correlated structures or recording session specific variability within {EEG}. Furthermore, recent methods have mostly trained and evaluated based on single session {EEG} data. We address this problem from an invariant representation-learning perspective. We propose an adversarial inference approach to extend such deep learning models to learn session-invariant person-discriminative representations that can provide robustness in terms of longitudinal usability. Using adversarial learning within a deep convolutional network, we empirically assess and show improvements with our approach based on longitudinally collected {EEG} data for person identification from half-second {EEG} epochs.},
	pages = {710--714},
	number = {5},
	journaltitle = {{IEEE} Signal Processing Letters},
	author = {Özdenizci, O. and Wang, Y. and Koike-Akino, T. and Erdoğmuş, D.},
	date = {2019-05},
	note = {Conference Name: {IEEE} Signal Processing Letters},
	keywords = {{EEG}, electroencephalography, Electroencephalography, Training, Brain modeling, Convolution, learning (artificial intelligence), medical signal processing, Feature extraction, brain, biometrics, Biometrics (access control), person identification, adversarial deep learning, adversarial inference approach, adversarial learning, Biological system modeling, convolutional networks, convolutional neural nets, deep convolutional network, deep learning models, {EEG} biometrics, electroencephalographic brain activity, invariant representation, invariant representation-learning perspective, longitudinally collected {EEG} data, Person identification, recording session specific variability, session-invariant person-discriminative representations, single session {EEG} data, temporally correlated structures},
	file = {Özdenizci et al. - 2019 - Adversarial Deep Learning in EEG Biometrics.pdf:C\:\\Users\\miche\\Zotero\\storage\\PU3BILH6\\Özdenizci et al. - 2019 - Adversarial Deep Learning in EEG Biometrics.pdf:application/pdf},
}

@article{jalaly_bidgoly_survey_2020,
	title = {A survey on methods and challenges in {EEG} based authentication},
	volume = {93},
	issn = {0167-4048},
	url = {http://www.sciencedirect.com/science/article/pii/S0167404820300730},
	doi = {10.1016/j.cose.2020.101788},
	abstract = {{EEG} is the recording of electrical activities of the brain, usually along the scalp surface, which are the results of synaptic activations of the brain’s neurons. In recent years, it has been shown that {EEG} is an appropriate signal for the biometric authentication and has important features such as resistance to spoofing attacks and impossibility to use under pressure and coercion states. In this paper, the state-of-the-art methods in {EEG} based authentication are reviewed. This review includes a number of aspects such as the various tasks that the user required to perform during the authentication, devices and available datasets, the preprocessing procedures and the classification methods used in the {EEG} biometric authentication. Both shallow and deep classification methods are reviewed in this paper. The study shows that the deep learning approaches which are used in the past few years, although still require further research, have shown great results. Moreover, the paper summarizes the works to address the open challenges of this area. The {EEG} authentication challenges have been discussed from a variety of points of view, including privacy, user-friendliness, attacks, and authentication requirements such as universality, permanency, uniqueness, and collectability. This paper can be used as a preliminary plan and a roadmap for researchers interested in {EEG} biometric.},
	pages = {101788},
	journaltitle = {Computers \& Security},
	shortjournal = {Computers \& Security},
	author = {Jalaly Bidgoly, Amir and Jalaly Bidgoly, Hamed and Arezoumand, Zeynab},
	urldate = {2020-11-24},
	date = {2020-06-01},
	langid = {english},
	keywords = {{EEG}, User identification, Authentication, review, overview, Biometric factor, datasets, Pattern recognition, Survey},
	file = {Jalaly Bidgoly et al. - 2020 - A survey on methods and challenges in EEG based au.html:C\:\\Users\\miche\\Zotero\\storage\\2WC5LUQU\\Jalaly Bidgoly et al. - 2020 - A survey on methods and challenges in EEG based au.html:text/html;Jalaly Bidgoly et al. - 2020 - A survey on methods and challenges in EEG based au.pdf:C\:\\Users\\miche\\Zotero\\storage\\SJG7Y7J8\\Jalaly Bidgoly et al. - 2020 - A survey on methods and challenges in EEG based au.pdf:application/pdf},
}

@article{lun_simplified_2020,
	title = {A Simplified {CNN} Classification Method for {MI}-{EEG} via the Electrode Pairs Signals},
	volume = {14},
	issn = {1662-5161},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2020.00338/full},
	doi = {10.3389/fnhum.2020.00338},
	abstract = {The brain-computer interface ({BCI}), which is based on electroencephalography ({EEG}), provides independent information exchange and control channels for the brain and the outside world. However, {EEG} signals come from multiple electrodes, and the data of each electrode can extract multiple features. How to select electrodes and features to improve classification accuracy has become an urgent problem to be solved. This paper proposes a deep convolutional neural network ({CNN}) architecture with separated temporal and spatial filters, which selects the raw {EEG} signals of the electrode pairs over the motor cortex region as hybrid samples without any preprocessing or artificial feature extraction operations. It uses 5-layer {CNN} to learn {EEG} features, 4-layer max pooling to reduce dimensionality, and a fully connected ({FC}) layer for classification. Dropout and batch normalization are used to solve the overfitting problem of the model. In the experiment, the 4 s {EEG} data of 10, 20, 60, and 100 subjects in the Physionet database are used as the data source, and the motor imaginations ({MI}) tasks are divided into four types: left fist, right fist, both fists and both feet. The results indicate that the global averaged accuracy on group-level classification can reach 97.28\%, the area under the receiver operating characteristic ({ROC}) curve stands out at 0.997, and the electrode pair with the highest accuracy on 10 subjects dataset is {FC}3-{FC}4, with 98.61\%. The research results also show that this work achieves high accuracy with a {CNN} classification approach using minimal (2) electrodes, which is the advantage compared to other methods on the same database. This proposed approach provides a new idea for simplifying the design of {BCI} system, and accelerates the process of clinical application.},
	journaltitle = {Frontiers in Human Neuroscience},
	shortjournal = {Front. Hum. Neurosci.},
	author = {Lun, Xiangmin and Yu, Zhenglin and Chen, Tao and Wang, Fang and Hou, Yimin},
	urldate = {2021-01-23},
	date = {2020},
	note = {Publisher: Frontiers},
	keywords = {Electroencephalography ({EEG}), Brain computer interface ({BCI}), Convolutional neural network ({CNN}), Electrode pairs, Motor Imagery ({MI})},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\Z8F3DJKQ\\Lun et al. - 2020 - A Simplified CNN Classification Method for MI-EEG .pdf:application/pdf},
}

@article{xu_one-dimensional_2020,
	title = {A One-Dimensional {CNN}-{LSTM} Model for Epileptic Seizure Recognition Using {EEG} Signal Analysis},
	volume = {14},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2020.578126/full#h4},
	doi = {10.3389/fnins.2020.578126},
	abstract = {Frequent epileptic seizure causes damage to the human’s brain, resulting in memory impairment, mental decline and so on. Therefore, it is important to detect epileptic seizure and provide medical treatment in a timely manner. Currently, medical experts recognize epileptic seizure activity through the visual inspection of electroencephalographic ({EEG}) signal recordings of patients based on their experience, which takes much time and effort of medical experts. In view of this, this paper proposes a one-dimensional convolutional neural network-long short-term memory (1D {CNN}-{LSTM}) model for automatic recognition of epileptic seizure through {EEG} signal analysis. Firstly, the raw {EEG} signal data is preprocessed and normalized. Then, a 1D convolutional neural network ({CNN}) is designed to effectively extract the features of the normalized {EEG} sequence data. In addition, the extracted features are then processed by the {LSTM} layers in order to further extract the temporal features. After that, the output features are fed into several fully connected layers for final epileptic seizure recognition. The performance of the proposed 1D {CNN}-{LSTM} model is verified on the public {UCI} epileptic seizure recognition data set. Experiments results show that the proposed method achieves high recognition accuracies of 99.39\% and 82.00\% on the binary and five-class epileptic seizure recognition tasks, respectively. Comparing results with traditional machine learning methods including k-nearest neighbor, support vector machine and decision tree, other deep learning methods including standard deep neural network and {CNN} further verify the superiority of the proposed method.},
	journaltitle = {Frontiers in Neuroscience},
	shortjournal = {Front. Neurosci.},
	author = {Xu, Gaowei and Ren, Tianhe and Chen, Yu and Che, Wenliang},
	urldate = {2021-01-22},
	date = {2020},
	note = {Publisher: Frontiers},
	keywords = {Signal analysis, Convolutional neural network ({CNN}), electroencephalographic ({EEG}), Epileptic Seizure Recognition, Long short-term memory ({LSTM})},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\A8KQYEXU\\Xu et al. - 2020 - A One-Dimensional CNN-LSTM Model for Epileptic Sei.pdf:application/pdf},
}

@inproceedings{elessawy_long_2020,
	title = {A Long Short-Term Memory Autoencoder Approach for {EEG} Motor Imagery Classification},
	doi = {10.1109/ICCAKM46823.2020.9051489},
	abstract = {Motor imagery represents one Brain-Computer Interface ({BCI}) paradigm that has been utilized in developing applications to assist subjects with motor disability. Such paradigm relies on analyzing brain electroencephalography ({EEG}) activity to identify the intended movement direction. Existing motor imagery feature extraction techniques are focused on utilizing traditional signal processing and machine learning techniques. Recent advances in the deep learning field has inspired the development of few methods for motor imagery classification that achieved further performance improvement. This paper proposes a deep neural network approach for motor imagery classification using Long Short-Term Memory ({LSTM}) combined with Autoencoders based on a sequence-to-sequence architecture. The proposed network extracts features from the frequency-domain representation of {EEG} signals. This network is trained to obtain low-dimensional representation of {EEG} features that are then fed into multilayer perceptron of 3 layers for classification. Systematic and extensive examinations have been carried out by applying the approach to public benchmark {EEG} datasets. The obtained results outperformed classical state-of-the-art methods employing standard frequency-domain features and common spatial patterns, and comparative results to methods such as filter bank common spatial pattern and its variants. Our results indicate the efficacy of the proposed {LSTM} autoencoder approach in {EEG} motor imagery classification.},
	eventtitle = {2020 International Conference on Computation, Automation and Knowledge Management ({ICCAKM})},
	pages = {79--84},
	booktitle = {2020 International Conference on Computation, Automation and Knowledge Management ({ICCAKM})},
	author = {Elessawy, R. H. and Eldawlatly, S. and Abbas, H. M.},
	date = {2020-01},
	keywords = {{EEG}, brain-computer interfaces, electroencephalography, learning (artificial intelligence), medical signal processing, deep learning, signal classification, feature extraction, signal processing, brain computer interface, Motor imagery, long short-term memory, recurrent neural nets, brain-computer interface paradigm, deep neural network approach, {EEG} motor imagery classification, long short-term memory autoencoder approach, machine learning techniques, motor disability, motor imagery feature extraction techniques, multilayer perceptrons},
	file = {Elessawy et al. - 2020 - A Long Short-Term Memory Autoencoder Approach for .html:C\:\\Users\\miche\\Zotero\\storage\\6CEKGHWM\\Elessawy et al. - 2020 - A Long Short-Term Memory Autoencoder Approach for .html:text/html;Elessawy et al. - 2020 - A Long Short-Term Memory Autoencoder Approach for .pdf:C\:\\Users\\miche\\Zotero\\storage\\9DKR2Q9I\\Elessawy et al. - 2020 - A Long Short-Term Memory Autoencoder Approach for .pdf:application/pdf},
}

@book{wang_collaborative_2011,
	title = {A collaborative brain-computer interface},
	volume = {1},
	abstract = {Electroencephalogram ({EEG}) based brain-computer interfaces ({BCI}) have been studied for several decades since the 1970s. Current {BCI} research mainly aims to provide a new communication channel to patients with motor disabilities to improve their quality of life. The {BCI} technology can also benefit normal healthy users; however, little progress has been made in real-world practices due to low {BCI} performance caused by technical limits of {EEG}. To overcome this bottleneck, this study uses a collaborative {BCI} to improve overall performance through integrating information from multiple users. A dataset involving 15 subjects participating in a Go/{NoGo} decision-making experiment was used to evaluate the collaborative method. Using collaborative computing techniques, the classification accuracy for predicting a Go/{NoGo} decision was enhanced substantially from 75.8\% to 91.4\%, 97.6\%, and 99.1\% as the number of subjects increased from 1 to 5, 10, and 15, respectively. These results suggest that a collaborative {BCI} can effectively fuse brain activities of a group of people to improve human behavior.},
	pagetotal = {580},
	author = {Wang, Yijun and Wang, Yu-Te and Jung, Tzyy-Ping and Gao, Xiaorong and Gao, Shangkai},
	date = {2011-10-01},
	doi = {10.1109/BMEI.2011.6098286},
	note = {Journal Abbreviation: Proceedings - 2011 4th International Conference on Biomedical Engineering and Informatics, {BMEI} 2011
Pages: 583
Publication Title: Proceedings - 2011 4th International Conference on Biomedical Engineering and Informatics, {BMEI} 2011},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\HYJ89RVN\\Wang et al. - 2011 - A collaborative brain-computer interface.pdf:application/pdf;Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\L65HYQ7X\\Wang et al. - 2011 - A collaborative brain-computer interface.pdf:application/pdf},
}

@article{thammasan_continuous_2016,
	title = {Continuous Music-Emotion Recognition Based on Electroencephalogram},
	volume = {E99.D},
	doi = {10.1587/transinf.2015EDP7251},
	abstract = {Research on emotion recognition using electroencephalogram ({EEG}) of subjects listening to music has become more active in the past decade. However, previous works did not consider emotional oscillations within a single musical piece. In this research, we propose a continuous music-emotion recognition approach based on brainwave signals. While considering the subject-dependent and changing-over-time characteristics of emotion, our experiment included self-reporting and continuous emotion annotation in the arousal-valence space. Fractal dimension ({FD}) and power spectral density ({PSD}) approaches were adopted to extract informative features from raw {EEG} signals and then we applied emotion classification algorithms to discriminate binary classes of emotion. According to our experimental results, {FD} slightly outperformed {PSD} approach both in arousal and valence classification, and {FD} was found to have the higher correlation with emotion reports than {PSD}. In addition, continuous emotion recognition during music listening based on {EEG} was found to be an effective method for tracking emotional reporting oscillations and provides an opportunity to better understand human emotional processes.},
	pages = {1234--1241},
	journaltitle = {{IEICE} Transactions on Information and Systems},
	shortjournal = {{IEICE} Transactions on Information and Systems},
	author = {Thammasan, Nattapong and Moriyama, Koichi and Fukui, Ken-ichi and Numao, Masayuki},
	date = {2016-04-01},
	file = {Thammasan et al. - 2016 - Continuous Music-Emotion Recognition Based on Elec.pdf:C\:\\Users\\miche\\Zotero\\storage\\HEYGDN6U\\Thammasan et al. - 2016 - Continuous Music-Emotion Recognition Based on Elec.pdf:application/pdf},
}

@article{salimpoor_rewarding_2009,
	title = {The Rewarding Aspects of Music Listening Are Related to Degree of Emotional Arousal},
	volume = {4},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0007487},
	doi = {10.1371/journal.pone.0007487},
	abstract = {Background Listening to music is amongst the most rewarding experiences for humans. Music has no functional resemblance to other rewarding stimuli, and has no demonstrated biological value, yet individuals continue listening to music for pleasure. It has been suggested that the pleasurable aspects of music listening are related to a change in emotional arousal, although this link has not been directly investigated. In this study, using methods of high temporal sensitivity we investigated whether there is a systematic relationship between dynamic increases in pleasure states and physiological indicators of emotional arousal, including changes in heart rate, respiration, electrodermal activity, body temperature, and blood volume pulse. Methodology Twenty-six participants listened to self-selected intensely pleasurable music and “neutral” music that was individually selected for them based on low pleasure ratings they provided on other participants' music. The “chills” phenomenon was used to index intensely pleasurable responses to music. During music listening, continuous real-time recordings of subjective pleasure states and simultaneous recordings of sympathetic nervous system activity, an objective measure of emotional arousal, were obtained. Principal Findings Results revealed a strong positive correlation between ratings of pleasure and emotional arousal. Importantly, a dissociation was revealed as individuals who did not experience pleasure also showed no significant increases in emotional arousal. Conclusions/Significance These results have broader implications by demonstrating that strongly felt emotions could be rewarding in themselves in the absence of a physically tangible reward or a specific functional goal.},
	pages = {e7487},
	number = {10},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Salimpoor, Valorie N. and Benovoy, Mitchel and Longo, Gregory and Cooperstock, Jeremy R. and Zatorre, Robert J.},
	urldate = {2021-03-01},
	date = {2009-10-16},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Emotions, Autonomic nervous system, Bioacoustics, Heart rate, Music perception, Nervous system physiology, Respiratory physiology, Sympathetic nervous system},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\VRQUXLQ7\\article.html:text/html;Salimpoor et al. - 2009 - The Rewarding Aspects of Music Listening Are Relat.pdf:C\:\\Users\\miche\\Zotero\\storage\\5DSYJ6X2\\Salimpoor et al. - 2009 - The Rewarding Aspects of Music Listening Are Relat.pdf:application/pdf},
}

@article{ruiz_de_miras_fractal_2019,
	title = {Fractal dimension analysis of states of consciousness and unconsciousness using transcranial magnetic stimulation},
	volume = {175},
	issn = {0169-2607},
	url = {https://www.sciencedirect.com/science/article/pii/S0169260718314263},
	doi = {10.1016/j.cmpb.2019.04.017},
	abstract = {Background and objective
Knowing whether a subject is conscious or not is a current challenge with a deep potential clinical impact. Recent theoretical considerations suggest that consciousness is linked to the complexity of distributed interactions within the corticothalamic system. The fractal dimension ({FD}) is a quantitative parameter that has been extensively used to analyse the complexity of structural and functional patterns of the human brain. In this study we investigate {FD} to assess whether it can discriminate between consciousness and different states of unconsciousness in healthy individuals.
Methods
We study 69 high-density electroencephalogram (hd-{EEG}) measurements after transcranial magnetic stimulation ({TMS}) in 18 healthy subjects progressing from wakefulness to non-rapid eye movement ({NREM}) sleep and sedation induced by different anaesthetic agents (xenon and propofol). We quantify the integration of thalamocortical networks by calculating the {FD} of a spatiotemporal voxelization obtained from the locations of all sources that are significantly activated by the perturbation (4DFD). Moreover, we study the temporal evolution of the evoked spatial distributions and compute a measure of the differentiation of the response by means of the Higuchi {FD} ({HFD}). Finally, a Fractal Dimension Index ({FDI}) of perturbational complexity is computed as the product of both quantities: integration {FD} (4DFD) and differentiation {FD} ({HFD}).
Results
We found that {FDI} is significantly lower in sleep and sedation when compared to wakefulness and provides an almost perfect intra-subject discrimination between conscious and unconscious states.
Conclusions
These results support the combination of {FD} measures of cortical integration and cortical differentiation as a novel paradigm of tracking complex spatiotemporal dynamics in the brain that could provide further insights into the link between complexity and the brain's capacity to sustain consciousness.},
	pages = {129--137},
	journaltitle = {Computer Methods and Programs in Biomedicine},
	shortjournal = {Computer Methods and Programs in Biomedicine},
	author = {Ruiz de Miras, J. and Soler, F. and Iglesias-Parro, S. and Ibáñez-Molina, A. J. and Casali, A. G. and Laureys, S. and Massimini, M. and Esteban, F. J. and Navas, J. and Langa, J. A.},
	urldate = {2021-03-01},
	date = {2019-07-01},
	langid = {english},
	keywords = {{EEG}, Consciousness, Fractal dimension, Transcranial magnetic stimulation},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\Z96TDCLR\\S0169260718314263.html:text/html;ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\YU27QVH5\\Ruiz de Miras et al. - 2019 - Fractal dimension analysis of states of consciousn.pdf:application/pdf},
}

@article{smith_hemispheric_1987,
	title = {Hemispheric asymmetry and emotion: Lateralized parietal processing of affect and cognition},
	volume = {25},
	issn = {0301-0511},
	url = {https://www.sciencedirect.com/science/article/pii/0301051187900500},
	doi = {10.1016/0301-0511(87)90050-0},
	shorttitle = {Hemispheric asymmetry and emotion},
	abstract = {The differential cerebral processing of affect and cognition may have important implications for a more general understanding of how these two complex sets of functions differ and how they interact. Building upon recent studies of hemispheric asymmetry in emotion, the present study focused on the differential parietal processing of emotional stimuli under affective and cognitive conditions. Subjects were exposed to neutral and emotional stimuli presented under cognitive and affective instructional sets. Bilateral electroencephalographic ({EEG}) data showed that the principal differentiation between affective and cognitive conditions occurred in the right hemisphere, whereas the highest overall level of activation during emotional stimulation was in the left hemisphere. It was also found that affective conditions produced higher of levels of both {EEG} and electrodermal activity than either cognitive or neutral conditions. Finally, significant patterns of gender differentiation suggested greater focal organization for affective arousal in females than males.},
	pages = {247--260},
	number = {3},
	journaltitle = {Biological Psychology},
	shortjournal = {Biological Psychology},
	author = {Smith, Barry D. and Meyers, Marilyn and Kline, Robert and Bozman, Alan},
	urldate = {2021-03-01},
	date = {1987-12-01},
	langid = {english},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\GFN6N4CK\\0301051187900500.html:text/html;Smith et al. - 1987 - Hemispheric asymmetry and emotion Lateralized par.pdf:C\:\\Users\\miche\\Zotero\\storage\\L9ZQBQW9\\Smith et al. - 1987 - Hemispheric asymmetry and emotion Lateralized par.pdf:application/pdf},
}

@book{scherer_approaches_2014,
	title = {Approaches To Emotion},
	isbn = {978-1-317-75764-1},
	abstract = {This sourcebook is intended as a reader in the fullest sense of that word: a work that offers researchers and students alike the opportunity to examine the many different aspects and widely divergent approaches to the study of emotion. The contributors include samples of biological, ontogenetic, ethological, psychological, sociological, and anthropological approaches.},
	pagetotal = {441},
	publisher = {Psychology Press},
	author = {Scherer, Klaus R. and Ekman, Paul},
	date = {2014-05-22},
	langid = {english},
	note = {Google-Books-{ID}: k0mhAwAAQBAJ},
	keywords = {Psychology / General, Psychology / Social Psychology},
}

@article{koelsch_towards_2005,
	title = {Towards a neural basis of music perception},
	volume = {9},
	issn = {1364-6613},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661305002901},
	doi = {10.1016/j.tics.2005.10.001},
	abstract = {Music perception involves complex brain functions underlying acoustic analysis, auditory memory, auditory scene analysis, and processing of musical syntax and semantics. Moreover, music perception potentially affects emotion, influences the autonomic nervous system, the hormonal and immune systems, and activates (pre)motor representations. During the past few years, research activities on different aspects of music processing and their neural correlates have rapidly progressed. This article provides an overview of recent developments and a framework for the perceptual side of music processing. This framework lays out a model of the cognitive modules involved in music perception, and incorporates information about the time course of activity of some of these modules, as well as research findings about where in the brain these modules might be located.},
	pages = {578--584},
	number = {12},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Koelsch, Stefan and Siebel, Walter A.},
	urldate = {2021-03-01},
	date = {2005-12-01},
	langid = {english},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\GYQT3S4U\\S1364661305002901.html:text/html;ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\DY26WFSU\\Koelsch e Siebel - 2005 - Towards a neural basis of music perception.pdf:application/pdf},
}

@article{jentschke_neural_2014,
	title = {Neural correlates of music-syntactic processing in two-year old children},
	volume = {9},
	issn = {1878-9293},
	url = {https://www.sciencedirect.com/science/article/pii/S1878929314000322},
	doi = {10.1016/j.dcn.2014.04.005},
	abstract = {Music is a basic and ubiquitous socio-cognitive domain. However, our understanding of the time course of the development of music perception, particularly regarding implicit knowledge of music-syntactic regularities, remains contradictory and incomplete. Some authors assume that the acquisition of knowledge about these regularities lasts until late childhood, but there is also evidence for the presence of such knowledge in four- and five-year-olds. To explore whether such knowledge is already present in younger children, we tested whether 30-month-olds (N = 62) show neurophysiological responses to music-syntactically irregular harmonies. We observed an early right anterior negativity in response to both irregular in-key and out-of-key chords. The N5, a brain response usually present in older children and adults, was not observed, indicating that processes of harmonic integration (as reflected in the N5) are still in development in this age group. In conclusion, our results indicate that 30-month-olds already have acquired implicit knowledge of complex harmonic music-syntactic regularities and process musical information according to this knowledge.},
	pages = {200--208},
	journaltitle = {Developmental Cognitive Neuroscience},
	shortjournal = {Developmental Cognitive Neuroscience},
	author = {Jentschke, Sebastian and Friederici, Angela D. and Koelsch, Stefan},
	urldate = {2021-03-01},
	date = {2014-07-01},
	langid = {english},
	keywords = {{EEG}, Music perception, {ERPs}, Infants (30-month-olds), Musical syntax, Neurophysiology},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\HF88VKQE\\S1878929314000322.html:text/html;ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\377SXYZD\\Jentschke et al. - 2014 - Neural correlates of music-syntactic processing in.pdf:application/pdf},
}

@article{fang_perception_2017,
	title = {Perception of Western Musical Modes: A Chinese Study},
	volume = {8},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2017.01905/full},
	doi = {10.3389/fpsyg.2017.01905},
	shorttitle = {Perception of Western Musical Modes},
	abstract = {The major mode conveys positive emotion, whereas the minor mode conveys negative emotion. However, previous studies have primarily focused on the emotions induced by Western music in Western participants. The influence of the musical mode (major or minor) on Chinese individuals’ perception of Western music is unclear. In the present experiments, we investigated the effects of musical mode and harmonic complexity on psychological perception among Chinese participants. In Experiment 1, the participants (N = 30) evaluated 24 musical excerpts in five dimensions (pleasure, arousal, dominance, emotional tension and liking). In Experiment 2, the participants (N = 40) evaluated 48 musical excerpts. Perceptions of the musical excerpts differed significantly according to mode, even if the stimuli were Western musical excerpts. The major-mode music induced greater pleasure and arousal and produced higher liking ratings than the minor-mode music, whereas the minor-mode music induced greater tension than the major-mode music. Mode did not influence the dominance rating. Perception of Western music was not influenced by harmonic complexity. Moreover, preference for musical mode was influenced by previous exposure to Western music. These results confirm the cross-cultural emotion induction effects of musical modes in Western music.},
	journaltitle = {Frontiers in Psychology},
	shortjournal = {Front. Psychol.},
	author = {Fang, Lele and Shang, Junchen and Chen, Nan},
	urldate = {2021-03-01},
	date = {2017},
	note = {Publisher: Frontiers},
	keywords = {emotion, culture, harmonic complexity, mode, Perception},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\CA58NDRA\\Fang et al. - 2017 - Perception of Western Musical Modes A Chinese Stu.pdf:application/pdf},
}

@article{keelawat_spatiotemporal_nodate,
	title = {Spatiotemporal Emotion Recognition using Deep {CNN} Based on {EEG} during Music Listening},
	abstract = {Emotion recognition based on {EEG} has become an active research area. As one of the machine learning models, {CNN} has been utilized to solve diverse problems including issues in this domain. In this work, a study of {CNN} and its spatiotemporal feature extraction has been conducted in order to explore the model’s capabilities in varied window sizes and electrode orders. Our investigation was conducted in subjectindependent fashion. Results have shown that temporal information in distinct window sizes significantly affects recognition performance in both 10-fold and leave-one-subject-out cross validation. Spatial information from varying electrode order has modicum effect on classification. {SVM} classifier depending on spatiotemporal knowledge on the same dataset was previously employed and compared to these empirical results. Even though {CNN} and {SVM} have a homologous trend in window size effect, {CNN} outperformed {SVM} using leave-one-subject-out cross validation. This could be caused by different extracted features in the elicitation process.},
	pages = {11},
	author = {Keelawat, Panayu and Thammasan, Nattapong and Numao, Masayuki and Kijsirikul, Boonserm},
	langid = {english},
	file = {Keelawat et al. - Spatiotemporal Emotion Recognition using Deep CNN .pdf:C\:\\Users\\miche\\Zotero\\storage\\WEZRMFAW\\Keelawat et al. - Spatiotemporal Emotion Recognition using Deep CNN .pdf:application/pdf},
}

@article{vialatte_steady-state_2010,
	title = {Steady-state visually evoked potentials: Focus on essential paradigms and future perspectives},
	volume = {90},
	issn = {0301-0082},
	url = {https://www.sciencedirect.com/science/article/pii/S0301008209001853},
	doi = {10.1016/j.pneurobio.2009.11.005},
	shorttitle = {Steady-state visually evoked potentials},
	abstract = {After 40 years of investigation, steady-state visually evoked potentials ({SSVEPs}) have been shown to be useful for many paradigms in cognitive (visual attention, binocular rivalry, working memory, and brain rhythms) and clinical neuroscience (aging, neurodegenerative disorders, schizophrenia, ophthalmic pathologies, migraine, autism, depression, anxiety, stress, and epilepsy). Recently, in engineering, {SSVEPs} found a novel application for {SSVEP}-driven brain–computer interface ({BCI}) systems. Although some {SSVEP} properties are well documented, many questions are still hotly debated. We provide an overview of recent {SSVEP} studies in neuroscience (using implanted and scalp {EEG}, {fMRI}, or {PET}), with the perspective of modern theories about the visual pathway. We investigate the steady-state evoked activity, its properties, and the mechanisms behind {SSVEP} generation. Next, we describe the {SSVEP}-{BCI} paradigm and review recently developed {SSVEP}-based {BCI} systems. Lastly, we outline future research directions related to basic and applied aspects of {SSVEPs}.},
	pages = {418--438},
	number = {4},
	journaltitle = {Progress in Neurobiology},
	shortjournal = {Progress in Neurobiology},
	author = {Vialatte, François-Benoît and Maurice, Monique and Dauwels, Justin and Cichocki, Andrzej},
	urldate = {2021-02-21},
	date = {2010-04-01},
	langid = {english},
	keywords = {{EEG}, {fMRI}, {BCI}, Clinical, Cognitive, Evoked potentials, {PET}, {SSVEP}},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\SCHF7LSS\\S0301008209001853.html:text/html;ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\9JV45GNA\\Vialatte et al. - 2010 - Steady-state visually evoked potentials Focus on .pdf:application/pdf},
}

@book{ikehara_lecture_2013,
	title = {Lecture Notes in Computer Science},
	isbn = {978-3-642-39453-9},
	abstract = {The strategic goal of augmented cognition is to increase task performance capacity by using physiological sensor feedback to adjust or modify the activity for the user. Gamification has been shown to increase performance by using certain combinations of game elements. Both augmented cognition and gamification address increased task performance capacity. Gamification adds to augmented cognition by directly addressing the motivation of the user to remain engaged in the activity. This has also been referred to as flow, or the optimal experience. This paper describes an example of a gamified activity in which the physiological sensors of augmented cognition are used to foster the optimal experience desired in gamification. Also, discussed is how the strategic goals of augmented cognition and gamification overlap through the use of a gamified example that describes how the components of augmented cognition and elements of gamification can be used together to better achieve the goal of increased task performance capacity.},
	pagetotal = {676},
	author = {Ikehara, Curtis and Crosby, Martha and Silva, Paula Alexandra},
	date = {2013-07-21},
	doi = {10.1007/978-3-642-39454-6_72},
	note = {Pages: 684},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\C2XPZGLD\\Ikehara et al. - 2013 - Lecture Notes in Computer Science.pdf:application/pdf},
}

@online{noauthor_melomind_nodate,
	title = {Melomind - Activez le mode sérénité de votre cerveau.},
	url = {https://www.melomind.com/},
	abstract = {Tous les bienfaits de la neuroscience et de la méditation pour vous entraîner à la relaxation profonde. Embarquez vers l’harmonie et la sérénité.},
	titleaddon = {Melomind},
	urldate = {2021-02-21},
	langid = {french},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\9XWJPJSZ\\www.melomind.com.html:text/html},
}

@online{noauthor_melomind_nodate-1,
	title = {melomind at {DuckDuckGo}},
	url = {https://duckduckgo.com/?q=melomind},
	urldate = {2021-02-21},
	file = {melomind at DuckDuckGo:C\:\\Users\\miche\\Zotero\\storage\\ZFEQZK5U\\duckduckgo.com.html:text/html},
}

@online{noauthor_nextmind_nodate,
	title = {{NextMind} {\textbar} Let your mind take control {\textbar} Order your Dev Kit},
	url = {https://www.next-mind.com/},
	abstract = {{NextMind} is shipping World’s First Real-time Brain-Sensing Wearable to the Developers community, offering new human-computer interactions.},
	titleaddon = {{NextMind}},
	urldate = {2021-02-21},
	langid = {american},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\RW3KVIL6\\www.next-mind.com.html:text/html},
}

@article{fazel-rezai_p300_2012,
	title = {P300 brain computer interface: current challenges and emerging trends},
	volume = {5},
	issn = {1662-6443},
	url = {https://www.frontiersin.org/articles/10.3389/fneng.2012.00014/full},
	doi = {10.3389/fneng.2012.00014},
	shorttitle = {P300 brain computer interface},
	abstract = {A brain-computer interface ({BCI}) enables communication without movement based on brain signals measured with electroencephalography ({EEG}). {BCIs} usually rely on one of three types of signals: the P300 and other components of the event-related potential ({ERP}), steady state visual evoked potential ({SSVEP}), or event related desynchronization ({ERD}). Although P300 {BCIs} were introduced over twenty years ago, the past few years have seen a strong increase in P300 {BCI} research. This closed-loop {BCI} approach relies on the P300 and other components of the event-related potential ({ERP}), based on an oddball paradigm presented to the subject. In this paper, we overview the current status of P300 {BCI} technology, and then discuss new directions: paradigms for eliciting P300s; signal processing methods; applications; and hybrid {BCIs}. We conclude that P300 {BCIs} are quite promising, as several emerging directions have not yet been fully explored and could lead to improvements in bit rate, reliability, usability, and flexibility.},
	journaltitle = {Frontiers in Neuroengineering},
	shortjournal = {Front. Neuroeng.},
	author = {Fazel-Rezai, Reza and Allison, Brendan Z. and Guger, Christoph and Sellers, Eric W. and Kleih, Sonja C. and Kübler, Andrea},
	urldate = {2021-02-21},
	date = {2012},
	note = {Publisher: Frontiers},
	keywords = {{BCI}, Brain Computer Interface, event-related potential ({ERP}), P300, Trends and Challenges},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\TCVY7H9X\\Fazel-Rezai et al. - 2012 - P300 brain computer interface current challenges .pdf:application/pdf},
}

@article{tan_effect_2014,
	title = {Effect of mindfulness meditation on brain–computer interface performance},
	volume = {23},
	issn = {1053-8100},
	url = {https://www.sciencedirect.com/science/article/pii/S1053810013001499},
	doi = {10.1016/j.concog.2013.10.010},
	abstract = {Electroencephalogram based brain–computer interfaces ({BCIs}) enable stroke and motor neuron disease patients to communicate and control devices. Mindfulness meditation has been claimed to enhance metacognitive regulation. The current study explores whether mindfulness meditation training can thus improve the performance of {BCI} users. To eliminate the possibility of expectation of improvement influencing the results, we introduced a music training condition. A norming study found that both meditation and music interventions elicited clear expectations for improvement on the {BCI} task, with the strength of expectation being closely matched. In the main 12week intervention study, seventy-six healthy volunteers were randomly assigned to three groups: a meditation training group; a music training group; and a no treatment control group. The mindfulness meditation training group obtained a significantly higher {BCI} accuracy compared to both the music training and no-treatment control groups after the intervention, indicating effects of meditation above and beyond expectancy effects.},
	pages = {12--21},
	journaltitle = {Consciousness and Cognition},
	shortjournal = {Consciousness and Cognition},
	author = {Tan, Lee-Fan and Dienes, Zoltan and Jansari, Ashok and Goh, Sing-Yau},
	urldate = {2021-02-16},
	date = {2014-01-01},
	langid = {english},
	keywords = {Music, {BCI} performance, Brain–computer interface, Expectation, Meditation, Mindfulness},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\535XDLRB\\Tan et al. - 2014 - Effect of mindfulness meditation on brain–computer.pdf:application/pdf},
}

@online{noauthor_2_nodate,
	title = {(2) ({PDF}) Human-Computer Interaction for {BCI} Games Usability and User Experience},
	url = {https://www.researchgate.net/publication/220916493_Human-Computer_Interaction_for_BCI_Games_Usability_and_User_Experience},
	urldate = {2021-02-16},
	file = {(2) (PDF) Human-Computer Interaction for BCI Games Usability and User Experience:C\:\\Users\\miche\\Zotero\\storage\\PEPK5LU4\\220916493_Human-Computer_Interaction_for_BCI_Games_Usability_and_User_Experience.html:text/html},
}

@article{friedman_navigating_2007,
	title = {Navigating Virtual Reality by Thought: What Is It Like?},
	volume = {16},
	doi = {10.1162/pres.16.1.100},
	shorttitle = {Navigating Virtual Reality by Thought},
	abstract = {Abstract We have set up a Brain-Computer Interface ({BCI}) to be used as aninput device to a highly immersive,virtual reality Cave-like system. We have carried out two navigation experiments: three subjects were required to rotate in a virtual bar room by imagining left or right hand movement, and to walk along a single axis in a virtual street by imagining foot or hand movement. In this paper we focus on the subjective experience of navigating virtual reality “by thought”, and on the interrelations between,{BCI} and presence.},
	pages = {100--110},
	journaltitle = {Presence},
	shortjournal = {Presence},
	author = {Friedman, Doron and Leeb, Robert and Guger, Christoph and Steed, Anthony and Pfurtscheller, Gert and Slater, Mel},
	date = {2007-02-01},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\RSKP8JTK\\Friedman et al. - 2007 - Navigating Virtual Reality by Thought What Is It .pdf:application/pdf},
}

@book{friedman_contact_nodate,
	title = {Contact:},
	shorttitle = {Contact},
	abstract = {We have set up a Brain-Computer Interface ({BCI}) to be used as an input device to a highly immersive virtual reality Cave-like system. We have carried out two navigation experiments: three subjects were required to rotate in a virtual bar room by imagining left or right hand movement, and to walk along a single axis in a virtual street by imagining foot or hand movement. In this paper we focus on the subjective experience of navigating virtual reality “by thought”, and on the interrelations between {BCI} and presence. 1.},
	author = {Friedman, Doron and Leeb, Robert and Guger, Christoph and Steed, Anthony and Pfurtscheller, Gert and Slater, Mel and Friedman, Doron},
	file = {Citeseer - Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\6XAEG5E2\\Friedman et al. - Contact.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\miche\\Zotero\\storage\\YMZYQ2LS\\summary.html:text/html},
}

@article{cherubino_consumer_2019,
	title = {Consumer Behaviour through the Eyes of Neurophysiological Measures: State-of-the-Art and Future Trends},
	volume = {2019},
	issn = {1687-5273},
	doi = {10.1155/2019/1976847},
	shorttitle = {Consumer Behaviour through the Eyes of Neurophysiological Measures},
	abstract = {The new technological advances achieved during the last decade allowed the scientific community to investigate and employ neurophysiological measures not only for research purposes but also for the study of human behaviour in real and daily life situations. The aim of this review is to understand how and whether neuroscientific technologies can be effectively employed to better understand the human behaviour in real decision-making contexts. To do so, firstly, we will describe the historical development of neuromarketing and its main applications in assessing the sensory perceptions of some marketing and advertising stimuli. Then, we will describe the main neuroscientific tools available for such kind of investigations (e.g., measuring the cerebral electrical or hemodynamic activity, the eye movements, and the psychometric responses). Also, this review will present different brain measurement techniques, along with their pros and cons, and the main cerebral indexes linked to the specific mental states of interest (used in most of the neuromarketing research). Such indexes have been supported by adequate validations from the scientific community and are largely employed in neuromarketing research. This review will also discuss a series of papers that present different neuromarketing applications, such us in-store choices and retail, services, pricing, brand perception, web usability, neuropolitics, evaluation of the food and wine taste, and aesthetic perception of artworks. Furthermore, this work will face the ethical issues arisen on the use of these tools for the evaluation of the human behaviour during decision-making tasks. In conclusion, the main challenges that neuromarketing is going to face, as well as future directions and possible scenarios that could be derived by the use of neuroscience in the marketing field, will be identified and discussed.},
	pages = {1976847},
	journaltitle = {Computational Intelligence and Neuroscience},
	shortjournal = {Comput Intell Neurosci},
	author = {Cherubino, Patrizia and Martinez-Levy, Ana C. and Caratù, Myriam and Cartocci, Giulia and Di Flumeri, Gianluca and Modica, Enrica and Rossi, Dario and Mancini, Marco and Trettel, Arianna},
	date = {2019},
	pmid = {31641346},
	pmcid = {PMC6766676},
	keywords = {Humans, Brain, Neurophysiology, Advertising, Consumer Behavior, Eye, Neurosciences},
	file = {Full Text:C\:\\Users\\miche\\Zotero\\storage\\AQ2CZRVZ\\Cherubino et al. - 2019 - Consumer Behaviour through the Eyes of Neurophysio.pdf:application/pdf},
}

@article{h_neurofeedback_2016,
	title = {Neurofeedback: A Comprehensive Review on System Design, Methodology and Clinical Applications.},
	volume = {7},
	issn = {2008-126X, 2228-7442},
	url = {http://europepmc.org/article/PMC/4892319},
	doi = {10.15412/j.bcn.03070208},
	shorttitle = {Neurofeedback},
	abstract = {Europe {PMC} is an archive of life sciences journal literature., Neurofeedback: A Comprehensive Review on System Design, Methodology and Clinical Applications.},
	pages = {143--158},
	number = {2},
	journaltitle = {Basic and Clinical Neuroscience},
	shortjournal = {Basic Clin Neurosci},
	author = {H, Marzbani and Hr, Marateb and M, Mansourian},
	urldate = {2021-02-15},
	date = {2016-04-01},
	pmid = {27303609},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\8HA6J3GQ\\4892319.html:text/html;Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\FHZ8BDBD\\H et al. - 2016 - Neurofeedback A Comprehensive Review on System De.pdf:application/pdf},
}

@online{noauthor_hackerrank_nodate,
	title = {{HackerRank}},
	url = {https://www.hackerrank.com/},
	abstract = {{HackerRank} is the market-leading technical assessment and remote interview solution for hiring developers. Learn how to hire technical talent from anywhere!},
	titleaddon = {{HackerRank}},
	urldate = {2021-02-15},
	langid = {american},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\VKT39RLB\\www.hackerrank.com.html:text/html},
}

@online{noauthor_5_nodate,
	title = {5 simple Drawing Exercises for Beginners and Pros},
	url = {https://cravepainting.com/blog/simple-drawing-exercises},
	abstract = {I have collected some easy drawing exercises for beginners and pros, that have helped me to learn drawing and sketching, so I am sharing them with you today.},
	titleaddon = {Crave Painting},
	urldate = {2021-02-15},
	langid = {british},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\P5JSWWRN\\simple-drawing-exercises.html:text/html},
}

@article{kato_development_2011,
	title = {Development of a {BCI} master switch based on single-trial detection of contingent negative variation related potentials},
	volume = {2011},
	doi = {10.1109/IEMBS.2011.6091146},
	abstract = {To control the startup/shutdown of a conventional brain-computer interface ({BCI}) that is always running for daily use, we proposed and developed a new {BCI} system called a {BCI} master switch. We designed it with on/off switching functions by detecting the contingent negative variation ({CNV})--related potentials. We chose {CNV} to improve the single-trial discrimination of user intentions to switch because {CNV} had a high signal-to-noise ratio and needed high concentration for its elicitation. We also applied a support vector machine ({SVM}) to improve the single-trial detection of {CNV}-related potentials. As the best parameters of {SVM} were estimated and applied, the offline evaluation's best performance achieved a {CNV} detection rate of 99.3\% for the intention to switch and 2.1\% for the intention not to switch. Remarkably, this performance was achieved from single-trial detection, imaginary response of user's intention without physical reaction, and the data from only one recording electrode. These results suggest that our proposed {BCI} system might work as a master switch by single-trial detection.},
	pages = {4629--32},
	journaltitle = {Conference proceedings : ... Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society. {IEEE} Engineering in Medicine and Biology Society. Conference},
	shortjournal = {Conference proceedings : ... Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society. {IEEE} Engineering in Medicine and Biology Society. Conference},
	author = {Kato, Yasuhiro and Yonemura, Tomoko and Samejima, Kazuyuki and Maeda, Taro and Ando, Hideyuki},
	date = {2011-08-01},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\DTS8QI59\\Kato et al. - 2011 - Development of a BCI master switch based on single.pdf:application/pdf},
}

@article{haynes_decoding_2006,
	title = {Decoding mental states from brain activity in humans},
	volume = {7},
	issn = {1471-003X},
	doi = {10.1038/nrn1931},
	abstract = {Recent advances in human neuroimaging have shown that it is possible to accurately decode a person's conscious experience based only on non-invasive measurements of their brain activity. Such 'brain reading' has mostly been studied in the domain of visual perception, where it helps reveal the way in which individual experiences are encoded in the human brain. The same approach can also be extended to other types of mental state, such as covert attitudes and lie detection. Such applications raise important ethical issues concerning the privacy of personal thought.},
	pages = {523--534},
	number = {7},
	journaltitle = {Nature Reviews. Neuroscience},
	shortjournal = {Nat Rev Neurosci},
	author = {Haynes, John-Dylan and Rees, Geraint},
	date = {2006-07},
	pmid = {16791142},
	keywords = {Humans, Brain, Consciousness, Brain Mapping, Magnetic Resonance Imaging, Mental Processes, Photic Stimulation, Visual Perception},
}

@article{parvizi_detecting_2018,
	title = {Detecting silent seizures by their sound},
	volume = {59},
	issn = {1528-1167},
	doi = {10.1111/epi.14043},
	abstract = {{OBJECTIVE}: The traditional approach to interpreting electroencephalograms ({EEGs}) requires physicians with formal training to visually assess the waveforms. This approach can be less practical in critical settings where a trained {EEG} specialist is not readily available to review the {EEG} and diagnose ongoing subclinical seizures, such as nonconvulsive status epilepticus.
{METHODS}: We have developed a novel method by which {EEG} data are converted to sound in real time by letting the underlying electrophysiological signal modulate a voice tone that is in the audible range. Here, we explored whether individuals without any prior {EEG} training could listen to 15-second sonified {EEG} and determine whether the {EEG} represents seizures or nonseizure conditions. We selected 84 {EEG} samples to represent seizures (n = 7), seizure-like activity (n = 25), or nonperiodic, nonrhythmic activity (normal or focal/generalized slowing, n = 52). {EEGs} from single channels in the left and right hemispheres were then converted to sound files. After a 4-minute training video, medical students (n = 34) and nurses (n = 30) were asked to designate each audio sample as "seizure" or "nonseizure." We then compared their performance with that of {EEG}-trained neurologists (n = 12) and medical students (n = 29) who also diagnosed the same {EEGs} on visual display.
{RESULTS}: Nonexperts listening to single-channel sonified {EEGs} detected seizures with remarkable sensitivity (students, 98\% ± 5\%; nurses, 95\% ± 14\%) compared to experts or nonexperts reviewing the same {EEGs} on visual display (neurologists, 88\% ± 11\%; students, 76\% ± 19\%). If the {EEGs} contained seizures or seizure-like activity, nonexperts listening to sonified {EEGs} rated them as seizures with high specificity (students, 85\% ± 9\%; nurses, 82\% ± 12\%) compared to experts or nonexperts viewing the {EEGs} visually (neurologists, 90\% ± 7\%; students, 65\% ± 20\%).
{SIGNIFICANCE}: Our study confirms that individuals without {EEG} training can detect ongoing seizures or seizure-like rhythmic periodic patterns by listening to sonified {EEG}. Although sonification of {EEG} cannot replace the traditional approaches to {EEG} interpretation, it provides a meaningful triage tool for fast assessment of patients with suspected subclinical seizures.},
	pages = {877--884},
	number = {4},
	journaltitle = {Epilepsia},
	shortjournal = {Epilepsia},
	author = {Parvizi, Josef and Gururangan, Kapil and Razavi, Babak and Chafe, Chris},
	date = {2018-04},
	pmid = {29558565},
	keywords = {Humans, Electroencephalography, Photic Stimulation, Acoustic Stimulation, {EEG} sonification, Epilepsies, Partial, Health Personnel, nonconvulsive status epilepticus, Retrospective Studies, rhythmic periodic pattern, Status Epilepticus, subclinical seizure},
	file = {Full Text:C\:\\Users\\miche\\Zotero\\storage\\PXXKU3BE\\Parvizi et al. - 2018 - Detecting silent seizures by their sound.pdf:application/pdf},
}

@article{fifel_readiness_2018,
	title = {Readiness Potential and Neuronal Determinism: New Insights on Libet Experiment},
	volume = {38},
	issn = {1529-2401},
	doi = {10.1523/JNEUROSCI.3136-17.2017},
	shorttitle = {Readiness Potential and Neuronal Determinism},
	pages = {784--786},
	number = {4},
	journaltitle = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
	shortjournal = {J Neurosci},
	author = {Fifel, Karim},
	date = {2018-01-24},
	pmid = {29367289},
	pmcid = {PMC6596234},
	keywords = {Contingent Negative Variation, Corpus Striatum, Neostriatum},
	file = {Full Text:C\:\\Users\\miche\\Zotero\\storage\\KMENSNRK\\Fifel - 2018 - Readiness Potential and Neuronal Determinism New .pdf:application/pdf},
}

@inproceedings{kenwright_brief_2017,
	location = {New York, {NY}, {USA}},
	title = {Brief review of video games in learning \&amp; education how far we have come},
	isbn = {978-1-4503-5409-7},
	url = {https://doi.org/10.1145/3134368.3139220},
	doi = {10.1145/3134368.3139220},
	series = {{SA} '17},
	abstract = {This paper presents a survey on video games in learning and education, including patterns and trends in technologies and correlations in popularity with regard to the entertainment industry. The fact that games have the ability to engage and captivate a person's attention for long periods of time, while offering numerous additional benefits, such as, developing high-level thinking skills, is extremely attractive and important. The capacity to unconsciously learn and master complex concepts through video games has enormous benefit in learning (beyond simple `educational' games, such as, sharpening focus, responsiveness, and collaborative working). As we show in this paper, research dating right back to the early 1980s has consistently demonstrated that playing computer games (irrespective of genre) develops faster reaction times, improved hand-eye co-ordination and raises players' self-esteem. We review video game literature in the area of education (and learning) and how technologies are changing traditional learning paradigms (e.g., mobile devices and virtual reality). What is more, we also review the disadvantages of video games in certain contexts and debate the reasons for their failures - but more importantly what measures are necessary to ensure video games facilitate as an educational `aid' and not a `hindrance'. Having said that, we deliberate on questions, such as, what makes an `educational game' and how is the design and structure different from a traditional `video game'? Above all, educational video games have changed enormously over the past few decades, with a greater emphasis on understanding the audience, learning objectives and evaluation mechanisms to `guarantee' the game is successful and accomplishes its end goal - as we discuss, this is embodied by a whole assortment of elements, from psychology, age, gender and technological factors to social and usability development. In conclusion, video games connect with a vast assortment of areas, such as, medicine and robotics, but most importantly, education and learning. With video games one of the largest growing sectors, we contemplate how past research and recent developments in technologies are changing the learning and educational sector for the better, thereby gaining insights into future strength and directions.},
	pages = {1--10},
	booktitle = {{SIGGRAPH} Asia 2017 Symposium on Education},
	publisher = {Association for Computing Machinery},
	author = {Kenwright, Ben},
	urldate = {2021-02-14},
	date = {2017-11-27},
	keywords = {computing, education, gamification, learning, serious games, technologies, video games},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\WIEDE5KV\\Kenwright - 2017 - Brief review of video games in learning &amp\; educ.pdf:application/pdf},
}

@online{noauthor_iclabel_nodate,
	title = {{ICLabel} - {SCCN}},
	url = {https://sccn.ucsd.edu/wiki/ICLabel},
	urldate = {2021-02-14},
	file = {ICLabel - SCCN:C\:\\Users\\miche\\Zotero\\storage\\22XNWRW9\\ICLabel.html:text/html},
}

@software{noauthor_sccncleanline_2020,
	title = {sccn/cleanline},
	rights = {View license         ,                 View license},
	url = {https://github.com/sccn/cleanline},
	abstract = {Clean Line. Contribute to sccn/cleanline development by creating an account on {GitHub}.},
	publisher = {Swartz Center for Computational Neuroscience},
	urldate = {2021-02-14},
	date = {2020-10-26},
	note = {original-date: 2019-12-03T21:30:50Z},
}

@software{noauthor_sccnclean_rawdata_2021,
	title = {sccn/clean\_rawdata},
	rights = {{GPL}-3.0 License         ,                 {GPL}-3.0 License},
	url = {https://github.com/sccn/clean_rawdata},
	abstract = {Cleaning Raw {EEG} data. Contribute to sccn/clean\_rawdata development by creating an account on {GitHub}.},
	publisher = {Swartz Center for Computational Neuroscience},
	urldate = {2021-02-14},
	date = {2021-01-24},
	note = {original-date: 2019-01-21T00:01:49Z},
}

@online{inc_crowdcast_nodate,
	title = {Crowdcast – Connect with your audience over live video},
	url = {https://www.crowdcast.io/},
	abstract = {Simple \& powerful Q\&As, webinars, live courses \& online summits with your audience.},
	titleaddon = {Crowdcast},
	author = {Inc, Crowdcast},
	urldate = {2021-02-10},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\9KMWYBQD\\1.html:text/html},
}

@article{ijsselsteijn_game_2013,
	title = {The Game Experience Questionnaire},
	url = {https://research.tue.nl/en/publications/the-game-experience-questionnaire},
	author = {{IJsselsteijn}, W. A. and Kort, Y. A. W. de and Poels, K.},
	urldate = {2021-02-10},
	date = {2013},
	note = {Publisher: Technische Universiteit Eindhoven},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\H5NYDL6W\\the-game-experience-questionnaire.html:text/html;Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\C7UTNQUI\\IJsselsteijn et al. - 2013 - The Game Experience Questionnaire.pdf:application/pdf},
}

@online{noauthor_muse_nodate,
	title = {{MUSE} Data Collection},
	url = {https://www.krigolsonlab.com/muse-data-collection.html},
	urldate = {2021-02-10},
}

@online{noauthor_tutorial_nodate,
	title = {Tutorial - Muse Developer Resources},
	url = {https://sites.google.com/a/interaxon.ca/muse-developer-site/muselab/tutorial},
	urldate = {2021-02-10},
}

@online{noauthor_jdpigeonbci-workshop_nodate,
	title = {jdpigeon/bci-workshop},
	url = {https://github.com/jdpigeon/bci-workshop},
	abstract = {Material for the {BCI} Workshop held at District 3 in May 2015 by {BCI} Montréal. - jdpigeon/bci-workshop},
	titleaddon = {{GitHub}},
	urldate = {2021-02-10},
	langid = {english},
}

@online{carroll_meditation_nodate,
	title = {Meditation for mind-control},
	url = {https://engineering.cmu.edu/news-events/news/2020/09/23-meditation.html},
	abstract = {Carnegie Mellon Biomedical Engineering Department Head Bin He and his team have discovered that mindful meditation can help subjects learn and improve the ability to mind-control brain computer interfaces ({BCIs}).},
	author = {Carroll, Dan},
	urldate = {2021-02-10},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\J2434H33\\21-parylene-photonics.html:text/html},
}

@article{sung_development_2012,
	title = {A Development Architecture for Serious Games Using {BCI} (Brain Computer Interface) Sensors},
	volume = {12},
	issn = {1424-8220},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3522980/},
	doi = {10.3390/s121115671},
	abstract = {Games that use brainwaves via brain–computer interface ({BCI}) devices, to improve brain functions are known as {BCI} serious games. Due to the difficulty of developing {BCI} serious games, various {BCI} engines and authoring tools are required, and these reduce the development time and cost. However, it is desirable to reduce the amount of technical knowledge of brain functions and {BCI} devices needed by game developers. Moreover, a systematic {BCI} serious game development process is required. In this paper, we present a methodology for the development of {BCI} serious games. We describe an architecture, authoring tools, and development process of the proposed methodology, and apply it to a game development approach for patients with mild cognitive impairment as an example. This application demonstrates that {BCI} serious games can be developed on the basis of expert-verified theories.},
	pages = {15671--15688},
	number = {11},
	journaltitle = {Sensors (Basel, Switzerland)},
	shortjournal = {Sensors (Basel)},
	author = {Sung, Yunsick and Cho, Kyungeun and Um, Kyhyun},
	urldate = {2021-02-10},
	date = {2012-11-12},
	pmid = {23202227},
	pmcid = {PMC3522980},
	file = {PubMed Central Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\VSVI9LPH\\Sung et al. - 2012 - A Development Architecture for Serious Games Using.pdf:application/pdf},
}

@article{garcia_ensemble_2021,
	title = {An Ensemble of Autonomous Auto-Encoders for Human Activity Recognition},
	doi = {10.1016/j.neucom.2020.01.125},
	abstract = {Human Activity Recognition is focused on the use of sensing technology to classify human activities and to infer human behavior. While traditional machine learning approaches use hand-crafted features to train their models, recent advancements in neural networks allow for automatic feature extraction. Auto-encoders are a type of neural network that can learn complex representations of the data and are commonly used for anomaly detection. In this work we propose a novel multi-class algorithm which consists of an ensemble of auto-encoders where each auto-encoder is associated with a unique class. We compared the proposed approach with other state-of-the-art approaches in the context of human activity recognition. Experimental results show that ensembles of auto-encoders can be efficient, robust and competitive. Moreover, this modular classifier structure allows for more flexible models. For example, the extension of the number of classes, by the inclusion of new auto-encoders, without the necessity to retrain the whole model.},
	journaltitle = {Neurocomputing},
	shortjournal = {Neurocomputing},
	author = {Garcia, Kemilly and Rebelo de Sá, Cláudio and Poel, Mannes and Carvalho, Tiago and Moreira, João and Cardoso, João and de Carvalho, Andre and Kok, Joost},
	date = {2021-01-26},
	file = {Garcia et al. - 2021 - An Ensemble of Autonomous Auto-Encoders for Human .pdf:C\:\\Users\\miche\\Zotero\\storage\\WLQ2NTUB\\Garcia et al. - 2021 - An Ensemble of Autonomous Auto-Encoders for Human .pdf:application/pdf},
}

@misc{noauthor_notitle_nodate,
}

@article{delorme_independent_2012,
	title = {Independent {EEG} Sources Are Dipolar},
	volume = {7},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0030135},
	doi = {10.1371/journal.pone.0030135},
	pages = {e30135},
	number = {2},
	journaltitle = {{PLoS} {ONE}},
	shortjournal = {{PLoS} {ONE}},
	author = {Delorme, Arnaud and Palmer, Jason and Onton, Julie and Oostenveld, Robert and Makeig, Scott},
	editor = {Ward, Lawrence M.},
	urldate = {2021-02-01},
	date = {2012-02-15},
	langid = {english},
	file = {Full Text:C\:\\Users\\miche\\Zotero\\storage\\KCLPPK67\\Delorme et al. - 2012 - Independent EEG Sources Are Dipolar.pdf:application/pdf},
}

@online{noauthor_consumers_nodate,
	title = {Consumers want manufacturers \& retailers to reduce plastic usage - Retail Gazette},
	url = {https://www.retailgazette.co.uk/blog/2019/09/plastic-usage-waste-sustainability-enviroment-consumers/},
	urldate = {2021-01-28},
}

@article{dilkes-hoffman_public_2019,
	title = {Public attitudes towards plastics},
	volume = {147},
	issn = {0921-3449},
	url = {http://www.sciencedirect.com/science/article/pii/S0921344919302101},
	doi = {10.1016/j.resconrec.2019.05.005},
	abstract = {Understanding and engaging the public is key for ensuring the success of government and industry initiatives aimed at addressing the problem of plastic waste. However, there has been little focus on documenting the general public’s attitudes towards plastics. This study examines public beliefs and attitudes towards plastics in Australia and provides insight on a global level. The research was conducted using an online survey of a nationally representative sample (2518 respondents). Overall, the survey results indicate that the public view plastics as a serious environmental issue. Plastic in the ocean had the highest mean rating for seriousness out of nine environmental issues, followed by two other issues relating to plastic waste production and disposal. Whilst there was an association of plastics with food packaging and convenience, there was more of a negative association with the use of plastic overall. Eighty percent of respondents indicated a desire to reduce plastic use and the majority of respondents believe that paper and glass are more environmentally friendly packaging materials than plastics. However, the results showed that many respondents do not translate their aspiration to reduce plastic use into action. Overall, while a majority of the Australian public are concerned about plastics as an environmental issue, they place the bulk of the responsibility for reducing the use of disposable plastic on industry and government.},
	pages = {227--235},
	journaltitle = {Resources, Conservation and Recycling},
	shortjournal = {Resources, Conservation and Recycling},
	author = {Dilkes-Hoffman, Leela Sarena and Pratt, Steven and Laycock, Bronwyn and Ashworth, Peta and Lant, Paul Andrew},
	urldate = {2021-01-28},
	date = {2019-08-01},
	langid = {english},
	keywords = {Consumer attitude, Environmental issues, Plastic in the ocean, Plastic waste, Reduce plastic use, Responsibility},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\3XWZ5V8W\\S0921344919302101.html:text/html;ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\L6WVBI94\\Dilkes-Hoffman et al. - 2019 - Public attitudes towards plastics.pdf:application/pdf},
}

@online{noauthor_ban_nodate,
	title = {Ban on sale of single-use plastics},
	url = {https://business.gov.nl/amendment/ban-sale-single-use-plastics/},
	abstract = {Business.gov.nl - The official source of information for doing business in the Netherlands, made available by the Dutch government.},
	titleaddon = {business.gov.nl},
	urldate = {2021-01-28},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\BL77VAWK\\ban-sale-single-use-plastics.html:text/html},
}

@patent{noauthor_micropits_2015,
	title = {Micropits for ultrasonic treatment},
	url = {https://patents.google.com/patent/WO2015144918A1/en},
	abstract = {The invention provides a method for treating an object (100), the method comprising: (a) providing a liquid (210); (b) arranging the object (100) in the liquid (210), wherein the object (100) is at least partially enclosed in an enclosure (300), wherein the enclosure (300) comprises polymeric enclosure material (310) having a polymeric material surface (320) directed to the object (100), the polymeric material surface (320) comprising cavities (330) having equivalent circular diameters selected from the range of 10 μm - 2 mm; and (c) providing ultrasound to the liquid (210).},
	type = {patent},
	urldate = {2021-01-28},
	date = {2015-03-27},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\SD9VY8LL\\en.html:text/html;Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\VIVH3BJ8\\2015 - Micropits for ultrasonic treatment.pdf:application/pdf},
}

@online{noauthor_6_2020,
	title = {6 ways to strengthen your online presence to benefit your business},
	url = {https://www.experian.co.uk/blogs/latest-thinking/small-business/6-benefits-to-an-online-presence/},
	abstract = {Being able to adapt and make the most of the opportunities presented by the changing digital world has already seen many small businesses not only survive, but thrive. The good news is that now, more than ever, there are a multitude of low-cost, accessible ways to do that, with the potential for a great return on investment.},
	titleaddon = {Latest Thinking Blog},
	urldate = {2021-01-28},
	date = {2020-09-16},
	langid = {british},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\IW9QTU5P\\6-benefits-to-an-online-presence.html:text/html},
}

@book{corporation_popular_1970,
	title = {Popular Science},
	abstract = {Popular Science gives our readers the information and tools to improve
their technology and their world.  The core belief that Popular
Science and our readers share: The future is going to be better, and
science and technology are the driving forces that will help make it
better.},
	pagetotal = {162},
	publisher = {Bonnier Corporation},
	author = {Corporation, Bonnier},
	date = {1970-03},
	langid = {english},
	note = {Google-Books-{ID}: 6QAAAAAAMBAJ},
}

@article{luo_data_2020,
	title = {Data Augmentation for Enhancing {EEG}-based Emotion Recognition with Deep Generative Models},
	url = {http://arxiv.org/abs/2006.05331},
	abstract = {The data scarcity problem in emotion recognition from electroencephalography ({EEG}) leads to difficulty in building an affective model with high accuracy using machine learning algorithms or deep neural networks. Inspired by emerging deep generative models, we propose three methods for augmenting {EEG} training data to enhance the performance of emotion recognition models. Our proposed methods are based on two deep generative models, variational autoencoder ({VAE}) and generative adversarial network ({GAN}), and two data augmentation strategies. For the full usage strategy, all of the generated data are augmented to the training dataset without judging the quality of the generated data, while for partial usage, only high-quality data are selected and appended to the training dataset. These three methods are called conditional Wasserstein {GAN} ({cWGAN}), selective {VAE} ({sVAE}), and selective {WGAN} ({sWGAN}). To evaluate the effectiveness of these methods, we perform a systematic experimental study on two public {EEG} datasets for emotion recognition, namely, {SEED} and {DEAP}. We first generate realistic-like {EEG} training data in two forms: power spectral density and differential entropy. Then, we augment the original training datasets with a different number of generated realistic-like {EEG} data. Finally, we train support vector machines and deep neural networks with shortcut layers to build affective models using the original and augmented training datasets. The experimental results demonstrate that the augmented training datasets produced by our methods enhance the performance of {EEG}-based emotion recognition models and outperform the existing data augmentation methods such as conditional {VAE}, Gaussian noise, and rotational data augmentation.},
	journaltitle = {{arXiv}:2006.05331 [cs, eess]},
	author = {Luo, Yun and Zhu, Li-Zhen and Wan, Zi-Yu and Lu, Bao-Liang},
	urldate = {2021-05-03},
	date = {2020-06-17},
	eprinttype = {arxiv},
	eprint = {2006.05331},
	note = {version: 2},
	keywords = {Electrical Engineering and Systems Science - Signal Processing, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\miche\\Zotero\\storage\\TGKTZYWG\\Luo et al. - 2020 - Data Augmentation for Enhancing EEG-based Emotion .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\miche\\Zotero\\storage\\CBZCPRI2\\2006.html:text/html},
}

@article{slutter_exploring_2021,
	title = {Exploring the Brain Activity Related to Missing Penalty Kicks: An {fNIRS} Study},
	volume = {3},
	issn = {2624-9898},
	url = {https://www.frontiersin.org/articles/10.3389/fcomp.2021.661466/full},
	doi = {10.3389/fcomp.2021.661466},
	shorttitle = {Exploring the Brain Activity Related to Missing Penalty Kicks},
	abstract = {At vital moments in professional soccer matches, penalties were often missed. Psychological factors, such as anxiety and pressure, are among the critical causes of the mistakes, commonly known as choking under pressure. Nevertheless, the factors have not been fully explored. In this study, we used functional near-infrared spectroscopy ({fNIRS}) to investigate the influence of the brain on this process. An in-situ study was set-up (N=22), in which each participant took 15 penalties under three different pressure conditions: without a goalkeeper, with an amiable goalkeeper, and with a competitive goalkeeper. Both experienced and inexperienced soccer players were recruited, and the brain activation was compared across groups. Besides, {fNIRS} activation was compared between sessions that participants felt anxious against sessions without anxiety report, and between penalty-scoring and -missing sessions. The results show that the task-relevant brain region, the motor cortex, was more activated when players were not experiencing performance anxiety. The activation of task-irrelevant areas was shown to be related to players experiencing anxiety and missing penalties, especially the prefrontal cortex ({PFC}). More particularly, an overall higher activation of the {PFC} and an increase of {PFC} lateral asymmetry were related to anxious players and missed penalties, which can be caused by players' worries about the consequences of scoring or missing the penalty kicks. When experienced players were feeling anxious, their left temporal cortex activation increased, which could be an indication that experienced overthink the situation and neglect their automated skills. Besides, the left temporal cortex activation is higher when inexperienced players succeeded to score a penalty. Overall, the results of this study are in line with the neural efficiency theory and demonstrate the feasibility and ecological validity to detect neurological clues relevant to anxiety and performance from {fNIRS} recordings in the field.},
	journaltitle = {Frontiers in Computer Science},
	shortjournal = {Front. Comput. Sci.},
	author = {Slutter, Max W. J. and Thammasan, Nattapong and Poel, Mannes},
	urldate = {2021-05-07},
	date = {2021},
	note = {Publisher: Frontiers},
	keywords = {choking, {fNIRS}, Football, Mental pressure, neural efficiency, Penalty kick, Soccer, Sports},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\JNHJFVUP\\Slutter et al. - 2021 - Exploring the Brain Activity Related to Missing Pe.pdf:application/pdf},
}

@inproceedings{liu_eeg_2013,
	title = {{EEG} Databases for Emotion Recognition},
	doi = {10.1109/CW.2013.52},
	abstract = {Emotion recognition from Electroencephalogram ({EEG}) rapidly gains interest from research community. Two affective {EEG} databases are presented in this paper. Two experiments are conducted to set up the databases. Audio and visual stimuli are used to evoke emotions during the experiments. The stimuli are selected from {IADS} and {IAPS} databases.14 subjects participated in each experiment. Emotiv {EEG} device is used for the data recording. The {EEG} data are rated by the participants with arousal, valence, and dominance levels. The correlation between powers of different {EEG} bands and the affective ratings is studied. The results agree with the literature findings and analyses of benchmark {DEAP} database that proves the reliability of the two databases. Similar brain patterns of emotions are obtained between the established databases and the benchmark database. A {SVM}-based emotion recognition algorithm is proposed and applied to both databases and the benchmark database. Use of a Fractal Dimension feature in combination with statistical and Higher Order Crossings ({HOC}) features gives us results with the best accuracy. Up to 8 emotions can be recognized. The accuracy is consistent between the established databases and the benchmark database.},
	eventtitle = {2013 International Conference on Cyberworlds},
	pages = {302--309},
	booktitle = {2013 International Conference on Cyberworlds},
	author = {Liu, Yisi and Sourina, Olga},
	date = {2013-10},
	keywords = {{EEG}, Electroencephalography, Electrodes, Databases, Visualization, Correlation, Emotion recognition, emotion recognition, affective computing, affective database, fractal dimension, Fractals},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\MAHIZW4A\\6680130.html:text/html},
}

@article{jerbi_coherent_2007,
	title = {Coherent neural representation of hand speed in humans revealed by {MEG} imaging},
	volume = {104},
	rights = {© 2007 by The National Academy of Sciences of the {USA}},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/104/18/7676},
	doi = {10.1073/pnas.0609632104},
	abstract = {The spiking activity of single neurons in the primate motor cortex is correlated with various limb movement parameters, including velocity. Recent findings obtained using local field potentials suggest that hand speed may also be encoded in the summed activity of neuronal populations. At this macroscopic level, the motor cortex has also been shown to display synchronized rhythmic activity modulated by motor behavior. Yet whether and how neural oscillations might be related to limb speed control is still poorly understood. Here, we applied magnetoencephalography ({MEG}) source imaging to the ongoing brain activity in subjects performing a continuous visuomotor ({VM}) task. We used coherence and phase synchronization to investigate the coupling between the estimated activity throughout the brain and the simultaneously recorded instantaneous hand speed. We found significant phase locking between slow (2- to 5-Hz) oscillatory activity in the contralateral primary motor cortex and time-varying hand speed. In addition, we report long-range task-related coupling between primary motor cortex and multiple brain regions in the same frequency band. The detected large-scale {VM} network spans several cortical and subcortical areas, including structures of the frontoparietal circuit and the cerebello–thalamo–cortical pathway. These findings suggest a role for slow coherent oscillations in mediating neural representations of hand kinematics in humans and provide further support for the putative role of long-range neural synchronization in large-scale {VM} integration. Our findings are discussed in the context of corticomotor communication, distributed motor encoding, and possible implications for brain–machine interfaces.},
	pages = {7676--7681},
	number = {18},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {{PNAS}},
	author = {Jerbi, Karim and Lachaux, Jean-Philippe and N′Diaye, Karim and Pantazis, Dimitrios and Leahy, Richard M. and Garnero, Line and Baillet, Sylvain},
	urldate = {2021-05-14},
	date = {2007-05-01},
	langid = {english},
	pmid = {17442753},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {large-scale networks, magnetoencephalography, motor cortex, oscillations, visuomotor integration},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\NWAC98ND\\Jerbi et al. - 2007 - Coherent neural representation of hand speed in hu.pdf:application/pdf},
}

@article{kostas_bendr_2021,
	title = {{BENDR}: using transformers and a contrastive self-supervised learning task to learn from massive amounts of {EEG} data},
	url = {http://arxiv.org/abs/2101.12037},
	shorttitle = {{BENDR}},
	abstract = {Deep neural networks ({DNNs}) used for brain-computer-interface ({BCI}) classification are commonly expected to learn general features when trained across a variety of contexts, such that these features could be fine-tuned to specific contexts. While some success is found in such an approach, we suggest that this interpretation is limited and an alternative would better leverage the newly (publicly) available massive {EEG} datasets. We consider how to adapt techniques and architectures used for language modelling ({LM}), that appear capable of ingesting awesome amounts of data, towards the development of encephalography modelling ({EM}) with {DNNs} in the same vein. We specifically adapt an approach effectively used for automatic speech recognition, which similarly (to {LMs}) uses a self-supervised training objective to learn compressed representations of raw data signals. After adaptation to {EEG}, we find that a single pre-trained model is capable of modelling completely novel raw {EEG} sequences recorded with differing hardware, and different subjects performing different tasks. Furthermore, both the internal representations of this model and the entire architecture can be fine-tuned to a variety of downstream {BCI} and {EEG} classification tasks, outperforming prior work in more task-specific (sleep stage classification) self-supervision.},
	journaltitle = {{arXiv}:2101.12037 [cs, q-bio]},
	author = {Kostas, Demetres and Aroca-Ouellette, Stephane and Rudzicz, Frank},
	urldate = {2021-05-14},
	date = {2021-01-28},
	eprinttype = {arxiv},
	eprint = {2101.12037},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Quantitative Biology - Quantitative Methods},
	file = {arXiv Fulltext PDF:C\:\\Users\\miche\\Zotero\\storage\\GWF8MA5L\\Kostas et al. - 2021 - BENDR using transformers and a contrastive self-s.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\miche\\Zotero\\storage\\EE2EFUC2\\2101.html:text/html},
}

@article{sangnark_revealing_2021,
	title = {Revealing Preference in Popular Music Through Familiarity and Brain Response},
	issn = {1530-437X, 1558-1748, 2379-9153},
	url = {http://arxiv.org/abs/2102.00159},
	doi = {10.1109/JSEN.2021.3073040},
	abstract = {Music preference was reported as a factor, which could elicit innermost music emotion, entailing accurate ground-truth data and music therapy efficiency. This study executes statistical analysis to investigate the distinction of music preference through familiarity scores, response times (response rates), and brain response ({EEG}). Twenty participants did self-assessment after listening to two types of popular music's chorus section: music without lyrics (Melody) and music with lyrics (Song). {\textbackslash}textcolor\{red\}\{We then conduct a music preference classification using a support vector machine, random forest, and k-nearest neighbors with the familiarity scores, the response rates, and {EEG} as the feature vectors. The statistical analysis and F1-score of {EEG} are congruent, which is the brain's right side outperformed its left side in classification performance.\} Finally, these behavioral and brain studies support that preference, familiarity, and response rates can contribute to the music emotion experiment's design to understand music, emotion, and listener. Not only to the music industry, the biomedical and healthcare industry can also exploit this experiment to collect data from patients to improve the efficiency of healing by music.},
	pages = {1--1},
	journaltitle = {{IEEE} Sensors Journal},
	shortjournal = {{IEEE} Sensors J.},
	author = {Sangnark, Soravitt and Autthasan, Phairot and Ponglertnapakorn, Puntawat and Chalekarn, Phudit and Sudhawiyangkul, Thapanun and Trakulruangroj, Manatsanan and Songsermsawad, Sarita and Assabumrungrat, Rawin and Amplod, Supalak and Ounjai, Kajornvut and Wilaiprasitporn, Theerawit},
	urldate = {2021-05-17},
	date = {2021},
	eprinttype = {arxiv},
	eprint = {2102.00159},
	keywords = {Electrical Engineering and Systems Science - Signal Processing, Computer Science - Human-Computer Interaction},
	file = {arXiv Fulltext PDF:C\:\\Users\\miche\\Zotero\\storage\\JEW78YUT\\Sangnark et al. - 2021 - Revealing Preference in Popular Music Through Fami.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\miche\\Zotero\\storage\\YT9SX2HH\\2102.html:text/html},
}

@article{ward_same_2013,
	title = {The same old song: The power of familiarity in music choice},
	volume = {25},
	doi = {10.1007/s11002-013-9238-1},
	shorttitle = {The same old song},
	abstract = {Does "familiarity breed contempt" or is "to know you is to love you"? In this research, we explore the role of familiarity in music choice. We show that although consumers say they would prefer to listen to unfamiliar music, in actuality familiarity with music positively predicts preference for songs, play lists, and radio stations. Familiarity with music is at least as good, if not a better, predictor of choice as are liking, satiation (which actually positively predicts choice), and regret. We suggest that the need for familiarity is driven by consumers' low need for stimulation in the music domain, and show that when the need for stimulation decreases, the power of familiarity significantly increases. In addition to their theoretical contribu-tion, these results are informative for music managers determining playlists, for the promotion of music events and products, and for advertisers selecting the most potentially lucrative music venues.},
	journaltitle = {Marketing Letters},
	shortjournal = {Marketing Letters},
	author = {Ward, Morgan and Goodman, Joseph and Irwin, Julie},
	date = {2013-05-01},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\AYUHPAQX\\Ward et al. - 2013 - The same old song The power of familiarity in mus.pdf:application/pdf},
}

@online{le_how_2017,
	title = {How to build a simple song recommender system},
	url = {https://towardsdatascience.com/how-to-build-a-simple-song-recommender-296fcbc8c85},
	abstract = {This blog post is inspired by Siraj Raval’s Deep Learning Foundation Nanodegree at Udacity. Then repo of this exercise can be found here.},
	titleaddon = {Medium},
	author = {Le, Eric},
	urldate = {2021-05-17},
	date = {2017-04-26},
	langid = {english},
}

@article{chang_experiencing_2015,
	title = {Experiencing affective music in eyes-closed and eyes-open states: an electroencephalography study},
	volume = {6},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01160/full},
	doi = {10.3389/fpsyg.2015.01160},
	shorttitle = {Experiencing affective music in eyes-closed and eyes-open states},
	abstract = {In real life, listening to music may be associated with an eyes-closed or eyes-open state. The effect of eye state on listeners' reaction to music has attracted some attention, but its influence on brain activity has not been fully investigated. The present study aimed to evaluate the electroencephalographic ({EEG}) markers for the emotional valence of music in different eye states. Thirty participants listened to musical excerpts with different emotional content in the eyes-closed and eyes-open states. The results showed that participants rated the music as more pleasant or with more positive valence under an eyes-open state. In addition, we found that the alpha asymmetry indices calculated on the parietal and temporal sites reflected emotion valence in the eyes-closed and eyes-open states, respectively. The theta power in the frontal area significantly increased while listening to emotional-positive music compared to emotional-negative music under the eyes-closed condition. These effects of eye states on {EEG} markers are discussed in terms of brain mechanisms underlying attention and emotion.},
	journaltitle = {Frontiers in Psychology},
	shortjournal = {Front. Psychol.},
	author = {Chang, Yun-Hsuan and Lee, You-Yun and Liang, Keng-Chen and Chen, I.-Ping and Tsai, Chen-Gia and Hsieh, Shulan},
	urldate = {2021-05-20},
	date = {2015},
	note = {Publisher: Frontiers},
	keywords = {Electroencephalography, Music, Alpha asymmetry, emotional valence, eye state},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\77JKV5B3\\Chang et al. - 2015 - Experiencing affective music in eyes-closed and ey.pdf:application/pdf},
}

@article{eerola_review_2013,
	title = {A Review of Music and Emotion Studies: Approaches, Emotion Models, and Stimuli},
	doi = {10.1525/mp.2012.30.3.307},
	shorttitle = {A Review of Music and Emotion Studies},
	abstract = {{THE} {FIELD} {OF} {MUSIC} {AND} {EMOTION} {RESEARCH} {HAS} grown rapidly and diversified during the last decade. This has led to a certain degree of confusion and inconsistency between competing notions of emotions, data, and results. The present review of 251 studies describes the focus of prevalent research approaches, methods, and models of emotion, and documents the types of musical stimuli used over the past twenty years. Although self-report approaches to emotions are the most common way of dealing with music and emotions, using multiple approaches is becoming increasingly popular. A large majority (70\%) of the studies employed variants of the discrete or the dimensional emotion models. A large proportion of stimuli rely on a relatively modest amount of familiar classical examples. The evident shortcomings of these prevalent patterns in music and emotion studies are highlighted, and concrete plans of action for future studies are suggested.},
	journaltitle = {Music Perception},
	shortjournal = {Music Perception},
	author = {Eerola, Tuomas and Vuoskoski, Jonna},
	date = {2013-02-01},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\BUHURTR3\\Eerola and Vuoskoski - 2013 - A Review of Music and Emotion Studies Approaches,.pdf:application/pdf},
}

@article{reuderink_valence_2013,
	title = {Valence, arousal and dominance in the {EEG} during game play},
	volume = {6},
	doi = {10.1504/IJAACS.2013.050691},
	abstract = {In this paper, we describe our investigation of traces of naturally occurring emotions in electrical brain signals, that can be used to build interfaces that respond to our emotional state. This study confirms a number of known affective correlates in a realistic, uncontrolled environment for the emotions of valence (or pleasure), arousal and dominance: (1) a significant decrease in frontal power in the theta range is found for increasingly positive valence, (2) a significant frontal increase in power in the alpha range is associated with increasing emotional arousal, (3) a significant right posterior power increase in the delta range correlates with increasing arousal and (4) asymmetry in power in the lower alpha bands correlates with self-reported valence. Furthermore, asymmetry in the higher alpha bands correlates with self-reported dominance. These last two effects provide a simple measure for subjective feelings of pleasure and feelings of control.},
	pages = {45--62},
	journaltitle = {International Journal of Autonomous and Adaptive Communications Systems},
	shortjournal = {International Journal of Autonomous and Adaptive Communications Systems},
	author = {Reuderink, Boris and Mühl, Christian and Poel, Mannes},
	date = {2013-12-01},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\K4YCJCSE\\Reuderink et al. - 2013 - Valence, arousal and dominance in the EEG during g.pdf:application/pdf},
}

@article{asghar_eeg-based_2019,
	title = {{EEG}-Based Multi-Modal Emotion Recognition using Bag of Deep Features: An Optimal Feature Selection Approach},
	volume = {19},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/19/23/5218},
	doi = {10.3390/s19235218},
	shorttitle = {{EEG}-Based Multi-Modal Emotion Recognition using Bag of Deep Features},
	abstract = {Much attention has been paid to the recognition of human emotions with the help of electroencephalogram ({EEG}) signals based on machine learning technology. Recognizing emotions is a challenging task due to the non-linear property of the {EEG} signal. This paper presents an advanced signal processing method using the deep neural network ({DNN}) for emotion recognition based on {EEG} signals. The spectral and temporal components of the raw {EEG} signal are first retained in the 2D Spectrogram before the extraction of features. The pre-trained {AlexNet} model is used to extract the raw features from the 2D Spectrogram for each channel. To reduce the feature dimensionality, spatial, and temporal based, bag of deep features ({BoDF}) model is proposed. A series of vocabularies consisting of 10 cluster centers of each class is calculated using the k-means cluster algorithm. Lastly, the emotion of each subject is represented using the histogram of the vocabulary set collected from the raw-feature of a single channel. Features extracted from the proposed {BoDF} model have considerably smaller dimensions. The proposed model achieves better classification accuracy compared to the recently reported work when validated on {SJTU} {SEED} and {DEAP} data sets. For optimal classification performance, we use a support vector machine ({SVM}) and k-nearest neighbor (k-{NN}) to classify the extracted features for the different emotional states of the two data sets. The {BoDF} model achieves 93.8\% accuracy in the {SEED} data set and 77.4\% accuracy in the {DEAP} data set, which is more accurate compared to other state-of-the-art methods of human emotion recognition.},
	pages = {5218},
	number = {23},
	journaltitle = {Sensors},
	author = {Asghar, Muhammad Adeel and Khan, Muhammad Jamil and Fawad and Amin, Yasar and Rizwan, Muhammad and Rahman, {MuhibUr} and Badnava, Salman and Mirjavadi, Seyed Sajad},
	urldate = {2021-05-30},
	date = {2019-01},
	langid = {english},
	note = {Number: 23
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {brain computer interface, emotion recognition, bag of deep features, continuous wavelet transform},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\JWHKEYGV\\Asghar et al. - 2019 - EEG-Based Multi-Modal Emotion Recognition using Ba.pdf:application/pdf;Snapshot:C\:\\Users\\miche\\Zotero\\storage\\KJ7N3G83\\htm.html:text/html},
}

@article{wang_emotion_2020,
	title = {Emotion recognition with convolutional neural network and {EEG}-based {EFDMs}},
	volume = {146},
	issn = {0028-3932},
	url = {https://www.sciencedirect.com/science/article/pii/S0028393220301780},
	doi = {10.1016/j.neuropsychologia.2020.107506},
	abstract = {Electroencephalogram ({EEG}), as a direct response to brain activity, can be used to detect mental states and physical conditions. Among various {EEG}-based emotion recognition studies, due to the non-linear, non-stationary and the individual difference of {EEG} signals, traditional recognition methods still have the disadvantages of complicated feature extraction and low recognition rates. Thus, this paper first proposes a novel concept of electrode-frequency distribution maps ({EFDMs}) with short-time Fourier transform ({STFT}). Residual block based deep convolutional neural network ({CNN}) is proposed for automatic feature extraction and emotion classification with {EFDMs}. Aim at the shortcomings of the small amount of {EEG} samples and the challenge of differences in individual emotions, which makes it difficult to construct a universal model, this paper proposes a cross-datasets emotion recognition method of deep model transfer learning. Experiments carried out on two publicly available datasets. The proposed method achieved an average classification score of 90.59\% based on a short length of {EEG} data on {SEED}, which is 4.51\% higher than the baseline method. Then, the pre-trained model was applied to {DEAP} through deep model transfer learning with a few samples, resulted an average accuracy of 82.84\%. Finally, this paper adopts the gradient weighted class activation mapping (Grad-{CAM}) to get a glimpse of what features the {CNN} has learned during training from {EFDMs} and concludes that the high frequency bands are more favorable for emotion recognition.},
	pages = {107506},
	journaltitle = {Neuropsychologia},
	shortjournal = {Neuropsychologia},
	author = {Wang, Fei and Wu, Shichao and Zhang, Weiwei and Xu, Zongfeng and Zhang, Yahui and Wu, Chengdong and Coleman, Sonya},
	urldate = {2021-05-30},
	date = {2020-09-01},
	langid = {english},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\SGS5CFWH\\Wang et al. - 2020 - Emotion recognition with convolutional neural netw.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\SUEZTXFI\\S0028393220301780.html:text/html},
}

@article{zhao_frontal_2018,
	title = {Frontal {EEG} Asymmetry and Middle Line Power Difference in Discrete Emotions},
	volume = {12},
	issn = {1662-5153},
	url = {https://www.frontiersin.org/articles/10.3389/fnbeh.2018.00225/full},
	doi = {10.3389/fnbeh.2018.00225},
	abstract = {A traditional model of emotion cannot explain the differences in brain activities between two discrete emotions that are similar in the valence-arousal coordinate space. The current study elicited two positive emotions (amusement and tenderness) and two negative emotions (anger and fear) that are similar in both valence and arousal dimensions to examine the differences in brain activities in these emotional states. Frontal electroencephalographic ({EEG}) asymmetry and midline power in three bands (theta, alpha, and beta) were measured when participants watched affective film excerpts. Significant differences were detected between tenderness and amusement on {FP}1/{FP}2 theta asymmetry, F3/F4 theta and alpha asymmetry. Significant differences between anger and fear on {FP}1/{FP}2 theta asymmetry and F3/F4 alpha asymmetry were also observed. For midline power, midline theta power could distinguish two negative emotions, while midline alpha and beta power could effectively differentiate two positive emotions. Liking and dominance were also related to {EEG} features. Stepwise multiple linear regression results revealed that frontal alpha and theta asymmetry could predict the subjective feelings of two positive and two negative emotions in different patterns. The binary classification accuracy, which used {EEG} frontal asymmetry and midline power as features and {SVM} as classifiers, was as high as 64.52\% for tenderness and amusement and 78.79\% for anger and fear. The classification accuracy was improved after adding these features to other features extracted across the scalp. These findings indicate that frontal {EEG} asymmetry and midline power might have the potential to recognize discrete emotions that are similar in the valence-arousal coordinate space.},
	journaltitle = {Frontiers in Behavioral Neuroscience},
	shortjournal = {Front. Behav. Neurosci.},
	author = {Zhao, Guozhen and Zhang, Yulin and Ge, Yan},
	urldate = {2021-05-30},
	date = {2018},
	note = {Publisher: Frontiers},
	keywords = {discrete emotion, frontal {EEG} asymmetry, midline power, Negative Staining, Positive emotions},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\BCSFAN9G\\Zhao et al. - 2018 - Frontal EEG Asymmetry and Middle Line Power Differ.pdf:application/pdf},
}

@online{noauthor_view_nodate,
	title = {View of A Review on {EEG} Signals Based Emotion Recognition},
	url = {https://journals.sbmu.ac.ir/neuroscience/article/view/18477/1},
	urldate = {2021-05-31},
	file = {View of A Review on EEG Signals Based Emotion Recognition:C\:\\Users\\miche\\Zotero\\storage\\VDMTYCJP\\1.html:text/html},
}

@inproceedings{wu_estimation_2017,
	title = {Estimation of valence of emotion using two frontal {EEG} channels},
	doi = {10.1109/BIBM.2017.8217815},
	abstract = {Emotion recognition using {EEG} signals has become a hot research topic in the last few years. This paper aims at providing a novel method for emotion recognition using less channels of frontal {EEG} signals. By employing the asymmetry theory of frontal brain, a new method fusing spatial and frequency features was presented, which only adopted two channels of frontal {EEG} signals at Fp1 and Fp2. In order to estimate the efficiency of the method, a {GBDT} classifier was evaluated and selected, and the method was implemented on the {DEAP} database. The maximum and mean classification accuracy were achieved as 76.34\% and 75.18\% respectively, which exhibited the best result comparing with other related studies. This method is extremely suitable for wearable {EEG} monitoring applications in human daily life.},
	eventtitle = {2017 {IEEE} International Conference on Bioinformatics and Biomedicine ({BIBM})},
	pages = {1127--1130},
	booktitle = {2017 {IEEE} International Conference on Bioinformatics and Biomedicine ({BIBM})},
	author = {Wu, Shiyi and Xu, Xiangmin and Shu, Lin and Hu, Bin},
	date = {2017-11},
	keywords = {Electroencephalography, Entropy, Feature extraction, Emotion recognition, {DEAP}, Biomedical monitoring, Frontal {EEG}, {GBDT} classifier, Indexes},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\W43D52SS\\Wu et al. - 2017 - Estimation of valence of emotion using two frontal.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\MSWUHK8R\\8217815.html:text/html},
}

@article{garg_emotion_2020,
	title = {Emotion Recognition in Valence-Arousal Space from Multi-channel {EEG} data and Wavelet based Deep Learning Framework},
	volume = {171},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050920310644},
	doi = {10.1016/j.procs.2020.04.093},
	series = {Third International Conference on Computing and Network Communications ({CoCoNet}'19)},
	abstract = {The conventional emotion recognition methods are mostly based on the frequency characteristics of electroencephalograph ({EEG}) signals. However, spatial features are likewise valuable as it contains latent information related to emotional states. In this paper, a wavelet-based Deep Learning framework proposed by considering both frequency and spatial characteristics of multi-channel {EEG} signal for emotion recognition. The Continuous Wavelet Transform is utilized to produce Scalogram, a function of frequency and time to getting better time localization for short-duration, high-frequency events, and better frequency localization for low-frequency, longer-duration events. Then, the {GoogleNet} model is presented to recognize emotion states from Scalogram. The experiments performed with benchmark {DEAP} database having a three-dimensional valence, arousal, and dominance data along with multi-channel {EEG} data. The experimental results demonstrate that the characteristics contained in the Scalogram were complementary, and {GoogleNet} is more suitable for emotion recognition in two/ three-dimension space.},
	pages = {857--867},
	journaltitle = {Procedia Computer Science},
	shortjournal = {Procedia Computer Science},
	author = {Garg, Divya and Verma, Gyanendra K.},
	urldate = {2021-06-14},
	date = {2020-01-01},
	langid = {english},
	keywords = {{EEG}, {CNN}, Affective Computing, {DEAP} database, {GoogleNet}, Scalograms, Wavelet Transform},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\CUWPVC58\\Garg and Verma - 2020 - Emotion Recognition in Valence-Arousal Space from .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\EZME98K2\\S1877050920310644.html:text/html},
}

@inproceedings{noauthor_fractal-based_2011,
	location = {Rome, Italy},
	title = {A {FRACTAL}-{BASED} {ALGORITHM} {OF} {EMOTION} {RECOGNITION} {FROM} {EEG} {USING} {AROUSAL}-{VALENCE} {MODEL}:},
	isbn = {978-989-8425-35-5},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0003151802090214},
	doi = {10.5220/0003151802090214},
	shorttitle = {A {FRACTAL}-{BASED} {ALGORITHM} {OF} {EMOTION} {RECOGNITION} {FROM} {EEG} {USING} {AROUSAL}-{VALENCE} {MODEL}},
	eventtitle = {International Conference on Bio-inspired Systems and Signal Processing},
	pages = {209--214},
	booktitle = {Proceedings of the International Conference on Bio-inspired Systems and Signal Processing},
	publisher = {{SciTePress} - Science and and Technology Publications},
	urldate = {2021-06-23},
	date = {2011},
	langid = {english},
}

@inproceedings{sourina_fractal-based_2011,
	title = {A Fractal-based Algorithm of Emotion Recognition from {EEG} using Arousal-Valence Model},
	doi = {10.5220/0003151802090214},
	abstract = {Emotion recognition from {EEG} could be used in many applications as it allows us to know the “inner” emotion regardless of the human facial expression, behaviour, or verbal communication. In this paper, we proposed and described a novel fractal dimension ({FD}) based emotion recognition algorithm using an Arousal-Valence emotion model. {FD} values calculated from the {EEG} signal recorded from the corresponding brain lobes are mapped to the 2D emotion model. The proposed algorithm allows us to recognize emotions that could be defined by arousal and valence levels. Only 3 electrodes are needed for the emotions recognition. Higuchi and box-counting algorithms were used for the {EEG} analysis and comparison. Support Vector Machine classifier was applied for arousal and valence levels recognition. The proposed method is a subject dependent one. Experiments with music and sound stimuli to induce human emotions were realized. Sound clips from the International Affective Digitized Sounds ({IADS}) database were used in the experiments.},
	booktitle = {{BIOSIGNALS}},
	author = {Sourina, O. and Liu, Yisi},
	date = {2011},
	file = {2011 - A FRACTAL-BASED ALGORITHM OF EMOTION RECOGNITION F.pdf:C\:\\Users\\miche\\Zotero\\storage\\SXNPKV3F\\2011 - A FRACTAL-BASED ALGORITHM OF EMOTION RECOGNITION F.pdf:application/pdf},
}

@article{keelawat_spatiotemporal_2019-1,
	title = {Spatiotemporal Emotion Recognition using Deep {CNN} Based on {EEG} during Music Listening},
	url = {http://arxiv.org/abs/1910.09719},
	abstract = {Emotion recognition based on {EEG} has become an active research area. As one of the machine learning models, {CNN} has been utilized to solve diverse problems including issues in this domain. In this work, a study of {CNN} and its spatiotemporal feature extraction has been conducted in order to explore capabilities of the model in varied window sizes and electrode orders. Our investigation was conducted in subject-independent fashion. Results have shown that temporal information in distinct window sizes significantly affects recognition performance in both 10-fold and leave-one-subject-out cross validation. Spatial information from varying electrode order has modicum effect on classification. {SVM} classifier depending on spatiotemporal knowledge on the same dataset was previously employed and compared to these empirical results. Even though {CNN} and {SVM} have a homologous trend in window size effect, {CNN} outperformed {SVM} using leave-one-subject-out cross validation. This could be caused by different extracted features in the elicitation process.},
	journaltitle = {{arXiv}:1910.09719 [cs, eess, stat]},
	author = {Keelawat, Panayu and Thammasan, Nattapong and Numao, Masayuki and Kijsirikul, Boonserm},
	urldate = {2021-07-12},
	date = {2019-10-21},
	eprinttype = {arxiv},
	eprint = {1910.09719},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\miche\\Zotero\\storage\\7TNI6H5M\\Keelawat et al. - 2019 - Spatiotemporal Emotion Recognition using Deep CNN .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\miche\\Zotero\\storage\\KDSBGMZG\\1910.html:text/html},
}

@article{chang_personalized_2017-1,
	title = {A personalized music recommendation system based on electroencephalography feedback},
	volume = {76},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-015-3202-4},
	doi = {10.1007/s11042-015-3202-4},
	abstract = {Numerous domestic and foreign studies have demonstrated that music can relieve stress and that listening to music is one method of stress relief used presently. Although stress-relief music is available on the market, various music genres produce distinct effects on people. Clinical findings have indicated that approximately 30 \% of people listen to inappropriate music genres for relaxation and, consequently, their stress level increases. Therefore, to achieve the effect of stress relief, choosing the appropriate music genre is crucial. For example, a 70-year-old woman living in a military community since childhood might not consider general stress-relief music to be helpful in relieving stress, but when patriotic songs are played, her autonomic nervous system automatically relaxes because of her familiarity with the music style. Therefore, people have dissimilar needs regarding stress-relief music. In this paper, we proposed a personalized stress-relieving music recommendation system based on electroencephalography ({EEG}) feedback. The system structure comprises the following features: (a) automated music categorization, in which a new clustering algorithm, K-{MeansH}, is employed to precluster music and improve processing time; (b) the access and analysis of users’ {EEG} data to identify perceived stress-relieving music; and (c) personalized recommendations based on collaborative filtering and provided according to personal preferences. Experimental results indicated that the overall clustering effect of K-{MeansH} surpassed that of K-Means and K-Medoids by approximately 71 and 57 \%, respectively. In terms of accuracy, K-{MeansH} also surpassed K-Means and K-Medoids.},
	pages = {19523--19542},
	number = {19},
	journaltitle = {Multimedia Tools and Applications},
	shortjournal = {Multimed Tools Appl},
	author = {Chang, Hong-Yi and Huang, Shih-Chang and Wu, Jia-Hao},
	urldate = {2021-07-12},
	date = {2017-10-01},
	langid = {english},
	file = {Springer Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\JZVJCZAU\\Chang et al. - 2017 - A personalized music recommendation system based o.pdf:application/pdf},
}

@inproceedings{khosrowabadi_affective_2009,
	title = {Affective computation on {EEG} correlates of emotion from musical and vocal stimuli},
	doi = {10.1109/IJCNN.2009.5178748},
	abstract = {Affective interface that acquires and detects the emotion of the user can potentially enhance the human-computer interface experience. In this paper, an affective brain-computer interface ({ABCI}) is proposed to perform affective computation on electroencephalogram ({EEG}) correlates of emotion. The proposed {ABCI} extracts {EEG} features from subjects while exposed to 6 emotionally-related musical and vocal stimuli using kernel smoothing density estimation ({KSDE}) and Gaussian mixture model probability estimation ({GMM}). A classification algorithm is subsequently used to learn and classify the extracted {EEG} features. An inter-subject validation study is performed on healthy subjects to assess the performance of {ABCI} using a selection of classification algorithms. The results show that {ABCI} that employed the Bayesian network and the one-rule classifier yielded a promising inter-subject validation accuracy of 90\%.},
	eventtitle = {2009 International Joint Conference on Neural Networks},
	pages = {1590--1594},
	booktitle = {2009 International Joint Conference on Neural Networks},
	author = {Khosrowabadi, Reza and Wahab, Abdul and Ang, Kai Keng and Baniasad, Mohammad H.},
	date = {2009-06},
	note = {{ISSN}: 2161-4407},
	keywords = {Humans, Electroencephalography, Feature extraction, Neural networks, Emotion recognition, Heart rate, Brain computer interfaces, Classification algorithms, Computer interfaces, Speech},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\D4C8CZV6\\Khosrowabadi et al. - 2009 - Affective computation on EEG correlates of emotion.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\LW7TYSL5\\5178748.html:text/html},
}

@article{gertz_autonomy_2016,
	title = {Autonomy online: Jacques Ellul and the Facebook emotional manipulation study},
	volume = {12},
	issn = {1747-0161},
	url = {https://doi.org/10.1177/1747016115579534},
	doi = {10.1177/1747016115579534},
	shorttitle = {Autonomy online},
	abstract = {Though we would expect the revelation of the Facebook emotional manipulation study to have had a negative impact on Facebook, its number of active users only continues to grow. As this is precisely the result that Jacques Ellul would have predicted, this paper examines his philosophy of technology in order to investigate the relationship between Facebook and its users and what this relationship means in terms of autonomy. That Facebook can manipulate its users without losing users reveals that Facebook’s autonomy is growing while the autonomy of users is diminishing. The paper concludes by showing that the answer to this increasingly asymmetrical relationship cannot be the creation of review boards and oversight committees as the underlying issues concerning autonomy are existential more than they are ethical.},
	pages = {55--61},
	number = {1},
	journaltitle = {Research Ethics},
	shortjournal = {Research Ethics},
	author = {Gertz, Nolen},
	urldate = {2021-07-14},
	date = {2016-01-01},
	langid = {english},
	keywords = {autonomy, Facebook emotional manipulation study, Jacques Ellul, research ethics, technology},
	file = {SAGE PDF Full Text:C\:\\Users\\miche\\Zotero\\storage\\PDC4FGLV\\Gertz - 2016 - Autonomy online Jacques Ellul and the Facebook em.pdf:application/pdf},
}

@article{tromp_design_2011,
	title = {Design for Socially Responsible Behavior: A Classification of Influence Based on Intended User Experience},
	volume = {27},
	issn = {0747-9360},
	url = {https://doi.org/10.1162/DESI_a_00087},
	doi = {10.1162/DESI_a_00087},
	shorttitle = {Design for Socially Responsible Behavior},
	pages = {3--19},
	number = {3},
	journaltitle = {Design Issues},
	shortjournal = {Design Issues},
	author = {Tromp, Nynke and Hekkert, Paul and Verbeek, Peter-Paul},
	urldate = {2021-07-14},
	date = {2011-07-01},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\VHUG8FX3\\Tromp et al. - 2011 - Design for Socially Responsible Behavior A Classi.pdf:application/pdf;Snapshot:C\:\\Users\\miche\\Zotero\\storage\\6WS3P8RS\\Design-for-Socially-Responsible-Behavior-A.html:text/html},
}

@book{glasgow_minimal_2018,
	title = {Minimal Selfhood and the Origins of Consciousness},
	rights = {https://creativecommons.org/licenses/by-sa/4.0/deed.de},
	isbn = {978-3-95826-078-8 978-3-95826-079-5},
	url = {https://opus.bibliothek.uni-wuerzburg.de/frontdoor/index/index/docId/15747},
	abstract = {The aim of the book is to ground the logical origins of consciousness in what I have previously called the ‘minimal self’. The idea is that elementary forms of consciousness are logically dependent not, as is commonly assumed, on ownership of an anatomical brain or nervous system, but on the intrinsic reflexivity that defines minimal selfhood. The book seeks to trace the logical pathway by which minimal selfhood gives rise to the possible appearance of consciousness. It is argued that in specific circumstances it thus makes sense to ascribe elementary consciousness to certain predatory single-celled organisms such as amoebae and dinoflagellates as well as to some of the simpler animals. Such an argument involves establishing exactly what those specific circumstances are and determining how elementary consciousness differs in nature and scope from its more complex manifestations.},
	publisher = {Würzburg University Press},
	author = {Glasgow, Rupert},
	urldate = {2021-07-16},
	date = {2018},
	doi = {10.25972/WUP-978-3-95826-079-5},
}

@thesis{plass-oude_bos_making_2014,
	location = {Enschede, The Netherlands},
	title = {Making brain-computer interfaces better : improving usability through post-processing},
	url = {http://purl.org/utwente/doi/10.3990/1.9789036537797},
	shorttitle = {Making brain-computer interfaces better},
	institution = {University of Twente},
	type = {phdthesis},
	author = {Plass-Oude Bos, Danny},
	urldate = {2021-07-16},
	date = {2014-11-21},
	langid = {english},
	doi = {10.3990/1.9789036537797},
	note = {{ISBN}: 9789036537797},
	file = {Plass-Oude Bos - 2014 - Making brain-computer interfaces better  improvin.pdf:C\:\\Users\\miche\\Zotero\\storage\\3FJJZL9Q\\Plass-Oude Bos - 2014 - Making brain-computer interfaces better  improvin.pdf:application/pdf},
}

@book{glasgow_minimal_2018-1,
	title = {Minimal Selfhood and the Origins of Consciousness},
	rights = {https://creativecommons.org/licenses/by-sa/4.0/deed.de},
	isbn = {978-3-95826-078-8 978-3-95826-079-5},
	url = {https://opus.bibliothek.uni-wuerzburg.de/frontdoor/index/index/docId/15747},
	abstract = {The aim of the book is to ground the logical origins of consciousness in what I have previously called the ‘minimal self’. The idea is that elementary forms of consciousness are logically dependent not, as is commonly assumed, on ownership of an anatomical brain or nervous system, but on the intrinsic reflexivity that defines minimal selfhood. The book seeks to trace the logical pathway by which minimal selfhood gives rise to the possible appearance of consciousness. It is argued that in specific circumstances it thus makes sense to ascribe elementary consciousness to certain predatory single-celled organisms such as amoebae and dinoflagellates as well as to some of the simpler animals. Such an argument involves establishing exactly what those specific circumstances are and determining how elementary consciousness differs in nature and scope from its more complex manifestations.},
	publisher = {Würzburg University Press},
	author = {Glasgow, Rupert},
	urldate = {2021-07-16},
	date = {2018},
	doi = {10.25972/WUP-978-3-95826-079-5},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\IRSWIHQF\\Glasgow - 2018 - Minimal Selfhood and the Origins of Consciousness.pdf:application/pdf;Snapshot:C\:\\Users\\miche\\Zotero\\storage\\XAHWPJBJ\\15747.html:text/html},
}

@online{noauthor_brain_nodate,
	title = {The Brain Facts Book},
	url = {http://www.brainfacts.org:80/book},
	urldate = {2021-07-16},
	langid = {english},
	file = {Brain Facts Book 2018 high res.pdf:C\:\\Users\\miche\\Zotero\\storage\\RKAKGWRY\\Brain Facts Book 2018 high res.pdf:application/pdf;Snapshot:C\:\\Users\\miche\\Zotero\\storage\\8B82XGH7\\book.html:text/html},
}

@book{ikehara_lecture_2013-1,
	title = {Lecture Notes in Computer Science},
	isbn = {978-3-642-39453-9},
	abstract = {The strategic goal of augmented cognition is to increase task performance capacity by using physiological sensor feedback to adjust or modify the activity for the user. Gamification has been shown to increase performance by using certain combinations of game elements. Both augmented cognition and gamification address increased task performance capacity. Gamification adds to augmented cognition by directly addressing the motivation of the user to remain engaged in the activity. This has also been referred to as flow, or the optimal experience. This paper describes an example of a gamified activity in which the physiological sensors of augmented cognition are used to foster the optimal experience desired in gamification. Also, discussed is how the strategic goals of augmented cognition and gamification overlap through the use of a gamified example that describes how the components of augmented cognition and elements of gamification can be used together to better achieve the goal of increased task performance capacity.},
	pagetotal = {676},
	author = {Ikehara, Curtis and Crosby, Martha and Silva, Paula Alexandra},
	date = {2013-07-21},
	doi = {10.1007/978-3-642-39454-6_72},
	note = {Pages: 684},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\Y2CEL6CC\\Ikehara et al. - 2013 - Lecture Notes in Computer Science.pdf:application/pdf},
}

@online{noauthor_mikexcohencom_nodate,
	title = {mikexcohen.com},
	url = {https://www.mikexcohen.com/},
	urldate = {2021-07-21},
	file = {mikexcohen.com:C\:\\Users\\miche\\Zotero\\storage\\38TCCAF2\\www.mikexcohen.com.html:text/html},
}

@article{zhang_human_2019,
	title = {Human Mind Control of Rat Cyborg’s Continuous Locomotion with Wireless Brain-to-Brain Interface},
	volume = {9},
	rights = {2019 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-018-36885-0},
	doi = {10.1038/s41598-018-36885-0},
	abstract = {Brain-machine interfaces ({BMIs}) provide a promising information channel between the biological brain and external devices and are applied in building brain-to-device control. Prior studies have explored the feasibility of establishing a brain-brain interface ({BBI}) across various brains via the combination of {BMIs}. However, using {BBI} to realize the efficient multidegree control of a living creature, such as a rat, to complete a navigation task in a complex environment has yet to be shown. In this study, we developed a {BBI} from the human brain to a rat implanted with microelectrodes (i.e., rat cyborg), which integrated electroencephalogram-based motor imagery and brain stimulation to realize human mind control of the rat’s continuous locomotion. Control instructions were transferred from continuous motor imagery decoding results with the proposed control models and were wirelessly sent to the rat cyborg through brain micro-electrical stimulation. The results showed that rat cyborgs could be smoothly and successfully navigated by the human mind to complete a navigation task in a complex maze. Our experiments indicated that the cooperation through transmitting multidimensional information between two brains by computer-assisted {BBI} is promising.},
	pages = {1321},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Zhang, Shaomin and Yuan, Sheng and Huang, Lipeng and Zheng, Xiaoxiang and Wu, Zhaohui and Xu, Kedi and Pan, Gang},
	urldate = {2021-07-21},
	date = {2019-02-04},
	langid = {english},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Cognitive neuroscience;Motor control
Subject\_term\_id: cognitive-neuroscience;motor-control},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\3XDIJKZE\\Zhang et al. - 2019 - Human Mind Control of Rat Cyborg’s Continuous Loco.pdf:application/pdf;Snapshot:C\:\\Users\\miche\\Zotero\\storage\\MTJCKXIT\\s41598-018-36885-0.html:text/html},
}

@inproceedings{khosrowabadi_affective_2009-1,
	title = {Affective computation on {EEG} correlates of emotion from musical and vocal stimuli},
	doi = {10.1109/IJCNN.2009.5178748},
	abstract = {Affective interface that acquires and detects the emotion of the user can potentially enhance the human-computer interface experience. In this paper, an affective brain-computer interface ({ABCI}) is proposed to perform affective computation on electroencephalogram ({EEG}) correlates of emotion. The proposed {ABCI} extracts {EEG} features from subjects while exposed to 6 emotionally-related musical and vocal stimuli using kernel smoothing density estimation ({KSDE}) and Gaussian mixture model probability estimation ({GMM}). A classification algorithm is subsequently used to learn and classify the extracted {EEG} features. An inter-subject validation study is performed on healthy subjects to assess the performance of {ABCI} using a selection of classification algorithms. The results show that {ABCI} that employed the Bayesian network and the one-rule classifier yielded a promising inter-subject validation accuracy of 90\%.},
	eventtitle = {2009 International Joint Conference on Neural Networks},
	pages = {1590--1594},
	booktitle = {2009 International Joint Conference on Neural Networks},
	author = {Khosrowabadi, Reza and Wahab, Abdul and Ang, Kai Keng and Baniasad, Mohammad H.},
	date = {2009-06},
	note = {{ISSN}: 2161-4407},
	keywords = {Humans, Electroencephalography, Feature extraction, Neural networks, Emotion recognition, Heart rate, Brain computer interfaces, Classification algorithms, Computer interfaces, Speech},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\P9CFWLV4\\Khosrowabadi et al. - 2009 - Affective computation on EEG correlates of emotion.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\Y9YWD5Q6\\5178748.html:text/html;Khosrowabadi et al. - 2009 - Affective computation on EEG correlates of emotion.pdf:C\:\\Users\\miche\\Zotero\\storage\\89SSADW7\\Khosrowabadi et al. - 2009 - Affective computation on EEG correlates of emotion.pdf:application/pdf},
}

@article{keelawat_spatiotemporal_2019-2,
	title = {Spatiotemporal Emotion Recognition using Deep {CNN} Based on {EEG} during Music Listening},
	url = {http://arxiv.org/abs/1910.09719},
	abstract = {Emotion recognition based on {EEG} has become an active research area. As one of the machine learning models, {CNN} has been utilized to solve diverse problems including issues in this domain. In this work, a study of {CNN} and its spatiotemporal feature extraction has been conducted in order to explore capabilities of the model in varied window sizes and electrode orders. Our investigation was conducted in subject-independent fashion. Results have shown that temporal information in distinct window sizes significantly affects recognition performance in both 10-fold and leave-one-subject-out cross validation. Spatial information from varying electrode order has modicum effect on classification. {SVM} classifier depending on spatiotemporal knowledge on the same dataset was previously employed and compared to these empirical results. Even though {CNN} and {SVM} have a homologous trend in window size effect, {CNN} outperformed {SVM} using leave-one-subject-out cross validation. This could be caused by different extracted features in the elicitation process.},
	journaltitle = {{arXiv}:1910.09719 [cs, eess, stat]},
	author = {Keelawat, Panayu and Thammasan, Nattapong and Numao, Masayuki and Kijsirikul, Boonserm},
	urldate = {2021-07-30},
	date = {2019-10-21},
	eprinttype = {arxiv},
	eprint = {1910.09719},
	keywords = {Electrical Engineering and Systems Science - Signal Processing, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Human-Computer Interaction},
}

@online{noauthor_deap_nodate-1,
	title = {{DEAP}: A Database for Emotion Analysis ;Using Physiological Signals {\textbar} {IEEE} Journals \& Magazine {\textbar} {IEEE} Xplore},
	url = {https://ieeexplore.ieee.org/document/5871728},
	urldate = {2021-07-30},
	file = {DEAP\: A Database for Emotion Analysis \;Using Physiological Signals | IEEE Journals & Magazine | IEEE Xplore:C\:\\Users\\miche\\Zotero\\storage\\8RG762RE\\5871728.html:text/html},
}

@article{koelstra_deap_2012-1,
	title = {{DEAP}: A Database for Emotion Analysis ;Using Physiological Signals},
	volume = {3},
	issn = {1949-3045},
	doi = {10.1109/T-AFFC.2011.15},
	shorttitle = {{DEAP}},
	abstract = {We present a multimodal data set for the analysis of human affective states. The electroencephalogram ({EEG}) and peripheral physiological signals of 32 participants were recorded as each watched 40 one-minute long excerpts of music videos. Participants rated each video in terms of the levels of arousal, valence, like/dislike, dominance, and familiarity. For 22 of the 32 participants, frontal face video was also recorded. A novel method for stimuli selection is proposed using retrieval by affective tags from the last.fm website, video highlight detection, and an online assessment tool. An extensive analysis of the participants' ratings during the experiment is presented. Correlates between the {EEG} signal frequencies and the participants' ratings are investigated. Methods and results are presented for single-trial classification of arousal, valence, and like/dislike ratings using the modalities of {EEG}, peripheral physiological signals, and multimedia content analysis. Finally, decision fusion of the classification results from different modalities is performed. The data set is made publicly available and we encourage other researchers to use it for testing their own affective state estimation methods.},
	pages = {18--31},
	number = {1},
	journaltitle = {{IEEE} Transactions on Affective Computing},
	author = {Koelstra, Sander and Muhl, Christian and Soleymani, Mohammad and Lee, Jong-Seok and Yazdani, Ashkan and Ebrahimi, Touradj and Pun, Thierry and Nijholt, Anton and Patras, Ioannis},
	date = {2012-01},
	note = {Conference Name: {IEEE} Transactions on Affective Computing},
	keywords = {{EEG}, Electroencephalography, Databases, Visualization, pattern classification, Face, signal processing, affective computing., Emotion classification, Motion pictures, Multimedia communication, physiological signals, Videos},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\KITWZGCF\\Koelstra et al. - 2012 - DEAP A Database for Emotion Analysis \;Using Physi.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\5DJZDAVK\\5871728.html:text/html;Koelstra et al. - 2012 - DEAP A Database for Emotion Analysis \;Using Physi.pdf:C\:\\Users\\miche\\Zotero\\storage\\J3FFEQTZ\\Koelstra et al. - 2012 - DEAP A Database for Emotion Analysis \;Using Physi.pdf:application/pdf},
}

@inproceedings{wu_estimation_2017-1,
	title = {Estimation of valence of emotion using two frontal {EEG} channels},
	doi = {10.1109/BIBM.2017.8217815},
	abstract = {Emotion recognition using {EEG} signals has become a hot research topic in the last few years. This paper aims at providing a novel method for emotion recognition using less channels of frontal {EEG} signals. By employing the asymmetry theory of frontal brain, a new method fusing spatial and frequency features was presented, which only adopted two channels of frontal {EEG} signals at Fp1 and Fp2. In order to estimate the efficiency of the method, a {GBDT} classifier was evaluated and selected, and the method was implemented on the {DEAP} database. The maximum and mean classification accuracy were achieved as 76.34\% and 75.18\% respectively, which exhibited the best result comparing with other related studies. This method is extremely suitable for wearable {EEG} monitoring applications in human daily life.},
	eventtitle = {2017 {IEEE} International Conference on Bioinformatics and Biomedicine ({BIBM})},
	pages = {1127--1130},
	booktitle = {2017 {IEEE} International Conference on Bioinformatics and Biomedicine ({BIBM})},
	author = {Wu, Shiyi and Xu, Xiangmin and Shu, Lin and Hu, Bin},
	date = {2017-11},
	keywords = {Electroencephalography, Entropy, Feature extraction, Emotion recognition, {DEAP}, Biomedical monitoring, Frontal {EEG}, {GBDT} classifier, Indexes},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\2UP5N8IT\\Wu et al. - 2017 - Estimation of valence of emotion using two frontal.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\8H62ASU6\\8217815.html:text/html},
}

@article{feurer_efficient_nodate,
	title = {Efficient and Robust Automated Machine Learning},
	abstract = {The success of machine learning in a broad range of applications has led to an ever-growing demand for machine learning systems that can be used off the shelf by non-experts. To be effective in practice, such systems need to automatically choose a good algorithm and feature preprocessing steps for a new dataset at hand, and also set their respective hyperparameters. Recent work has started to tackle this automated machine learning ({AutoML}) problem with the help of efﬁcient Bayesian optimization methods. Building on this, we introduce a robust new {AutoML} system based on scikit-learn (using 15 classiﬁers, 14 feature preprocessing methods, and 4 data preprocessing methods, giving rise to a structured hypothesis space with 110 hyperparameters). This system, which we dub {AUTO}-{SKLEARN}, improves on existing {AutoML} methods by automatically taking into account past performance on similar datasets, and by constructing ensembles from the models evaluated during the optimization. Our system won the ﬁrst phase of the ongoing {ChaLearn} {AutoML} challenge, and our comprehensive analysis on over 100 diverse datasets shows that it substantially outperforms the previous state of the art in {AutoML}. We also demonstrate the performance gains due to each of our contributions and derive insights into the effectiveness of the individual components of {AUTO}-{SKLEARN}.},
	pages = {9},
	author = {Feurer, Matthias and Klein, Aaron and Eggensperger, Katharina and Springenberg, Jost and Blum, Manuel and Hutter, Frank},
	langid = {english},
	file = {Feurer et al. - Efficient and Robust Automated Machine Learning.pdf:C\:\\Users\\miche\\Zotero\\storage\\4NHBT9N2\\Feurer et al. - Efficient and Robust Automated Machine Learning.pdf:application/pdf},
}

@article{russell_circumplex_1980,
	title = {A Circumplex Model of Affect},
	volume = {39},
	doi = {10.1037/h0077714},
	abstract = {Factor-analytic evidence has led most psychologists to describe affect as a set of dimensions, such as displeasure, distress, depression, excitement, and so on, with each dimension varying independently of the others. However, there is other evidence that rather than being independent, these affective dimensions are interrelated in a highly systematic fashion. The evidence suggests that these interrelationships can be represented by a spatial model in which affective concepts fall in a circle in the following order: pleasure (0), excitement (45), arousal (90), distress (135), displeasure (180), depression (225), sleepiness (270), and relaxation (315). This model was offered both as a way psychologists can represent the structure of affective experience, as assessed through self-report, and as a representation of the cognitive structure that laymen utilize in conceptualizing affect. Supportive evidence was obtained by scaling 28 emotion-denoting adjectives in 4 different ways: R. T. Ross's (1938) technique for a circular ordering of variables, a multidimensional scaling procedure based on perceived similarity among the terms, a unidimensional scaling on hypothesized pleasure–displeasure and degree-of-arousal dimensions, and a principal-components analysis of 343 Ss' self-reports of their current affective states. (70 ref) ({PsycINFO} Database Record (c) 2012 {APA}, all rights reserved)},
	pages = {1161--1178},
	journaltitle = {Journal of Personality and Social Psychology},
	shortjournal = {Journal of Personality and Social Psychology},
	author = {Russell, James},
	date = {1980-12-01},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\G9GAA2LK\\Russell - 1980 - A Circumplex Model of Affect.pdf:application/pdf},
}

@article{picard_mit_nodate,
	title = {{MIT} Media Laboratory; Perceptual Computing; 20 Ames St., Cambridge, {MA} 02139 picard@media.mit.edu, http://www.media.mit.edu/˜picard/},
	abstract = {Computers are beginning to acquire the ability to express and recognize aﬀect, and may soon be given the ability to “have emotions.” The essential role of emotion in both human cognition and perception, as demonstrated by recent neurological studies, indicates that aﬀective computers should not only provide better performance in assisting humans, but also might enhance computers’ abilities to make decisions. This paper presents and discusses key issues in “aﬀective computing,” computing that relates to, arises from, or inﬂuences emotions. Models are suggested for computer recognition of human emotion, and new applications are presented for computerassisted learning, perceptual information retrieval, arts and entertainment, and human health and interaction. Aﬀective computing, coupled with new wearable computers, will also provide the ability to gather new data necessary for advances in emotion and cognition theory.},
	pages = {16},
	author = {Picard, R W},
	langid = {english},
	file = {Picard - MIT Media Laboratory\; Perceptual Computing\; 20 Ame.pdf:C\:\\Users\\miche\\Zotero\\storage\\XZIGZ9FU\\Picard - MIT Media Laboratory\; Perceptual Computing\; 20 Ame.pdf:application/pdf},
}

@article{habibi_music_2014,
	title = {Music, feelings, and the human brain.},
	volume = {24},
	issn = {2162-1535, 0275-3987},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/pmu0000033},
	doi = {10.1037/pmu0000033},
	abstract = {Music of varied kinds consistently triggers a large range of drives and emotions, which, in turn, induce a particular class of mental experiences known as feelings. The feelings are often pleasurable, though not necessarily. Neuroimaging and electrophysiological studies, in normal individuals as well as in patients with focal neurological lesions, reveal that music can change the state of large-scale neural systems of the human brain. The changes are not confined to brain sectors related to auditory and motor processing; they also occur in regions related to the regulation of life processes (homeostasis), including those related to emotions and feelings, most prominently in the insula and cingulate cortices, in the ventral striatum, in the amygdala, and in certain upper brainstem nuclei. The ease with which music leads to feelings, the predictability with which it does so, the fact that human beings of many cultures actively seek and consume music, and the evidence that early humans engaged in music practices lead us to hypothesize that music has long had a consistent relation to the neural devices of human life regulation. It is conceivable that, as a result, music-induced feelings can be informative and nourishing at the individual level and can also operate as significant promoters of sociocultural organization. We venture that the close relationship between music and feelings along with music’s effectiveness in certain personal and social contexts, that is, its roles in homeostasis, explain, at least in part, the considerable degree of selection and replication of music-related phenomena, both biologically and culturally. As the invention of music forms continued and as intellectual analysis of compositions and reflection on music expanded, the practices and uses of music became less closely aligned with its affective and homeostatic aspects and, to a certain degree, gained autonomy relative to those aspects. This may account for the varied panorama of music invention, practice, and consumption that can be found today.},
	pages = {92--102},
	number = {1},
	journaltitle = {Psychomusicology: Music, Mind, and Brain},
	shortjournal = {Psychomusicology: Music, Mind, and Brain},
	author = {Habibi, Assal and Damasio, Antonio},
	urldate = {2021-08-06},
	date = {2014},
	langid = {english},
	file = {Habibi and Damasio - 2014 - Music, feelings, and the human brain..pdf:C\:\\Users\\miche\\Zotero\\storage\\JSDWEVE7\\Habibi and Damasio - 2014 - Music, feelings, and the human brain..pdf:application/pdf},
}

@article{smith_hemispheric_1987-1,
	title = {Hemispheric asymmetry and emotion: Lateralized parietal processing of affect and cognition},
	volume = {25},
	issn = {0301-0511},
	url = {https://www.sciencedirect.com/science/article/pii/0301051187900500},
	doi = {10.1016/0301-0511(87)90050-0},
	shorttitle = {Hemispheric asymmetry and emotion},
	abstract = {The differential cerebral processing of affect and cognition may have important implications for a more general understanding of how these two complex sets of functions differ and how they interact. Building upon recent studies of hemispheric asymmetry in emotion, the present study focused on the differential parietal processing of emotional stimuli under affective and cognitive conditions. Subjects were exposed to neutral and emotional stimuli presented under cognitive and affective instructional sets. Bilateral electroencephalographic ({EEG}) data showed that the principal differentiation between affective and cognitive conditions occurred in the right hemisphere, whereas the highest overall level of activation during emotional stimulation was in the left hemisphere. It was also found that affective conditions produced higher of levels of both {EEG} and electrodermal activity than either cognitive or neutral conditions. Finally, significant patterns of gender differentiation suggested greater focal organization for affective arousal in females than males.},
	pages = {247--260},
	number = {3},
	journaltitle = {Biological Psychology},
	shortjournal = {Biological Psychology},
	author = {Smith, Barry D. and Meyers, Marilyn and Kline, Robert and Bozman, Alan},
	urldate = {2021-08-07},
	date = {1987-12-01},
	langid = {english},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\NKBXVNM4\\0301051187900500.html:text/html},
}

@article{smith_hemispheric_1987-2,
	title = {Hemispheric asymmetry and emotion: Lateralized parietal processing of affect and cognition},
	volume = {25},
	issn = {0301-0511},
	url = {https://www.sciencedirect.com/science/article/pii/0301051187900500},
	doi = {10.1016/0301-0511(87)90050-0},
	shorttitle = {Hemispheric asymmetry and emotion},
	abstract = {The differential cerebral processing of affect and cognition may have important implications for a more general understanding of how these two complex sets of functions differ and how they interact. Building upon recent studies of hemispheric asymmetry in emotion, the present study focused on the differential parietal processing of emotional stimuli under affective and cognitive conditions. Subjects were exposed to neutral and emotional stimuli presented under cognitive and affective instructional sets. Bilateral electroencephalographic ({EEG}) data showed that the principal differentiation between affective and cognitive conditions occurred in the right hemisphere, whereas the highest overall level of activation during emotional stimulation was in the left hemisphere. It was also found that affective conditions produced higher of levels of both {EEG} and electrodermal activity than either cognitive or neutral conditions. Finally, significant patterns of gender differentiation suggested greater focal organization for affective arousal in females than males.},
	pages = {247--260},
	number = {3},
	journaltitle = {Biological Psychology},
	shortjournal = {Biological Psychology},
	author = {Smith, Barry D. and Meyers, Marilyn and Kline, Robert and Bozman, Alan},
	urldate = {2021-08-07},
	date = {1987-12-01},
	langid = {english},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\IWBWQDV8\\0301051187900500.html:text/html},
}

@article{bradley_measuring_1994,
	title = {Measuring emotion: The self-assessment manikin and the semantic differential},
	volume = {25},
	issn = {0005-7916},
	url = {https://www.sciencedirect.com/science/article/pii/0005791694900639},
	doi = {10.1016/0005-7916(94)90063-9},
	shorttitle = {Measuring emotion},
	abstract = {The Self-Assessment Manikin ({SAM}) is a non-verbal pictorial assessment technique that directly measures the pleasure, arousal, and dominance associated with a person's affective reaction to a wide variety of stimuli. In this experiment, we compare reports of affective experience obtained using {SAM}, which requires only three simple judgments, to the Semantic Differential scale devised by Mehrabian and Russell (An approach to environmental psychology, 1974) which requires 18 different ratings. Subjective reports were measured to a series of pictures that varied in both affective valence and intensity. Correlations across the two rating methods were high both for reports of experienced pleasure and felt arousal. Differences obtained in the dominance dimension of the two instruments suggest that {SAM} may better track the personal response to an affective stimulus. {SAM} is an inexpensive, easy method for quickly assessing reports of affective response in many contexts.},
	pages = {49--59},
	number = {1},
	journaltitle = {Journal of Behavior Therapy and Experimental Psychiatry},
	shortjournal = {Journal of Behavior Therapy and Experimental Psychiatry},
	author = {Bradley, Margaret M. and Lang, Peter J.},
	urldate = {2021-08-08},
	date = {1994-03-01},
	langid = {english},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\XXRD52VB\\0005791694900639.html:text/html},
}

@online{noauthor_implicit_nodate,
	title = {Implicit and automated emotional tagging of videos {\textbar} Semantic Scholar},
	url = {https://www.semanticscholar.org/paper/Implicit-and-automated-emotional-tagging-of-videos-Soleymani/2c92e50293b3ef711ca0de5f7f352cecc60cc2ae},
	urldate = {2021-08-08},
	file = {Implicit and automated emotional tagging of videos.html:C\:\\Users\\miche\\Zotero\\storage\\Z3F5TSUE\\Implicit and automated emotional tagging of videos.html:text/html;Implicit and automated emotional tagging of videos.pdf:C\:\\Users\\miche\\Zotero\\storage\\6VMS3S6Y\\Implicit and automated emotional tagging of videos.pdf:application/pdf},
}

@article{etzel_cardiovascular_2006,
	title = {Cardiovascular and respiratory responses during musical mood induction},
	volume = {61},
	issn = {0167-8760},
	url = {https://www.sciencedirect.com/science/article/pii/S0167876005002850},
	doi = {10.1016/j.ijpsycho.2005.10.025},
	series = {Psychophiosology and Cognitive Neuroscience},
	abstract = {Music is used to induce moods in experimental settings as well as for therapeutic purposes. Prior studies suggest that subjects listening to certain types of music experience strong moods and show physiological responses associated with the induced emotions. We hypothesized that cardiovascular and respiratory patterns could discriminate moods induced via music. 18 healthy subjects listened to 12 music clips, four each to induce happiness, sadness, and fear, while cardiovascular and respiratory responses were recorded using an electrocardiogram and chest strain-gauge belt. After each clip subjects completed a questionnaire. Subjects consistently reported experiencing the targeted mood, suggesting successful mood induction. Cardiovascular activity was measured by calculating time domain measures and heart rate changes during each clip. Respiratory activity was measured by total, inspiration, and expiration lengths as well as changes in mean respiration rate during each clip. Evaluation of individuals' patterns and mixed-model analyses were performed. Contrary to expectations, the time domain measures of subjects' cardiovascular responses did not vary significantly between the induced moods, although a heart rate deceleration was found during the sadness inductions and acceleration during the fear inductions. The time domain respiratory measures varied with clip type: the mean breath length was longest for the sad induction, intermediate during fear, and shortest during the happiness induction. However, analysis using normalized least mean squares adaptive filters to measure time correlation indicated that much of this difference may be attributable to entrainment of respiration to characteristics of the music which varied between the stimuli. Our findings point to the difficulty in detecting psychophysiological correlates of mood induction, and further suggest that part of this difficulty may arise from failure to differentiate it from tempo-related contributions when music is used as the inducer.},
	pages = {57--69},
	number = {1},
	journaltitle = {International Journal of Psychophysiology},
	shortjournal = {International Journal of Psychophysiology},
	author = {Etzel, Joset A. and Johnsen, Erica L. and Dickerson, Julie and Tranel, Daniel and Adolphs, Ralph},
	urldate = {2021-08-08},
	date = {2006-07-01},
	langid = {english},
	keywords = {Music, Mood, Cardiovascular and respiratory responses},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\N5GXMZB7\\S0167876005002850.html:text/html},
}

@article{watson_development_nodate,
	title = {Development and Validation of Brief Measures of Positive and Negative Affect: The {PANAS} Scales},
	pages = {8},
	author = {Watson, David and Anna, Lee and Tellegen, Auke},
	langid = {english},
	file = {Watson et al. - Development and Validation of Brief Measures of Po.pdf:C\:\\Users\\miche\\Zotero\\storage\\U8PG99YN\\Watson et al. - Development and Validation of Brief Measures of Po.pdf:application/pdf},
}

@article{hagemann_effects_2001,
	title = {The effects of ocular artifacts on (lateralized) broadband power in the {EEG}},
	volume = {112},
	doi = {10.1016/S1388-2457(00)00541-1},
	abstract = {Empirical evidence suggests that blinks and eye movements do not generate substantial activity outside the delta and theta range, and that the propagation of ocular activity to the {EEG} is rather symmetrical. These observations suggest that an alteration of the alpha and beta asymmetry of the {EEG} due to ocular artifacts is not likely to occur. The aim of the present study is to examine the effects of ocular artifacts on broadband {EEG} parameters.
{EEG} and {EOG} were recorded from 31 participants in a resting condition with eyes open and closed, allowing for spontaneous ocular activity. General effects of ocular artifacts were examined with mean comparisons, and differential effects were examined with correlation analysis of data portions that were selected for a presence or absence of artifacts.
At single sites, blinks and eye movements exerted substantial general effects on the whole {EEG} spectrum, but there were no substantial differential effects of artifacts in the alpha and beta bands, except at the frontopolar sites. The distorting effects of ocular artifacts were smaller in magnitude for asymmetry than for single site measures.
The control of ocular artifacts may be dispensable for correlation analyses of alpha or beta band parameters.},
	pages = {215--31},
	journaltitle = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
	shortjournal = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
	author = {Hagemann, Dirk and Naumann, Ewald},
	date = {2001-03-01},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\GVQIVPTU\\Hagemann and Naumann - 2001 - The effects of ocular artifacts on (lateralized) b.pdf:application/pdf},
}

@article{liu_real-time_2018,
	title = {Real-Time Movie-Induced Discrete Emotion Recognition from {EEG} Signals},
	volume = {9},
	issn = {1949-3045},
	doi = {10.1109/TAFFC.2017.2660485},
	abstract = {Recognition of a human's continuous emotional states in real time plays an important role in machine emotional intelligence and human-machine interaction. Existing real-time emotion recognition systems use stimuli with low ecological validity (e.g., picture, sound) to elicit emotions and to recognise only valence and arousal. To overcome these limitations, in this paper, we construct a standardised database of 16 emotional film clips that were selected from over one thousand film excerpts. Based on emotional categories that are induced by these film clips, we propose a real-time movie-induced emotion recognition system for identifying an individual's emotional states through the analysis of brain waves. Thirty participants took part in this study and watched 16 standardised film clips that characterise real-life emotional experiences and target seven discrete emotions and neutrality. Our system uses a 2-s window and a 50 percent overlap between two consecutive windows to segment the {EEG} signals. Emotional states, including not only the valence and arousal dimensions but also similar discrete emotions in the valence-arousal coordinate space, are predicted in each window. Our real-time system achieves an overall accuracy of 92.26 percent in recognising high-arousal and valenced emotions from neutrality and 86.63 percent in recognising positive from negative emotions. Moreover, our system classifies three positive emotions (joy, amusement, tenderness) with an average of 86.43 percent accuracy and four negative emotions (anger, disgust, fear, sadness) with an average of 65.09 percent accuracy. These results demonstrate the advantage over the existing state-of-the-art real-time emotion recognition systems from {EEG} signals in terms of classification accuracy and the ability to recognise similar discrete emotions that are close in the valence-arousal coordinate space.},
	pages = {550--562},
	number = {4},
	journaltitle = {{IEEE} Transactions on Affective Computing},
	author = {Liu, Yong-Jin and Yu, Minjing and Zhao, Guozhen and Song, Jinjing and Ge, Yan and Shi, Yuanchun},
	date = {2018-10},
	note = {Conference Name: {IEEE} Transactions on Affective Computing},
	keywords = {{EEG}, Electroencephalography, Brain models, Support vector machines, Emotion recognition, emotion recognition, Affective computing, Real-time systems, Films, movie},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\4Q3U7AW5\\media.html:text/html},
}

@article{grosselin_quality_2019,
	title = {Quality Assessment of Single-Channel {EEG} for Wearable Devices},
	volume = {19},
	issn = {1424-8220},
	doi = {10.3390/s19030601},
	abstract = {The recent embedding of electroencephalographic ({EEG}) electrodes in wearable devices raises the problem of the quality of the data recorded in such uncontrolled environments. These recordings are often obtained with dry single-channel {EEG} devices, and may be contaminated by many sources of noise which can compromise the detection and characterization of the brain state studied. In this paper, we propose a classification-based approach to effectively quantify artefact contamination in {EEG} segments, and discriminate muscular artefacts. The performance of our method were assessed on different databases containing either artificially contaminated or real artefacts recorded with different type of sensors, including wet and dry {EEG} electrodes. Furthermore, the quality of unlabelled databases was evaluated. For all the studied databases, the proposed method is able to rapidly assess the quality of the {EEG} signals with an accuracy higher than 90\%. The obtained performance suggests that our approach provide an efficient, fast and automated quality assessment of {EEG} signals from low-cost wearable devices typically composed of a dry single {EEG} channel.},
	pages = {E601},
	number = {3},
	journaltitle = {Sensors (Basel, Switzerland)},
	shortjournal = {Sensors (Basel)},
	author = {Grosselin, Fanny and Navarro-Sune, Xavier and Vozzi, Alessia and Pandremmenou, Katerina and De Vico Fallani, Fabrizio and Attal, Yohan and Chavez, Mario},
	date = {2019-01-31},
	pmid = {30709004},
	pmcid = {PMC6387437},
	keywords = {Humans, Brain, Brain-Computer Interfaces, Electroencephalography, Algorithms, Electrodes, Artifacts, electroencephalography ({EEG}), artefact detection, muscular artefacts, quality assessment, single-channel {EEG}, wearable systems, Wearable Electronic Devices},
	file = {Full Text:C\:\\Users\\miche\\Zotero\\storage\\IFH4TEZ3\\Grosselin et al. - 2019 - Quality Assessment of Single-Channel EEG for Weara.pdf:application/pdf},
}

@article{hernandez-olivan_music_2021,
	title = {Music Composition with Deep Learning: A Review},
	url = {http://arxiv.org/abs/2108.12290},
	shorttitle = {Music Composition with Deep Learning},
	abstract = {Generating a complex work of art such as a musical composition requires exhibiting true creativity that depends on a variety of factors that are related to the hierarchy of musical language. Music generation have been faced with Algorithmic methods and recently, with Deep Learning models that are being used in other fields such as Computer Vision. In this paper we want to put into context the existing relationships between {AI}-based music composition models and human musical composition and creativity processes. We give an overview of the recent Deep Learning models for music composition and we compare these models to the music composition process from a theoretical point of view. We have tried to answer some of the most relevant open questions for this task by analyzing the ability of current Deep Learning models to generate music with creativity or the similarity between {AI} and human composition processes, among others.},
	journaltitle = {{arXiv}:2108.12290 [cs, eess]},
	author = {Hernandez-Olivan, Carlos and Beltran, Jose R.},
	urldate = {2021-09-08},
	date = {2021-09-07},
	eprinttype = {arxiv},
	eprint = {2108.12290},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
	file = {arXiv Fulltext PDF:C\:\\Users\\miche\\Zotero\\storage\\BTTFX3TV\\Hernandez-Olivan and Beltran - 2021 - Music Composition with Deep Learning A Review.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\miche\\Zotero\\storage\\WSH3PI5Q\\2108.html:text/html},
}

@article{orgo_effect_2015,
	title = {Effect of negative and positive emotions on {EEG} spectral asymmetry},
	volume = {2015},
	issn = {2694-0604},
	doi = {10.1109/EMBC.2015.7320275},
	abstract = {The aim of the study was to evaluate the applicability of electroencephalogram ({EEG}) spectral asymmetry index ({SASI}) for discrimination of the effect of negative and positive emotions on human brain bioelectrical activity. {SASI} has been previously proposed as a method to detect depression based on the balance of {EEG} theta and beta frequency band powers. Emotions were evoked on 22 healthy subjects using emotional pictures portraying humans from International Affective Picture System ({IAPS}) and late response to stimuli was examined (1700-2200 ms). Electroencephalogram ({EEG}) was recorded in 30 channels divided into 10 brain regions: left frontal, right frontal, left temporal, right temporal, frontal, frontocentral, central, centroparietal, parietal and occipital. Negative stimuli, compared to neutral stimuli, significantly increased {SASI} in frontocentral, central, centroparietal, parietal and occipital areas. Positive stimuli, compared to neutral stimuli, significantly decreased {SASI} in left temporal, centroparietal, parietal and occipital areas. The results indicate that {SASI} provides a good discrimination between the effects of negative, neutral and positive emotions on human {EEG}.},
	pages = {8107--8110},
	journaltitle = {Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society. {IEEE} Engineering in Medicine and Biology Society. Annual International Conference},
	shortjournal = {Annu Int Conf {IEEE} Eng Med Biol Soc},
	author = {Orgo, L. and Bachmann, M. and Lass, J. and Hinrikus, H.},
	date = {2015-08},
	pmid = {26738175},
	keywords = {Humans, Brain, Electroencephalography, Emotions, Brain Mapping, Depression},
}

@article{sammler_music_nodate,
	title = {Music and emotion: Electrophysiological correlates of the processing of pleasant and unpleasant music},
	abstract = {Human emotion and its electrophysiological correlates are still poorly understood. The present study examined whether the valence of perceived emotions would differentially inﬂuence {EEG} power spectra and heart rate ({HR}). Pleasant and unpleasant emotions were induced by consonant and dissonant music. Unpleasant (compared to pleasant) music evoked a significant decrease of {HR}, replicating the pattern of {HR} responses previously described for the processing of emotional pictures, sounds, and ﬁlms. In the {EEG}, pleasant (contrasted to unpleasant) music was associated with an increase of frontal midline (Fm) theta power. This effect is taken to reﬂect emotional processing in close interaction with attentional functions. These ﬁndings show that Fm theta is modulated by emotion more strongly than previously believed.},
	pages = {12},
	author = {Sammler, Daniela and Grigutsch, Maren and Fritz, Thomas and Koelsch, Stefan},
	langid = {english},
	file = {Sammler et al. - Music and emotion Electrophysiological correlates.pdf:C\:\\Users\\miche\\Zotero\\storage\\I89YEW6J\\Sammler et al. - Music and emotion Electrophysiological correlates.pdf:application/pdf},
}

@article{ishii_frontal_2014,
	title = {Frontal midline theta rhythm and gamma power changes during focused attention on mental calculation: an {MEG} beamformer analysis},
	volume = {8},
	issn = {1662-5161},
	url = {https://www.frontiersin.org/article/10.3389/fnhum.2014.00406},
	doi = {10.3389/fnhum.2014.00406},
	shorttitle = {Frontal midline theta rhythm and gamma power changes during focused attention on mental calculation},
	abstract = {Frontal midline theta rhythm (Fmθ) appears widely distributed over medial prefrontal areas in {EEG} recordings, indicating focused attention. Although mental calculation is often used as an attention-demanding task, little has been reported on calculation-related activation in Fmθ experiments. In this study we used spatially filtered {MEG} and permutation analysis to precisely localize cortical generators of the magnetic counterpart of Fmθ, as well as other sources of oscillatory activity associated with mental calculation processing (i.e., arithmetic subtraction). Our results confirmed and extended earlier {EEG}/{MEG} studies indicating that Fmθ during mental calculation is generated in the dorsal anterior cingulate and adjacent medial prefrontal cortex. Mental subtraction was also associated with gamma event-related synchronization, as an index of activation, in right parietal regions subserving basic numerical processing and number-based spatial attention. Gamma event-related desynchronization appeared in the right lateral prefrontal cortex, likely representing a mechanism to interrupt neural activity that can interfere with the ongoing cognitive task.},
	pages = {406},
	journaltitle = {Frontiers in Human Neuroscience},
	author = {Ishii, Ryouhei and Canuet, Leonides and Ishihara, Tsutomu and Aoki, Yasunori and Ikeda, Shunichiro and Hata, Masahiro and Katsimichas, Themistoklis and Gunji, Atsuko and Takahashi, Hidetoshi and Nakahachi, Takayuki and Iwase, Masao and Takeda, Masatoshi},
	urldate = {2021-09-09},
	date = {2014},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\I53FMV52\\Ishii et al. - 2014 - Frontal midline theta rhythm and gamma power chang.pdf:application/pdf},
}

@article{inanaga_frontal_1998,
	title = {Frontal midline theta rhythm and mental activity},
	volume = {52},
	issn = {1440-1819},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1440-1819.1998.00452.x},
	doi = {10.1046/j.1440-1819.1998.00452.x},
	abstract = {Theta rhythm at the midline of the frontal area can be observed in normal subjects, during mental task performance, rest and sleep. Frontal midline theta rhythm (Fm θ) is a train of rhythmic waves at the frequency of 6–7 Hz and can be induced by various mental tasks. Fm θ is induced not only during mental tasks but also during nocturnal sleep in which it was most frequent during rapid eye movement ({REM}) and second most frequent during stage 1 of non-{REM} ({NREM}) sleep, and the relationship of Fm θ to dream images during sleep was found. It is concluded, therefore, that the appearance of Fm θ is related to mental activity even during sleep. Fm θ shows individual differences and is related to certain personality traits. High Fm θ groups showed the lowest anxiety score in the Manifest Anxiety Scale ({MAS}), the highest score in the extrovertive scale of the Maudsley Personality Inventory ({MPI}) and the lowest score in the neurotic scale of {MPI}. Low Fm θ groups showed the opposite correlation. Significant negative correlation was found between the amount of Fm θ and platelet monoamine oxidase ({MAO}) activity. Summarizing the above-mentioned results, it may be concluded that the appearance of Fm θ is related to mental activity, personality traits and platelet {MAO} activity. Furthermore, the correlation of such markers as platelet {MAO} activity and Fm θ with personality traits as measured by various psychological tests may prove to be of great importance in the exploration of the biological bases of personality.},
	pages = {555--566},
	number = {6},
	journaltitle = {Psychiatry and Clinical Neurosciences},
	author = {Inanaga, Kazutoyo},
	urldate = {2021-09-09},
	date = {1998},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1046/j.1440-1819.1998.00452.x},
	keywords = {{EEG}, mental activity, monoamine oxidase, personality, theta rhythm},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\GIVGZXA5\\j.1440-1819.1998.00452.html:text/html;Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\5WGBWAKV\\Inanaga - 1998 - Frontal midline theta rhythm and mental activity.pdf:application/pdf},
}

@article{ravaja_emotional_nodate,
	title = {Emotional effects of startling background music during reading news reports: The moderating influence of dispositional {BIS} and {BAS} sensitivities},
	volume = {45},
	issn = {0036-5564},
	url = {https://www.academia.edu/17060372/Emotional_effects_of_startling_background_music_during_reading_news_reports_The_moderating_influence_of_dispositional_BIS_and_BAS_sensitivities},
	shorttitle = {Emotional effects of startling background music during reading news reports},
	abstract = {We examined the moderating influence of dispositional behavioral inhibition system ({BIS}) and behavioral activation system ({BAS}) sensitivities on the relationship of startling background music with emotion-related subjective and physiological},
	pages = {231--238},
	number = {3},
	journaltitle = {Scandinavian Journal of Psychology},
	author = {Ravaja, Niklas and Kallinen, Kari},
	urldate = {2021-09-10},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\ZLVKM2P7\\Emotional_effects_of_startling_background_music_during_reading_news_reports_The_moderating_infl.html:text/html},
}

@article{reuderink_valence_2013-1,
	title = {Valence, arousal and dominance in the {EEG} during game play},
	volume = {6},
	doi = {10.1504/IJAACS.2013.050691},
	abstract = {In this paper, we describe our investigation of traces of naturally occurring emotions in electrical brain signals, that can be used to build interfaces that respond to our emotional state. This study confirms a number of known affective correlates in a realistic, uncontrolled environment for the emotions of valence (or pleasure), arousal and dominance: (1) a significant decrease in frontal power in the theta range is found for increasingly positive valence, (2) a significant frontal increase in power in the alpha range is associated with increasing emotional arousal, (3) a significant right posterior power increase in the delta range correlates with increasing arousal and (4) asymmetry in power in the lower alpha bands correlates with self-reported valence. Furthermore, asymmetry in the higher alpha bands correlates with self-reported dominance. These last two effects provide a simple measure for subjective feelings of pleasure and feelings of control.},
	pages = {45--62},
	journaltitle = {International Journal of Autonomous and Adaptive Communications Systems},
	shortjournal = {International Journal of Autonomous and Adaptive Communications Systems},
	author = {Reuderink, Boris and Mühl, Christian and Poel, Mannes},
	date = {2013-12-01},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\ZQFEW88M\\Reuderink et al. - 2013 - Valence, arousal and dominance in the EEG during g.pdf:application/pdf},
}

@article{lin_eeg-based_2010-2,
	title = {{EEG}-Based Emotion Recognition in Music Listening},
	volume = {57},
	issn = {1558-2531},
	doi = {10.1109/TBME.2010.2048568},
	abstract = {Ongoing brain activity can be recorded as electroen-cephalograph ({EEG}) to discover the links between emotional states and brain activity. This study applied machine-learning algorithms to categorize {EEG} dynamics according to subject self-reported emotional states during music listening. A framework was proposed to optimize {EEG}-based emotion recognition by systematically 1) seeking emotion-specific {EEG} features and 2) exploring the efficacy of the classifiers. Support vector machine was employed to classify four emotional states (joy, anger, sadness, and pleasure) and obtained an averaged classification accuracy of 82.29\% ± 3.06\% across 26 subjects. Further, this study identified 30 subject-independent features that were most relevant to emotional processing across subjects and explored the feasibility of using fewer electrodes to characterize the {EEG} dynamics during music listening. The identified features were primarily derived from electrodes placed near the frontal and the parietal lobes, consistent with many of the findings in the literature. This study might lead to a practical system for noninvasive assessment of the emotional states in practical or clinical applications.},
	pages = {1798--1806},
	number = {7},
	journaltitle = {{IEEE} Transactions on Biomedical Engineering},
	author = {Lin, Yuan-Pin and Wang, Chi-Hong and Jung, Tzyy-Ping and Wu, Tien-Lin and Jeng, Shyh-Kang and Duann, Jeng-Ren and Chen, Jyh-Horng},
	date = {2010-07},
	note = {Conference Name: {IEEE} Transactions on Biomedical Engineering},
	keywords = {Humans, {EEG}, Brain, Electroencephalography, Electrodes, Support vector machines, Electromyography, emotion, Emotion recognition, Hospitals, {IEEE} activities, machine learning, music, Support vector machine classification},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\TU7KBSKB\\Lin et al. - 2010 - EEG-Based Emotion Recognition in Music Listening.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\JKYZ5CZ6\\5458075.html:text/html},
}

@article{schmidt_frontal_1999,
	title = {Frontal Brain Electrical Activity in Shyness and Sociability},
	volume = {10},
	issn = {0956-7976},
	url = {https://doi.org/10.1111/1467-9280.00161},
	doi = {10.1111/1467-9280.00161},
	abstract = {A number of studies have shown that shyness and sociability may be two independent personality traits that are distinguishable across a variety of measures and cultures. Utilizing recent frontal activation–emotion models as a theoretical framework, this study examined the pattern of resting frontal electroencephalographic ({EEG}) activity in undergraduates who self-reported high and low shyness and sociability. Analyses revealed that shyness was associated with greater relative right frontal {EEG} activity, whereas sociability was associated with greater relative left frontal {EEG} activity. Also, different combinations of shyness and sociability were distinguishable on the basis of resting frontal {EEG} power. Although high-shy/high-social and high-shy/low-social subjects both exhibited greater relative right frontal {EEG} activity, they differed significantly on {EEG} power in the left, but not right, frontal lead. High-shy/high-social subjects exhibited significantly less {EEG} power (i.e., more activity) in the left frontal lead compared with the high-shy/low-social subjects. These findings suggest that in distinguishing individual differences in personality and personality subtypes, it is important to consider not only frontal {EEG} asymmetry measures, but also the pattern of absolute {EEG} power in each frontal hemisphere.},
	pages = {316--320},
	number = {4},
	journaltitle = {Psychological Science},
	shortjournal = {Psychol Sci},
	author = {Schmidt, Louis A.},
	urldate = {2021-09-17},
	date = {1999-07-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Inc},
}

@article{heller_neuropsychological_1993,
	title = {Neuropsychological Mechanisms of Individual Differences in Emotion, Personality, and Arousal},
	volume = {7},
	issn = {0894-4105},
	url = {http://www.scopus.com/inward/record.url?scp=0001052432&partnerID=8YFLogxK},
	doi = {10.1037/0894-4105.7.4.476},
	abstract = {Evidence is reviewed to suggest that parietotemporal regions of the right hemisphere not only are specialized for the processing of emotional information but also play a critical role in the experience of emotion. In particular, it is argued that these regions of the right hemisphere constitute a system involved in modulating autonomic and behavioral arousal in emotional states. This system is characterized by a set of cognitive and attentional qualities that make it uniquely suited to respond to environmental events in an adaptive fashion. The current proposal is an elaboration of a model of emotion and brain organization (Heller, 1990) that incorporates several aspects of emotional function: (a) perception and production of emotional information, (b) mood and emotional experience, and (c) autonomic arousal. In the context of this model, it is suggested that the right-hemisphere system operates in conjunction with a system localized to the frontal lobes that is involved in modulating the emotional valence of experience. The interaction of these two systems is hypothesized to be conditioned by individual differences and developmental tendencies that contribute to the production of a unique and stable pattern of personality traits and emotional characteristics.},
	pages = {476--489},
	number = {4},
	journaltitle = {Neuropsychology},
	author = {Heller, Wendy},
	urldate = {2021-09-17},
	date = {1993-10},
}

@article{dawson_frontal_1994,
	title = {Frontal electroencephalographic correlates of individual differences in emotion expression in infants: a brain systems perspective on emotion},
	volume = {59},
	issn = {0037-976X},
	shorttitle = {Frontal electroencephalographic correlates of individual differences in emotion expression in infants},
	abstract = {Emotion expressions can be characterized by both the type of emotion displayed and the intensity with which the emotion is expressed. Individual differences in these two aspects of emotion appear to vary independently and may perhaps account for distinct dimensions of temperament, personality, and vulnerability to psychopathology. We reviewed several sets of data gathered in our laboratory that indicate that these two dimensions of emotion expression are associated with distinct and independent patterns of frontal {EEG} activity in infants. Specifically, whereas the type of emotion expression was found to be associated with asymmetries in frontal {EEG} activity, the intensity of emotion expression was found to be associated with generalized activation of both the right and the left frontal regions. Moreover, we reviewed and provided evidence that measures of asymmetrical frontal activity are better predictors of individual differences in the tendency to express certain emotions, such as distress and sadness, whereas measures of generalized frontal activity are better predictors of individual differences in emotional reactivity and emotion intensity. The neuroanatomical bases of emotion were discussed with special reference to the role of the frontal lobe in emotion regulation. It was hypothesized that the frontal activation asymmetries that have been found to accompany emotion expressions reflect specific regulation strategies. The left frontal region is specialized for regulation strategies involving action schemes that serve to maintain continuity and stability of the organism-environment relation and of ongoing motor schemes, such as those involved in language and the expression of happiness and interest. In contrast, the right frontal region appears to be specialized for regulation strategies that involve processing novel stimuli that disrupt ongoing activity, such as might occur during the expression of fear, disgust, and distress. Furthermore, it was proposed that individual differences in patterns of frontal {EEG} asymmetries during emotion may be related to socialization influences rather than solely innate factors. It was speculated that the pattern of generalized frontal lobe activation that accompanies the experience of intense emotions may reflect, in part, the relatively diffuse influence of subcortical structures on the cortex and may serve to increase the infant's general readiness to receive and respond to significant external stimuli.},
	pages = {135--151},
	number = {2},
	journaltitle = {Monographs of the Society for Research in Child Development},
	shortjournal = {Monogr Soc Res Child Dev},
	author = {Dawson, G.},
	date = {1994},
	pmid = {7984157},
	keywords = {Humans, Electroencephalography, Infant, Affect, Emotions, Anxiety, Separation, Facial Expression, Frontal Lobe, Functional Laterality, Parietal Lobe},
}

@article{nicolas-alonso_brain_2012,
	title = {Brain Computer Interfaces, a Review},
	volume = {12},
	issn = {1424-8220},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3304110/},
	doi = {10.3390/s120201211},
	abstract = {A brain-computer interface ({BCI}) is a hardware and software communications system that permits cerebral activity alone to control computers or external devices. The immediate goal of {BCI} research is to provide communications capabilities to severely disabled people who are totally paralyzed or ‘locked in’ by neurological neuromuscular disorders, such as amyotrophic lateral sclerosis, brain stem stroke, or spinal cord injury. Here, we review the state-of-the-art of {BCIs}, looking at the different steps that form a standard {BCI}: signal acquisition, preprocessing or signal enhancement, feature extraction, classification and the control interface. We discuss their advantages, drawbacks, and latest advances, and we survey the numerous technologies reported in the scientific literature to design each step of a {BCI}. First, the review examines the neuroimaging modalities used in the signal acquisition step, each of which monitors a different functional brain activity such as electrical, magnetic or metabolic activity. Second, the review discusses different electrophysiological control signals that determine user intentions, which can be detected in brain activity. Third, the review includes some techniques used in the signal enhancement step to deal with the artifacts in the control signals and improve the performance. Fourth, the review studies some mathematic algorithms used in the feature extraction and classification steps which translate the information in the control signals into commands that operate a computer or other device. Finally, the review provides an overview of various {BCI} applications that control a range of devices.},
	pages = {1211--1279},
	number = {2},
	journaltitle = {Sensors (Basel, Switzerland)},
	shortjournal = {Sensors (Basel)},
	author = {Nicolas-Alonso, Luis Fernando and Gomez-Gil, Jaime},
	urldate = {2021-09-17},
	date = {2012-01-31},
	file = {PubMed Central Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\XXEZ4GSV\\Nicolas-Alonso and Gomez-Gil - 2012 - Brain Computer Interfaces, a Review.pdf:application/pdf},
}

@article{davidson_anterior_1992,
	title = {Anterior cerebral asymmetry and the nature of emotion},
	volume = {20},
	issn = {0278-2626},
	doi = {10.1016/0278-2626(92)90065-t},
	abstract = {This article presents an overview of the author's recent electrophysiological studies of anterior cerebral asymmetries related to emotion and affective style. A theoretical account is provided of the role of the two hemispheres in emotional processing. This account assigns a major role in approach- and withdrawal-related behavior to the left and right frontal and anterior temporal regions of two hemispheres, respectively. Individual differences in approach- and withdrawal-related emotional reactivity and temperament are associated with stable differences in baseline measures of activation asymmetry in these anterior regions. Phasic state changes in emotion result in shifts in anterior activation asymmetry which are superimposed upon these stable baseline differences. Future directions for research in this area are discussed.},
	pages = {125--151},
	number = {1},
	journaltitle = {Brain and Cognition},
	shortjournal = {Brain Cogn},
	author = {Davidson, R. J.},
	date = {1992-09},
	pmid = {1389117},
	keywords = {Female, Humans, Male, Brain, Electroencephalography, Adult, Child, Child, Preschool, Infant, Infant, Newborn, Emotions, Models, Neurological, Cerebral Cortex, Functional Laterality, Child Development, Depressive Disorder, Individuality, Research Design},
}

@article{chang_experiencing_2015-1,
	title = {Experiencing affective music in eyes-closed and eyes-open states: an electroencephalography study},
	volume = {6},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2015.01160},
	doi = {10.3389/fpsyg.2015.01160},
	shorttitle = {Experiencing affective music in eyes-closed and eyes-open states},
	abstract = {In real life, listening to music may be associated with an eyes-closed or eyes-open state. The effect of eye state on listeners’ reaction to music has attracted some attention, but its influence on brain activity has not been fully investigated. The present study aimed to evaluate the electroencephalographic ({EEG}) markers for the emotional valence of music in different eye states. Thirty participants listened to musical excerpts with different emotional content in the eyes-closed and eyes-open states. The results showed that participants rated the music as more pleasant or with more positive valence under an eyes-open state. In addition, we found that the alpha asymmetry indices calculated on the parietal and temporal sites reflected emotion valence in the eyes-closed and eyes-open states, respectively. The theta power in the frontal area significantly increased while listening to emotional-positive music compared to emotional-negative music under the eyes-closed condition. These effects of eye states on {EEG} markers are discussed in terms of brain mechanisms underlying attention and emotion.},
	pages = {1160},
	journaltitle = {Frontiers in Psychology},
	author = {Chang, Yun-Hsuan and Lee, You-Yun and Liang, Keng-Chen and Chen, I-Ping and Tsai, Chen-Gia and Hsieh, Shulan},
	urldate = {2021-10-06},
	date = {2015},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\482BF6GM\\Chang et al. - 2015 - Experiencing affective music in eyes-closed and ey.pdf:application/pdf},
}

@article{barry_eeg_2007,
	title = {{EEG} differences between eyes-closed and eyes-open resting conditions},
	volume = {118},
	issn = {1388-2457},
	doi = {10.1016/j.clinph.2007.07.028},
	abstract = {{OBJECTIVE}: Recent work has attempted to clarify the energetics of physiological responding and behaviour by refining and separating the operational definitions of "arousal" and "activation", which have different effects on physiological responding and behaviour. At the {EEG} level, we relate the former to widespread activity, and the latter to task-specific topographically-focussed activity reflecting regional processing. This study aimed to investigate this further in terms of differences in {EEG} activity between eyes-closed and eyes-open resting conditions.
{METHODS}: {EEG} activity was recorded from 28 university students during both eyes-closed and eyes-open resting conditions, Fourier transformed to provide estimates for absolute power in the delta, theta, alpha and beta bands, and analysed in 9 regions across the scalp. Skin conductance level was also measured as an indicator of arousal level.
{RESULTS}: Across the eyes-closed conditions, skin conductance levels were negatively correlated with mean alpha levels. Skin conductance levels increased significantly from eyes-closed to eyes-open conditions. Reductions were found in across-scalp mean absolute delta, theta, alpha and beta from the eyes-closed to eyes-open condition. Topographic changes were also evident in all bands except for alpha, with reduced lateral frontal delta and posterior theta, and decreased posterior/increased frontal beta in the eyes-open condition. In particular, the topographic beta effects indicate that the across-scalp reduction arose from focal reductions rather than global changes.
{CONCLUSIONS}: The obtained results confirm the use of mean alpha level as a measure of resting-state arousal under eyes-closed and eyes-open conditions. The focal nature of {EEG} effects in the other bands suggests that these reflect cortical processing of visual input, producing differences in activation between eyes-closed and eyes-open resting conditions, rather than just the simple increase in arousal level shown in alpha.
{SIGNIFICANCE}: This study demonstrates that the eyes-closed and eyes-open conditions provide {EEG} measures differing in topography as well as power levels. These differences should be recognised when evaluating {EEG} research, and considered when choosing eyes-open or eyes-closed baseline conditions for different paradigms.},
	pages = {2765--2773},
	number = {12},
	journaltitle = {Clinical Neurophysiology: Official Journal of the International Federation of Clinical Neurophysiology},
	shortjournal = {Clin Neurophysiol},
	author = {Barry, Robert J. and Clarke, Adam R. and Johnstone, Stuart J. and Magee, Christopher A. and Rushby, Jacqueline A.},
	date = {2007-12},
	pmid = {17911042},
	keywords = {Female, Humans, Male, Attention, Electroencephalography, Adolescent, Adult, Middle Aged, Brain Mapping, Photic Stimulation, Visual Perception, Arousal, Nerve Net, Fourier Analysis, Evoked Potentials, Cerebral Cortex, Wakefulness},
}

@article{picard_affective_2003,
	title = {Affective computing: challenges},
	volume = {59},
	issn = {10715819},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581903000521},
	doi = {10.1016/S1071-5819(03)00052-1},
	shorttitle = {Affective computing},
	pages = {55--64},
	number = {1},
	journaltitle = {International Journal of Human-Computer Studies},
	shortjournal = {International Journal of Human-Computer Studies},
	author = {Picard, Rosalind W.},
	urldate = {2021-10-14},
	date = {2003-07},
	langid = {english},
	file = {Picard - 2003 - Affective computing challenges.pdf:C\:\\Users\\miche\\Zotero\\storage\\39WEMFYV\\Picard - 2003 - Affective computing challenges.pdf:application/pdf},
}

@inproceedings{thammasan_multimodal_2017,
	title = {Multimodal stability-sensitive emotion recognition based on brainwave and physiological signals},
	doi = {10.1109/ACIIW.2017.8272584},
	abstract = {This paper presents a framework for adaptive multimodal emotion recognition based on signal stability as a context. To verify the efficacy of the method, experiments were conducted using a dataset of brainwave and physiological signals ({EEG}, {ECG}, {GSR}) captured from nine subjects listening to music. The proposed method uses a combination of signal-based features as well as accelerometer data to quantify the approximate reliability of each modality. In contrast to existing approaches, unstable modalities are not rejected outright, instead their relative contribution is dynamically adapted based on a corresponding stability index. In the case of {EEG}, the stability index was calculated using an artifact rejection technique, while for the {ECG} and {GSR} modalities it was calculated based on body movement detected through accelerometers. The experimental results show that temporally varying the relative contribution of each modality can improve emotion recognition performance.},
	eventtitle = {2017 Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos ({ACIIW})},
	pages = {44--49},
	booktitle = {2017 Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos ({ACIIW})},
	author = {Thammasan, Nattapong and Hagad, Juan Lorenzo and Fukui, Ken-ichi and Numao, Masayuki},
	date = {2017-10},
	keywords = {Electroencephalography, Feature extraction, Music, Accelerometers, Emotion recognition, Electrocardiography},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\77B7FIAF\\8272584.html:text/html},
}

@inproceedings{thammasan_multimodal_2017-1,
	title = {Multimodal stability-sensitive emotion recognition based on brainwave and physiological signals},
	doi = {10.1109/ACIIW.2017.8272584},
	abstract = {This paper presents a framework for adaptive multimodal emotion recognition based on signal stability as a context. To verify the efficacy of the method, experiments were conducted using a dataset of brainwave and physiological signals ({EEG}, {ECG}, {GSR}) captured from nine subjects listening to music. The proposed method uses a combination of signal-based features as well as accelerometer data to quantify the approximate reliability of each modality. In contrast to existing approaches, unstable modalities are not rejected outright, instead their relative contribution is dynamically adapted based on a corresponding stability index. In the case of {EEG}, the stability index was calculated using an artifact rejection technique, while for the {ECG} and {GSR} modalities it was calculated based on body movement detected through accelerometers. The experimental results show that temporally varying the relative contribution of each modality can improve emotion recognition performance.},
	eventtitle = {2017 Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos ({ACIIW})},
	pages = {44--49},
	booktitle = {2017 Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos ({ACIIW})},
	author = {Thammasan, Nattapong and Hagad, Juan Lorenzo and Fukui, Ken-ichi and Numao, Masayuki},
	date = {2017-10},
	keywords = {Electroencephalography, Feature extraction, Music, Accelerometers, Emotion recognition, Electrocardiography},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\TJE5CCAN\\8272584.html:text/html},
}

@inproceedings{thammasan_multimodal_2017-2,
	title = {Multimodal stability-sensitive emotion recognition based on brainwave and physiological signals},
	doi = {10.1109/ACIIW.2017.8272584},
	abstract = {This paper presents a framework for adaptive multimodal emotion recognition based on signal stability as a context. To verify the efficacy of the method, experiments were conducted using a dataset of brainwave and physiological signals ({EEG}, {ECG}, {GSR}) captured from nine subjects listening to music. The proposed method uses a combination of signal-based features as well as accelerometer data to quantify the approximate reliability of each modality. In contrast to existing approaches, unstable modalities are not rejected outright, instead their relative contribution is dynamically adapted based on a corresponding stability index. In the case of {EEG}, the stability index was calculated using an artifact rejection technique, while for the {ECG} and {GSR} modalities it was calculated based on body movement detected through accelerometers. The experimental results show that temporally varying the relative contribution of each modality can improve emotion recognition performance.},
	eventtitle = {2017 Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos ({ACIIW})},
	pages = {44--49},
	booktitle = {2017 Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos ({ACIIW})},
	author = {Thammasan, Nattapong and Hagad, Juan Lorenzo and Fukui, Ken-ichi and Numao, Masayuki},
	date = {2017-10},
	keywords = {Electroencephalography, Feature extraction, Music, Accelerometers, Emotion recognition, Electrocardiography},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\UU58KKI9\\8272584.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\HYQEP8KX\\Thammasan et al. - 2017 - Multimodal stability-sensitive emotion recognition.pdf:application/pdf},
}

@article{chicco_advantages_2020,
	title = {The advantages of the Matthews correlation coefficient ({MCC}) over F1 score and accuracy in binary classification evaluation},
	volume = {21},
	issn = {1471-2164},
	doi = {10.1186/s12864-019-6413-7},
	abstract = {{BACKGROUND}: To evaluate binary classifications and their confusion matrices, scientific researchers can employ several statistical rates, accordingly to the goal of the experiment they are investigating. Despite being a crucial issue in machine learning, no widespread consensus has been reached on a unified elective chosen measure yet. Accuracy and F1 score computed on confusion matrices have been (and still are) among the most popular adopted metrics in binary classification tasks. However, these statistical measures can dangerously show overoptimistic inflated results, especially on imbalanced datasets.
{RESULTS}: The Matthews correlation coefficient ({MCC}), instead, is a more reliable statistical rate which produces a high score only if the prediction obtained good results in all of the four confusion matrix categories (true positives, false negatives, true negatives, and false positives), proportionally both to the size of positive elements and the size of negative elements in the dataset.
{CONCLUSIONS}: In this article, we show how {MCC} produces a more informative and truthful score in evaluating binary classifications than accuracy and F1 score, by first explaining the mathematical properties, and then the asset of {MCC} in six synthetic use cases and in a real genomics scenario. We believe that the Matthews correlation coefficient should be preferred to accuracy and F1 score in evaluating binary classification tasks by all scientific communities.},
	pages = {6},
	number = {1},
	journaltitle = {{BMC} genomics},
	shortjournal = {{BMC} Genomics},
	author = {Chicco, Davide and Jurman, Giuseppe},
	date = {2020-01-02},
	pmid = {31898477},
	pmcid = {PMC6941312},
	keywords = {Machine learning, Accuracy, Algorithms, Genomics, Computational Biology, Data Interpretation, Statistical, Binary classification, Biostatistics, Confusion matrices, Correlation of Data, Dataset imbalance, F1 score, Machine Learning, Matthews correlation coefficient},
	file = {Full Text:C\:\\Users\\miche\\Zotero\\storage\\C6GMMMKH\\Chicco and Jurman - 2020 - The advantages of the Matthews correlation coeffic.pdf:application/pdf},
}

@article{matthews_comparison_1975,
	title = {Comparison of the predicted and observed secondary structure of T4 phage lysozyme},
	volume = {405},
	issn = {0006-3002},
	doi = {10.1016/0005-2795(75)90109-9},
	abstract = {Predictions of the secondary structure of T4 phage lysozyme, made by a number of investigators on the basis of the amino acid sequence, are compared with the structure of the protein determined experimentally by X-ray crystallography. Within the amino terminal half of the molecule the locations of helices predicted by a number of methods agree moderately well with the observed structure, however within the carboxyl half of the molecule the overall agreement is poor. For eleven different helix predictions, the coefficients giving the correlation between prediction and observation range from 0.14 to 0.42. The accuracy of the predictions for both beta-sheet regions and for turns are generally lower than for the helices, and in a number of instances the agreement between prediction and observation is no better than would be expected for a random selection of residues. The structural predictions for T4 phage lysozyme are much less successful than was the case for adenylate kinase (Schulz et al. (1974) Nature 250, 140-142). No one method of prediction is clearly superior to all others, and although empirical predictions based on larger numbers of known protein structure tend to be more accurate than those based on a limited sample, the improvement in accuracy is not dramatic, suggesting that the accuracy of current empirical predictive methods will not be substantially increased simply by the inclusion of more data from additional protein structure determinations.},
	pages = {442--451},
	number = {2},
	journaltitle = {Biochimica Et Biophysica Acta},
	shortjournal = {Biochim Biophys Acta},
	author = {Matthews, B. W.},
	date = {1975-10-20},
	pmid = {1180967},
	keywords = {Mathematics, Adenylate Kinase, Coliphages, {DNA} Viruses, Muramidase, Protein Conformation, X-Ray Diffraction},
}

@article{bigdely-shamlo_prep_2015,
	title = {The {PREP} pipeline: standardized preprocessing for large-scale {EEG} analysis},
	volume = {9},
	issn = {1662-5196},
	url = {https://www.frontiersin.org/article/10.3389/fninf.2015.00016},
	doi = {10.3389/fninf.2015.00016},
	shorttitle = {The {PREP} pipeline},
	abstract = {The technology to collect brain imaging and physiological measures has become portable and ubiquitous, opening the possibility of large-scale analysis of real-world human imaging. By its nature, such data is large and complex, making automated processing essential. This paper shows how lack of attention to the very early stages of an {EEG} preprocessing pipeline can reduce the signal-to-noise ratio and introduce unwanted artifacts into the data, particularly for computations done in single precision. We demonstrate that ordinary average referencing improves the signal-to-noise ratio, but that noisy channels can contaminate the results. We also show that identification of noisy channels depends on the reference and examine the complex interaction of filtering, noisy channel identification, and referencing. We introduce a multi-stage robust referencing scheme to deal with the noisy channel-reference interaction. We propose a standardized early-stage {EEG} processing pipeline ({PREP}) and discuss the application of the pipeline to more than 600 {EEG} datasets. The pipeline includes an automatically generated report for each dataset processed. Users can download the {PREP} pipeline as a freely available {MATLAB} library from http://eegstudy.org/prepcode.},
	pages = {16},
	journaltitle = {Frontiers in Neuroinformatics},
	author = {Bigdely-Shamlo, Nima and Mullen, Tim and Kothe, Christian and Su, Kyung-Min and Robbins, Kay A.},
	urldate = {2021-11-12},
	date = {2015},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\9GDEKQ8E\\Bigdely-Shamlo et al. - 2015 - The PREP pipeline standardized preprocessing for .pdf:application/pdf},
}

@article{cohen_analyzing_2014,
	title = {Analyzing Neural Time Series Data: Theory and Practice},
	url = {https://direct.mit.edu/books/book/4013/Analyzing-Neural-Time-Series-DataTheory-and},
	doi = {10.7551/mitpress/9609.001.0001},
	shorttitle = {Analyzing Neural Time Series Data},
	abstract = {A comprehensive guide to the conceptual, mathematical, and implementational aspects of analyzing electrical brain signals, including data from {MEG}, {EEG}, and {LFP}},
	author = {Cohen, Mike X.},
	urldate = {2021-11-12},
	date = {2014-01-17},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\KL9N652A\\Analyzing-Neural-Time-Series-DataTheory-and.html:text/html},
}

@inproceedings{navarro_wearable_2004,
	title = {Wearable, wireless brain computer interfaces in augmented reality environments},
	volume = {2},
	doi = {10.1109/ITCC.2004.1286726},
	abstract = {After Pierre Gloor and Hans Berger discovered the human electroencephalogram or {EEG} produced in the brain in 1969, brain computer interfaces ({BCIs}) became a reality. However, for more than a couple of decades, besides the common social fascination with such devices, they have not yet been considered as a feasible alternative interface for common daily activities. This is attributed to issues such as response time, costs and long initial user training periods. We define and outlines the current {BCI} technologies and reviews the current status of {BCIs} in the context of wearable computers. The use of augmented reality environments and the integration of wireless technologies such as Bluetooth are proposed as potential catalysts in the process of incorporating {BCIs} into daily life.},
	eventtitle = {International Conference on Information Technology: Coding and Computing, 2004. Proceedings. {ITCC} 2004.},
	pages = {643--647 Vol.2},
	booktitle = {International Conference on Information Technology: Coding and Computing, 2004. Proceedings. {ITCC} 2004.},
	author = {Navarro, K.F.},
	date = {2004-04},
	keywords = {Humans, Electroencephalography, Signal processing, Electromyography, Brain computer interfaces, Augmented reality, Bluetooth, Costs, Delay, Wearable computers},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\BVJILNIV\\Navarro - 2004 - Wearable, wireless brain computer interfaces in au.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\QJLY4ZMA\\1286726.html:text/html},
}

@article{bradley_measuring_1994-1,
	title = {Measuring emotion: the Self-Assessment Manikin and the Semantic Differential},
	volume = {25},
	issn = {0005-7916},
	doi = {10.1016/0005-7916(94)90063-9},
	shorttitle = {Measuring emotion},
	abstract = {The Self-Assessment Manikin ({SAM}) is a non-verbal pictorial assessment technique that directly measures the pleasure, arousal, and dominance associated with a person's affective reaction to a wide variety of stimuli. In this experiment, we compare reports of affective experience obtained using {SAM}, which requires only three simple judgments, to the Semantic Differential scale devised by Mehrabian and Russell (An approach to environmental psychology, 1974) which requires 18 different ratings. Subjective reports were measured to a series of pictures that varied in both affective valence and intensity. Correlations across the two rating methods were high both for reports of experienced pleasure and felt arousal. Differences obtained in the dominance dimension of the two instruments suggest that {SAM} may better track the personal response to an affective stimulus. {SAM} is an inexpensive, easy method for quickly assessing reports of affective response in many contexts.},
	pages = {49--59},
	number = {1},
	journaltitle = {Journal of Behavior Therapy and Experimental Psychiatry},
	shortjournal = {J Behav Ther Exp Psychiatry},
	author = {Bradley, M. M. and Lang, P. J.},
	date = {1994-03},
	pmid = {7962581},
	keywords = {Female, Humans, Male, Adult, Affect, Emotions, Arousal, Internal-External Control, Factor Analysis, Statistical, Personality Inventory, Psychometrics, Semantic Differential},
}

@incollection{lin_toward_2015,
	title = {Toward Affective Brain-Computer Interface: Fundamentals and Analysis of {EEG}-Based Emotion Classification},
	isbn = {978-1-118-13066-7},
	shorttitle = {Toward Affective Brain-Computer Interface},
	abstract = {Emotion classification from non-invasively measured electroencephalographic ({EEG}) data has been a growing research topic because of its potential application to affective brain–computer interfaces ({ABCI}), such as brain-inspired multimedia interaction and clinical assessment. This chapter explores principles for translating neuroscientific findings into a practical {ABCI}. It covers not only an overview of state-of-the-art {EEG}-based emotion recognition techniques, but also the basic research exploring neurophysiological {EEG} dynamics associated with affective responses. The chapter aims at resolving {EEG} feature selection and electrode reduction issues by the generalization of subject-independent feature/electrode set extraction techniques that we have proposed in our series of emotion classification studies. It addresses several practical issues and potential challenges for {ABCIs} as well. The authors believe a user-friendly {EEG} cap with a small number of electrodes can efficiently detect affective states, and therefore significantly promote practical {ABCI} applications in daily life.},
	pages = {315--341},
	author = {Lin, Yuan-Pin and Jung, Tzyy-Ping and Onton, Julie},
	date = {2015-01-02},
	doi = {10.1002/9781118910566.ch13},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\IJDD693B\\Lin et al. - 2015 - Toward Affective Brain-Computer Interface Fundame.pdf:application/pdf},
}

@article{zhao_frontal_2018-1,
	title = {Frontal {EEG} Asymmetry and Middle Line Power Difference in Discrete Emotions},
	volume = {12},
	issn = {1662-5153},
	url = {https://www.frontiersin.org/article/10.3389/fnbeh.2018.00225},
	doi = {10.3389/fnbeh.2018.00225},
	abstract = {A traditional model of emotion cannot explain the differences in brain activities between two discrete emotions that are similar in the valence-arousal coordinate space. The current study elicited two positive emotions (amusement and tenderness) and two negative emotions (anger and fear) that are similar in both valence and arousal dimensions to examine the differences in brain activities in these emotional states. Frontal electroencephalographic ({EEG}) asymmetry and midline power in three bands (theta, alpha and beta) were measured when participants watched affective film excerpts. Significant differences were detected between tenderness and amusement on {FP}1/{FP}2 theta asymmetry, F3/F4 theta and alpha asymmetry. Significant differences between anger and fear on {FP}1/{FP}2 theta asymmetry and F3/F4 alpha asymmetry were also observed. For midline power, midline theta power could distinguish two negative emotions, while midline alpha and beta power could effectively differentiate two positive emotions. Liking and dominance were also related to {EEG} features. Stepwise multiple linear regression results revealed that frontal alpha and theta asymmetry could predict the subjective feelings of two positive and two negative emotions in different patterns. The binary classification accuracy, which used {EEG} frontal asymmetry and midline power as features and support vector machine ({SVM}) as classifiers, was as high as 64.52\% for tenderness and amusement and 78.79\% for anger and fear. The classification accuracy was improved after adding these features to other features extracted across the scalp. These findings indicate that frontal {EEG} asymmetry and midline power might have the potential to recognize discrete emotions that are similar in the valence-arousal coordinate space.},
	pages = {225},
	journaltitle = {Frontiers in Behavioral Neuroscience},
	author = {Zhao, Guozhen and Zhang, Yulin and Ge, Yan},
	urldate = {2021-11-23},
	date = {2018},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\XDSDGJFI\\Zhao et al. - 2018 - Frontal EEG Asymmetry and Middle Line Power Differ.pdf:application/pdf},
}

@inproceedings{lin_support_2008,
	title = {Support vector machine for {EEG} signal classification during listening to emotional music},
	doi = {10.1109/MMSP.2008.4665061},
	abstract = {An approach to recognize the emotion responses during multimedia presentation using the electroencephalogram ({EEG}) signals is proposed. The association between {EEG} signals and music-induced emotion responses was investigated in three factors, including: 1) the types of features, 2) the temporal resolutions of features, and 3) the components of {EEG}. The results showed that the spectrum power asymmetry index of {EEG} signal was a sensitive marker to reflect the brain activation related to emotion responses, especially for the low frequency bands of delta, theta and alpha components. Besides, the maximum classification accuracy was obtained around 92.73\% by using support vector machine ({SVM}) based on 60 features derived from all {EEG} components with the feature temporal resolution of one second. As such, it will be able to provide key clues to develop {EEG}-inspired multimedia applications, in which multimedia contents could be offered interactively according to the userspsila immediate feedback.},
	eventtitle = {2008 {IEEE} 10th Workshop on Multimedia Signal Processing},
	pages = {127--130},
	booktitle = {2008 {IEEE} 10th Workshop on Multimedia Signal Processing},
	author = {Lin, Yuan-Pin and Wang, Chi-Hong and Wu, Tien-Lin and Jeng, Shyh-Kang and Chen, Jyh-Horng},
	date = {2008-10},
	keywords = {Electroencephalography, Accuracy, Electrodes, Feature extraction, Support vector machines, Emotion recognition, Multimedia communication},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\HZAFQXKF\\Lin et al. - 2008 - Support vector machine for EEG signal classificati.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\V7DKMF22\\4665061.html:text/html},
}

@article{lin_improving_2017,
	title = {Improving {EEG}-Based Emotion Classification Using Conditional Transfer Learning},
	volume = {11},
	issn = {1662-5161},
	url = {https://www.frontiersin.org/article/10.3389/fnhum.2017.00334},
	doi = {10.3389/fnhum.2017.00334},
	abstract = {To overcome the individual differences, an accurate electroencephalogram ({EEG})-based emotion-classification system requires a considerable amount of ecological calibration data for each individual, which is labor-intensive and time-consuming. Transfer learning ({TL}) has drawn increasing attention in the field of {EEG} signal mining in recent years. The {TL} leverages existing data collected from other people to build a model for a new individual with little calibration data. However, brute-force transfer to an individual (i.e., blindly leveraged the labeled data from others) may lead to a negative transfer that degrades performance rather than improving it. This study thus proposed a conditional {TL} ({cTL}) framework to facilitate a positive transfer (improving subject-specific performance without increasing the labeled data) for each individual. The {cTL} first assesses an individual’s transferability for positive transfer and then selectively leverages the data from others with comparable feature spaces. The empirical results showed that among 26 individuals, the proposed {cTL} framework identified 16 and 14 transferable individuals who could benefit from the data from others for emotion valence and arousal classification, respectively. These transferable individuals could then leverage the data from 18 and 12 individuals who had similar {EEG} signatures to attain maximal {TL} improvements in valence- and arousal-classification accuracy. The {cTL} improved the overall classification performance of 26 individuals by {\textasciitilde}15\% for valence categorization and {\textasciitilde}12\% for arousal counterpart, as compared to their default performance based solely on the subject-specific data. This study evidently demonstrated the feasibility of the proposed {cTL} framework for improving an individual’s default emotion-classification performance given a data repository. The {cTL} framework may shed light on the development of a robust emotion-classification model using fewer labeled subject-specific data toward a real-life affective brain-computer interface ({ABCI}).},
	pages = {334},
	journaltitle = {Frontiers in Human Neuroscience},
	author = {Lin, Yuan-Pin and Jung, Tzyy-Ping},
	urldate = {2021-11-25},
	date = {2017},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\IF6B7WYL\\Lin and Jung - 2017 - Improving EEG-Based Emotion Classification Using C.pdf:application/pdf},
}

@article{krauledat_towards_2008,
	title = {Towards zero training for brain-computer interfacing},
	volume = {3},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0002967},
	abstract = {Electroencephalogram ({EEG}) signals are highly subject-specific and vary considerably even between recording sessions of the same user within the same experimental paradigm. This challenges a stable operation of Brain-Computer Interface ({BCI}) systems. The classical approach is to train users by neurofeedback to produce fixed stereotypical patterns of brain activity. In the machine learning approach, a widely adapted method for dealing with those variances is to record a so called calibration measurement on the beginning of each session in order to optimize spatial filters and classifiers specifically for each subject and each day. This adaptation of the system to the individual brain signature of each user relieves from the need of extensive user training. In this paper we suggest a new method that overcomes the requirement of these time-consuming calibration recordings for long-term {BCI} users. The method takes advantage of knowledge collected in previous sessions: By a novel technique, prototypical spatial filters are determined which have better generalization properties compared to single-session filters. In particular, they can be used in follow-up sessions without the need to recalibrate the system. This way the calibration periods can be dramatically shortened or even completely omitted for these 'experienced' {BCI} users. The feasibility of our novel approach is demonstrated with a series of online {BCI} experiments. Although performed without any calibration measurement at all, no loss of classification performance was observed.},
	pages = {e2967},
	number = {8},
	journaltitle = {{PloS} One},
	shortjournal = {{PLoS} One},
	author = {Krauledat, Matthias and Tangermann, Michael and Blankertz, Benjamin and Müller, Klaus-Robert},
	date = {2008-08-13},
	pmid = {18698427},
	pmcid = {PMC2500157},
	keywords = {Humans, Brain, Electroencephalography, User-Computer Interface, Pattern Recognition, Automated, Artificial Intelligence, Neurophysiology, Brain Mapping, Evoked Potentials, Learning, Wakefulness, Cortical Synchronization},
	file = {Full Text:C\:\\Users\\miche\\Zotero\\storage\\PEK9IQEF\\Krauledat et al. - 2008 - Towards zero training for brain-computer interfaci.pdf:application/pdf},
}

@inproceedings{jeong_hybrid_2021,
	title = {Hybrid Zero-Training {BCI} based on Convolutional Neural Network for Lower-limb Motor-Imagery},
	doi = {10.1109/BCI51272.2021.9385316},
	abstract = {Zero-training {BCI} was presented to overcome the inconvenience and impractical aspects of the training session in the Brain-Computer Interface ({BCI}) based on Motor Imagery ({MI}). Zero-training {BCI} can be classified into a session-to-session transfer {BCI} and a subject-independent {BCI}. The session-to-session transfer {BCI} is characterized by high classification accuracy, but there is a limitation that the model could not be improved as the number of subjects increased. On the other hand, the subject-independent {BCI} has advantage in increasing the number of subjects, but had the problem of requiring too many subjects for high accuracy. In this study, we proposed the hybrid zero-training {BCI} that integrates the advantages of the aforementioned two methods and Multidomain {CNN} that combined time-, spatial-, and phase-domain, and aimed for more practical application and higher classification accuracy. We collected three-class {MI} {EEG} data related to lower-limb movement (gait, sit-down, and rest) from three subjects with three sessions per subject. The classification accuracy of the proposed method (82.10 ±10.66\%) in the classification of three-class of {MI} tasks was significantly higher than that of the existing zero-training {BCIs} (66.42 ±9.68\%, 66.67±6.83\%) I, and also higher than the conventional {BCI} (70.86±9.46\%) that trains and evaluates with training sessions collected on the same day although not statistically significant.},
	eventtitle = {2021 9th International Winter Conference on Brain-Computer Interface ({BCI})},
	pages = {1--4},
	booktitle = {2021 9th International Winter Conference on Brain-Computer Interface ({BCI})},
	author = {Jeong, Ji Hyeok and Kim, Dong-Joo and Kim, Hyungmin},
	date = {2021-02},
	note = {{ISSN}: 2572-7672},
	keywords = {{EEG}, Electroencephalography, Training, Biological neural networks, Brain modeling, Brain-computer interfaces, Motor imagery, Task analysis, Brain-Computer interface, Convolutional neural network, Convolutional neural networks, Zero-training},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\QJPSB7X6\\9385316.html:text/html},
}

@article{pieter-jan_zero-training_2015,
	title = {Zero-Training for Brain-Computer Interfaces},
	volume = {9},
	issn = {1662-5188},
	url = {http://www.frontiersin.org/Community/AbstractDetails.aspx?ABS_DOI=10.3389/conf.fncom.2015.56.00017},
	doi = {10.3389/conf.fncom.2015.56.00017},
	journaltitle = {Frontiers in Computational Neuroscience},
	shortjournal = {Front. Comput. Neurosci.},
	author = {Pieter-Jan, Kindermans},
	urldate = {2021-11-26},
	date = {2015},
}

@online{noauthor_gartners_nodate,
	title = {Gartner's 2016 Hype Cycle for Emerging Technologies Identifies Three Key Trends That Organizations Must Track to Gain Competitive Advantage},
	url = {https://www.gartner.com/en/newsroom/press-releases/2016-08-16-gartners-2016-hype-cycle-for-emerging-technologies-identifies-three-key-trends-that-organizations-must-track-to-gain-competitive-advantage},
	abstract = {The technologies on Gartner Inc.'s Hype Cycle for Emerging Technologies, 2016 reveal three distinct technology trends that are poised to be of the highest priority for organizations facing rapidly accelerating digital business innovation.},
	titleaddon = {Gartner},
	urldate = {2021-11-29},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\WGD9TTI6\\2016-08-16-gartners-2016-hype-cycle-for-emerging-technologies-identifies-three-key-trends-that-.html:text/html},
}

@online{statt_facebook_2019,
	title = {Facebook acquires neural interface startup {CTRL}-Labs for its mind-reading wristband},
	url = {https://www.theverge.com/2019/9/23/20881032/facebook-ctrl-labs-acquisition-neural-interface-armband-ar-vr-deal},
	abstract = {The deal is reportedly worth between \$500 million and \$1 billion},
	titleaddon = {The Verge},
	author = {Statt, Nick},
	urldate = {2021-11-29},
	date = {2019-09-23},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\E86WPB5F\\facebook-ctrl-labs-acquisition-neural-interface-armband-ar-vr-deal.html:text/html},
}

@online{parfenov_brainflow_nodate,
	title = {{BrainFlow} 4.6.0},
	url = {https://brainflow.org/2021-08-17-enophone/},
	abstract = {{BrainFlow} is the {SDK} for Enophone},
	author = {Parfenov, Andrey},
	urldate = {2021-11-29},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\SNRQTTD6\\2021-08-17-enophone.html:text/html},
}

@online{parfenov_openbci_nodate,
	title = {{OpenBCI} Galea with {BrainFlow}},
	url = {https://brainflow.org/2021-01-26-galea-brainflow/},
	abstract = {{OpenBCI} Galea device developed in collaboration with Valve corporation will use {BrainFlow} {SDK}},
	author = {Parfenov, Andrey},
	urldate = {2021-11-29},
	langid = {english},
}

@article{koelsch_toward_2011,
	title = {Toward a Neural Basis of Music Perception – A Review and Updated Model},
	volume = {2},
	issn = {1664-1078},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3114071/},
	doi = {10.3389/fpsyg.2011.00110},
	abstract = {Music perception involves acoustic analysis, auditory memory, auditory scene analysis, processing of interval relations, of musical syntax and semantics, and activation of (pre)motor representations of actions. Moreover, music perception potentially elicits emotions, thus giving rise to the modulation of emotional effector systems such as the subjective feeling system, the autonomic nervous system, the hormonal, and the immune system. Building on a previous article (Koelsch and Siebel, ), this review presents an updated model of music perception and its neural correlates. The article describes processes involved in music perception, and reports {EEG} and {fMRI} studies that inform about the time course of these processes, as well as about where in the brain these processes might be located.},
	pages = {110},
	journaltitle = {Frontiers in Psychology},
	shortjournal = {Front Psychol},
	author = {Koelsch, Stefan},
	urldate = {2021-11-30},
	date = {2011-06-09},
	pmid = {21713060},
	pmcid = {PMC3114071},
	file = {PubMed Central Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\2MEIYZTT\\Koelsch - 2011 - Toward a Neural Basis of Music Perception – A Revi.pdf:application/pdf},
}

@inproceedings{soleymani_bayesian_2009,
	location = {Amsterdam, Netherlands},
	title = {A Bayesian framework for video affective representation},
	isbn = {978-1-4244-4800-5},
	url = {http://ieeexplore.ieee.org/document/5349563/},
	doi = {10.1109/ACII.2009.5349563},
	abstract = {Emotions that are elicited in response to a video scene contain valuable information for multimedia tagging and indexing. The novelty of this paper is to introduce a Bayesian classification framework for affective video tagging that allows taking contextual information into account. A set of 21 full length movies was first {segmentedFirasntdAuintfhoormr} ative content-based features were {extracteIdnsfrtiotmuteioacnh}1shot and scene. Shots were then {emotIinosntailtluytiaonnn}1otaadteddr,espsroviding ground truth affect. Thefairrosutsaaluotfhsohro@tis 1w.aosrcgomputed using a linear regression on the content-based features. Bayesian classification based on the shots arousal and content-based features allowed tagging these scenes into three affective classes, namely calm, positive excited and negative excited. To improve classification accuracy, two contextual priors have been proposed: the movie genre prior, and the temporal dimension prior consisting of the probability of transition between emotions in consecutive scenes. The f1 classification measure of 54.9\% that was obtained on three emotional classes with a naïve Bayes classifier was improved to 63.4\% after utilizing all the priors.},
	eventtitle = {2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops ({ACII} 2009)},
	pages = {1--7},
	booktitle = {2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops},
	publisher = {{IEEE}},
	author = {Soleymani, Mohammad and Kierkels, Joep J.M. and Chanel, Guillaume and Pun, Thierry},
	urldate = {2021-12-02},
	date = {2009-09},
	langid = {english},
	file = {Soleymani et al. - 2009 - A Bayesian framework for video affective represent.pdf:C\:\\Users\\miche\\Zotero\\storage\\EYIMP5I8\\Soleymani et al. - 2009 - A Bayesian framework for video affective represent.pdf:application/pdf},
}

@online{noauthor_sensors_nodate,
	title = {Sensors {\textbar} Free Full-Text {\textbar} A Comparative Study of Window Size and Channel Arrangement on {EEG}-Emotion Recognition Using Deep {CNN} {\textbar} {HTML}},
	url = {https://www.mdpi.com/1424-8220/21/5/1678/htm},
	urldate = {2021-12-02},
	file = {Sensors | Free Full-Text | A Comparative Study of Window Size and Channel Arrangement on EEG-Emotion Recognition Using Deep CNN | HTML:C\:\\Users\\miche\\Zotero\\storage\\HJZFX9MB\\htm.html:text/html},
}

@book{cowie_feeltrace_2000,
	title = {'{FEELTRACE}': An instrument for recording perceived emotion in real time},
	shorttitle = {'{FEELTRACE}'},
	abstract = {{FEELTRACE} is an instrument developed to let observers track the emotional content of a stimulus as they perceive it over time, allowing the emotional dynamics of speech episodes to be examined. It is based on activation-evaluation space, a representation derived from psychology. The activation dimension measures how dynamic the emotional state is; the evaluation dimension is a global measure of the positive or negative feeling associated with the state. Research suggests that the space is naturally circular, i.e. states which are at the limit of emotional intensity define a circle, with alert neutrality at the centre. To turn those ideas into a recording tool, the space was represented by a circle on a computer screen, and observers described perceived emotional state by moving a pointer (in the form of a disc) to the appropriate point in the circle, using a mouse. Prototypes were tested, and in the light of results, refinements were made to ensure that outputs were as consistent and meaningful as possible. They include colour coding the pointer in a way that users readily associate with the relevant emotional state; presenting key emotion words as 'landmarks' at the strategic points in the space; and developing an induction procedure to introduce observers to the system. An experiment assessed the reliability of the developed system. Stimuli were 16 clips from {TV} programs, two showing relatively strong emotions in each quadrant of activation- evaluation space, each paired with one of the same person in a relatively neural state. 24 raters took part. Differences between clips chosen to contrast were statistically robust. Results were plotted in activation-evaluation space as ellipses, each with its centre at the mean co-ordinates for the clip, and its width proportional to standard deviation across raters. The size of the ellipses meant that about 25 could be fitted into the space, i.e. {FEELTRACE} has resolving power comparable to an emotion vocabulary of 20 non-overlapping words, with the advantage of allowing intermediate ratings, and above all, the ability to track impressions continuously.},
	author = {Cowie, Roddy and Douglas-Cowie, E. and Savvidou, Suzie and {McMahon}, E. and Sawey, M. and Schr\{{\textbackslash}textbackslash\}"oder, M.},
	date = {2000-01-01},
	note = {Journal Abbreviation: Proceedings of the {ISCA} Workshop on Speech and Emotion
Publication Title: Proceedings of the {ISCA} Workshop on Speech and Emotion},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\NM3AGVMZ\\Cowie et al. - 2000 - 'FEELTRACE' An instrument for recording perceived.pdf:application/pdf},
}

@online{martin_stacked_nodate,
	title = {Stacked Turtles},
	url = {https://kiwidamien.github.io},
	abstract = {View the blog.},
	titleaddon = {Stacked Turtles},
	author = {Martin, Damien},
	urldate = {2021-12-02},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\KMPZFPC5\\custom-loss-vs-custom-scoring.html:text/html},
}

@online{noauthor_please_nodate,
	title = {Please Support Customize Loss Function in {SGDClassifier}/Regressor · Issue \#1701 · scikit-learn/scikit-learn},
	url = {https://github.com/scikit-learn/scikit-learn/issues/1701},
	abstract = {Hi, I want to try on some customize loss function in my data, and find the {SGDClassifier} and {SGDRegressor} in sklearn. It\&\#39;s definitely a good framework to try my own loss function. I dig into th...},
	titleaddon = {{GitHub}},
	urldate = {2021-12-02},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\AT45PWPQ\\1701.html:text/html},
}

@article{chang_evaluation_2018,
	title = {Evaluation of Artifact Subspace Reconstruction for Automatic {EEG} Artifact Removal},
	volume = {2018},
	issn = {2694-0604},
	doi = {10.1109/EMBC.2018.8512547},
	abstract = {One of the greatest challenges that hinder the decoding and application of electroencephalography ({EEG}) is that {EEG} recordings almost always contain artifacts - non-brain signals. Among existing automatic artifact-removal methods, artifact subspace reconstruction ({ASR}) is an online and realtime capable, component-based method that can effectively remove transient or large-amplitude artifacts. However, the effectiveness of {ASR} and the optimal choice of its parameter have not been evaluated and reported, especially on real {EEG} data. This study systematically validates {ASR} on ten {EEG} recordings in a simulated driving experiment. Independent component analysis ({ICA}) is applied to separate artifacts from brain signals to allow a quantitative assessment of {ASR}'s effectiveness in removing various types of artifacts and preserving brain activities. Empirical results show that the optimal {ASR} parameter is between 10 and 100, which is small enough to remove activities from artifacts and eye-related components and large enough to retain signals from brain-related components. With the appropriate choice of the parameter, {ASR} can be a powerful and automatic artifact removal approach for offline data analysis or online real-time {EEG} applications such as clinical monitoring and brain-computer interfaces.},
	pages = {1242--1245},
	journaltitle = {Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society. {IEEE} Engineering in Medicine and Biology Society. Annual International Conference},
	shortjournal = {Annu Int Conf {IEEE} Eng Med Biol Soc},
	author = {Chang, Chi-Yuan and Hsu, Sheng-Hsiou and Pion-Tonachini, Luca and Jung, Tzyy-Ping},
	date = {2018-07},
	pmid = {30440615},
	keywords = {Humans, Brain, Brain-Computer Interfaces, Electroencephalography, Signal Processing, Computer-Assisted, Algorithms, Artifacts},
}

@article{barzegaran_eegsourcesim_2019,
	title = {{EEGSourceSim}: A framework for realistic simulation of {EEG} scalp data using {MRI}-based forward models and biologically plausible signals and noise},
	volume = {328},
	issn = {1872-678X},
	doi = {10.1016/j.jneumeth.2019.108377},
	shorttitle = {{EEGSourceSim}},
	abstract = {{BACKGROUND}: Electroencephalography ({EEG}) is widely used to investigate human brain function. Simulation studies are essential for assessing the validity of {EEG} analysis methods and the interpretability of results.
{NEW} {METHOD}: Here we present a simulation environment for generating {EEG} data by embedding biologically plausible signal and noise into {MRI}-based forward models that incorporate individual-subject variability in structure and function.
{RESULTS}: The package includes pipelines for the evaluation and validation of {EEG} analysis tools for source estimation, functional connectivity, and spatial filtering. {EEG} dynamics can be simulated using realistic noise and signal models with user specifiable signal-to-noise ratio ({SNR}). We also provide a set of quantitative metrics tailored to source estimation, connectivity and spatial filtering applications.
{COMPARISON} {WITH} {EXISTING} {METHOD}(S): We provide a larger set of forward solutions for individual {MRI}-based head models than has been available previously. These head models are surface-based and include two sets of regions-of-interest ({ROIs}) that have been brought into registration with the brain of each individual using surface-based alignment - one from a whole brain and the other from a visual cortex atlas. We derive a realistic model of noise by fitting different model components to measured resting state {EEG}. We also provide a set of quantitative metrics for evaluating source-localization, functional connectivity and spatial filtering methods.
{CONCLUSIONS}: The inclusion of a larger number of individual head-models, combined with surface-atlas based labeling of {ROIs} and plausible models of signal and noise, allows for simulation of {EEG} data with greater realism than previous packages.},
	pages = {108377},
	journaltitle = {Journal of Neuroscience Methods},
	shortjournal = {J Neurosci Methods},
	author = {Barzegaran, Elham and Bosse, Sebastian and Kohler, Peter J. and Norcia, Anthony M.},
	date = {2019-12-01},
	pmid = {31381946},
	pmcid = {PMC6815881},
	keywords = {Humans, Brain, Electroencephalography, Adult, Scalp, Magnetic Resonance Imaging, Functional connectivity, Computer Simulation, Atlases as Topic, Connectome, {EEG} simulation, Forward model, Inverse model, Models, Theoretical, Regions of interest, Spatial filtering},
	file = {Accepted Version:C\:\\Users\\miche\\Zotero\\storage\\GHLLTZV4\\Barzegaran et al. - 2019 - EEGSourceSim A framework for realistic simulation.pdf:application/pdf},
}

@book{cohen_analyzing_2014-1,
	location = {Cambridge, {MA}, {USA}},
	title = {Analyzing Neural Time Series Data: Theory and Practice},
	isbn = {978-0-262-01987-3},
	shorttitle = {Analyzing Neural Time Series Data},
	abstract = {A comprehensive guide to the conceptual, mathematical, and implementational aspects of analyzing electrical brain signals, including data from {MEG}, {EEG}, and {LFP} recordings.},
	pagetotal = {600},
	publisher = {{MIT} Press},
	author = {Cohen, Mike X.},
	date = {2014-01-17},
	langid = {english},
	keywords = {Artificial intelligence, Biological applications, Computational neuroscience, Neural networks (Computer science), Neural networks (Neurobiology)},
	file = {Cohen - 2014 - Analyzing neural time series data theory and prac.pdf:C\:\\Users\\miche\\Zotero\\storage\\W2IQPPEA\\Cohen - 2014 - Analyzing neural time series data theory and prac.pdf:application/pdf},
}

@article{kallioinen_moral_2019,
	title = {Moral Judgements on the Actions of Self-Driving Cars and Human Drivers in Dilemma Situations From Different Perspectives},
	volume = {10},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2019.02415},
	doi = {10.3389/fpsyg.2019.02415},
	abstract = {Self-driving cars have the potential to greatly improve public safety. However, their introduction onto public roads must overcome both ethical and technical challenges. To further understand the ethical issues of introducing self-driving cars, we conducted two moral judgement studies investigating potential differences in the moral norms applied to human drivers and self-driving cars. In the experiments, participants made judgements on a series of dilemma situations involving human drivers or self-driving cars. We manipulated which perspective situations were presented from in order to ascertain the effect of perspective on moral judgements. Two main findings were apparent from the results of the experiments. First, human drivers and self-driving cars were largely judged similarly. However, there was a stronger tendency to prefer self-driving cars to act in ways to minimize harm, compared to human drivers. Second, there was an indication that perspective influences judgements in some situations. Specifically, when considering situations from the perspective of a pedestrian, people preferred actions that would endanger car occupants instead of themselves. However, they did not show such a self-preservation tendency when the alternative was to endanger other pedestrians to save themselves. This effect was more prevalent for judgements on human drivers than self-driving cars. Overall, the results extend and agree with previous research, again contradicting existing ethical guidelines for self-driving car decision making and highlighting the difficulties with adapting public opinion to decision making algorithms.},
	pages = {2415},
	journaltitle = {Frontiers in Psychology},
	author = {Kallioinen, Noa and Pershina, Maria and Zeiser, Jannik and Nosrat Nezami, Farbod and Pipa, Gordon and Stephan, Achim and König, Peter},
	urldate = {2022-01-07},
	date = {2019},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\B3YRDDYI\\Kallioinen et al. - 2019 - Moral Judgements on the Actions of Self-Driving Ca.pdf:application/pdf},
}

@article{maxmen_self-driving_2018,
	title = {Self-driving car dilemmas reveal that moral choices are not universal},
	volume = {562},
	rights = {2021 Nature},
	url = {https://www.nature.com/articles/d41586-018-07135-0},
	doi = {10.1038/d41586-018-07135-0},
	abstract = {Survey maps global variations in ethics for programming autonomous vehicles.},
	pages = {469--470},
	number = {7728},
	journaltitle = {Nature},
	author = {Maxmen, Amy},
	urldate = {2022-01-07},
	date = {2018-10-24},
	langid = {english},
	note = {Bandiera\_abtest: a
Cg\_type: News
Number: 7728
Publisher: Nature Publishing Group
Subject\_term: Ethics, Technology, Computer science},
	keywords = {Computer science, Ethics, Technology},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\PBLF9V59\\Maxmen - 2018 - Self-driving car dilemmas reveal that moral choice.pdf:application/pdf},
}

@online{noauthor_effective_2021,
	title = {‘Effective, Deployable, Accountable: Pick Two’: Regulating Lethal Autonomous Weapon Systems Effective, Deployable, Accountable},
	url = {https://www.e-ir.info/2021/08/12/effective-deployable-accountable-pick-two-regulating-lethal-autonomous-weapons-system/},
	shorttitle = {‘Effective, Deployable, Accountable},
	abstract = {{LAWS} regulation looks as though it may be an object lesson in the risks of seeing ideational social-structural phenomena as material and immutable.},
	titleaddon = {E-International Relations},
	urldate = {2022-01-07},
	date = {2021-08-12},
	langid = {american},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\VYL6HL2Z\\effective-deployable-accountable-pick-two-regulating-lethal-autonomous-weapons-system.html:text/html},
}

@online{noauthor_what_nodate,
	title = {What if deepfakes made us doubt everything we see and hear? {\textbar} Think Tank {\textbar} European Parliament},
	url = {https://www.europarl.europa.eu/thinktank/en/document/EPRS_ATA(2021)690046},
	shorttitle = {What if deepfakes made us doubt everything we see and hear?},
	abstract = {What if deepfakes made us doubt everything we see and hear?},
	urldate = {2022-01-07},
	langid = {english},
}

@article{marcos_what_nodate,
	title = {What if deepfakes made us doubt everything we see and hear?},
	pages = {2},
	author = {Marcos, {FERNANDEZ} {ALVAREZ}},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\F29VRYL9\\EPRS_ATA(2021)690046.html:text/html;Marcos - What if deepfakes made us doubt everything we see .pdf:C\:\\Users\\miche\\Zotero\\storage\\PDLPSA3J\\Marcos - What if deepfakes made us doubt everything we see .pdf:application/pdf},
}

@article{awad_moral_2018,
	title = {The Moral Machine experiment},
	volume = {563},
	rights = {2018 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-018-0637-6},
	doi = {10.1038/s41586-018-0637-6},
	abstract = {With the rapid development of artificial intelligence have come concerns about how machines will make moral decisions, and the major challenge of quantifying societal expectations about the ethical principles that should guide machine behaviour. To address this challenge, we deployed the Moral Machine, an online experimental platform designed to explore the moral dilemmas faced by autonomous vehicles. This platform gathered 40 million decisions in ten languages from millions of people in 233 countries and territories. Here we describe the results of this experiment. First, we summarize global moral preferences. Second, we document individual variations in preferences, based on respondents’ demographics. Third, we report cross-cultural ethical variation, and uncover three major clusters of countries. Fourth, we show that these differences correlate with modern institutions and deep cultural traits. We discuss how these preferences can contribute to developing global, socially acceptable principles for machine ethics. All data used in this article are publicly available.},
	pages = {59--64},
	number = {7729},
	journaltitle = {Nature},
	author = {Awad, Edmond and Dsouza, Sohan and Kim, Richard and Schulz, Jonathan and Henrich, Joseph and Shariff, Azim and Bonnefon, Jean-François and Rahwan, Iyad},
	urldate = {2022-01-07},
	date = {2018-11},
	langid = {english},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 7729
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Culture;Ethics;Human behaviour
Subject\_term\_id: culture;ethics;human-behaviour},
	keywords = {Ethics, Culture, Human behaviour},
	file = {Full Text:C\:\\Users\\miche\\Zotero\\storage\\WJQY6CRR\\Awad et al. - 2018 - The Moral Machine experiment.pdf:application/pdf},
}

@article{martinho_ethical_2021,
	title = {Ethical issues in focus by the autonomous vehicles industry},
	volume = {41},
	issn = {0144-1647},
	url = {https://doi.org/10.1080/01441647.2020.1862355},
	doi = {10.1080/01441647.2020.1862355},
	abstract = {The onset of autonomous driving has provided fertile ground for discussions about ethics in recent years. These discussions are heavily documented in the scientific literature and have mainly revolved around extreme traffic situations depicted as moral dilemmas, i.e. situations in which the autonomous vehicle ({AV}) is required to make a difficult moral choice. Quite surprisingly, little is known about the ethical issues in focus by the {AV} industry. General claims have been made about the struggles of companies regarding the ethical issues of {AVs} but these lack proper substantiation. As private companies are highly influential on the development and acceptance of {AV} technologies, a meaningful debate about the ethics of {AVs} should take into account the ethical issues prioritised by industry. In order to assess the awareness and engagement of industry on the ethics of {AVs}, we inspected the narratives in the official business and technical reports of companies with an {AV} testing permit in California. The findings of our literature and industry review suggest that: (i) given the plethora of ethical issues addressed in the reports, autonomous driving companies seem to be aware of and engaged in the ethics of autonomous driving technology; (ii) scientific literature and industry reports prioritise safety and cybersecurity; (iii) scientific and industry communities agree that {AVs} will not eliminate the risk of accidents; (iv) scientific literature on {AV} technology ethics is dominated by discussions about the trolley problem; (v) moral dilemmas resembling trolley cases are not addressed in industry reports but there are nuanced allusions that unravel underlying concerns about these extreme traffic situations; (vi) autonomous driving companies have different approaches with respect to the authority of remote operators; and (vii) companies seem invested in a lowest liability risk design strategy relying on rules and regulations, expedite investigations, and crash/collision avoidance algorithms.},
	pages = {556--577},
	number = {5},
	journaltitle = {Transport Reviews},
	author = {Martinho, Andreia and Herber, Nils and Kroesen, Maarten and Chorus, Caspar},
	urldate = {2022-01-07},
	date = {2021-09-03},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/01441647.2020.1862355},
	keywords = {Autonomous vehicles, companies, ethics, industry, moral dilemma, trolley},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\28CCIEHJ\\Martinho et al. - 2021 - Ethical issues in focus by the autonomous vehicles.pdf:application/pdf},
}

@online{noauthor_ethics_nodate,
	title = {Ethics guidelines for trustworthy {AI} {\textbar} Shaping Europe’s digital future},
	url = {https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai},
	abstract = {On 8 April 2019, the High-Level Expert Group on {AI} presented Ethics Guidelines for Trustworthy Artificial Intelligence. This followed the publication of the guidelines' first draft in December 2018 on which more than 500 comments were received through an open consultation.},
	urldate = {2022-01-07},
	langid = {english},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\RVSMZVQR\\ethics-guidelines-trustworthy-ai.html:text/html},
}

@legislation{noauthor_proposal_2021,
	title = {Proposal for a {REGULATION} {OF} {THE} {EUROPEAN} {PARLIAMENT} {AND} {OF} {THE} {COUNCIL} {LAYING} {DOWN} {HARMONISED} {RULES} {ON} {ARTIFICIAL} {INTELLIGENCE} ({ARTIFICIAL} {INTELLIGENCE} {ACT}) {AND} {AMENDING} {CERTAIN} {UNION} {LEGISLATIVE} {ACTS}},
	url = {https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206},
	urldate = {2022-01-07},
	date = {2021},
	langid = {english},
	file = {EUR-Lex HTML (EN):C\:\\Users\\miche\\Zotero\\storage\\5R979R3J\\HTML.html:text/html},
}