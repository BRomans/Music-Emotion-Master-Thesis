
@article{lin_eeg-based_2010,
	title = {{EEG}-Based Emotion Recognition in Music Listening},
	volume = {57},
	issn = {1558-2531},
	doi = {10.1109/TBME.2010.2048568},
	abstract = {Ongoing brain activity can be recorded as electroen-cephalograph ({EEG}) to discover the links between emotional states and brain activity. This study applied machine-learning algorithms to categorize {EEG} dynamics according to subject self-reported emotional states during music listening. A framework was proposed to optimize {EEG}-based emotion recognition by systematically 1) seeking emotion-specific {EEG} features and 2) exploring the efficacy of the classifiers. Support vector machine was employed to classify four emotional states (joy, anger, sadness, and pleasure) and obtained an averaged classification accuracy of 82.29\% Â± 3.06\% across 26 subjects. Further, this study identified 30 subject-independent features that were most relevant to emotional processing across subjects and explored the feasibility of using fewer electrodes to characterize the {EEG} dynamics during music listening. The identified features were primarily derived from electrodes placed near the frontal and the parietal lobes, consistent with many of the findings in the literature. This study might lead to a practical system for noninvasive assessment of the emotional states in practical or clinical applications.},
	pages = {1798--1806},
	number = {7},
	journaltitle = {{IEEE} Transactions on Biomedical Engineering},
	author = {Lin, Y. and Wang, C. and Jung, T. and Wu, T. and Jeng, S. and Duann, J. and Chen, J.},
	date = {2010-07},
	note = {25 Conference Name: {IEEE} Transactions on Biomedical Engineering},
	keywords = {Brain, {EEG}, Electrodes, Electroencephalography, Electromyography, emotion, Emotion recognition, Hospitals, Humans, {IEEE} activities, machine learning, music, Support vector machine classification, Support vector machines},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\QXVMPPQN\\Lin et al. - 2010 - EEG-Based Emotion Recognition in Music Listening.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\7WAAPQNY\\5458075.html:text/html},
}

@inproceedings{lin_eeg-based_2009,
	title = {{EEG}-based emotion recognition in music listening: A comparison of schemes for multiclass support vector machine},
	doi = {10.1109/ICASSP.2009.4959627},
	shorttitle = {{EEG}-based emotion recognition in music listening},
	abstract = {Currently, how to equip machines with the ability for properly recognizing users' felt-emotion during multimedia presentation is a growing issue. In this study we focused on the approach for recognizing music-induced emotional responses from brain activity. A comparative study was conducted to testify the feasibility of using hierarchical binary classifiers to improve the classification performance as compared with nonhierarchical schemes. According to our classification results, we not only found that using one-against-one scheme of hierarchical binary classifier results in an improvement to performance, but also established an alternative solution for emotion recognition by proposed model-based scheme depending on 2D emotion model.},
	eventtitle = {2009 {IEEE} International Conference on Acoustics, Speech and Signal Processing},
	pages = {489--492},
	booktitle = {2009 {IEEE} International Conference on Acoustics, Speech and Signal Processing},
	author = {Lin, Y. and Wang, C. and Wu, T. and Jeng, S. and Chen, J.},
	date = {2009-04},
	note = {24 {ISSN}: 2379-190X},
	keywords = {Brain, brain activity, Brain activity, Data acquisition, {EEG}-based emotion recognition, electroencephalography, Electroencephalography, emotion recognition, Emotion recognition, Hospitals, Humans, multiclass support vector machine, Multilayer perceptrons, multimedia presentation, Multiple signal classification, music, music listening, music-induced emotional responses, Neural networks, support vector machines, Support vector machines},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\PMGNNMZ8\\4959627.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\B35SUXUE\\Lin et al. - 2009 - EEG-based emotion recognition in music listening .pdf:application/pdf;EEG-based_emotion_recognition_in_music_listening_A_comparison_of_schemes_for_multiclass_support_vector_machine.pdf:C\:\\Users\\miche\\Zotero\\storage\\IJD79NZK\\EEG-based_emotion_recognition_in_music_listening_A_comparison_of_schemes_for_multiclass_support_vector_machine.pdf:application/pdf},
}

@article{salimpoor_anatomically_2011,
	title = {Anatomically distinct dopamine release during anticipation and experience of peak emotion to music},
	volume = {14},
	doi = {10.1038/nn.2726},
	abstract = {Music, an abstract stimulus, can arouse feelings of euphoria and craving, similar to tangible rewards that involve the striatal dopaminergic system. Using the neurochemical specificity of [(11)C]raclopride positron emission tomography scanning, combined with psychophysiological measures of autonomic nervous system activity, we found endogenous dopamine release in the striatum at peak emotional arousal during music listening. To examine the time course of dopamine release, we used functional magnetic resonance imaging with the same stimuli and listeners, and found a functional dissociation: the caudate was more involved during the anticipation and the nucleus accumbens was more involved during the experience of peak emotional responses to music. These results indicate that intense pleasure in response to music can lead to dopamine release in the striatal system. Notably, the anticipation of an abstract reward can result in dopamine release in an anatomical pathway distinct from that associated with the peak pleasure itself. Our results help to explain why music is of such high value across all human societies.},
	pages = {257--62},
	journaltitle = {Nature neuroscience},
	shortjournal = {Nature neuroscience},
	author = {Salimpoor, Valorie and Benovoy, Mitchel and Larcher, Kevin and Dagher, Alain and Zatorre, Robert},
	date = {2011-02-01},
	note = {38},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\ETQLM87Z\\Salimpoor et al. - 2011 - Anatomically distinct dopamine release during anti.pdf:application/pdf},
}

@article{higuchi_approach_1988,
	title = {Approach to an irregular time series on the basis of the fractal theory},
	volume = {31},
	issn = {0167-2789},
	url = {https://www.sciencedirect.com/science/article/pii/0167278988900814},
	doi = {10.1016/0167-2789(88)90081-4},
	abstract = {We present a technique to measure the fractal dimension of the set of points (t, f(t)) forming the graph of a function f defined on the unit interval. First we apply it to a fractional Brownian function [1] which has a property of self-similarity for all scales, and we can get the stable and precise fractal dimension. This technique is also applied to the observational data of natural phenomena. It does not show self-similarity all over the scale but has a different self-similarity across the characteristic time scale. The present method gives us a stable characteristic time scale as well as the fractal dimension.},
	pages = {277--283},
	number = {2},
	journaltitle = {Physica D: Nonlinear Phenomena},
	shortjournal = {Physica D: Nonlinear Phenomena},
	author = {Higuchi, T.},
	urldate = {2021-03-17},
	date = {1988-06-01},
	langid = {english},
	note = {31},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\SNZPKBP2\\0167278988900814.html:text/html;ScienceDirect Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\RYUL8FKJ\\Higuchi - 1988 - Approach to an irregular time series on the basis .pdf:application/pdf},
}

@article{avramidis_multiscale_2021,
	title = {Multiscale Fractal Analysis on {EEG} Signals for Music-Induced Emotion Recognition},
	url = {http://arxiv.org/abs/2010.16310},
	abstract = {Emotion Recognition from {EEG} signals has long been researched as it can assist numerous medical and rehabilitative applications. However, their complex and noisy structure has proven to be a serious barrier for traditional modeling methods. In this paper, we employ multifractal analysis to examine the behavior of {EEG} signals in terms of presence of fluctuations and the degree of fragmentation along their major frequency bands, for the task of emotion recognition. In order to extract emotion-related features we utilize two novel algorithms for {EEG} analysis, based on Multiscale Fractal Dimension and Multifractal Detrended Fluctuation Analysis. The proposed feature extraction methods perform efficiently, surpassing some widely used baseline features on the competitive {DEAP} dataset, indicating that multifractal analysis could serve as basis for the development of robust models for affective state recognition.},
	journaltitle = {{arXiv}:2010.16310 [cs]},
	author = {Avramidis, Kleanthis and Zlatintsi, Athanasia and Garoufis, Christos and Maragos, Petros},
	urldate = {2021-03-17},
	date = {2021-03-02},
	note = {50 {arXiv}: 2010.16310},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\miche\\Zotero\\storage\\FZYHCG45\\2010.html:text/html;arXiv Fulltext PDF:C\:\\Users\\miche\\Zotero\\storage\\ID9V422X\\Avramidis et al. - 2021 - Multiscale Fractal Analysis on EEG Signals for Mus.pdf:application/pdf},
}

@article{abdul_emotion-aware_2018,
	title = {An Emotion-Aware Personalized Music Recommendation System Using a Convolutional Neural Networks Approach},
	volume = {8},
	doi = {10.3390/app8071103},
	abstract = {Recommending music based on a user's music preference is a way to improve user listening experience. Finding the correlation between the user data (e.g., location, time of the day, music listening history, emotion, etc.) and the music is a challenging task. In this paper, we propose an emotion-aware personalized music recommendation system ({EPMRS}) to extract the correlation between the user data and the music. To achieve this correlation, we combine the outputs of two approaches: the deep convolutional neural networks ({DCNN}) approach and the weighted feature extraction ({WFE}) approach. The {DCNN} approach is used to extract the latent features from music data (e.g., audio signals and corresponding metadata) for classification. In the {WFE} approach, we generate the implicit user rating for music to extract the correlation between the user data and the music data. In the {WFE} approach, we use the term-frequency and inverse document frequency ({TF}-{IDF}) approach to generate the implicit user ratings for the music. Later, the {EPMRS} recommends songs to the user based on calculated implicit user rating for the music. We use the million songs dataset ({MSD}) to train the {EPMRS}. For performance comparison, we take the content similarity music recommendation system ({CSMRS}) as well as the personalized music recommendation system based on electroencephalography feedback ({PMRSE}) as the baseline systems. Experimental results show that the {EPMRS} produces better accuracy of music recommendations than the {CSMRS} and the {PMRSE}. Moreover, we build the Android and {iOS} {APPs} to get realistic data of user experience on the {EPMRS}. The collected feedback from anonymous users also show that the {EPMRS} sufficiently reflect their preference on music.},
	pages = {1103},
	journaltitle = {Applied Sciences},
	shortjournal = {Applied Sciences},
	author = {Abdul, Ashu and Chen, Jenhui and Liao, Hua-Yuan and Chang, Shun-Hao},
	date = {2018-07-08},
	note = {06},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\A4T3B3SZ\\Abdul et al. - 2018 - An Emotion-Aware Personalized Music Recommendation.pdf:application/pdf},
}

@article{keelawat_comparative_2021,
	title = {A Comparative Study of Window Size and Channel Arrangement on {EEG}-Emotion Recognition Using Deep {CNN}},
	volume = {21},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/21/5/1678},
	doi = {10.3390/s21051678},
	abstract = {Emotion recognition based on electroencephalograms has become an active research area. Yet, identifying emotions using only brainwaves is still very challenging, especially the subject-independent task. Numerous studies have tried to propose methods to recognize emotions, including machine learning techniques like convolutional neural network ({CNN}). Since {CNN} has shown its potential in generalization to unseen subjects, manipulating {CNN} hyperparameters like the window size and electrode order might be beneficial. To our knowledge, this is the first work that extensively observed the parameter selection effect on the {CNN}. The temporal information in distinct window sizes was found to significantly affect the recognition performance, and {CNN} was found to be more responsive to changing window sizes than the support vector machine. Classifying the arousal achieved the best performance with a window size of ten seconds, obtaining 56.85\% accuracy and a Matthews correlation coefficient ({MCC}) of 0.1369. Valence recognition had the best performance with a window length of eight seconds at 73.34\% accuracy and an {MCC} value of 0.4669. Spatial information from varying the electrode orders had a small effect on the classification. Overall, valence results had a much more superior performance than arousal results, which were, perhaps, influenced by features related to brain activity asymmetry between the left and right hemispheres.},
	pages = {1678},
	number = {5},
	journaltitle = {Sensors},
	author = {Keelawat, Panayu and Thammasan, Nattapong and Numao, Masayuki and Kijsirikul, Boonserm},
	urldate = {2021-03-11},
	date = {2021-01},
	langid = {english},
	note = {34 
Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {brainwave, {CNN}, {EEG}, electrode order, emotion recognition, machine learning, neuroscience, spatiotemporal data, window size},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\F68EEJEX\\1678.html:text/html;Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\JF4QZCF8\\sensors-21-01678-v2.pdf:application/pdf},
}

@article{schmidt_frontal_2001,
	title = {Frontal brain electrical activity ({EEG}) distinguishes valence and intensity of musical emotions},
	volume = {15},
	issn = {0269-9931},
	url = {https://doi.org/10.1080/02699930126048},
	doi = {10.1080/02699930126048},
	abstract = {Using recent regional brain activation/emotion models as a theoretical framework, we examined whether the pattern of regional {EEG} activity distinguished emotions induced by musical excerpts which were known to vary in affective valence (i.e., positive vs. negative) and intensity (i.e., intense vs. calm) in a group of undergraduates. We found that the pattern of asymmetrical frontal {EEG} activity distinguished valence of the musical excerpts. Subjects exhibited greater relative left frontal {EEG} activity to joy and happy musical excerpts and greater relative right frontal {EEG} activity to fear and sad musical excerpts. We also found that, although the pattern of frontal {EEG} asymmetry did not distinguish the intensity of the emotions, the pattern of overall frontal {EEG} activity did, with the amount of frontal activity decreasing from fear to joy to happy to sad excerpts. These data appear to be the first to distinguish valence and intensity of musical emotions on frontal electrocortical measures.},
	pages = {487--500},
	number = {4},
	journaltitle = {Cognition and Emotion},
	author = {Schmidt, Louis A. and Trainor, Laurel J.},
	urldate = {2021-03-07},
	date = {2001-07-01},
	note = {15 Publisher: Routledge
\_eprint: https://doi.org/10.1080/02699930126048},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\6SW9N35B\\02699930126048.html:text/html;Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\9UPX9UWP\\Schmidt and Trainor - 2001 - Frontal brain electrical activity (EEG) distinguis.pdf:application/pdf},
}

@article{thammasan_continuous_2016,
	title = {Continuous Music-Emotion Recognition Based on Electroencephalogram},
	volume = {E99.D},
	doi = {10.1587/transinf.2015EDP7251},
	abstract = {Research on emotion recognition using electroencephalogram ({EEG}) of subjects listening to music has become more active in the past decade. However, previous works did not consider emotional oscillations within a single musical piece. In this research, we propose a continuous music-emotion recognition approach based on brainwave signals. While considering the subject-dependent and changing-over-time characteristics of emotion, our experiment included self-reporting and continuous emotion annotation in the arousal-valence space. Fractal dimension ({FD}) and power spectral density ({PSD}) approaches were adopted to extract informative features from raw {EEG} signals and then we applied emotion classification algorithms to discriminate binary classes of emotion. According to our experimental results, {FD} slightly outperformed {PSD} approach both in arousal and valence classification, and {FD} was found to have the higher correlation with emotion reports than {PSD}. In addition, continuous emotion recognition during music listening based on {EEG} was found to be an effective method for tracking emotional reporting oscillations and provides an opportunity to better understand human emotional processes.},
	pages = {1234--1241},
	journaltitle = {{IEICE} Transactions on Information and Systems},
	shortjournal = {{IEICE} Transactions on Information and Systems},
	author = {Thammasan, Nattapong and Moriyama, Koichi and Fukui, Ken-ichi and Numao, Masayuki},
	date = {2016-04-01},
	note = {27},
	file = {Thammasan et al. - 2016 - Continuous Music-Emotion Recognition Based on Elec.pdf:C\:\\Users\\miche\\Zotero\\storage\\HEYGDN6U\\Thammasan et al. - 2016 - Continuous Music-Emotion Recognition Based on Elec.pdf:application/pdf},
}

@article{fang_perception_2017,
	title = {Perception of Western Musical Modes: A Chinese Study},
	volume = {8},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2017.01905/full},
	doi = {10.3389/fpsyg.2017.01905},
	shorttitle = {Perception of Western Musical Modes},
	abstract = {The major mode conveys positive emotion, whereas the minor mode conveys negative emotion. However, previous studies have primarily focused on the emotions induced by Western music in Western participants. The influence of the musical mode (major or minor) on Chinese individualsâ perception of Western music is unclear. In the present experiments, we investigated the effects of musical mode and harmonic complexity on psychological perception among Chinese participants. In Experiment 1, the participants (N = 30) evaluated 24 musical excerpts in five dimensions (pleasure, arousal, dominance, emotional tension and liking). In Experiment 2, the participants (N = 40) evaluated 48 musical excerpts. Perceptions of the musical excerpts differed significantly according to mode, even if the stimuli were Western musical excerpts. The major-mode music induced greater pleasure and arousal and produced higher liking ratings than the minor-mode music, whereas the minor-mode music induced greater tension than the major-mode music. Mode did not influence the dominance rating. Perception of Western music was not influenced by harmonic complexity. Moreover, preference for musical mode was influenced by previous exposure to Western music. These results confirm the cross-cultural emotion induction effects of musical modes in Western music.},
	journaltitle = {Frontiers in Psychology},
	shortjournal = {Front. Psychol.},
	author = {Fang, Lele and Shang, Junchen and Chen, Nan},
	urldate = {2021-03-01},
	date = {2017},
	note = {39 Publisher: Frontiers},
	keywords = {culture, emotion, harmonic complexity, mode, Perception},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\CA58NDRA\\Fang et al. - 2017 - Perception of Western Musical Modes A Chinese Stu.pdf:application/pdf},
}

@article{sangnark_revealing_2021,
	title = {Revealing Preference in Popular Music Through Familiarity and Brain Response},
	issn = {1530-437X, 1558-1748, 2379-9153},
	url = {http://arxiv.org/abs/2102.00159},
	doi = {10.1109/JSEN.2021.3073040},
	abstract = {Music preference was reported as a factor, which could elicit innermost music emotion, entailing accurate ground-truth data and music therapy efficiency. This study executes statistical analysis to investigate the distinction of music preference through familiarity scores, response times (response rates), and brain response ({EEG}). Twenty participants did self-assessment after listening to two types of popular music's chorus section: music without lyrics (Melody) and music with lyrics (Song). {\textbackslash}textcolor\{red\}\{We then conduct a music preference classification using a support vector machine, random forest, and k-nearest neighbors with the familiarity scores, the response rates, and {EEG} as the feature vectors. The statistical analysis and F1-score of {EEG} are congruent, which is the brain's right side outperformed its left side in classification performance.\} Finally, these behavioral and brain studies support that preference, familiarity, and response rates can contribute to the music emotion experiment's design to understand music, emotion, and listener. Not only to the music industry, the biomedical and healthcare industry can also exploit this experiment to collect data from patients to improve the efficiency of healing by music.},
	pages = {1--1},
	journaltitle = {{IEEE} Sensors Journal},
	shortjournal = {{IEEE} Sensors J.},
	author = {Sangnark, Soravitt and Autthasan, Phairot and Ponglertnapakorn, Puntawat and Chalekarn, Phudit and Sudhawiyangkul, Thapanun and Trakulruangroj, Manatsanan and Songsermsawad, Sarita and Assabumrungrat, Rawin and Amplod, Supalak and Ounjai, Kajornvut and Wilaiprasitporn, Theerawit},
	urldate = {2021-05-17},
	date = {2021},
	note = {36 {arXiv}: 2102.00159},
	keywords = {Computer Science - Human-Computer Interaction, Electrical Engineering and Systems Science - Signal Processing},
	file = {arXiv Fulltext PDF:C\:\\Users\\miche\\Zotero\\storage\\JEW78YUT\\Sangnark et al. - 2021 - Revealing Preference in Popular Music Through Fami.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\miche\\Zotero\\storage\\YT9SX2HH\\2102.html:text/html},
}

@article{ward_same_2013,
	title = {The same old song: The power of familiarity in music choice},
	volume = {25},
	doi = {10.1007/s11002-013-9238-1},
	shorttitle = {The same old song},
	abstract = {Does "familiarity breed contempt" or is "to know you is to love you"? In this research, we explore the role of familiarity in music choice. We show that although consumers say they would prefer to listen to unfamiliar music, in actuality familiarity with music positively predicts preference for songs, play lists, and radio stations. Familiarity with music is at least as good, if not a better, predictor of choice as are liking, satiation (which actually positively predicts choice), and regret. We suggest that the need for familiarity is driven by consumers' low need for stimulation in the music domain, and show that when the need for stimulation decreases, the power of familiarity significantly increases. In addition to their theoretical contribu-tion, these results are informative for music managers determining playlists, for the promotion of music events and products, and for advertisers selecting the most potentially lucrative music venues.},
	journaltitle = {Marketing Letters},
	shortjournal = {Marketing Letters},
	author = {Ward, Morgan and Goodman, Joseph and Irwin, Julie},
	date = {2013-05-01},
	note = {37},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\AYUHPAQX\\Ward et al. - 2013 - The same old song The power of familiarity in mus.pdf:application/pdf},
}

@article{eerola_review_2013,
	title = {A Review of Music and Emotion Studies: Approaches, Emotion Models, and Stimuli},
	doi = {10.1525/mp.2012.30.3.307},
	shorttitle = {A Review of Music and Emotion Studies},
	abstract = {{THE} {FIELD} {OF} {MUSIC} {AND} {EMOTION} {RESEARCH} {HAS} grown rapidly and diversified during the last decade. This has led to a certain degree of confusion and inconsistency between competing notions of emotions, data, and results. The present review of 251 studies describes the focus of prevalent research approaches, methods, and models of emotion, and documents the types of musical stimuli used over the past twenty years. Although self-report approaches to emotions are the most common way of dealing with music and emotions, using multiple approaches is becoming increasingly popular. A large majority (70\%) of the studies employed variants of the discrete or the dimensional emotion models. A large proportion of stimuli rely on a relatively modest amount of familiar classical examples. The evident shortcomings of these prevalent patterns in music and emotion studies are highlighted, and concrete plans of action for future studies are suggested.},
	journaltitle = {Music Perception},
	shortjournal = {Music Perception},
	author = {Eerola, Tuomas and Vuoskoski, Jonna},
	date = {2013-02-01},
	note = {29},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\BUHURTR3\\Eerola and Vuoskoski - 2013 - A Review of Music and Emotion Studies Approaches,.pdf:application/pdf},
}

@article{reuderink_valence_2013,
	title = {Valence, arousal and dominance in the {EEG} during game play},
	volume = {6},
	doi = {10.1504/IJAACS.2013.050691},
	abstract = {In this paper, we describe our investigation of traces of naturally occurring emotions in electrical brain signals, that can be used to build interfaces that respond to our emotional state. This study confirms a number of known affective correlates in a realistic, uncontrolled environment for the emotions of valence (or pleasure), arousal and dominance: (1) a significant decrease in frontal power in the theta range is found for increasingly positive valence, (2) a significant frontal increase in power in the alpha range is associated with increasing emotional arousal, (3) a significant right posterior power increase in the delta range correlates with increasing arousal and (4) asymmetry in power in the lower alpha bands correlates with self-reported valence. Furthermore, asymmetry in the higher alpha bands correlates with self-reported dominance. These last two effects provide a simple measure for subjective feelings of pleasure and feelings of control.},
	pages = {45--62},
	journaltitle = {International Journal of Autonomous and Adaptive Communications Systems},
	shortjournal = {International Journal of Autonomous and Adaptive Communications Systems},
	author = {Reuderink, Boris and MÃ¼hl, Christian and Poel, Mannes},
	date = {2013-12-01},
	note = {23},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\K4YCJCSE\\Reuderink et al. - 2013 - Valence, arousal and dominance in the EEG during g.pdf:application/pdf},
}

@article{chang_personalized_2017,
	title = {A personalized music recommendation system based on electroencephalography feedback},
	volume = {76},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-015-3202-4},
	doi = {10.1007/s11042-015-3202-4},
	abstract = {Numerous domestic and foreign studies have demonstrated that music can relieve stress and that listening to music is one method of stress relief used presently. Although stress-relief music is available on the market, various music genres produce distinct effects on people. Clinical findings have indicated that approximately 30Â \% of people listen to inappropriate music genres for relaxation and, consequently, their stress level increases. Therefore, to achieve the effect of stress relief, choosing the appropriate music genre is crucial. For example, a 70-year-old woman living in a military community since childhood might not consider general stress-relief music to be helpful in relieving stress, but when patriotic songs are played, her autonomic nervous system automatically relaxes because of her familiarity with the music style. Therefore, people have dissimilar needs regarding stress-relief music. In this paper, we proposed a personalized stress-relieving music recommendation system based on electroencephalography ({EEG}) feedback. The system structure comprises the following features: (a) automated music categorization, in which a new clustering algorithm, K-{MeansH}, is employed to precluster music and improve processing time; (b) the access and analysis of usersâ {EEG} data to identify perceived stress-relieving music; and (c) personalized recommendations based on collaborative filtering and provided according to personal preferences. Experimental results indicated that the overall clustering effect of K-{MeansH} surpassed that of K-Means and K-Medoids by approximately 71 and 57Â \%, respectively. In terms of accuracy, K-{MeansH} also surpassed K-Means and K-Medoids.},
	pages = {19523--19542},
	number = {19},
	journaltitle = {Multimedia Tools and Applications},
	shortjournal = {Multimed Tools Appl},
	author = {Chang, Hong-Yi and Huang, Shih-Chang and Wu, Jia-Hao},
	urldate = {2021-07-12},
	date = {2017-10-01},
	langid = {english},
	note = {05},
	file = {Springer Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\JZVJCZAU\\Chang et al. - 2017 - A personalized music recommendation system based o.pdf:application/pdf},
}

@article{gertz_autonomy_2016,
	title = {Autonomy online: Jacques Ellul and the Facebook emotional manipulation study},
	volume = {12},
	issn = {1747-0161},
	url = {https://doi.org/10.1177/1747016115579534},
	doi = {10.1177/1747016115579534},
	shorttitle = {Autonomy online},
	abstract = {Though we would expect the revelation of the Facebook emotional manipulation study to have had a negative impact on Facebook, its number of active users only continues to grow. As this is precisely the result that Jacques Ellul would have predicted, this paper examines his philosophy of technology in order to investigate the relationship between Facebook and its users and what this relationship means in terms of autonomy. That Facebook can manipulate its users without losing users reveals that Facebookâs autonomy is growing while the autonomy of users is diminishing. The paper concludes by showing that the answer to this increasingly asymmetrical relationship cannot be the creation of review boards and oversight committees as the underlying issues concerning autonomy are existential more than they are ethical.},
	pages = {55--61},
	number = {1},
	journaltitle = {Research Ethics},
	shortjournal = {Research Ethics},
	author = {Gertz, Nolen},
	urldate = {2021-07-14},
	date = {2016-01-01},
	langid = {english},
	note = {08},
	keywords = {autonomy, Facebook emotional manipulation study, Jacques Ellul, research ethics, technology},
	file = {SAGE PDF Full Text:C\:\\Users\\miche\\Zotero\\storage\\PDC4FGLV\\Gertz - 2016 - Autonomy online Jacques Ellul and the Facebook em.pdf:application/pdf},
}

@article{tromp_design_2011,
	title = {Design for Socially Responsible Behavior: A Classification of Influence Based on Intended User Experience},
	volume = {27},
	issn = {0747-9360},
	url = {https://doi.org/10.1162/DESI_a_00087},
	doi = {10.1162/DESI_a_00087},
	shorttitle = {Design for Socially Responsible Behavior},
	pages = {3--19},
	number = {3},
	journaltitle = {Design Issues},
	shortjournal = {Design Issues},
	author = {Tromp, Nynke and Hekkert, Paul and Verbeek, Peter-Paul},
	urldate = {2021-07-14},
	date = {2011-07-01},
	note = {09},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\VHUG8FX3\\Tromp et al. - 2011 - Design for Socially Responsible Behavior A Classi.pdf:application/pdf;Snapshot:C\:\\Users\\miche\\Zotero\\storage\\6WS3P8RS\\Design-for-Socially-Responsible-Behavior-A.html:text/html},
}

@book{cohen_analyzing_2014,
	location = {Cambridge, Massachusetts},
	title = {Analyzing neural time series data: theory and practice},
	isbn = {978-0-262-01987-3},
	series = {Issues in clinical and cognitive neuropsychology},
	shorttitle = {Analyzing neural time series data},
	pagetotal = {578},
	publisher = {The {MIT} Press},
	author = {Cohen, Mike X.},
	date = {2014},
	langid = {english},
	note = {44},
	keywords = {Artificial intelligence, Biological applications, Computational neuroscience, Neural networks (Computer science), Neural networks (Neurobiology)},
	file = {Cohen - 2014 - Analyzing neural time series data theory and prac.pdf:C\:\\Users\\miche\\Zotero\\storage\\W2IQPPEA\\Cohen - 2014 - Analyzing neural time series data theory and prac.pdf:application/pdf},
}

@article{koelstra_deap_2012,
	title = {{DEAP}: A Database for Emotion Analysis ;Using Physiological Signals},
	volume = {3},
	issn = {1949-3045},
	doi = {10.1109/T-AFFC.2011.15},
	shorttitle = {{DEAP}},
	abstract = {We present a multimodal data set for the analysis of human affective states. The electroencephalogram ({EEG}) and peripheral physiological signals of 32 participants were recorded as each watched 40 one-minute long excerpts of music videos. Participants rated each video in terms of the levels of arousal, valence, like/dislike, dominance, and familiarity. For 22 of the 32 participants, frontal face video was also recorded. A novel method for stimuli selection is proposed using retrieval by affective tags from the last.fm website, video highlight detection, and an online assessment tool. An extensive analysis of the participants' ratings during the experiment is presented. Correlates between the {EEG} signal frequencies and the participants' ratings are investigated. Methods and results are presented for single-trial classification of arousal, valence, and like/dislike ratings using the modalities of {EEG}, peripheral physiological signals, and multimedia content analysis. Finally, decision fusion of the classification results from different modalities is performed. The data set is made publicly available and we encourage other researchers to use it for testing their own affective state estimation methods.},
	pages = {18--31},
	number = {1},
	journaltitle = {{IEEE} Transactions on Affective Computing},
	author = {Koelstra, Sander and Muhl, Christian and Soleymani, Mohammad and Lee, Jong-Seok and Yazdani, Ashkan and Ebrahimi, Touradj and Pun, Thierry and Nijholt, Anton and Patras, Ioannis},
	date = {2012-01},
	note = {28 Conference Name: {IEEE} Transactions on Affective Computing},
	keywords = {affective computing., Databases, {EEG}, Electroencephalography, Emotion classification, Face, Motion pictures, Multimedia communication, pattern classification, physiological signals, signal processing, Videos, Visualization},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\KITWZGCF\\Koelstra et al. - 2012 - DEAP A Database for Emotion Analysis \;Using Physi.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\5DJZDAVK\\5871728.html:text/html;Koelstra et al. - 2012 - DEAP A Database for Emotion Analysis \;Using Physi.pdf:C\:\\Users\\miche\\Zotero\\storage\\J3FFEQTZ\\Koelstra et al. - 2012 - DEAP A Database for Emotion Analysis \;Using Physi.pdf:application/pdf},
}

@inproceedings{wu_estimation_2017,
	title = {Estimation of valence of emotion using two frontal {EEG} channels},
	doi = {10.1109/BIBM.2017.8217815},
	abstract = {Emotion recognition using {EEG} signals has become a hot research topic in the last few years. This paper aims at providing a novel method for emotion recognition using less channels of frontal {EEG} signals. By employing the asymmetry theory of frontal brain, a new method fusing spatial and frequency features was presented, which only adopted two channels of frontal {EEG} signals at Fp1 and Fp2. In order to estimate the efficiency of the method, a {GBDT} classifier was evaluated and selected, and the method was implemented on the {DEAP} database. The maximum and mean classification accuracy were achieved as 76.34\% and 75.18\% respectively, which exhibited the best result comparing with other related studies. This method is extremely suitable for wearable {EEG} monitoring applications in human daily life.},
	eventtitle = {2017 {IEEE} International Conference on Bioinformatics and Biomedicine ({BIBM})},
	pages = {1127--1130},
	booktitle = {2017 {IEEE} International Conference on Bioinformatics and Biomedicine ({BIBM})},
	author = {Wu, Shiyi and Xu, Xiangmin and Shu, Lin and Hu, Bin},
	date = {2017-11},
	note = {26},
	keywords = {Biomedical monitoring, {DEAP}, Electroencephalography, Emotion recognition, Entropy, Feature extraction, Frontal {EEG}, {GBDT} classifier, Indexes},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\2UP5N8IT\\Wu et al. - 2017 - Estimation of valence of emotion using two frontal.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\8H62ASU6\\8217815.html:text/html},
}

@article{russell_circumplex_1980,
	title = {A Circumplex Model of Affect},
	volume = {39},
	doi = {10.1037/h0077714},
	abstract = {Factor-analytic evidence has led most psychologists to describe affect as a set of dimensions, such as displeasure, distress, depression, excitement, and so on, with each dimension varying independently of the others. However, there is other evidence that rather than being independent, these affective dimensions are interrelated in a highly systematic fashion. The evidence suggests that these interrelationships can be represented by a spatial model in which affective concepts fall in a circle in the following order: pleasure (0), excitement (45), arousal (90), distress (135), displeasure (180), depression (225), sleepiness (270), and relaxation (315). This model was offered both as a way psychologists can represent the structure of affective experience, as assessed through self-report, and as a representation of the cognitive structure that laymen utilize in conceptualizing affect. Supportive evidence was obtained by scaling 28 emotion-denoting adjectives in 4 different ways: R. T. Ross's (1938) technique for a circular ordering of variables, a multidimensional scaling procedure based on perceived similarity among the terms, a unidimensional scaling on hypothesized pleasureâdispleasure and degree-of-arousal dimensions, and a principal-components analysis of 343 Ss' self-reports of their current affective states. (70 ref) ({PsycINFO} Database Record (c) 2012 {APA}, all rights reserved)},
	pages = {1161--1178},
	journaltitle = {Journal of Personality and Social Psychology},
	shortjournal = {Journal of Personality and Social Psychology},
	author = {Russell, James},
	date = {1980-12-01},
	note = {12},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\G9GAA2LK\\Russell - 1980 - A Circumplex Model of Affect.pdf:application/pdf},
}

@article{picard_mit_nodate,
	title = {{MIT} Media Laboratory; Perceptual Computing; 20 Ames St., Cambridge, {MA} 02139 picard@media.mit.edu, http://www.media.mit.edu/Ëpicard/},
	abstract = {Computers are beginning to acquire the ability to express and recognize aï¬ect, and may soon be given the ability to âhave emotions.â The essential role of emotion in both human cognition and perception, as demonstrated by recent neurological studies, indicates that aï¬ective computers should not only provide better performance in assisting humans, but also might enhance computersâ abilities to make decisions. This paper presents and discusses key issues in âaï¬ective computing,â computing that relates to, arises from, or inï¬uences emotions. Models are suggested for computer recognition of human emotion, and new applications are presented for computerassisted learning, perceptual information retrieval, arts and entertainment, and human health and interaction. Aï¬ective computing, coupled with new wearable computers, will also provide the ability to gather new data necessary for advances in emotion and cognition theory.},
	pages = {16},
	author = {Picard, R W},
	langid = {english},
	note = {07},
	file = {Picard - MIT Media Laboratory\; Perceptual Computing\; 20 Ame.pdf:C\:\\Users\\miche\\Zotero\\storage\\XZIGZ9FU\\Picard - MIT Media Laboratory\; Perceptual Computing\; 20 Ame.pdf:application/pdf},
}

@article{bradley_measuring_1994,
	title = {Measuring emotion: The self-assessment manikin and the semantic differential},
	volume = {25},
	issn = {0005-7916},
	url = {https://www.sciencedirect.com/science/article/pii/0005791694900639},
	doi = {10.1016/0005-7916(94)90063-9},
	shorttitle = {Measuring emotion},
	abstract = {The Self-Assessment Manikin ({SAM}) is a non-verbal pictorial assessment technique that directly measures the pleasure, arousal, and dominance associated with a person's affective reaction to a wide variety of stimuli. In this experiment, we compare reports of affective experience obtained using {SAM}, which requires only three simple judgments, to the Semantic Differential scale devised by Mehrabian and Russell (An approach to environmental psychology, 1974) which requires 18 different ratings. Subjective reports were measured to a series of pictures that varied in both affective valence and intensity. Correlations across the two rating methods were high both for reports of experienced pleasure and felt arousal. Differences obtained in the dominance dimension of the two instruments suggest that {SAM} may better track the personal response to an affective stimulus. {SAM} is an inexpensive, easy method for quickly assessing reports of affective response in many contexts.},
	pages = {49--59},
	number = {1},
	journaltitle = {Journal of Behavior Therapy and Experimental Psychiatry},
	shortjournal = {Journal of Behavior Therapy and Experimental Psychiatry},
	author = {Bradley, Margaret M. and Lang, Peter J.},
	urldate = {2021-08-08},
	date = {1994-03-01},
	langid = {english},
	note = {13},
	file = {ScienceDirect Snapshot:C\:\\Users\\miche\\Zotero\\storage\\XXRD52VB\\0005791694900639.html:text/html},
}

@article{watson_development_nodate,
	title = {Development and Validation of Brief Measures of Positive and Negative Affect: The {PANAS} Scales},
	pages = {8},
	author = {Watson, David and Anna, Lee and Tellegen, Auke},
	langid = {english},
	note = {14},
	file = {Watson et al. - Development and Validation of Brief Measures of Po.pdf:C\:\\Users\\miche\\Zotero\\storage\\U8PG99YN\\Watson et al. - Development and Validation of Brief Measures of Po.pdf:application/pdf},
}

@article{hagemann_effects_2001,
	title = {The effects of ocular artifacts on (lateralized) broadband power in the {EEG}},
	volume = {112},
	doi = {10.1016/S1388-2457(00)00541-1},
	abstract = {Empirical evidence suggests that blinks and eye movements do not generate substantial activity outside the delta and theta range, and that the propagation of ocular activity to the {EEG} is rather symmetrical. These observations suggest that an alteration of the alpha and beta asymmetry of the {EEG} due to ocular artifacts is not likely to occur. The aim of the present study is to examine the effects of ocular artifacts on broadband {EEG} parameters.
{EEG} and {EOG} were recorded from 31 participants in a resting condition with eyes open and closed, allowing for spontaneous ocular activity. General effects of ocular artifacts were examined with mean comparisons, and differential effects were examined with correlation analysis of data portions that were selected for a presence or absence of artifacts.
At single sites, blinks and eye movements exerted substantial general effects on the whole {EEG} spectrum, but there were no substantial differential effects of artifacts in the alpha and beta bands, except at the frontopolar sites. The distorting effects of ocular artifacts were smaller in magnitude for asymmetry than for single site measures.
The control of ocular artifacts may be dispensable for correlation analyses of alpha or beta band parameters.},
	pages = {215--31},
	journaltitle = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
	shortjournal = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
	author = {Hagemann, Dirk and Naumann, Ewald},
	date = {2001-03-01},
	note = {40},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\GVQIVPTU\\Hagemann and Naumann - 2001 - The effects of ocular artifacts on (lateralized) b.pdf:application/pdf},
}

@article{grosselin_quality_2019,
	title = {Quality Assessment of Single-Channel {EEG} for Wearable Devices},
	volume = {19},
	issn = {1424-8220},
	doi = {10.3390/s19030601},
	abstract = {The recent embedding of electroencephalographic ({EEG}) electrodes in wearable devices raises the problem of the quality of the data recorded in such uncontrolled environments. These recordings are often obtained with dry single-channel {EEG} devices, and may be contaminated by many sources of noise which can compromise the detection and characterization of the brain state studied. In this paper, we propose a classification-based approach to effectively quantify artefact contamination in {EEG} segments, and discriminate muscular artefacts. The performance of our method were assessed on different databases containing either artificially contaminated or real artefacts recorded with different type of sensors, including wet and dry {EEG} electrodes. Furthermore, the quality of unlabelled databases was evaluated. For all the studied databases, the proposed method is able to rapidly assess the quality of the {EEG} signals with an accuracy higher than 90\%. The obtained performance suggests that our approach provide an efficient, fast and automated quality assessment of {EEG} signals from low-cost wearable devices typically composed of a dry single {EEG} channel.},
	pages = {E601},
	number = {3},
	journaltitle = {Sensors (Basel, Switzerland)},
	shortjournal = {Sensors (Basel)},
	author = {Grosselin, Fanny and Navarro-Sune, Xavier and Vozzi, Alessia and Pandremmenou, Katerina and De Vico Fallani, Fabrizio and Attal, Yohan and Chavez, Mario},
	date = {2019-01-31},
	pmcid = {PMC6387437},
	note = {43 {PMID}: 30709004},
	keywords = {Algorithms, artefact detection, Artifacts, Brain, Brain-Computer Interfaces, Electrodes, Electroencephalography, electroencephalography ({EEG}), Humans, muscular artefacts, quality assessment, single-channel {EEG}, Wearable Electronic Devices, wearable systems},
	file = {Full Text:C\:\\Users\\miche\\Zotero\\storage\\IFH4TEZ3\\Grosselin et al. - 2019 - Quality Assessment of Single-Channel EEG for Weara.pdf:application/pdf},
}

@article{orgo_effect_2015,
	title = {Effect of negative and positive emotions on {EEG} spectral asymmetry},
	volume = {2015},
	issn = {2694-0604},
	doi = {10.1109/EMBC.2015.7320275},
	abstract = {The aim of the study was to evaluate the applicability of electroencephalogram ({EEG}) spectral asymmetry index ({SASI}) for discrimination of the effect of negative and positive emotions on human brain bioelectrical activity. {SASI} has been previously proposed as a method to detect depression based on the balance of {EEG} theta and beta frequency band powers. Emotions were evoked on 22 healthy subjects using emotional pictures portraying humans from International Affective Picture System ({IAPS}) and late response to stimuli was examined (1700-2200 ms). Electroencephalogram ({EEG}) was recorded in 30 channels divided into 10 brain regions: left frontal, right frontal, left temporal, right temporal, frontal, frontocentral, central, centroparietal, parietal and occipital. Negative stimuli, compared to neutral stimuli, significantly increased {SASI} in frontocentral, central, centroparietal, parietal and occipital areas. Positive stimuli, compared to neutral stimuli, significantly decreased {SASI} in left temporal, centroparietal, parietal and occipital areas. The results indicate that {SASI} provides a good discrimination between the effects of negative, neutral and positive emotions on human {EEG}.},
	pages = {8107--8110},
	journaltitle = {Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society. {IEEE} Engineering in Medicine and Biology Society. Annual International Conference},
	shortjournal = {Annu Int Conf {IEEE} Eng Med Biol Soc},
	author = {Orgo, L. and Bachmann, M. and Lass, J. and Hinrikus, H.},
	date = {2015-08},
	note = {20 {PMID}: 26738175},
	keywords = {Brain, Brain Mapping, Depression, Electroencephalography, Emotions, Humans},
}

@article{sammler_music_nodate,
	title = {Music and emotion: Electrophysiological correlates of the processing of pleasant and unpleasant music},
	abstract = {Human emotion and its electrophysiological correlates are still poorly understood. The present study examined whether the valence of perceived emotions would differentially inï¬uence {EEG} power spectra and heart rate ({HR}). Pleasant and unpleasant emotions were induced by consonant and dissonant music. Unpleasant (compared to pleasant) music evoked a significant decrease of {HR}, replicating the pattern of {HR} responses previously described for the processing of emotional pictures, sounds, and ï¬lms. In the {EEG}, pleasant (contrasted to unpleasant) music was associated with an increase of frontal midline (Fm) theta power. This effect is taken to reï¬ect emotional processing in close interaction with attentional functions. These ï¬ndings show that Fm theta is modulated by emotion more strongly than previously believed.},
	pages = {12},
	author = {Sammler, Daniela and Grigutsch, Maren and Fritz, Thomas and Koelsch, Stefan},
	langid = {english},
	note = {21},
	file = {Sammler et al. - Music and emotion Electrophysiological correlates.pdf:C\:\\Users\\miche\\Zotero\\storage\\I89YEW6J\\Sammler et al. - Music and emotion Electrophysiological correlates.pdf:application/pdf},
}

@article{schmidt_frontal_1999,
	title = {Frontal Brain Electrical Activity in Shyness and Sociability},
	volume = {10},
	issn = {0956-7976},
	url = {https://doi.org/10.1111/1467-9280.00161},
	doi = {10.1111/1467-9280.00161},
	abstract = {A number of studies have shown that shyness and sociability may be two independent personality traits that are distinguishable across a variety of measures and cultures. Utilizing recent frontal activationâemotion models as a theoretical framework, this study examined the pattern of resting frontal electroencephalographic ({EEG}) activity in undergraduates who self-reported high and low shyness and sociability. Analyses revealed that shyness was associated with greater relative right frontal {EEG} activity, whereas sociability was associated with greater relative left frontal {EEG} activity. Also, different combinations of shyness and sociability were distinguishable on the basis of resting frontal {EEG} power. Although high-shy/high-social and high-shy/low-social subjects both exhibited greater relative right frontal {EEG} activity, they differed significantly on {EEG} power in the left, but not right, frontal lead. High-shy/high-social subjects exhibited significantly less {EEG} power (i.e., more activity) in the left frontal lead compared with the high-shy/low-social subjects. These findings suggest that in distinguishing individual differences in personality and personality subtypes, it is important to consider not only frontal {EEG} asymmetry measures, but also the pattern of absolute {EEG} power in each frontal hemisphere.},
	pages = {316--320},
	number = {4},
	journaltitle = {Psychological Science},
	shortjournal = {Psychol Sci},
	author = {Schmidt, Louis A.},
	urldate = {2021-09-17},
	date = {1999-07-01},
	langid = {english},
	note = {18 Publisher: {SAGE} Publications Inc},
}

@article{heller_neuropsychological_1993,
	title = {Neuropsychological Mechanisms of Individual Differences in Emotion, Personality, and Arousal},
	volume = {7},
	issn = {0894-4105},
	url = {http://www.scopus.com/inward/record.url?scp=0001052432&partnerID=8YFLogxK},
	doi = {10.1037/0894-4105.7.4.476},
	abstract = {Evidence is reviewed to suggest that parietotemporal regions of the right hemisphere not only are specialized for the processing of emotional information but also play a critical role in the experience of emotion. In particular, it is argued that these regions of the right hemisphere constitute a system involved in modulating autonomic and behavioral arousal in emotional states. This system is characterized by a set of cognitive and attentional qualities that make it uniquely suited to respond to environmental events in an adaptive fashion. The current proposal is an elaboration of a model of emotion and brain organization (Heller, 1990) that incorporates several aspects of emotional function: (a) perception and production of emotional information, (b) mood and emotional experience, and (c) autonomic arousal. In the context of this model, it is suggested that the right-hemisphere system operates in conjunction with a system localized to the frontal lobes that is involved in modulating the emotional valence of experience. The interaction of these two systems is hypothesized to be conditioned by individual differences and developmental tendencies that contribute to the production of a unique and stable pattern of personality traits and emotional characteristics.},
	pages = {476--489},
	number = {4},
	journaltitle = {Neuropsychology},
	author = {Heller, Wendy},
	urldate = {2021-09-17},
	date = {1993-10},
	note = {19},
}

@article{dawson_frontal_1994,
	title = {Frontal electroencephalographic correlates of individual differences in emotion expression in infants: a brain systems perspective on emotion},
	volume = {59},
	issn = {0037-976X},
	shorttitle = {Frontal electroencephalographic correlates of individual differences in emotion expression in infants},
	abstract = {Emotion expressions can be characterized by both the type of emotion displayed and the intensity with which the emotion is expressed. Individual differences in these two aspects of emotion appear to vary independently and may perhaps account for distinct dimensions of temperament, personality, and vulnerability to psychopathology. We reviewed several sets of data gathered in our laboratory that indicate that these two dimensions of emotion expression are associated with distinct and independent patterns of frontal {EEG} activity in infants. Specifically, whereas the type of emotion expression was found to be associated with asymmetries in frontal {EEG} activity, the intensity of emotion expression was found to be associated with generalized activation of both the right and the left frontal regions. Moreover, we reviewed and provided evidence that measures of asymmetrical frontal activity are better predictors of individual differences in the tendency to express certain emotions, such as distress and sadness, whereas measures of generalized frontal activity are better predictors of individual differences in emotional reactivity and emotion intensity. The neuroanatomical bases of emotion were discussed with special reference to the role of the frontal lobe in emotion regulation. It was hypothesized that the frontal activation asymmetries that have been found to accompany emotion expressions reflect specific regulation strategies. The left frontal region is specialized for regulation strategies involving action schemes that serve to maintain continuity and stability of the organism-environment relation and of ongoing motor schemes, such as those involved in language and the expression of happiness and interest. In contrast, the right frontal region appears to be specialized for regulation strategies that involve processing novel stimuli that disrupt ongoing activity, such as might occur during the expression of fear, disgust, and distress. Furthermore, it was proposed that individual differences in patterns of frontal {EEG} asymmetries during emotion may be related to socialization influences rather than solely innate factors. It was speculated that the pattern of generalized frontal lobe activation that accompanies the experience of intense emotions may reflect, in part, the relatively diffuse influence of subcortical structures on the cortex and may serve to increase the infant's general readiness to receive and respond to significant external stimuli.},
	pages = {135--151},
	number = {2},
	journaltitle = {Monographs of the Society for Research in Child Development},
	shortjournal = {Monogr Soc Res Child Dev},
	author = {Dawson, G.},
	date = {1994},
	note = {17 {PMID}: 7984157},
	keywords = {Affect, Anxiety, Separation, Electroencephalography, Emotions, Facial Expression, Frontal Lobe, Functional Laterality, Humans, Infant, Parietal Lobe},
}

@article{nicolas-alonso_brain_2012,
	title = {Brain Computer Interfaces, a Review},
	volume = {12},
	issn = {1424-8220},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3304110/},
	doi = {10.3390/s120201211},
	abstract = {A brain-computer interface ({BCI}) is a hardware and software communications system that permits cerebral activity alone to control computers or external devices. The immediate goal of {BCI} research is to provide communications capabilities to severely disabled people who are totally paralyzed or âlocked inâ by neurological neuromuscular disorders, such as amyotrophic lateral sclerosis, brain stem stroke, or spinal cord injury. Here, we review the state-of-the-art of {BCIs}, looking at the different steps that form a standard {BCI}: signal acquisition, preprocessing or signal enhancement, feature extraction, classification and the control interface. We discuss their advantages, drawbacks, and latest advances, and we survey the numerous technologies reported in the scientific literature to design each step of a {BCI}. First, the review examines the neuroimaging modalities used in the signal acquisition step, each of which monitors a different functional brain activity such as electrical, magnetic or metabolic activity. Second, the review discusses different electrophysiological control signals that determine user intentions, which can be detected in brain activity. Third, the review includes some techniques used in the signal enhancement step to deal with the artifacts in the control signals and improve the performance. Fourth, the review studies some mathematic algorithms used in the feature extraction and classification steps which translate the information in the control signals into commands that operate a computer or other device. Finally, the review provides an overview of various {BCI} applications that control a range of devices.},
	pages = {1211--1279},
	number = {2},
	journaltitle = {Sensors (Basel, Switzerland)},
	shortjournal = {Sensors (Basel)},
	author = {Nicolas-Alonso, Luis Fernando and Gomez-Gil, Jaime},
	urldate = {2021-09-17},
	date = {2012-01-31},
	note = {11},
	file = {PubMed Central Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\XXEZ4GSV\\Nicolas-Alonso and Gomez-Gil - 2012 - Brain Computer Interfaces, a Review.pdf:application/pdf},
}

@article{davidson_anterior_1992,
	title = {Anterior cerebral asymmetry and the nature of emotion},
	volume = {20},
	issn = {0278-2626},
	doi = {10.1016/0278-2626(92)90065-t},
	abstract = {This article presents an overview of the author's recent electrophysiological studies of anterior cerebral asymmetries related to emotion and affective style. A theoretical account is provided of the role of the two hemispheres in emotional processing. This account assigns a major role in approach- and withdrawal-related behavior to the left and right frontal and anterior temporal regions of two hemispheres, respectively. Individual differences in approach- and withdrawal-related emotional reactivity and temperament are associated with stable differences in baseline measures of activation asymmetry in these anterior regions. Phasic state changes in emotion result in shifts in anterior activation asymmetry which are superimposed upon these stable baseline differences. Future directions for research in this area are discussed.},
	pages = {125--151},
	number = {1},
	journaltitle = {Brain and Cognition},
	shortjournal = {Brain Cogn},
	author = {Davidson, R. J.},
	date = {1992-09},
	note = {16 {PMID}: 1389117},
	keywords = {Adult, Brain, Cerebral Cortex, Child, Child Development, Child, Preschool, Depressive Disorder, Electroencephalography, Emotions, Female, Functional Laterality, Humans, Individuality, Infant, Infant, Newborn, Male, Models, Neurological, Research Design},
}

@article{chang_experiencing_2015,
	title = {Experiencing affective music in eyes-closed and eyes-open states: an electroencephalography study},
	volume = {6},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2015.01160},
	doi = {10.3389/fpsyg.2015.01160},
	shorttitle = {Experiencing affective music in eyes-closed and eyes-open states},
	abstract = {In real life, listening to music may be associated with an eyes-closed or eyes-open state. The effect of eye state on listenersâ reaction to music has attracted some attention, but its influence on brain activity has not been fully investigated. The present study aimed to evaluate the electroencephalographic ({EEG}) markers for the emotional valence of music in different eye states. Thirty participants listened to musical excerpts with different emotional content in the eyes-closed and eyes-open states. The results showed that participants rated the music as more pleasant or with more positive valence under an eyes-open state. In addition, we found that the alpha asymmetry indices calculated on the parietal and temporal sites reflected emotion valence in the eyes-closed and eyes-open states, respectively. The theta power in the frontal area significantly increased while listening to emotional-positive music compared to emotional-negative music under the eyes-closed condition. These effects of eye states on {EEG} markers are discussed in terms of brain mechanisms underlying attention and emotion.},
	pages = {1160},
	journaltitle = {Frontiers in Psychology},
	author = {Chang, Yun-Hsuan and Lee, You-Yun and Liang, Keng-Chen and Chen, I-Ping and Tsai, Chen-Gia and Hsieh, Shulan},
	urldate = {2021-10-06},
	date = {2015},
	note = {42},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\482BF6GM\\Chang et al. - 2015 - Experiencing affective music in eyes-closed and ey.pdf:application/pdf},
}

@article{barry_eeg_2007,
	title = {{EEG} differences between eyes-closed and eyes-open resting conditions},
	volume = {118},
	issn = {1388-2457},
	doi = {10.1016/j.clinph.2007.07.028},
	abstract = {{OBJECTIVE}: Recent work has attempted to clarify the energetics of physiological responding and behaviour by refining and separating the operational definitions of "arousal" and "activation", which have different effects on physiological responding and behaviour. At the {EEG} level, we relate the former to widespread activity, and the latter to task-specific topographically-focussed activity reflecting regional processing. This study aimed to investigate this further in terms of differences in {EEG} activity between eyes-closed and eyes-open resting conditions.
{METHODS}: {EEG} activity was recorded from 28 university students during both eyes-closed and eyes-open resting conditions, Fourier transformed to provide estimates for absolute power in the delta, theta, alpha and beta bands, and analysed in 9 regions across the scalp. Skin conductance level was also measured as an indicator of arousal level.
{RESULTS}: Across the eyes-closed conditions, skin conductance levels were negatively correlated with mean alpha levels. Skin conductance levels increased significantly from eyes-closed to eyes-open conditions. Reductions were found in across-scalp mean absolute delta, theta, alpha and beta from the eyes-closed to eyes-open condition. Topographic changes were also evident in all bands except for alpha, with reduced lateral frontal delta and posterior theta, and decreased posterior/increased frontal beta in the eyes-open condition. In particular, the topographic beta effects indicate that the across-scalp reduction arose from focal reductions rather than global changes.
{CONCLUSIONS}: The obtained results confirm the use of mean alpha level as a measure of resting-state arousal under eyes-closed and eyes-open conditions. The focal nature of {EEG} effects in the other bands suggests that these reflect cortical processing of visual input, producing differences in activation between eyes-closed and eyes-open resting conditions, rather than just the simple increase in arousal level shown in alpha.
{SIGNIFICANCE}: This study demonstrates that the eyes-closed and eyes-open conditions provide {EEG} measures differing in topography as well as power levels. These differences should be recognised when evaluating {EEG} research, and considered when choosing eyes-open or eyes-closed baseline conditions for different paradigms.},
	pages = {2765--2773},
	number = {12},
	journaltitle = {Clinical Neurophysiology: Official Journal of the International Federation of Clinical Neurophysiology},
	shortjournal = {Clin Neurophysiol},
	author = {Barry, Robert J. and Clarke, Adam R. and Johnstone, Stuart J. and Magee, Christopher A. and Rushby, Jacqueline A.},
	date = {2007-12},
	note = {41 {PMID}: 17911042},
	keywords = {Adolescent, Adult, Arousal, Attention, Brain Mapping, Cerebral Cortex, Electroencephalography, Evoked Potentials, Female, Fourier Analysis, Humans, Male, Middle Aged, Nerve Net, Photic Stimulation, Visual Perception, Wakefulness},
}

@article{picard_affective_2003,
	title = {Affective computing: challenges},
	volume = {59},
	issn = {10715819},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581903000521},
	doi = {10.1016/S1071-5819(03)00052-1},
	shorttitle = {Affective computing},
	pages = {55--64},
	number = {1},
	journaltitle = {International Journal of Human-Computer Studies},
	shortjournal = {International Journal of Human-Computer Studies},
	author = {Picard, Rosalind W.},
	urldate = {2021-10-14},
	date = {2003-07},
	langid = {english},
	note = {10},
	file = {Picard - 2003 - Affective computing challenges.pdf:C\:\\Users\\miche\\Zotero\\storage\\39WEMFYV\\Picard - 2003 - Affective computing challenges.pdf:application/pdf},
}

@inproceedings{thammasan_multimodal_2017,
	title = {Multimodal stability-sensitive emotion recognition based on brainwave and physiological signals},
	doi = {10.1109/ACIIW.2017.8272584},
	abstract = {This paper presents a framework for adaptive multimodal emotion recognition based on signal stability as a context. To verify the efficacy of the method, experiments were conducted using a dataset of brainwave and physiological signals ({EEG}, {ECG}, {GSR}) captured from nine subjects listening to music. The proposed method uses a combination of signal-based features as well as accelerometer data to quantify the approximate reliability of each modality. In contrast to existing approaches, unstable modalities are not rejected outright, instead their relative contribution is dynamically adapted based on a corresponding stability index. In the case of {EEG}, the stability index was calculated using an artifact rejection technique, while for the {ECG} and {GSR} modalities it was calculated based on body movement detected through accelerometers. The experimental results show that temporally varying the relative contribution of each modality can improve emotion recognition performance.},
	eventtitle = {2017 Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos ({ACIIW})},
	pages = {44--49},
	booktitle = {2017 Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos ({ACIIW})},
	author = {Thammasan, Nattapong and Hagad, Juan Lorenzo and Fukui, Ken-ichi and Numao, Masayuki},
	date = {2017-10},
	note = {32},
	keywords = {Accelerometers, Electrocardiography, Electroencephalography, Emotion recognition, Feature extraction, Music},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\UU58KKI9\\8272584.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\HYQEP8KX\\Thammasan et al. - 2017 - Multimodal stability-sensitive emotion recognition.pdf:application/pdf},
}

@article{chicco_advantages_2020,
	title = {The advantages of the Matthews correlation coefficient ({MCC}) over F1 score and accuracy in binary classification evaluation},
	volume = {21},
	issn = {1471-2164},
	doi = {10.1186/s12864-019-6413-7},
	abstract = {{BACKGROUND}: To evaluate binary classifications and their confusion matrices, scientific researchers can employ several statistical rates, accordingly to the goal of the experiment they are investigating. Despite being a crucial issue in machine learning, no widespread consensus has been reached on a unified elective chosen measure yet. Accuracy and F1 score computed on confusion matrices have been (and still are) among the most popular adopted metrics in binary classification tasks. However, these statistical measures can dangerously show overoptimistic inflated results, especially on imbalanced datasets.
{RESULTS}: The Matthews correlation coefficient ({MCC}), instead, is a more reliable statistical rate which produces a high score only if the prediction obtained good results in all of the four confusion matrix categories (true positives, false negatives, true negatives, and false positives), proportionally both to the size of positive elements and the size of negative elements in the dataset.
{CONCLUSIONS}: In this article, we show how {MCC} produces a more informative and truthful score in evaluating binary classifications than accuracy and F1 score, by first explaining the mathematical properties, and then the asset of {MCC} in six synthetic use cases and in a real genomics scenario. We believe that the Matthews correlation coefficient should be preferred to accuracy and F1 score in evaluating binary classification tasks by all scientific communities.},
	pages = {6},
	number = {1},
	journaltitle = {{BMC} genomics},
	shortjournal = {{BMC} Genomics},
	author = {Chicco, Davide and Jurman, Giuseppe},
	date = {2020-01-02},
	pmcid = {PMC6941312},
	note = {46 {PMID}: 31898477},
	keywords = {Accuracy, Algorithms, Binary classification, Biostatistics, Computational Biology, Confusion matrices, Correlation of Data, Data Interpretation, Statistical, Dataset imbalance, F1 score, Genomics, Machine learning, Machine Learning, Matthews correlation coefficient},
	file = {Full Text:C\:\\Users\\miche\\Zotero\\storage\\C6GMMMKH\\Chicco and Jurman - 2020 - The advantages of the Matthews correlation coeffic.pdf:application/pdf},
}

@article{matthews_comparison_1975,
	title = {Comparison of the predicted and observed secondary structure of T4 phage lysozyme},
	volume = {405},
	issn = {0006-3002},
	doi = {10.1016/0005-2795(75)90109-9},
	abstract = {Predictions of the secondary structure of T4 phage lysozyme, made by a number of investigators on the basis of the amino acid sequence, are compared with the structure of the protein determined experimentally by X-ray crystallography. Within the amino terminal half of the molecule the locations of helices predicted by a number of methods agree moderately well with the observed structure, however within the carboxyl half of the molecule the overall agreement is poor. For eleven different helix predictions, the coefficients giving the correlation between prediction and observation range from 0.14 to 0.42. The accuracy of the predictions for both beta-sheet regions and for turns are generally lower than for the helices, and in a number of instances the agreement between prediction and observation is no better than would be expected for a random selection of residues. The structural predictions for T4 phage lysozyme are much less successful than was the case for adenylate kinase (Schulz et al. (1974) Nature 250, 140-142). No one method of prediction is clearly superior to all others, and although empirical predictions based on larger numbers of known protein structure tend to be more accurate than those based on a limited sample, the improvement in accuracy is not dramatic, suggesting that the accuracy of current empirical predictive methods will not be substantially increased simply by the inclusion of more data from additional protein structure determinations.},
	pages = {442--451},
	number = {2},
	journaltitle = {Biochimica Et Biophysica Acta},
	shortjournal = {Biochim Biophys Acta},
	author = {Matthews, B. W.},
	date = {1975-10-20},
	note = {45 {PMID}: 1180967},
	keywords = {Adenylate Kinase, Coliphages, {DNA} Viruses, Mathematics, Muramidase, Protein Conformation, X-Ray Diffraction},
}

@article{bigdely-shamlo_prep_2015,
	title = {The {PREP} pipeline: standardized preprocessing for large-scale {EEG} analysis},
	volume = {9},
	issn = {1662-5196},
	url = {https://www.frontiersin.org/article/10.3389/fninf.2015.00016},
	doi = {10.3389/fninf.2015.00016},
	shorttitle = {The {PREP} pipeline},
	abstract = {The technology to collect brain imaging and physiological measures has become portable and ubiquitous, opening the possibility of large-scale analysis of real-world human imaging. By its nature, such data is large and complex, making automated processing essential. This paper shows how lack of attention to the very early stages of an {EEG} preprocessing pipeline can reduce the signal-to-noise ratio and introduce unwanted artifacts into the data, particularly for computations done in single precision. We demonstrate that ordinary average referencing improves the signal-to-noise ratio, but that noisy channels can contaminate the results. We also show that identification of noisy channels depends on the reference and examine the complex interaction of filtering, noisy channel identification, and referencing. We introduce a multi-stage robust referencing scheme to deal with the noisy channel-reference interaction. We propose a standardized early-stage {EEG} processing pipeline ({PREP}) and discuss the application of the pipeline to more than 600 {EEG} datasets. The pipeline includes an automatically generated report for each dataset processed. Users can download the {PREP} pipeline as a freely available {MATLAB} library from http://eegstudy.org/prepcode.},
	pages = {16},
	journaltitle = {Frontiers in Neuroinformatics},
	author = {Bigdely-Shamlo, Nima and Mullen, Tim and Kothe, Christian and Su, Kyung-Min and Robbins, Kay A.},
	urldate = {2021-11-12},
	date = {2015},
	note = {33},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\9GDEKQ8E\\Bigdely-Shamlo et al. - 2015 - The PREP pipeline standardized preprocessing for .pdf:application/pdf},
}

@incollection{lin_toward_2015,
	title = {Toward Affective Brain-Computer Interface: Fundamentals and Analysis of {EEG}-Based Emotion Classification},
	isbn = {978-1-118-13066-7},
	shorttitle = {Toward Affective Brain-Computer Interface},
	abstract = {Emotion classification from non-invasively measured electroencephalographic ({EEG}) data has been a growing research topic because of its potential application to affective brainâcomputer interfaces ({ABCI}), such as brain-inspired multimedia interaction and clinical assessment. This chapter explores principles for translating neuroscientific findings into a practical {ABCI}. It covers not only an overview of state-of-the-art {EEG}-based emotion recognition techniques, but also the basic research exploring neurophysiological {EEG} dynamics associated with affective responses. The chapter aims at resolving {EEG} feature selection and electrode reduction issues by the generalization of subject-independent feature/electrode set extraction techniques that we have proposed in our series of emotion classification studies. It addresses several practical issues and potential challenges for {ABCIs} as well. The authors believe a user-friendly {EEG} cap with a small number of electrodes can efficiently detect affective states, and therefore significantly promote practical {ABCI} applications in daily life.},
	pages = {315--341},
	author = {Lin, Yuan-Pin and Jung, Tzyy-Ping and Onton, Julie},
	date = {2015-01-02},
	note = {48 {DOI}: 10.1002/9781118910566.ch13},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\IJDD693B\\Lin et al. - 2015 - Toward Affective Brain-Computer Interface Fundame.pdf:application/pdf},
}

@article{zhao_frontal_2018,
	title = {Frontal {EEG} Asymmetry and Middle Line Power Difference in Discrete Emotions},
	volume = {12},
	issn = {1662-5153},
	url = {https://www.frontiersin.org/article/10.3389/fnbeh.2018.00225},
	doi = {10.3389/fnbeh.2018.00225},
	abstract = {A traditional model of emotion cannot explain the differences in brain activities between two discrete emotions that are similar in the valence-arousal coordinate space. The current study elicited two positive emotions (amusement and tenderness) and two negative emotions (anger and fear) that are similar in both valence and arousal dimensions to examine the differences in brain activities in these emotional states. Frontal electroencephalographic ({EEG}) asymmetry and midline power in three bands (theta, alpha and beta) were measured when participants watched affective film excerpts. Significant differences were detected between tenderness and amusement on {FP}1/{FP}2 theta asymmetry, F3/F4 theta and alpha asymmetry. Significant differences between anger and fear on {FP}1/{FP}2 theta asymmetry and F3/F4 alpha asymmetry were also observed. For midline power, midline theta power could distinguish two negative emotions, while midline alpha and beta power could effectively differentiate two positive emotions. Liking and dominance were also related to {EEG} features. Stepwise multiple linear regression results revealed that frontal alpha and theta asymmetry could predict the subjective feelings of two positive and two negative emotions in different patterns. The binary classification accuracy, which used {EEG} frontal asymmetry and midline power as features and support vector machine ({SVM}) as classifiers, was as high as 64.52\% for tenderness and amusement and 78.79\% for anger and fear. The classification accuracy was improved after adding these features to other features extracted across the scalp. These findings indicate that frontal {EEG} asymmetry and midline power might have the potential to recognize discrete emotions that are similar in the valence-arousal coordinate space.},
	pages = {225},
	journaltitle = {Frontiers in Behavioral Neuroscience},
	author = {Zhao, Guozhen and Zhang, Yulin and Ge, Yan},
	urldate = {2021-11-23},
	date = {2018},
	note = {22},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\XDSDGJFI\\Zhao et al. - 2018 - Frontal EEG Asymmetry and Middle Line Power Differ.pdf:application/pdf},
}

@article{krauledat_towards_2008,
	title = {Towards zero training for brain-computer interfacing},
	volume = {3},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0002967},
	abstract = {Electroencephalogram ({EEG}) signals are highly subject-specific and vary considerably even between recording sessions of the same user within the same experimental paradigm. This challenges a stable operation of Brain-Computer Interface ({BCI}) systems. The classical approach is to train users by neurofeedback to produce fixed stereotypical patterns of brain activity. In the machine learning approach, a widely adapted method for dealing with those variances is to record a so called calibration measurement on the beginning of each session in order to optimize spatial filters and classifiers specifically for each subject and each day. This adaptation of the system to the individual brain signature of each user relieves from the need of extensive user training. In this paper we suggest a new method that overcomes the requirement of these time-consuming calibration recordings for long-term {BCI} users. The method takes advantage of knowledge collected in previous sessions: By a novel technique, prototypical spatial filters are determined which have better generalization properties compared to single-session filters. In particular, they can be used in follow-up sessions without the need to recalibrate the system. This way the calibration periods can be dramatically shortened or even completely omitted for these 'experienced' {BCI} users. The feasibility of our novel approach is demonstrated with a series of online {BCI} experiments. Although performed without any calibration measurement at all, no loss of classification performance was observed.},
	pages = {e2967},
	number = {8},
	journaltitle = {{PloS} One},
	shortjournal = {{PLoS} One},
	author = {Krauledat, Matthias and Tangermann, Michael and Blankertz, Benjamin and MÃ¼ller, Klaus-Robert},
	date = {2008-08-13},
	pmcid = {PMC2500157},
	note = {51 {PMID}: 18698427},
	keywords = {Artificial Intelligence, Brain, Brain Mapping, Cortical Synchronization, Electroencephalography, Evoked Potentials, Humans, Learning, Neurophysiology, Pattern Recognition, Automated, User-Computer Interface, Wakefulness},
	file = {Full Text:C\:\\Users\\miche\\Zotero\\storage\\PEK9IQEF\\Krauledat et al. - 2008 - Towards zero training for brain-computer interfaci.pdf:application/pdf},
}

@inproceedings{jeong_hybrid_2021,
	title = {Hybrid Zero-Training {BCI} based on Convolutional Neural Network for Lower-limb Motor-Imagery},
	doi = {10.1109/BCI51272.2021.9385316},
	abstract = {Zero-training {BCI} was presented to overcome the inconvenience and impractical aspects of the training session in the Brain-Computer Interface ({BCI}) based on Motor Imagery ({MI}). Zero-training {BCI} can be classified into a session-to-session transfer {BCI} and a subject-independent {BCI}. The session-to-session transfer {BCI} is characterized by high classification accuracy, but there is a limitation that the model could not be improved as the number of subjects increased. On the other hand, the subject-independent {BCI} has advantage in increasing the number of subjects, but had the problem of requiring too many subjects for high accuracy. In this study, we proposed the hybrid zero-training {BCI} that integrates the advantages of the aforementioned two methods and Multidomain {CNN} that combined time-, spatial-, and phase-domain, and aimed for more practical application and higher classification accuracy. We collected three-class {MI} {EEG} data related to lower-limb movement (gait, sit-down, and rest) from three subjects with three sessions per subject. The classification accuracy of the proposed method (82.10 Â±10.66\%) in the classification of three-class of {MI} tasks was significantly higher than that of the existing zero-training {BCIs} (66.42 Â±9.68\%, 66.67Â±6.83\%) I, and also higher than the conventional {BCI} (70.86Â±9.46\%) that trains and evaluates with training sessions collected on the same day although not statistically significant.},
	eventtitle = {2021 9th International Winter Conference on Brain-Computer Interface ({BCI})},
	pages = {1--4},
	booktitle = {2021 9th International Winter Conference on Brain-Computer Interface ({BCI})},
	author = {Jeong, Ji Hyeok and Kim, Dong-Joo and Kim, Hyungmin},
	date = {2021-02},
	note = {52 {ISSN}: 2572-7672},
	keywords = {Biological neural networks, Brain modeling, Brain-Computer interface, Brain-computer interfaces, Convolutional neural network, Convolutional neural networks, {EEG}, Electroencephalography, Motor imagery, Task analysis, Training, Zero-training},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\miche\\Zotero\\storage\\QJPSB7X6\\9385316.html:text/html},
}

@online{noauthor_gartners_nodate,
	title = {Gartner's 2016 Hype Cycle for Emerging Technologies Identifies Three Key Trends That Organizations Must Track to Gain Competitive Advantage},
	url = {https://www.gartner.com/en/newsroom/press-releases/2016-08-16-gartners-2016-hype-cycle-for-emerging-technologies-identifies-three-key-trends-that-organizations-must-track-to-gain-competitive-advantage},
	abstract = {The technologies on Gartner Inc.'s Hype Cycle for Emerging Technologies, 2016 reveal three distinct technology trends that are poised to be of the highest priority for organizations facing rapidly accelerating digital business innovation.},
	titleaddon = {Gartner},
	urldate = {2021-11-29},
	langid = {english},
	note = {01},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\WGD9TTI6\\2016-08-16-gartners-2016-hype-cycle-for-emerging-technologies-identifies-three-key-trends-that-.html:text/html},
}

@online{statt_facebook_2019,
	title = {Facebook acquires neural interface startup {CTRL}-Labs for its mind-reading wristband},
	url = {https://www.theverge.com/2019/9/23/20881032/facebook-ctrl-labs-acquisition-neural-interface-armband-ar-vr-deal},
	abstract = {The deal is reportedly worth between \$500 million and \$1 billion},
	titleaddon = {The Verge},
	author = {Statt, Nick},
	urldate = {2021-11-29},
	date = {2019-09-23},
	langid = {english},
	note = {04},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\E86WPB5F\\facebook-ctrl-labs-acquisition-neural-interface-armband-ar-vr-deal.html:text/html},
}

@online{parfenov_brainflow_nodate,
	title = {{BrainFlow} 4.6.0},
	url = {https://brainflow.org/2021-08-17-enophone/},
	abstract = {{BrainFlow} is the {SDK} for Enophone},
	author = {Parfenov, Andrey},
	urldate = {2021-11-29},
	langid = {english},
	note = {02},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\SNRQTTD6\\2021-08-17-enophone.html:text/html},
}

@online{parfenov_openbci_nodate,
	title = {{OpenBCI} Galea with {BrainFlow}},
	url = {https://brainflow.org/2021-01-26-galea-brainflow/},
	abstract = {{OpenBCI} Galea device developed in collaboration with Valve corporation will use {BrainFlow} {SDK}},
	author = {Parfenov, Andrey},
	urldate = {2021-11-29},
	langid = {english},
	note = {03},
}

@inproceedings{soleymani_bayesian_2009,
	location = {Amsterdam, Netherlands},
	title = {A Bayesian framework for video affective representation},
	isbn = {978-1-4244-4800-5},
	url = {http://ieeexplore.ieee.org/document/5349563/},
	doi = {10.1109/ACII.2009.5349563},
	abstract = {Emotions that are elicited in response to a video scene contain valuable information for multimedia tagging and indexing. The novelty of this paper is to introduce a Bayesian classification framework for affective video tagging that allows taking contextual information into account. A set of 21 full length movies was first {segmentedFirasntdAuintfhoormr} ative content-based features were {extracteIdnsfrtiotmuteioacnh}1shot and scene. Shots were then {emotIinosntailtluytiaonnn}1otaadteddr,espsroviding ground truth affect. Thefairrosutsaaluotfhsohro@tis 1w.aosrcgomputed using a linear regression on the content-based features. Bayesian classification based on the shots arousal and content-based features allowed tagging these scenes into three affective classes, namely calm, positive excited and negative excited. To improve classification accuracy, two contextual priors have been proposed: the movie genre prior, and the temporal dimension prior consisting of the probability of transition between emotions in consecutive scenes. The f1 classification measure of 54.9\% that was obtained on three emotional classes with a naÃ¯ve Bayes classifier was improved to 63.4\% after utilizing all the priors.},
	eventtitle = {2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops ({ACII} 2009)},
	pages = {1--7},
	booktitle = {2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops},
	publisher = {{IEEE}},
	author = {Soleymani, Mohammad and Kierkels, Joep J.M. and Chanel, Guillaume and Pun, Thierry},
	urldate = {2021-12-02},
	date = {2009-09},
	langid = {english},
	note = {30},
	file = {Soleymani et al. - 2009 - A Bayesian framework for video affective represent.pdf:C\:\\Users\\miche\\Zotero\\storage\\EYIMP5I8\\Soleymani et al. - 2009 - A Bayesian framework for video affective represent.pdf:application/pdf},
}

@book{cowie_feeltrace_2000,
	title = {'{FEELTRACE}': An instrument for recording perceived emotion in real time},
	shorttitle = {'{FEELTRACE}'},
	abstract = {{FEELTRACE} is an instrument developed to let observers track the emotional content of a stimulus as they perceive it over time, allowing the emotional dynamics of speech episodes to be examined. It is based on activation-evaluation space, a representation derived from psychology. The activation dimension measures how dynamic the emotional state is; the evaluation dimension is a global measure of the positive or negative feeling associated with the state. Research suggests that the space is naturally circular, i.e. states which are at the limit of emotional intensity define a circle, with alert neutrality at the centre. To turn those ideas into a recording tool, the space was represented by a circle on a computer screen, and observers described perceived emotional state by moving a pointer (in the form of a disc) to the appropriate point in the circle, using a mouse. Prototypes were tested, and in the light of results, refinements were made to ensure that outputs were as consistent and meaningful as possible. They include colour coding the pointer in a way that users readily associate with the relevant emotional state; presenting key emotion words as 'landmarks' at the strategic points in the space; and developing an induction procedure to introduce observers to the system. An experiment assessed the reliability of the developed system. Stimuli were 16 clips from {TV} programs, two showing relatively strong emotions in each quadrant of activation- evaluation space, each paired with one of the same person in a relatively neural state. 24 raters took part. Differences between clips chosen to contrast were statistically robust. Results were plotted in activation-evaluation space as ellipses, each with its centre at the mean co-ordinates for the clip, and its width proportional to standard deviation across raters. The size of the ellipses meant that about 25 could be fitted into the space, i.e. {FEELTRACE} has resolving power comparable to an emotion vocabulary of 20 non-overlapping words, with the advantage of allowing intermediate ratings, and above all, the ability to track impressions continuously.},
	author = {Cowie, Roddy and Douglas-Cowie, E. and Savvidou, Suzie and {McMahon}, E. and Sawey, M. and Schr\{{\textbackslash}textbackslash\}"oder, M.},
	date = {2000-01-01},
	note = {35 Journal Abbreviation: Proceedings of the {ISCA} Workshop on Speech and Emotion
Publication Title: Proceedings of the {ISCA} Workshop on Speech and Emotion},
	file = {Full Text PDF:C\:\\Users\\miche\\Zotero\\storage\\NM3AGVMZ\\Cowie et al. - 2000 - 'FEELTRACE' An instrument for recording perceived.pdf:application/pdf},
}

@online{martin_stacked_nodate,
	title = {Stacked Turtles},
	url = {https://kiwidamien.github.io},
	abstract = {View the blog.},
	titleaddon = {Stacked Turtles},
	author = {Martin, Damien},
	urldate = {2021-12-02},
	langid = {english},
	note = {47},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\KMPZFPC5\\custom-loss-vs-custom-scoring.html:text/html},
}

@online{noauthor_please_nodate,
	title = {Please Support Customize Loss Function in {SGDClassifier}/Regressor Â· Issue \#1701 Â· scikit-learn/scikit-learn},
	url = {https://github.com/scikit-learn/scikit-learn/issues/1701},
	abstract = {Hi, I want to try on some customize loss function in my data, and find the {SGDClassifier} and {SGDRegressor} in sklearn. It\&\#39;s definitely a good framework to try my own loss function. I dig into th...},
	titleaddon = {{GitHub}},
	urldate = {2021-12-02},
	langid = {english},
	note = {49},
	file = {Snapshot:C\:\\Users\\miche\\Zotero\\storage\\AT45PWPQ\\1701.html:text/html},
}

@article{chang_evaluation_2018,
	title = {Evaluation of Artifact Subspace Reconstruction for Automatic {EEG} Artifact Removal},
	volume = {2018},
	issn = {2694-0604},
	doi = {10.1109/EMBC.2018.8512547},
	abstract = {One of the greatest challenges that hinder the decoding and application of electroencephalography ({EEG}) is that {EEG} recordings almost always contain artifacts - non-brain signals. Among existing automatic artifact-removal methods, artifact subspace reconstruction ({ASR}) is an online and realtime capable, component-based method that can effectively remove transient or large-amplitude artifacts. However, the effectiveness of {ASR} and the optimal choice of its parameter have not been evaluated and reported, especially on real {EEG} data. This study systematically validates {ASR} on ten {EEG} recordings in a simulated driving experiment. Independent component analysis ({ICA}) is applied to separate artifacts from brain signals to allow a quantitative assessment of {ASR}'s effectiveness in removing various types of artifacts and preserving brain activities. Empirical results show that the optimal {ASR} parameter is between 10 and 100, which is small enough to remove activities from artifacts and eye-related components and large enough to retain signals from brain-related components. With the appropriate choice of the parameter, {ASR} can be a powerful and automatic artifact removal approach for offline data analysis or online real-time {EEG} applications such as clinical monitoring and brain-computer interfaces.},
	pages = {1242--1245},
	journaltitle = {Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society. {IEEE} Engineering in Medicine and Biology Society. Annual International Conference},
	shortjournal = {Annu Int Conf {IEEE} Eng Med Biol Soc},
	author = {Chang, Chi-Yuan and Hsu, Sheng-Hsiou and Pion-Tonachini, Luca and Jung, Tzyy-Ping},
	date = {2018-07},
	note = {53 {PMID}: 30440615},
	keywords = {Algorithms, Artifacts, Brain, Brain-Computer Interfaces, Electroencephalography, Humans, Signal Processing, Computer-Assisted},
}

@article{barzegaran_eegsourcesim_2019,
	title = {{EEGSourceSim}: A framework for realistic simulation of {EEG} scalp data using {MRI}-based forward models and biologically plausible signals and noise},
	volume = {328},
	issn = {1872-678X},
	doi = {10.1016/j.jneumeth.2019.108377},
	shorttitle = {{EEGSourceSim}},
	abstract = {{BACKGROUND}: Electroencephalography ({EEG}) is widely used to investigate human brain function. Simulation studies are essential for assessing the validity of {EEG} analysis methods and the interpretability of results.
{NEW} {METHOD}: Here we present a simulation environment for generating {EEG} data by embedding biologically plausible signal and noise into {MRI}-based forward models that incorporate individual-subject variability in structure and function.
{RESULTS}: The package includes pipelines for the evaluation and validation of {EEG} analysis tools for source estimation, functional connectivity, and spatial filtering. {EEG} dynamics can be simulated using realistic noise and signal models with user specifiable signal-to-noise ratio ({SNR}). We also provide a set of quantitative metrics tailored to source estimation, connectivity and spatial filtering applications.
{COMPARISON} {WITH} {EXISTING} {METHOD}(S): We provide a larger set of forward solutions for individual {MRI}-based head models than has been available previously. These head models are surface-based and include two sets of regions-of-interest ({ROIs}) that have been brought into registration with the brain of each individual using surface-based alignment - one from a whole brain and the other from a visual cortex atlas. We derive a realistic model of noise by fitting different model components to measured resting state {EEG}. We also provide a set of quantitative metrics for evaluating source-localization, functional connectivity and spatial filtering methods.
{CONCLUSIONS}: The inclusion of a larger number of individual head-models, combined with surface-atlas based labeling of {ROIs} and plausible models of signal and noise, allows for simulation of {EEG} data with greater realism than previous packages.},
	pages = {108377},
	journaltitle = {Journal of Neuroscience Methods},
	shortjournal = {J Neurosci Methods},
	author = {Barzegaran, Elham and Bosse, Sebastian and Kohler, Peter J. and Norcia, Anthony M.},
	date = {2019-12-01},
	pmcid = {PMC6815881},
	note = {54 {PMID}: 31381946},
	keywords = {Adult, Atlases as Topic, Brain, Computer Simulation, Connectome, {EEG} simulation, Electroencephalography, Forward model, Functional connectivity, Humans, Inverse model, Magnetic Resonance Imaging, Models, Theoretical, Regions of interest, Scalp, Spatial filtering},
	file = {Accepted Version:C\:\\Users\\miche\\Zotero\\storage\\GHLLTZV4\\Barzegaran et al. - 2019 - EEGSourceSim A framework for realistic simulation.pdf:application/pdf},
}